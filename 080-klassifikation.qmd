

# Klassifikation von Hatespeech





## Vorab


### Lernziele


- Sie k√∂nnen grundlegende Verfahren zur Klassifikation von Hatespeech einsetzen und erkl√§ren








### Ben√∂tigte R-Pakete

```{r}
#| message: false
library(tidyverse)
library(easystats)
library(tidymodels)
library(tidytext)
library(textrecipes)  # Textanalysen in Tidymodels-Rezepten
library(lsa)  # stopwords
library(discrim)  # naive bayes classification
library(naivebayes)
library(tictoc)  # Zeitmessung
library(fastrtext)  # Worteinbettungen
library(remoji)  # Emojis
library(tokenizers)  # Vektoren tokenisieren
library(tictoc)  # Zeitmessung
```


## Daten


F√ºr Maschinenlernen brauchen wir Trainingsdaten,
Daten also, bei denen wir pro Beobachtung der Wert der Zielvariablen kennen.
Man spricht auch von "gelabelten" Daten.

Wir nutzen die Daten von @germeval bzw. @wiegand-data.
Die Daten sind unter CC-By-4.0 Int. lizensiert.

```{r import-heidelberg-data}
#| message: false
d_raw <- 
  data_read("data/germeval2018.training.txt",
         header = FALSE,
         quote = "")
```


Die Daten finden sich auch im Paket [pradadata](https://github.com/sebastiansauer/pradadata).

Da die Daten keine Spaltenk√∂pfe haben, informieren wir die Funktion dazu mit `header = FALSE`.

Benennen wir die die Spalten um:

```{r}
names(d_raw) <- c("text", "c1", "c2")
```

Dabei soll `c1` und `c2` f√ºr die 1. bzw. 2. Klassifikation stehen.


In `c1` finden sich diese Werte:

```{r}
d_raw %>% 
  count(c1)
```

Mit `c1` wurde klassifiziert,
ob beleidigende Sprache (offensive language) vorlag oder nicht [@risch-etal-2021-overview, S. 2], also `OFFENSE` bzw. `OTHER`:



>   Task 1 was to decide whether a tweet includes some form of offensive language or not. The tweets had to be classiÔ¨Åed into the two classes OFFENSE and OTHER. The OFFENSE category covered abusive language, insults, as well as merely profane statements.


Und in `c2` finden sich die vier Auspr√§gungen `ABUSE`, `INSULT`, `PROFANITY` und `OTHER`:

```{r}
d_raw %>% 
  count(c2)
```


In `c2` ging es um eine *feinere Klassifikation* beleidigender Sprache [@risch-etal-2021-overview, S. 2]:

>   The second task involved four categories, a nonoffensive OTHER class and three sub-categories of what is OFFENSE in Task 1. In the case of PROFANITY, profane words are used, however, the tweet does not want to insult anyone. This typically concerns the usage of swearwords (Schei√üe, Fuck etc.) and cursing (Zur H√∂lle! Verdammt! etc.). This can be often found in youth language. Swearwords and cursing may, but need not, co-occur with insults or abusive speech. Profane language may in fact be used in tweets with positive sentiment to express emphasis. Whenever profane words are not directed towards a speciÔ¨Åc person or group of persons and there are no separate cues of INSULT or ABUSE, then tweets are labeled as simple cases of PROFANITY.




Sind Texte, die als `OFFENSE` klassifiziert sind,
auch (fast) immer nie als `OTHER`, sondern stattdessen als `ABUSE`, `INSULT` oder `PROFANITY` klassifiziert?



```{r}
d_raw %>% 
  filter(c1 == "OFFENSE", c2 != "OTHER") %>% 
  nrow() / nrow(d_raw)
```


In ca. 2/3 der F√§lle wurden in beiden Klassifikation `OTHER` klassifiziert:


```{r}
d_raw %>% 
  filter(c1 == "OTHER", c2 == "OTHER") %>% 
  nrow() / nrow(d_raw)
```

```{r}
d_raw %>% 
  filter(c1 != "OTHER", c2 != "OTHER") %>% 
  nrow() / nrow(d_raw)
```

Entsprechend in ca. 1/3 der F√§lle wurde jeweils nicht mit `OTHER` klassifiziert.


Wir begn√ºgen uns hier mit der ersten, gr√∂beren Klassifikation.



F√ºgen wir abschlie√üend noch eine ID-Variable hinzu:

```{r}
d1 <-
  d_raw %>% 
  mutate(id = as.character(1:nrow(.)))
```


Die *ID-Variable* definieren als *Text* (nicht als Integer),
da die Twitter-IDs zwar nat√ºrliche Zahlen sind,
aber zu gro√ü, um von R als Integer verarbeitet zu werden.
Faktisch sind sie f√ºr uns auch nur nominal skalierte Variablen,
so dass wir keinen Informationsverlust haben.


```{r}
#| eval: false
#write_rds(d1, "objects/d1.rds")
```



## Feature Engineering


Reichern wir die Daten mit weiteren Features an,
in der Hoffnung, damit eine bessere Klassifikation erzielen zu k√∂nnen.


### Textl√§nge




```{r d2}
d2 <-
  d1 %>% 
  mutate(text_length = str_length(text))

head(d2)
```



### Sentimentanalyse

Wir nutzen dazu `SentiWS` [@Remus2010].

```{r read-sentiws}
sentiws <- read_csv("https://osf.io/x89wq/?action=download")
```




```{r d2-long}
d2_long <-
  d2 %>% 
  unnest_tokens(input = text, output = token)

head(d2_long)
```

Jetzt filtern wir unsere Textdaten so,
dass nur W√∂rter mit Sentimentwert √ºbrig bleiben:

```{r d2-senti-long}
d2_long_senti <- 
  d2_long %>%  
  inner_join(sentiws %>% select(-inflections), by = c("token" = "word"))

head(d2_long)
```


Schlie√ülich berechnen wir die Sentimentwert pro Polarit√§t und pro Tweet:

```{r d2-sentis}
d2_sentis <-
  d2_long_senti %>% 
  group_by(id, neg_pos) %>% 
  summarise(senti_avg = mean(value))

head(d2_sentis)
```


Diese Tabelle bringen wir wieder eine breitere Form,
um sie dann wieder mit den Hauptdaten zu vereinigen.


```{r d2-sentis-wide}
d2_sentis_wide <-
  d2_sentis %>% 
  pivot_wider(names_from = "neg_pos", values_from = "senti_avg")

d2_sentis_wide %>% head()
```


```{r d3}
d3 <-
  d2 %>% 
  full_join(d2_sentis_wide)

head(d3)
```


:::callout-note
Die Sentimentanalyse hier vernachl√§ssigt Flexionen der W√∂rter. 
Der  Autor f√ºhlt den Drang zu schreiben: "Left as an exercise for the reader" :-)
:::


### Schimpfw√∂rter


Z√§hlen wir die Schimpfw√∂rter pro Text.
Dazu nutzen wir die Daten von [LDNOOBW](https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/blob/master/LICENSE), lizensiert nach CC-BY-4.0-Int.




```{r schimpf1}
schimpf1 <- read_csv("https://raw.githubusercontent.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/master/de", col_names = FALSE)
```


L√§nger aber noch ist die Liste aus dem [InsultWiki](https://www.insult.wiki/schimpfwort-liste), lizensiert CC0.


```{r schimpf2}
schimpf2 <- 
  data_read("data/insult-de.txt", header = FALSE) %>% 
  mutate_all(str_to_lower)
```



Die Daten finden sich auch im Paket [pradadata](https://github.com/sebastiansauer/pradadata).

Binden wir die Listen zusammen:

```{r schimpf}
schimpf <-
  schimpf1 %>% 
  bind_rows(schimpf2) %>% 
  distinct() %>% 
  rename(word = "V1")

nrow(schimpf)
```


Um die Lesis vor (unn√∂tiger?) Kopfverschmutzung zu bewahren,
sind diese Schimpfw√∂rter hier nicht abgedruckt.

Jetzt z√§hlen wir, ob unsere Tweets/Texte solcherlei W√∂rter enthalten.


```{r d_schimpf}
d_schimpf <- 
d2_long %>% 
  select(id, token) %>% 
  mutate(schimpf = token %in% schimpf$word)
```


Wie viele Schimpfw√∂rter haben wir gefunden?

```{r}
d_schimpf %>% 
  count(schimpf)
```


Etwa ein Prozent der W√∂rter (ca. 1k) sind Schimpfw√∂rter in unserem Corpus.


```{r d-schimpf2}
d_schimpf2 <-
  d_schimpf %>% 
  group_by(id) %>% 
  summarise(schimpf_n = sum(schimpf))

head(d_schimpf2)
```


```{r d_main}
d_main <-
  d3 %>% 
  full_join(d_schimpf2)
```


:::callout-important
Namen wie `final`, `main` oder `result` sind gef√§hrlich,
da es unter Garantie ein "final-final geben wird, oder der "Haupt-Datensatz" pl√∂tzlich nicht mehr so wichtig erscheint und so weiter.
:::



### Emojis


```{r get-emoji-list}
emj <- emoji(list_emoji(), pad = FALSE)

head(emj)
```

Diese Liste umfasst knapp 900 Emojis, 
das sind allerdings noch nicht alle, die es gibt.
[Diese Liste](https://unicode.org/emoji/charts/full-emoji-list.html) umfasst mit gut 1800 Emojis
gut das Doppelte.


Selbstkuratierte Liste an "wilden" Emoji;
diese Liste ist inspiriert von [emojicombos.com](https://emojicombos.com/disgust).

```{r wild-emojis}
wild_emojis <- 
  c(
    emoji(find_emoji("gun")),
    emoji(find_emoji("bomb")),
    emoji(find_emoji("fist")),
    emoji(find_emoji("knife"))[1],
    emoji(find_emoji("ambulance")),
    emoji(find_emoji("fist")),
    emoji(find_emoji("skull")),
    "‚ò†Ô∏è",     "üóë",       "üò†",    "üëπ",    "üí©" ,
    "üñï",    "üëéÔ∏è",
    emoji(find_emoji("middle finger")),    "üò°",    "ü§¢",    "ü§Æ",  
    "üòñ",    "üò£",    "üò©",    "üò®",    "üòù",    "üò≥",    "üò¨",    "üò±",    "üòµ",
       "üò§",    "ü§¶‚Äç‚ôÄÔ∏è",    "ü§¶‚Äç"
  )
```


```{r}
wild_emojis_df <-
  tibble(emoji = wild_emojis)

#save(wild_emojis_df, file = "data/wild_emojis.RData")
```



Auf dieser Basis k√∂nnen wir einen Pr√§diktor erstellen,
der z√§hlt, ob ein Tweet einen oder mehrere der "wilden" Emojis enth√§lt.


## Workflow 1: Rezept 1 + Naive-Bayes


### Dummy-Rezept


Hier ist ein einfaches Beispiel,
um die Textvorbereitung mit `{textrecipes}` zu verdeutlichen.

Wir erstellen uns einen Dummy-Text:

```{r}
dummy <- 
  tibble(text = c("Ich gehe heim und der die das nicht in ein and the"))
```


Dann tokenisieren wir den Text:

```{r rec-dummy1}
rec_dummy <-
  recipe(text ~ 1, data = dummy) %>% 
  step_tokenize(text)
  
rec_dummy
```


Die Tokens kann man sich so zeigen lassen:

```{r}
show_tokens(rec_dummy, text)
```


Jetzt entfernen wir die Stopw√∂rter deutscher Sprache;
daf√ºr nutzen wir die Stopwort-Quelle `snowball`:


```{r rec-dummy2}
rec_dummy <-
  recipe(text ~ 1, data = dummy) %>% 
  step_tokenize(text) %>% 
  step_stopwords(text, language = "de", stopword_source = "snowball")

rec_dummy
```


Pr√ºfen wir die Tokens; 
sind die Stopw√∂rter wirklich entfernt?

```{r}
show_tokens(rec_dummy, text)
```


Ja, die deutschen Stopw√∂rter sind entfernt. Die englischen nicht;
das macht Sinn!


### Datenaufteilung


```{r d-split2}
d_split <- initial_split(d_main, strata = c1)

d_train <- training(d_split)
d_test <- testing(d_split)
```





### Rezept 1


Rezept definieren:

```{r rec1}
rec1 <- 
  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% 
  update_role(id, new_role = "id") %>% 
  step_tokenize(text) %>% 
  step_stopwords(text, language = "de", stopword_source = "snowball") %>% 
  step_stem(text) %>% 
  step_tokenfilter(text, max_tokens = 1e2) %>%  # wir behalten nur die h√§ufigsten Tokens
  step_tfidf(text) %>%  
  step_normalize(all_numeric_predictors())

rec1
```


Preppen:

```{r rec1-prepped}
rec1_prepped <- prep(rec1)
```

Und backen:

```{r rec1-baked}
d_rec1 <- bake(rec1_prepped, new_data = NULL)

head(d_rec1)
```



### Modellspezifikation 1

Wir definiere einen Naive-Bayes-Algorithmus:

```{r nb-spec}
nb_spec <- naive_Bayes() %>%
  set_mode("classification") %>%
  set_engine("naivebayes")

nb_spec
```



Und setzen auf die klassische zehnfache Kreuzvalidierung.


```{r folds1}
set.seed(42)
folds1 <- vfold_cv(d_train)
```



### Workflow 1


```{r wf1}
wf1 <-
  workflow() %>% 
  add_recipe(rec1) %>% 
  add_model(nb_spec)

wf1
```


### Fitting 1


```{r fit1}
#| eval: false
fit1 <-
  fit_resamples(
    wf1,
    folds1,
    control = control_resamples(save_pred = TRUE)
  )
```

Die Vorhersagen speichern wir ab,
um die Performanz in den Faltungen des Hold-out-Samples zu berechnen.


M√∂chte man sich die Zeit sparen, die Syntax wieder durchlaufen zu lassen,
kann man das Objekt speichern. 
Aber Vorsicht: Dabei kann es passieren, dass man mit veralteten Objekten arbeitet.



```{r write-fit1}
#| eval: false
#write_rds(fit1, "objects/chap_classific_fit1.rds")
```


```{r read-fit1}
#| echo: false
fit1 <- read_rds("objects/chap_classific_fit1.rds")
```



### Performanz 1

```{r wf1-perf}
#| eval: false
wf1_performance <-
  collect_metrics(fit1)

wf1_performance
```



```{r wf1-preds}
wf_preds <-
  collect_predictions(fit1)

wf_preds %>% 
  group_by(id) %>% 
  roc_curve(truth = c1, .pred_OFFENSE) %>% 
  autoplot()
```


conf_mat_resampled(fit1, tidy = FALSE) %>% 
  autoplot(type = "heatmap")
```{r}
conf_mat_resampled(fit1, tidy = FALSE) %>% 
  autoplot(type = "heatmap")
```




## Nullmodell


```{r nullmodel}
#| eval: false
null_classification <- 
  parsnip::null_model() %>%
  set_engine("parsnip") %>%
  set_mode("classification")

null_rs <- workflow() %>%
  add_recipe(rec1) %>%
  add_model(null_classification) %>%
  fit_resamples(
    folds1
  )
```


```{r}
#| eval: false
#| echo: false
#write_rds(null_rs, file = "/Users/sebastiansaueruser/github-repos/datascience-text/objects/chap_classific_fit_nullmodel.rds")
```


```{r}
#| echo: false
null_rs <- read_rds("/Users/sebastiansaueruser/github-repos/datascience-text/objects/chap_classific_fit3.rds")
```



Hier ist die Performanz des Nullmodells.

```{r}
#| eval: false
null_rs %>%
  collect_metrics()
```


```{r}
show_best(null_rs)
```




## Workflow 2: Rezept 1 + Lasso



```{r lasso-spec}
lasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

lasso_spec
```



Wir definieren die Auspr√§gungen von `penalty`, 
die wir ausprobieren wollen:


```{r lambda-grid}
lambda_grid <- grid_regular(penalty(), levels = 3)  # hier nur 3 Werte, um Rechenzeit zu sparen
```



```{r wf2}
wf2 <-
  workflow() %>% 
  add_recipe(rec1) %>% 
  add_model(lasso_spec)

wf2
```


Tunen und Fitten:

```{r fit2}
#| eval: false
set.seed(42)

fit2 <-
  tune_grid(
    wf2,
    folds1,
    grid = lambda_grid,
    control = control_resamples(save_pred = TRUE)
  )

fit2
```


Vorsicht beim Abspeichern.

```{r}
#| eval: false
#write_rds(fit2, "objects/chap_classific_fit2.rds")
```


```{r read-fit2}
#| echo: false
fit2 <- read_rds("objects/chap_classific_fit2.rds")
```



Hier ist die Performanz:

```{r}
#| eval: false
collect_metrics(fit2) %>% 
  filter(.metric == "roc_auc") %>% 
  slice_max(mean, n = 3)
```


```{r}
autoplot(fit2)
```



```{r}
fit2 %>% 
  show_best("roc_auc")
```



```{r chosen-auc-fit2}
chosen_auc <- 
  fit2 %>%
  select_by_one_std_err(metric = "roc_auc", -penalty)
```



Finalisieren:


```{r wf2-final}
wf2_final <-
  finalize_workflow(wf2, chosen_auc)

wf2_final
```



```{r fit2-final-train}
fit2_final_train <-
  fit(wf2_final, d_train)
```


```{r}
fit2_final_train %>% 
  extract_fit_parsnip() %>% 
  tidy() %>% 
  arrange(-abs(estimate)) %>% 
  head()
```



```{r fit2-final-test}
fit2_final_test <-
  last_fit(wf2_final, d_split)

collect_metrics(fit2_final_test)
```



### Vorhersage


### Vohersagedaten

Pfad zu den Daten:

```{r}
tweet_data_path <- "/Users/sebastiansaueruser/github-repos/hate-speech-data/data-raw/tweets/"
```


:::

```{r}
tweet_data_files_names <- list.files(path = tweet_data_path,
                                     pattern  = "tweets-to-.*\\.rds$")
head(tweet_data_files_names)
```


Wie viele Dateien sind es?

```{r}
length(tweet_data_files_names)
```


Wir geben den Elementen des Vektors g√§ngige Namen,
das hilft uns gleich bei `map`:


```{r}
names(tweet_data_files_names) <- 
  str_remove(tweet_data_files_names, "\\.rds$")  # Datei-Suffix entfernen 
```





OK, weiter: So k√∂nnen wir *eine* der Datendateien einlesen:

```{r read-tweets}
#| eval: false
d_raw <-
  read_rds(file = paste0(tweet_data_path, tweet_data_files_names[1])) 

d <- 
  d_raw %>% 
  select(id, author_id, created_at, public_metrics) %>% 
  unnest_wider(public_metrics)

head(d)
```


Und so lesen wir alle ein:


Zun√§chst erstellen wir uns eine Helper-Funktion:


```{r fun-read-and-select}
read_and_select <- function(file_name, path_to_tweet_data = tweet_data_path) {
  
  out <- 
    read_rds(file = paste0(path_to_tweet_data, file_name)) %>% 
    select(id, author_id, created_at, text, public_metrics) %>% 
    unnest_wider(public_metrics)
  
  cat("Data file was read.\n")
  
  return(out)
}
```

Testen:

```{r read-and-seelct-test}
#| eval: false
d1 <- read_and_select(tweet_data_files_names[1])

head(d1)
```



Die Funktion `read_and_select`  mappen wir auf alle Datendateien:


```{r map-read-and-select}
#| eval: false
tic()
ds <-
  tweet_data_files_names %>% 
  map_dfr(read_and_select, .id = "dataset")
toc()
```


`214.531 sec elapsed`

Da wir den Elementen von `tweet_data_files_names` Namen gegeben haben, 
finden wir diese Namen praktischerweise wieder in `ds`.


```{r}
#| echo: false
#| eval: false
#write_rds(ds, file = paste0(tweet_data_path, "ds.rds"))
```



```{r read-ds}
#| echo: false
#| eval: false
ds <- read_rds(file = "/Users/sebastiansaueruser/datasets/Twitter/hate-classific/ds.rds")  # 305 Mb
```




Vielleicht ist es zum Entwickeln besser,
mit einem kleineren Datensatz einstweilen zu arbeiten:

```{r ds-short}
ds_short <- read_rds(file = "/Users/sebastiansaueruser/github-repos/hate-speech-data/objects/ds_short.rds")  # 300kb

ds <- ds_short
```



```{r}
#| echo: false
#| eval: false
#write_rds(ds_short, "/Users/sebastiansaueruser/datasets/Twitter/hate-classific/ds_short.rds")
```




### Vokabular erstellen


```{r ds-long}
#| eval: false
ds_long <-
  ds %>% 
  select(text) %>% 
  unnest_tokens(input = text, output = word)
```

Puh, das hat gedauert!

Speichern wir uns diese Daten daher auf die Festplatte:

```{r}
#| eval: false
#write_rds(ds_long, file = paste0(tweet_data_path, "ds_long.rds"))
```

Entfernen wir daraus die Duplikate,
um uns ein Vokabular zu erstellen:

```{r ds-voc}
#| eval: false
ds_voc <-
  ds_long %>% 
  distinct(word)

head(ds_voc)
```

Insgesamt umfasst `nrow(ds_voc)` W√∂rter.

Und das resultierende Objekt speichern wir wieder ab:


```{r}
#| eval: false
#write_rds(ds_voc, file = paste0("objects/", "ds_voc.rds"))
```


```{r}
#| echo: false
#| eval: false
ds_voc <- read_rds("objects/ds_voc.rds")
```





## Worteinbettungen erstellen

>    üë®‚Äçüè´ Hey ChatGPT, beschreibe Das FastText-Modell f√ºr Worteinbettungen.

>    ü§ñ Ja, Moment...



### Was ist das FastText-Modell? {#sec-fasttext}

Das [FastText-Modell](https://fasttext.cc/) f√ºr Worteinbettungen (auch als Word Embeddings bezeichnet) ist ein NLP-Modell, das von Facebook AI Research entwickelt wurde. Es ist eine Erweiterung des klassischen Word2Vec-Modells und zielt darauf ab, Worte in Vektoren umzuwandeln, um semantische Informationen √ºber W√∂rter zu erfassen. Der Hauptunterschied zwischen FastText und Word2Vec besteht darin, wie sie Worte darstellen.

Hier sind einige wichtige Merkmale und Unterschiede des FastText-Modells:

Subword-Informationen: W√§hrend Word2Vec auf ganzen W√∂rtern basiert, behandelt FastText W√∂rter als eine Sammlung von Subw√∂rtern (n-Grammen). Diese Subw√∂rter sind buchst√§bliche Teile eines Wortes, die f√ºr die Analyse verwendet werden. Zum Beispiel, f√ºr das Wort "apple" k√∂nnte FastText die Subw√∂rter "ap," "app," "ppl," "ple" usw. ber√ºcksichtigen. Dies erm√∂glicht es dem Modell, semantische Informationen auf Buchstabenebene zu erfassen und seltene W√∂rter oder W√∂rter, die nicht im Trainingskorpus enthalten sind, besser zu behandeln.



Pre-trained Modelle: Es stehen vorab trainierte FastText-Modelle in vielen Sprachen zur Verf√ºgung. Diese vortrainierten Modelle k√∂nnen in verschiedenen NLP-Anwendungen verwendet werden, ohne von Grund auf neu trainiert werden zu m√ºssen.

Der Trainingsprozess f√ºr ein FastText-Modell umfasst das Lernen von Wortdarstellungen anhand gro√üer Textkorpora. Die resultierenden Wortvektoren k√∂nnen verwendet werden, um semantische Beziehungen zwischen W√∂rtern zu erkunden, √Ñhnlichkeiten zu berechnen oder als Eingabe f√ºr maschinelle Lernmodelle in verschiedenen nat√ºrlichsprachlichen Verarbeitungsaufgaben zu dienen. Insgesamt hat FastText aufgrund seiner F√§higkeit zur Ber√ºcksichtigung von Subw√∂rtern und seiner Effizienz bei der Verarbeitung gro√üer Vokabulare in der NLP-Gemeinschaft an Popularit√§t gewonnen.^[Der Text dieses Abschnitts wurde von ChatGPT 3.5 erstellt, 2023-10-29.]


### Ein Fast-Text-Modell trainieren


Definiere die Konstanten f√ºr das fastText-Modell:

```{r fastText-constants}
#| eval: false
texts <- ds %>% pull(text)
texts <- tolower(texts)
```


Wir k√∂nnen uns ein FastText-Modell f√ºr Worteinbettungen basierend auf unseren Daten berechnen lassen:


```{r fasttext-modell}
#| eval: false
#writeLines(text = texts, con = out_file_txt)
#execute(commands = c("skipgram", "-input", tmp_file_txt, "-output", out_file_model, "-verbose", 1))  # execute berechnet ein FastText-Mdlell
```

Im Standard werden 100 Dimensionen berechnet.

Hier ist schon ein vorab gespeichertes Modell, basierend auf den Twitter-Daten:

```{r fastText-filenames}
out_file_txt <- "/Users/sebastiansaueruser/datasets/Twitter/twitter-polit-model.vec"
out_file_model <- "/Users/sebastiansaueruser/datasets/Twitter/twitter-polit-model.bin"

file.exists(out_file_txt)
file.exists(out_file_model)
```



```
Read 22M words
Number of words:  130328
Number of labels: 0
Progress: 100.0% words/sec/thread:   49218 lr:  0.000000 avg.loss:  1.720812 ETA:   0h 0m 0s
```

Jetzt laden wir das Modell von der Festplatte:

```{r twitter-fasttext-model}
twitter_fasttext_model <- load_model(out_file_model)
dict <- get_dictionary(twitter_fasttext_model)
```

Das W√∂rterbuch umfasst `r length(dict)` (verschiedene) W√∂rter.


Schauen wir uns einige Begriffe aus dem Vokabular an:

```{r}
print(head(dict, 10))
```

Hier sind die ersten paar Elemente des Vektors f√ºr `menschen`:


```{r vector-menschen}
#| eval: false
vec1 <- get_word_vectors(twitter_fasttext_model, c("menschen"))
vec1[1:10]
```



```
 [1]  0.14156282  0.44875699  0.23911817 -0.02580349  0.29811972  0.03870077
 [7]  0.06518744  0.22527063  0.28198120  0.39931887
 ```


Erstellen wir uns einen Tibble, der 
als erste Spalte das Vokabular und in den √ºbrigen 100 Spalten die Dimensionen enth√§lt:

```{r}
word_embedding_twitter <-
  tibble(
    word = dict
  )
```


```{r words-vec-twitter}
#| eval: false
words_vecs_twitter <-
  get_word_vectors(twitter_fasttext_model)
```



```{r df-word-embedding-twitter}
#| eval: false
word_embedding_twitter <-
  word_embedding_twitter %>% 
  bind_cols(words_vecs_twitter)

names(word_embedding_twitter) <- c("word", paste0("v", sprintf("%03d", 1:100)))  # Namen versch√∂nern mit fortlaufender Nummer von 0 bis 100
```


Und als Worteinbettungs-Datei abspeichern:

```{r}
#| eval: false
#write_rds(word_embedding_twitter, file = paste0(tweet_data_path, "word_embedding_twitter.rds"))
```


```{r}
#| echo: false
word_embedding_twitter <- read_rds(file = "/Users/sebastiansaueruser/github-repos/hate-speech-data/objects/word_embedding_twitter.rds")

head(word_embedding_twitter)[1:5]
```



### Aufbereiten

Am besten nur die Spalten (unseres Twitter-Datensatzes) behalten,
die wir zum Modellieren nutzen:

```{r ds-short2}
ds_short2 <-
  ds_short %>% 
  select(text, id)
```


Wir definieren ein modifiziertesRezept `rec1`:



```{r}
rec1a <- 
  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% 
  update_role(id, new_role = "id") %>% 
  step_tokenize(text) %>% 
  step_stopwords(text, language = "de", stopword_source = "snowball") %>% 
  step_stem(text) %>% 
  step_tokenfilter(text, max_tokens = 1e2) %>%  # wir behalten nur die h√§ufigsten Tokens
  step_word_embeddings(text, embeddings = word_embedding_twitter)
```


Dann preppen und backen:

```{r}
rec1a_prepped <-
  prep(rec1a)
```



```{r ds-baked}
ds_baked_rec1a <- bake(rec1a_prepped, new_data = ds_short2)
```


```{r}
ds_baked_rec1a %>% `[`(1:10, 1:10)
```


Ist das nicht komfortabel?
Das Textrezept √ºbernimmt die Arbeit f√ºr uns,
mit den richtigen Features zu arbeiten,
und die Wort-Einbettungen f√ºr die richtigen W√∂rter bereitzustellen.

Wer dem Frieden nicht traut,
dem sei geraten, nachzupr√ºfen ü§ì.



## Workflow 3: Rezept 2 + Lasso

### Daten aufteilen



```{r split-data3}
d_split <- initial_split(d2, strata = c1)

d_train <- training(d_split)
d_test <- testing(d_split)
```



### Hilfsfunktionen



```{r}
source("funs/helper-funs-recipes.R")
```



Testen wir die Funktionen:

```{r}
dummy <- c("hallo", "baby", "fatal")

count_profane(dummy) 

count_emo_words(dummy)

dummy <- c("baby", "und", "üÜó", "üñï")

count_emojis(dummy)

count_wild_emojis(dummy) 
```


### Rezept mit Worteinbettungen

```{r rec2}
rec2 <- 
  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% 
  update_role(id, new_role = "id") %>% 
  step_text_normalization(text) %>% 
  step_mutate(text_copy = text,
              profane_n = map_int(text, count_profane),
              emo_words_n = map_int(text, count_emo_words),
              emojis_n = map_int(text, count_emojis),
              wild_emojis_n = map_int(text, count_wild_emojis)
  ) %>% 
  step_textfeature(text_copy) %>% 
  step_tokenize(text, token = "words") %>% 
  step_stopwords(text, language = "de", stopword_source = "snowball") %>% 
  step_word_embeddings(text, embeddings = word_embedding_twitter)
 
rec2
```




Jetzt preppen:


```{r rec2-prepped}
#| eval: false
rec2_prepped <- prep(rec2)
```




Vielleicht macht es Sinn, sich das Objekt zur sp√§teren
Verwendung abzuspeichern.^[Aber Vorsicht beim Abspeichern, man k√∂nnte versehentlich mit einer veralteten Version weiterarbeiten.]
`Feather` verarbeitet nur Dataframes,
daher nutzen wir hier RDS.


```{r}
#| eval: false
#write_rds(rec2_prepped, file = "~/datasets/Twitter/klassifik-rec2-prepped.rds")
```

```{r}
rec2_prepped <- read_rds("/Users/sebastiansaueruser/github-repos/hate-speech-data/objects/rec2_prepped.rds")
```




Das Element `rec2_prepped` ist recht gro√ü:


```{r}
format(object.size(rec2_prepped), units  = "Mb")
```

Jetzt k√∂nnen wir das pr√§parierte ("gepreppte") Rezept "backen":


```{r rec2-prepped-baked}
rec2_baked <- bake(rec2_prepped, new_data = NULL)
```


```{r}
rec2_baked %>% 
  select(1:15) %>% 
  glimpse()
```


Das Rezept beinhaltet also einige Textfeatures plus die FastText-Worteinbettungen.

### Fitting 3 {#sec-klassifik-fit3}




```{r wf3}
wf3 <-
  workflow() %>% 
  add_recipe(rec2) %>% 
  add_model(lasso_spec)

wf3
```





Tunen und Fitten:

```{r wf3-fit}
#| eval: false
set.seed(42)

tic()
fit3 <-
  tune_grid(
    wf3,
    folds1,
    grid = lambda_grid,
    control = control_resamples(save_pred = TRUE)
  )
(toc)
fit3
```





```{r}
#| eval: false
#write_rds(fit3, "objects/chap_classific_fit3.rds")
```


```{r}
#| echo: false
fit3 <- read_rds("/Users/sebastiansaueruser/github-repos/datascience-text/objects/chap_classific_fit3.rds")
```



Hier ist die Performanz:

```{r}
#| eval: false
collect_metrics(fit3)
```


```{r}
autoplot(fit3)
```



```{r}
fit3 %>% 
  show_best("roc_auc")
```



```{r chosenauc-fit3}
chosen_auc_fit3 <- 
  fit3 %>%
  select_by_one_std_err(metric = "roc_auc", -penalty)
```



Finalisieren:


```{r wf3-final}
wf3_final <-
  finalize_workflow(wf3, chosen_auc_fit3)

wf3_final
```



```{r fit3-final-train}
#| eval: false
#fit3_final_train <-  # die Berechnung kann dauern ...
  fit(wf3_final, d_train)
```




```{r}
#| echo: false
#write_rds(fit3_final_train, file = "objects/fit3_final_train.rds")
fit3_final_train <- read_rds("objects/fit3_final_train.rds")  # ca. 220MB
```



```{r fit3-final-train2}
fit3_final_train %>% 
  extract_fit_parsnip() %>% 
  tidy() %>% 
  arrange(-abs(estimate)) %>% 
  head()
```



```{r fit3-final-test}
#| eval: false
fit3_final_test <-
  last_fit(wf3_final, d_split)  # dauert etwas
```


```{r}
#| echo: false
#| eval: false
#write_rds(fit3_final_test, file = "objects/fit3_final_test.rds")
```



```{r load-fit3-final-test}
#| echo: false
fit3_final_test <- read_rds(file = "objects/fit3_final_test.rds")
```


Und endlich: Wie gut ist die Performanz?

```{r}
collect_metrics(fit3_final_test)
```


Am Ende so eines Arbeitsganges,
bei dem man wieder (und wieder) die gleichen Funktionen kopiert,
und nur aufpassen muss, aus `fit2` an der richtigen Stelle `fit3` zu machen:
Da blickt man jedem Umbau dieses Codes zu einer Funktion freudig ins Gesicht.

Ein anderes Problem,
f√ºr das hier keine elegante L√∂sung pr√§sentiert wird,
sind die langen Berechnungszeiten, die, wenn man Pech hat, auch noch
mehrfach wiederholt werden m√ºssen.

Die Gefahr mit dem Abspeichern via `write_rds` ist klar:
Man riskiert, sp√§ter ein veraltetes Objekt zu laden.

Zu diesen Punkten sp√§ter mehr.



## Fallstudien



Julia Silge stellt eine sch√∂ne [Fallstudie](https://juliasilge.com/blog/spam-email/) zur Klassifikation von Spam-Mails bereit. In der Fallstudie geht es nicht um Feature Engineering, sondern um Modellierung.

[ChatGPT generierten Text automatisch erkennen -- ](https://juliasilge.com/blog/gpt-detectors/) wie gut geht das? 
Die Maschine erkennt sich selbst, im besten (oder schlechtesten?) Fall. Die Fallstudie zeigt, naja, so mittel, zumindest in den Daten in der Fallstudie.


[OpenAIs Word-Einbettungen](https://platform.openai.com/docs/guides/embeddings) werden in [dieser Fallstudie](https://juliasilge.com/blog/horror-embeddings/) verwendet. Sehr sch√∂n!






