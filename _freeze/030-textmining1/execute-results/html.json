{
  "hash": "d9a2209c291a6000ed3c0232771d18a4",
  "result": {
    "markdown": "\n# Textmining1\n\n\n\n![Text als Datenbasis prädiktiver Modelle](img/text-mining-1476780_640.png){width=10%}\nBild von <a href=\"https://pixabay.com/de/users/mcmurryjulie-2375405/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1476780\">mcmurryjulie</a> auf <a href=\"https://pixabay.com/de//?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1476780\">Pixabay</a>\n\n\n\n## Vorab\n\n\n### Lernziele\n\n\n- Die vorgestellten Techniken des Textminings mit R anwenden können\n\n\n\n### Vorbereitung\n\n- Lesen Sie in @smltar Kap. 2.\n\n\n\n### Benötigte R-Pakete\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-1_66765c85b41b11e961aad1156c554841'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tokenizers)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(hcandersenr)\nlibrary(SnowballC)  # Stemming\nlibrary(lsa)  # Stopwörter\nlibrary(easystats)  # Komfort für deskriptive Statistiken, wie `describe_distribution`\nlibrary(textclean)  # Emojis ersetzen\nlibrary(wordcloud)\n```\n:::\n\n\n\n\n## Einfache Methoden des Textminings\n\n\nArbeiten Sie die folgenden grundlegenden Methoden des Textminigs durch.\n\n\n\n\n### Tokenisierung\n\nErarbeiten Sie dieses Kapitel: @smltar, [Kap. 2](https://smltar.com/tokenization.html#tokenization)\n\nWie viele Zeilen hat das Märchen \"The Fir tree\" (in der englischen Fassung?)\n\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-2_5191bf3ecd573f03dff0bed65fd1b970'}\n\n```{.r .cell-code}\nhcandersen_en %>% \n  filter(book == \"The fir tree\") %>% \n  nrow()\n## [1] 253\n```\n:::\n\n\n\n### Stopwörter entfernen\n\n\nErarbeiten Sie dieses Kapitel: s. @smltar, [Kap. 3](https://smltar.com/stopwords.html#stopwords)\n\n\n\nEine alternative Quelle von Stopwörtern - in verschiedenen Sprachen - \nbiwetet das Paket `quanteda`:\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-3_5ab35cb3a22e8cb3ee39449f416b2a5d'}\n\n```{.r .cell-code}\nstop2 <-\n  tibble(word = quanteda::stopwords(\"german\"))\n\nhead(stop2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"word\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"aber\"},{\"1\":\"alle\"},{\"1\":\"allem\"},{\"1\":\"allen\"},{\"1\":\"aller\"},{\"1\":\"alles\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nEs bestehst (in der deutschen Version) aus 231 Wörtern.\n\n\n\n\n### Wörter zählen {#sec-woerterzaehlen}\n\nIst der Text tokenisiert, kann man einfach mit \"Bordmitteln\" die Wörter zählen.\n\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-4_ffe513609bda502301a18c782b8ae143'}\n\n```{.r .cell-code}\nhc_andersen_count <- \n  hcandersen_de %>% \n  filter(book == \"Das Feuerzeug\") %>% \n  unnest_tokens(output = word, input = text) %>% \n  anti_join(stop2) %>% \n  count(word, sort = TRUE) \n## Joining with `by = join_by(word)`\n\nhc_andersen_count %>% \n  head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"word\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"soldat\",\"2\":\"35\"},{\"1\":\"sagte\",\"2\":\"28\"},{\"1\":\"hund\",\"2\":\"23\"},{\"1\":\"prinzessin\",\"2\":\"17\"},{\"1\":\"hexe\",\"2\":\"16\"},{\"1\":\"feuerzeug\",\"2\":\"14\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\nZur Visualisierung eignen sich Balkendiagramme, s. @fig-hcandersen-count.\n\n\n\n::: {.cell hash='030-textmining1_cache/html/fig-hc-andersen-count_27f2041f9e08ad0aeb2d7b1d33a21d74'}\n\n```{.r .cell-code}\nhc_andersen_count %>% \n  slice_max(order_by = n, n = 10) %>% \n  mutate(word = factor(word)) %>% \n  ggplot() +\n  aes(y = reorder(word, n), x = n) +\n  geom_col()\n  \n```\n\n::: {.cell-output-display}\n![Die häufigsten Wörter in H.C. Anderssens Feuerzeug](030-textmining1_files/figure-html/fig-hc-andersen-count-1.png){#fig-hc-andersen-count width=672}\n:::\n:::\n\n\n\nDabei macht es Sinn, aus `word` einen Faktor zu machen,\ndenn Faktorstufen kann man sortieren,\nzumindest ist das die einfachste Lösung in `ggplot2` (wenn auch nicht super komfortabel).\n\n\nEine (beliebite?) Methode, um Worthäufigkeiten in Corpora darzustellen, \nsind *Wortwolken*, s. @fig-wordcloud1.\nEs sei hinzugefügt, dass solche Wortwolken nicht gerade optimale\nperzeptorische Qualitäten aufweisen.\n\n\n::: {.cell hash='030-textmining1_cache/html/fig-wordcloud1_91379675028cde3bc2f48a21364aa262'}\n\n```{.r .cell-code}\nwordcloud(words = hc_andersen_count$word,\n          freq = hc_andersen_count$n,\n          max.words = 50,\n          rot.per = 0.35,\n          colors = brewer.pal(8, \"Dark2\"))\n```\n\n::: {.cell-output-display}\n![Eine Wortwolke zu den häufigsten Wörtern in H.C. Andersens Feuerzeug](030-textmining1_files/figure-html/fig-wordcloud1-1.png){#fig-wordcloud1 width=672}\n:::\n:::\n\n\n\n\n### Stemming (Wortstamm finden)\n\nErarbeiten Sie dieses Kapitel: @smltar, [Kap. 4](https://smltar.com/stemming.html#stemming)\n\n\nVertiefende Hinweise zum *UpSet plot* finden Sie [hier](https://ieeexplore.ieee.org/document/6876017), @lex_upset_2014.\n\n\nFür welche Sprachen gibt es Stemming im Paket `SnowballC`?\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-7_879a2f2860ce72906fa606c7354b66ff'}\n\n```{.r .cell-code}\nlibrary(SnowballC)\ngetStemLanguages()\n##  [1] \"arabic\"     \"basque\"     \"catalan\"    \"danish\"     \"dutch\"     \n##  [6] \"english\"    \"finnish\"    \"french\"     \"german\"     \"greek\"     \n## [11] \"hindi\"      \"hungarian\"  \"indonesian\" \"irish\"      \"italian\"   \n## [16] \"lithuanian\" \"nepali\"     \"norwegian\"  \"porter\"     \"portuguese\"\n## [21] \"romanian\"   \"russian\"    \"spanish\"    \"swedish\"    \"tamil\"     \n## [26] \"turkish\"\n```\n:::\n\n\n\nEinfacher Test: Suchen wir den Wordstamm für das Wort \"wissensdurstigen\", wie in \"die wissensdurstigen Studentis löcherten dis armi Professi\"^[[Gender-i](https://gender-i.de/#mit-bestimmtem-artikel)].\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-8_850971c4266ec6353fcd72d184dfb532'}\n\n```{.r .cell-code}\nwordStem(\"wissensdurstigen\", language = \"german\")\n## [1] \"wissensdurst\"\n```\n:::\n\n\n\nWerfen Sie mal einen Blick in das Handbuch von [SnowballC](https://cran.r-project.org/web/packages/SnowballC/SnowballC.pdf).\n\n\n\n### Fallstudie AfD-Parteiprogramm\n\n\n\nDaten einlesen:\n\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-9_db293641fe85aa248e8e6f23da40ca92'}\n\n```{.r .cell-code}\nd_link <- \"https://raw.githubusercontent.com/sebastiansauer/pradadata/master/data-raw/afd_2022.csv\"\nafd <- read_csv(d_link, show_col_types = FALSE)\n```\n:::\n\n\nWie viele Seiten hat das Dokument?\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-10_a06db4bfc12d48856a4c8ed05e88fece'}\n\n```{.r .cell-code}\nnrow(afd)\n## [1] 190\n```\n:::\n\n\nUnd wie viele Wörter?\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-11_d6875ddf1f92c5f689ede87df4619bc6'}\n\n```{.r .cell-code}\nstr_count(afd$text, pattern = \"\\\\w\") %>% sum(na.rm = TRUE)\n## [1] 179375\n```\n:::\n\n\n\n\nAus breit mach lang, oder: wir tokenisieren (nach Wörtern): \n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-12_28d982a51f56e5033824275113fd80fc'}\n\n```{.r .cell-code}\nafd %>% \n  unnest_tokens(output = token, input = text) %>% \n  filter(str_detect(token, \"[a-z]\")) -> afd_long\n```\n:::\n\n\n\nStopwörter entfernen:\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-13_a06089a367c4573d3c06b62d2c5ec2a5'}\n\n```{.r .cell-code}\ndata(stopwords_de, package = \"lsa\")\n\nstopwords_de <- tibble(word = stopwords_de)\n\n# Für das Joinen werden gleiche Spaltennamen benötigt:\nstopwords_de <- stopwords_de %>% \n  rename(token = word)  \n\nafd_long %>% \n  anti_join(stopwords_de) -> afd_no_stop\n## Joining with `by = join_by(token)`\n```\n:::\n\n\n\nWörter zählen:\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-14_74e3a336b38a583386d80eb22e2c79d9'}\n\n```{.r .cell-code}\nafd_no_stop %>% \n  count(token, sort = TRUE) -> afd_count\n\nhead(afd_count)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"token\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"afd\",\"2\":\"174\"},{\"1\":\"deutschland\",\"2\":\"113\"},{\"1\":\"wollen\",\"2\":\"66\"},{\"1\":\"euro\",\"2\":\"60\"},{\"1\":\"bürger\",\"2\":\"57\"},{\"1\":\"eu\",\"2\":\"54\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nWörter trunkieren:\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-15_d14cb4e3e9df192746201708912b319b'}\n\n```{.r .cell-code}\nafd_no_stop %>% \n  mutate(token_stem = wordStem(token, language = \"de\")) %>% \n  count(token_stem, sort = TRUE) -> afd_count_stemmed\n\nhead(afd_no_stop)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"page\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"token\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1\",\"2\":\"programm\"},{\"1\":\"1\",\"2\":\"deutschland\"},{\"1\":\"1\",\"2\":\"grundsatzprogramm\"},{\"1\":\"1\",\"2\":\"alternative\"},{\"1\":\"1\",\"2\":\"deutschland\"},{\"1\":\"2\",\"2\":\"inhaltsverzeichnis\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n### Stringverarbeitung\n\n\n\nErarbeiten Sie dieses Kapitel: @r4ds, [Kap. 14](https://r4ds.had.co.nz/strings.html)\n\n\n\n#### Regulärausdrücke {#regex}\n\nDas `\"[a-z]\"` in der Syntax oben steht für \"alle Buchstaben von a-z\". D\niese flexible Art von \"String-Verarbeitung mit Jokern\" nennt man *Regulärausdrücke* (regular expressions; regex). \nEs gibt eine ganze Reihe von diesen Regulärausdrücken, die die Verarbeitung von Texten erleichert. \nMit dem Paket `stringr` geht das - mit etwas Übung - gut von der Hand. \nNehmen wir als Beispiel den Text eines Tweets:\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-16_807243af845ebc14edfd282f30c2252e'}\n\n```{.r .cell-code}\nstring <- \"Correlation of unemployment and #AfD votes at #btw17: ***r = 0.18***\\n\\nhttps://t.co/YHyqTguVWx\"  \n```\n:::\n\n\nMöchte man Ziffern identifizieren, so hilft der Reulärausdruck `[:digit:]`:\n\n\"Gibt es mindestens eine Ziffer in dem String?\"\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-17_ded740aa4abd02c305e835a8b2bf03a5'}\n\n```{.r .cell-code}\nstr_detect(string, \"[:digit:]\")\n## [1] TRUE\n```\n:::\n\n\n\"Finde die Position der ersten Ziffer! Welche Ziffer ist es?\"\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-18_3aa8feaa1c7f2c4a7e920c8341ca0508'}\n\n```{.r .cell-code}\nstr_locate(string, \"[:digit:]\")\n##      start end\n## [1,]    51  51\nstr_extract(string, \"[:digit:]\")\n## [1] \"1\"\n```\n:::\n\n\n\"Finde alle Ziffern!\"\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-19_b901149871acfd335d0d864106908f53'}\n\n```{.r .cell-code}\nstr_extract_all(string, \"[:digit:]\")\n## [[1]]\n## [1] \"1\" \"7\" \"0\" \"1\" \"8\"\n```\n:::\n\n\n\n\"Finde alle Stellen an denen genau 2 Ziffern hintereinander folgen!\"\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-20_5c631ecd39dabb1bab479d2125f3bf0d'}\n\n```{.r .cell-code}\nstr_extract_all(string, \"[:digit:]{2}\")\n## [[1]]\n## [1] \"17\" \"18\"\n```\n:::\n\n\nDer Quantitätsoperator `{n}` findet alle Stellen, in der der der gesuchte Ausdruck genau $n$ mal auftaucht.\n\n\n\"Zeig die Hashtags!\"\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-21_b62e3fc8f9e985660da2367a50c9af07'}\n\n```{.r .cell-code}\nstr_extract_all(string, \"#[:alnum:]+\")\n## [[1]]\n## [1] \"#AfD\"   \"#btw17\"\n```\n:::\n\n\nDer Operator `[:alnum:]` steht für \"alphanumerischer Charakter\" - also eine Ziffer oder ein Buchstabe; synonym hätte man auch `\\\\w` schreiben können (w wie word). Warum werden zwei Backslashes gebraucht? Mit `\\\\w` wird signalisiert, dass nicht der Buchstabe *w*, sondern etwas Besonderes, eben der Regex-Operator `\\w` gesucht wird. \n\n\"Zeig die URLs!\"\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-22_0fead28da2394b20b71e43651b9fab6c'}\n\n```{.r .cell-code}\nstr_extract_all(string, \"https?://[:graph:]+\")\n## [[1]]\n## [1] \"https://t.co/YHyqTguVWx\"\n```\n:::\n\n\nDas Fragezeichen `?` ist eine Quantitätsoperator, der einen Treffer liefert, wenn das vorherige Zeichen (hier *s*) null oder einmal gefunden wird. `[:graph:]` ist die Summe von `[:alpha:]` (Buchstaben, groß und klein), `[:digit:]` (Ziffern) und `[:punct:]` (Satzzeichen u.ä.).\n\n\"Zähle die Wörter im String!\"\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-23_884acbc2400aef11508d026912150de7'}\n\n```{.r .cell-code}\nstr_count(string, boundary(\"word\"))\n## [1] 13\n```\n:::\n\n\n\n\"Liefere nur Buchstaben*folgen* zurück, lösche alles übrige\"\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-24_fa1f222c477647d6411099a0966f6dd0'}\n\n```{.r .cell-code}\nstr_extract_all(string, \"[:alpha:]+\")\n## [[1]]\n##  [1] \"Correlation\"  \"of\"           \"unemployment\" \"and\"          \"AfD\"         \n##  [6] \"votes\"        \"at\"           \"btw\"          \"r\"            \"https\"       \n## [11] \"t\"            \"co\"           \"YHyqTguVWx\"\n```\n:::\n\n\nDer Quantitätsoperator `+` liefert alle Stellen zurück, in denen der gesuchte Ausdruck *einmal oder häufiger*  vorkommt. Die Ergebnisse werden als Vektor von Wörtern zurückgegeben. Ein anderer Quantitätsoperator ist `*`, der für 0 oder mehr Treffer steht. Möchte man einen Vektor, der aus Stringen-Elementen besteht zu einem Strring zusammenfüngen, hilft `paste(string)` oder `str_c(string, collapse = \" \")`.\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-25_8f21f1581e5144a4b845ec899526d792'}\n\n```{.r .cell-code}\nstr_replace_all(string, \"[^[:alpha:]+]\", \"\")\n## [1] \"CorrelationofunemploymentandAfDvotesatbtwrhttpstcoYHyqTguVWx\"\n```\n:::\n\n\nMit dem Negationsoperator `[^x]` wird der Regulärausrck `x` negiert; die Syntax oben heißt also \"ersetze in `string` alles außer Buchstaben durch Nichts\". Mit \"Nichts\" sind hier Strings der Länge Null gemeint; ersetzt man einen belieibgen String durch einen String der Länge Null, so hat man den String gelöscht.\n\nDas Cheatsheet zur Strings bzw zu `stringr` von RStudio gibt einen guten Überblick über Regex; im Internet finden sich viele Beispiele.\n\n\n\n\n\n\n\n\n\n\n#### Regex im Texteditor\n\n\nEinige Texteditoren unterstützen Regex, so auch RStudio.\n\nDas ist eine praktische Sache. \nEin Beispiel: Sie haben eine Liste mit Namen der Art:\n\n- Nachname1, Vorname1\n- Nachname2, Vorname2\n- Nachname3, Vorname3\n\n\nUnd Sie möchten jetzt aber die Liste mit Stil *Vorname Nachname* sortiert haben.\n\nRStudio mit Regex macht's möglich, s. @fig-vorher-regex.\n\n\n::: {#fig-regrex-rstudio}\n\n![Vorher; mit Regex-Syntax](img/regex1.png){#fig-vorher-regex}\n![Vorher; mit Regex-Syntax](img/regex2.png){#fig-nacher-regex}\n\n:::\n\n\n\n\n\n### Emoji-Analyse\n\nEine einfache Art, Emojis in einer Textmining-Analyse zu verarbeiten, \nbietet das Paket `textclean`:\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-26_bedd3d51c513a79a95ff111d9574816b'}\n\n```{.r .cell-code}\nfls <- system.file(\"docs/emoji_sample.txt\", package = \"textclean\")\nx <- readLines(fls)[1]\nx\n## [1] \"Proin 😍 ut maecenas 😏 condimentum 😔 purus eget. Erat, 😂vitae nunc elit. Condimentum 😢 semper iaculis bibendum sed tellus. Ut suscipit interdum😑 in. Faucib😞 us nunc quis a vitae posuere. 😛 Eget amet sit condimentum non. Nascetur vitae ☹ et. Auctor ornare ☺ vestibulum primis justo congue 😀urna ac magna. Quam 😥 pharetra 😟 eros 😒facilisis ac lectus nibh est 😙vehicula 😐 ornare! Vitae, malesuada 😎 erat sociosqu urna, 😏 nec sed ad aliquet 😮 .\"\n```\n:::\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-27_06d75aa80e4aae2ca07bbd4f0d33fe4e'}\n\n```{.r .cell-code}\nreplace_emoji(x)\n## [1] \"Proin smiling face with heart-eyes ut maecenas smirking face condimentum pensive face purus eget. Erat, face with tears of joy vitae nunc elit. Condimentum crying face semper iaculis bibendum sed tellus. Ut suscipit interdum expressionless face in. Faucib disappointed face us nunc quis a vitae posuere. face with tongue Eget amet sit condimentum non. Nascetur vitae frowning face et. Auctor ornare smiling face vestibulum primis justo congue grinning face urna ac magna. Quam sad but relieved face pharetra worried face eros unamused face facilisis ac lectus nibh est kissing face with smiling eyes vehicula neutral face ornare! Vitae, malesuada smiling face with sunglasses erat sociosqu urna, smirking face nec sed ad aliquet face with open mouth .\"\nreplace_emoji_identifier(x)\n## [1] \"Proin lexiconwiutsdotskrupggpgmhm ut maecenas lexiconwizbukzesopzflfinotj condimentum lexiconwlnxqescoesytfatoevi purus eget. Erat, lexiconwcaiviebiytolowkanmb vitae nunc elit. Condimentum lexiconwpujksvgujncexktvyrn semper iaculis bibendum sed tellus. Ut suscipit interdum lexiconwknnasgueiicggptyzbx in. Faucib lexiconwoxfeslcareuqfkbyjgy us nunc quis a vitae posuere. lexiconwobmhqdrrzgygdexhnkk Eget amet sit condimentum non. Nascetur vitae lexiconbfalxvockmnmtmycmwyq et. Auctor ornare lexiconbgmujofaalvxqrklfqgd vestibulum primis justo congue lexiconvygwtlyrpywfarytvfis urna ac magna. Quam lexiconwurhpvewhizayynmfxqo pharetra lexiconwpmuduwgbxxrxeltrueb eros lexiconwkrvakxddtqckcjxeksl facilisis ac lectus nibh est lexiconwmsjgfnelqfeyhgudmfj vehicula lexiconwjfhkpcsgcjtotwlapxa ornare! Vitae, malesuada lexiconwivnupleicqgksianinp erat sociosqu urna, lexiconwizbukzesopzflfinotj nec sed ad aliquet lexiconxbwhfeflxbuupjezgdwl .\"\n```\n:::\n\n\n\n\n\n### Text aufräumen\n\nEine Reihe generischer Tests bietet das Paket `textclean` von [Tyler Rinker](https://github.com/trinker/textclean):\n\n\nHier ist ein \"unaufgeräumeter\" Text:\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-28_f51b11d7a9f7ce18b4956fed470ecf23'}\n\n```{.r .cell-code}\nx <- c(\"i like\", \"<p>i want. </p>. thet them ther .\", \"I am ! that|\", \"\", NA, \n    \"&quot;they&quot; they,were there\", \".\", \"   \", \"?\", \"3;\", \"I like goud eggs!\", \n    \"bi\\xdfchen Z\\xfcrcher\", \"i 4like...\", \"\\\\tgreat\",  \"She said \\\"yes\\\"\")\n```\n:::\n\n\n\n\nLassen wir uns dazu ein paar Diagnostiken ausgeben.\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-29_7d251693edb4d468c49855b9b676d9c5'}\n\n```{.r .cell-code}\nEncoding(x) <- \"latin1\"\nx <- as.factor(x)\ncheck_text(x)\n## \n## =============\n## NON CHARACTER\n## =============\n## \n## The text variable is not a character column (likely `factor`):\n## \n## \n## *Suggestion: Consider using `as.character` or `stringsAsFactors = FALSE` when reading in\n##              Also, consider rerunning `check_text` after fixing\n## \n## \n## =====\n## DIGIT\n## =====\n## \n## The following observations contain digits/numbers:\n## \n## 10, 13\n## \n## This issue affected the following text:\n## \n## 10: 3;\n## 13: i 4like...\n## \n## *Suggestion: Consider using `replace_number`\n## \n## \n## ========\n## EMOTICON\n## ========\n## \n## The following observations contain emoticons:\n## \n## 6\n## \n## This issue affected the following text:\n## \n## 6: &quot;they&quot; they,were there\n## \n## *Suggestion: Consider using `replace_emoticons`\n## \n## \n## =====\n## EMPTY\n## =====\n## \n## The following observations contain empty text cells (all white space):\n## \n## 1\n## \n## This issue affected the following text:\n## \n## 1: i like\n## \n## *Suggestion: Consider running `drop_empty_row`\n## \n## \n## =======\n## ESCAPED\n## =======\n## \n## The following observations contain escaped back spaced characters:\n## \n## 14\n## \n## This issue affected the following text:\n## \n## 14: \\tgreat\n## \n## *Suggestion: Consider using `replace_white`\n## \n## \n## ====\n## HTML\n## ====\n## \n## The following observations contain HTML markup:\n## \n## 2, 6\n## \n## This issue affected the following text:\n## \n## 2: <p>i want. </p>. thet them ther .\n## 6: &quot;they&quot; they,were there\n## \n## *Suggestion: Consider running `replace_html`\n## \n## \n## ==========\n## INCOMPLETE\n## ==========\n## \n## The following observations contain incomplete sentences (e.g., uses ending punctuation like '...'):\n## \n## 13\n## \n## This issue affected the following text:\n## \n## 13: i 4like...\n## \n## *Suggestion: Consider using `replace_incomplete`\n## \n## \n## =============\n## MISSING VALUE\n## =============\n## \n## The following observations contain missing values:\n## \n## 5\n## \n## *Suggestion: Consider running `drop_NA`\n## \n## \n## ========\n## NO ALPHA\n## ========\n## \n## The following observations contain elements with no alphabetic (a-z) letters:\n## \n## 4, 7, 8, 9, 10\n## \n## This issue affected the following text:\n## \n## 4: \n## 7: .\n## 8:    \n## 9: ?\n## 10: 3;\n## \n## *Suggestion: Consider cleaning the raw text or running `filter_row`\n## \n## \n## ==========\n## NO ENDMARK\n## ==========\n## \n## The following observations contain elements with missing ending punctuation:\n## \n## 1, 3, 4, 6, 8, 10, 12, 14, 15\n## \n## This issue affected the following text:\n## \n## 1: i like\n## 3: I am ! that|\n## 4: \n## 6: &quot;they&quot; they,were there\n## 8:    \n## 10: 3;\n## 12: bißchen Zürcher\n## 14: \\tgreat\n## 15: She said \"yes\"\n## \n## *Suggestion: Consider cleaning the raw text or running `add_missing_endmark`\n## \n## \n## ====================\n## NO SPACE AFTER COMMA\n## ====================\n## \n## The following observations contain commas with no space afterwards:\n## \n## 6\n## \n## This issue affected the following text:\n## \n## 6: &quot;they&quot; they,were there\n## \n## *Suggestion: Consider running `add_comma_space`\n## \n## \n## =========\n## NON ASCII\n## =========\n## \n## The following observations contain non-ASCII text:\n## \n## 12\n## \n## This issue affected the following text:\n## \n## 12: bißchen Zürcher\n## \n## *Suggestion: Consider running `replace_non_ascii`\n## \n## \n## ==================\n## NON SPLIT SENTENCE\n## ==================\n## \n## The following observations contain unsplit sentences (more than one sentence per element):\n## \n## 2, 3\n## \n## This issue affected the following text:\n## \n## 2: <p>i want. </p>. thet them ther .\n## 3: I am ! that|\n## \n## *Suggestion: Consider running `textshape::split_sentence`\n```\n:::\n\n\n\n\n\n### Diverse Wortlisten\n\n\n[Tyler Rinker](https://github.com/trinker/lexicon) stellt mit dem Paket `lexicon` eine Zusammenstellung von Wortlisten zu diversen Zwecken zur Verfügung.\nAllerding nur für die englische Sprache.\n\n\n\n\n\n\n### Sentimentanalyse {#sec-sentimentanalyse}\n\n\n#### Einführung\n\n\nEine weitere interessante Analyse ist, die \"Stimmung\" oder \"Emotionen\" (Sentiments) eines Textes auszulesen. \nDie Anführungszeichen deuten an, dass hier ein Maß an Verständnis suggeriert wird, welches nicht (unbedingt) von der Analyse eingehalten wird. \nJedenfalls ist das Prinzip der Sentiment-Analyse im einfachsten Fall so: \n\n\n\n\n\n1. Schau dir jeden Token aus dem Text an.  \n2. Prüfe, ob sich das Wort im Lexikon der Sentiments wiederfindet.  \n3. Wenn ja, dann addiere den Sentimentswert dieses Tokens zum bestehenden Sentiments-Wert.  \n4. Wenn nein, dann gehe weiter zum nächsten Wort.  \n5. Liefere zum Schluss die Summenwerte pro Sentiment zurück.  \n\n\n\n\n     \nEs gibt Sentiment-Lexika, die lediglich einen Punkt für \"positive Konnotation\" bzw. \"negative Konnotation\" geben; andere Lexiko weisen differenzierte Gefühlskonnotationen auf. Wir nutzen hier das *deutsche* Sentimentlexikon `sentiws` [@Remus2010]. Sie können das Lexikon als CSV hier herunterladen:\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-30_971a4a17a2d5165a991c25f4a5bdc2f0'}\n\n```{.r .cell-code}\nsentiws <- read_csv(\"https://osf.io/x89wq/?action=download\")\n```\n:::\n\n\n\nDen Volltext zum Paper finden Sie z.B. [hier](http://www.lrec-conf.org/proceedings/lrec2010/pdf/490_Paper.pdf).\n\nAlternativ können Sie die Daten aus dem Paket `pradadata` laden. Allerdings müssen Sie dieses Paket von Github installieren:\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-31_5c32257741d76045cc582ed6c8b1a157'}\n\n```{.r .cell-code}\ninstall.packages(\"devtools\", dep = TRUE)\ndevtools::install_github(\"sebastiansauer/pradadata\")\n```\n:::\n\n::: {.cell hash='030-textmining1_cache/html/parse-sentiment-dics_2f944246db19cf38ecaaf8715a47e148'}\n\n```{.r .cell-code}\ndata(sentiws, package = \"pradadata\")\n```\n:::\n\n\n@tbl-afdcount zeigt einen Ausschnitt aus dem Sentiment-Lexikon *SentiWS*.\n\n\n::: {#tbl-afdcount .cell tbl-cap='Auszug aus SentiWS' hash='030-textmining1_cache/html/tbl-afdcount_26fc02040d3d50d76f5ef18f6ea63ed6'}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"neg_pos\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"word\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"value\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"inflections\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"neg\",\"2\":\"Abbau\",\"3\":\"-0.0580\",\"4\":\"Abbaus,Abbaues,Abbauen,Abbaue\"},{\"1\":\"neg\",\"2\":\"Abbruch\",\"3\":\"-0.0048\",\"4\":\"Abbruches,Abbrüche,Abbruchs,Abbrüchen\"},{\"1\":\"neg\",\"2\":\"Abdankung\",\"3\":\"-0.0048\",\"4\":\"Abdankungen\"},{\"1\":\"neg\",\"2\":\"Abdämpfung\",\"3\":\"-0.0048\",\"4\":\"Abdämpfungen\"},{\"1\":\"neg\",\"2\":\"Abfall\",\"3\":\"-0.0048\",\"4\":\"Abfalles,Abfälle,Abfalls,Abfällen\"},{\"1\":\"neg\",\"2\":\"Abfuhr\",\"3\":\"-0.3367\",\"4\":\"Abfuhren\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n#### Ungewichtete Sentiment-Analyse\n\nNun können wir jedes Token des Textes mit dem Sentiment-Lexikon abgleichen; \ndabei zählen wir die Treffer für positive bzw. negative Terme. \nZuvor müssen wir aber noch die Daten (`afd_long`) mit dem Sentimentlexikon zusammenführen (joinen). \nDas geht nach bewährter Manier mit `inner_join`; \"inner\" sorgt dabei dafür, dass nur Zeilen behalten werden, die in beiden Dataframes vorkommen. Tabelle @tbl-afdsenti zeigt Summe, Anzahl und Anteil der Emotionswerte.\n\n\nWir nutzen die Tabelle `afd_long`,  die wir oben definiert haben.\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-32_b08798a0419e6b477151188f7aaee942'}\n\n```{.r .cell-code}\nafd_long %>% \n  inner_join(sentiws, by = c(\"token\" = \"word\")) %>% \n  select(-inflections) -> afd_senti  # die Spalte brauchen wir nicht\n## Warning in inner_join(., sentiws, by = c(token = \"word\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ℹ Row 9101 of `x` matches multiple rows in `y`.\n## ℹ Row 3190 of `y` matches multiple rows in `x`.\n## ℹ If a many-to-many relationship is expected, set `relationship =\n##   \"many-to-many\"` to silence this warning.\n\nafd_senti %>% \n  group_by(neg_pos) %>% \n  summarise(polarity_sum = sum(value),\n            polarity_count = n()) %>% \n  mutate(polarity_prop = (polarity_count / sum(polarity_count)) %>% round(2)) ->\n  afd_senti_tab\n```\n:::\n\n::: {#tbl-afdsenti .cell tbl-cap='Zusammenfassung von SentiWS' hash='030-textmining1_cache/html/tbl-afdsenti_4897d9a299a54aca47de12d879292a43'}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"neg_pos\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"polarity_sum\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"polarity_count\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"polarity_prop\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"neg\",\"2\":\"-48.5307\",\"3\":\"210\",\"4\":\"0.27\"},{\"1\":\"pos\",\"2\":\"30.6595\",\"3\":\"578\",\"4\":\"0.73\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nDie Analyse zeigt, dass die emotionale Bauart des Textes durchaus interessant ist: \nEs gibt viel mehr positiv getönte Wörter als negativ getönte. \nAllerdings sind die negativen Wörter offenbar deutlich stärker emotional aufgeladen, \ndenn die Summe an Emotionswert der negativen Wörter ist (überraschenderweise?) deutlich größer als die der positiven.\n\nBetrachten wir also die intensivsten negativ und positive konnotierten Wörter näher.\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-33_3ff2a31646341d604099cbe279011f24'}\n\n```{.r .cell-code}\nafd_senti %>% \n  distinct(token, .keep_all = TRUE) %>% \n  mutate(value_abs = abs(value)) %>% \n  top_n(20, value_abs) %>% \n  pull(token)\n##  [1] \"ungerecht\"    \"besonders\"    \"gefährlich\"   \"überflüssig\"  \"behindern\"   \n##  [6] \"gelungen\"     \"brechen\"      \"unzureichend\" \"gemein\"       \"verletzt\"    \n## [11] \"zerstören\"    \"trennen\"      \"falsch\"       \"vermeiden\"    \"zerstört\"    \n## [16] \"schwach\"      \"belasten\"     \"schädlich\"    \"töten\"        \"verbieten\"\n```\n:::\n\n\nDiese \"Hitliste\" wird zumeist (19/20) von negativ polarisierten Begriffen aufgefüllt, \nwobei \"besonders\" ein Intensivierwort ist, welches das Bezugswort verstärt (\"besonders gefährlich\"). \nDas Argument `keep_all = TRUE` sorgt dafür, dass alle Spalten zurückgegeben werden, \nnicht nur die durchsuchte Spalte `token`. \nMit `pull` haben wir aus dem Dataframe, der von den dplyr-Verben übergeben wird, \ndie Spalte `pull` \"herausgezogen\"; \nhier nur um Platz zu sparen bzw. der Übersichtlichkeit halber.\n\n\n     \nNun könnte man noch den erzielten \"Netto-Sentimentswert\" des Corpus ins Verhältnis setzen Sentimentswert des Lexikons:\nWenn es insgesamt im Sentiment-Lexikon sehr negativ zuginge,\nwäre ein negativer Sentimentwer in einem beliebigen Corpus nicht überraschend. `describe_distribution` aus `{easystats}` gibt uns einen Überblick der üblichen deskriptiven Statistiken.\n     \n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-34_17b8fed4fd872d4412e1174b34f1aa84'}\n\n```{.r .cell-code}\nsentiws %>% \n  select(value, neg_pos) %>% \n  #group_by(neg_pos) %>% \n  describe_distribution()\n```\n:::\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-35_a0e6662072146b99ad9d52dd46935c8a'}\n::: {.cell-output-display}\n|Variable |  Mean |   SD |  IQR |         Range | Skewness | Kurtosis |    n | n_Missing |\n|:--------|:-----:|:----:|:----:|:-------------:|:--------:|:--------:|:----:|:---------:|\n|value    | -0.05 | 0.20 | 0.05 | (-1.00, 1.00) |    -0.68 |     2.36 | 3468 |         0 |\n:::\n:::\n\n\nInsgesamt ist das Lexikon ziemlich ausgewogen; negative Werte sind leicht in der Überzahl im Lexikon. \nUnser Corpus hat eine ähnliche mittlere emotionale Konnotation wie das Lexikon:\n\n\n::: {.cell hash='030-textmining1_cache/html/unnamed-chunk-36_c50d588899ebf63038908874edcf73f6'}\n\n```{.r .cell-code}\nafd_senti %>% \n  summarise(senti_sum = mean(value) %>% round(2))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"senti_sum\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-0.02\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n### Weitere Sentiment-Lexika\n\n[Tyler Rinker](https://github.com/trinker/sentimentr) stellt das Paket `sentimentr` zur Verfügung.\n[Matthew Jockers](https://www.matthewjockers.net/2015/02/02/syuzhet/) stellt das Paket `Syushet` zur Verfügung.\n\n\n\n### Google Trends\n\nEine weitere Möglichkeit, \"Worthäufigkeiten\" zu identifizieren ist [Google Trends](https://trends.google.com/trends/?geo=US).\nDieser Post zeigt Ihnen eine Einsatzmöglichkeit.\n\n\n\n\n## Aufgaben\n\n\n- [purrr-map01](https://datenwerk.netlify.app/posts/purrr-map01/purrr-map01.html)\n- [purrr-map02](https://datenwerk.netlify.app/posts/purrr-map02/purrr-map02.html)\n- [purrr-map03](https://datenwerk.netlify.app/posts/purrr-map03/purrr-map03.html)\n- [purrr-map04](https://datenwerk.netlify.app/posts/purrr-map04/purrr-map04.html)\n- [Regex-Übungen](https://regexone.com/)\n- [Aufgaben zum Textmining von Tweets](https://datenwerk.netlify.app/#category=textmining)\n\n\n\n\n## Fallstudie Hate-Speech\n\n\n### Daten\n\nEs finden sich mehrere Datensätze zum Thema Hate-Speech im öffentlichen Internet, eine Quelle ist [Hate Speech Data](https://ckan.hatespeechdata.com/), ein Repositorium, das mehrere Datensätze beinhaltet.\n\n\n\n- [Kaggle Hate Speech and Offensive Language Dataset](https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset?select=labeled_data.csv)\n- [Bretschneider and Peters Prejudice on Facebook Dataset](https://ckan.hatespeechdata.com/dataset/bretschneider-and-peters-prejudice-on-facebook-dataset)\n- [Daten zum Fachartikel\"Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior\"](https://github.com/ENCASEH2020/hatespeech-twitter/blob/master/hatespeech_labels.csv)\n\n\nFür Textmining kann eine Liste mit anstößigen (obszönen) Wörten nützlich sein,\nauch wenn man solche Dinge ungern anfässt, verständlicherweise.\n[Jenyay](https://github.com/Jenyay/Obscene-Words-List) bietet solche Listen in verschiedenen Sprachen an. Die Liste von [KDNOOBW](https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words) sieht sehr ähnlich aus (zumindest die deutsche Version).\nEine lange Sammlung deutscher Schimpfwörter findet sich im [insult.wiki](https://www.insult.wiki/schimpfwort-liste);\nähnlich bei [Hyperhero](http://www.hyperhero.com/de/insults.htm).\n\n\n\n\n\n\n\nTwitterdaten dürfen nur in \"dehydrierter\" Form weitergegeben werden, so dass kein Rückschluss von ID zum Inhalt des Tweets möglich ist. \nDaher werden öffentlich nur die IDs der Tweets, als einzige Information zum Tweet, also ohne den eigentlichen Inhalt des Tweets, bereitgestellt.\n\nÜber die Twitter-API kann man sich, wie oben dargestellt, dann die Tweets wieder \"rehydrieren\", also wieder mit dem zugehörigen Tweet-Text (und sonstigen Infos des Tweets) zu versehen.\n\n\n\n\n### Grundlegendes Text Mining\n\n\nWenden Sie die oben aufgeführten Techniken des grundlegenden Textminings auf einen der oben dargestellten Hate-Speech-Datensätze an.\nErstellen Sie ein (HTML-Dokument) mit Ihren Ergebnissen. \nStellen Sie die Ergebnisse auf dem Github-Repo dieses Kurses ein.\nVergleichen Sie Ihre Lösung mit den Lösungen der anderen Kursmitglieder.\n\nWir nutzen noch nicht eigene Daten, die wir von Twitter ausgelesen haben, das heben wir uns für später auf.\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}