{
  "hash": "c332e43b3c58d41bcc29b0772744a51d",
  "result": {
    "markdown": "# Projektmanagement\n\n\n## Pipeline-Management\n\n### Am Anfang\n\n\nSie haben Großes vor! \nNaja, zumindest planen Sie ein neues Data-Science-Projekt.\n\nUnd, schlau wie Sie sind,\nstürzen Sie nicht sofort an die Tastatur,\num sich einige Modelle berechnen zu lassen. Nein!\nSie denken erst einmal nach.\nZum Beispiel,\nwie die einzelnen Analyseschritte aussehen,\nworin sie bestehen, und in welcher Abfolge sie zu berechnen sind,\ns. @fig-projekt1.\n\n\n![So könnte Ihr Projektplan am Anfang aussehen, man spricht auch von einer Pipeline](img/project1.JPG){#fig-projekt1 width=80%}\n\n\n:::callout-note\nDen Graph der einzelnen Analyseschritte in ihrer Abhängigkeit bezeichnet man als *Pipeline.\n:::\n\n\n\n\n### Sie träumen von einem Werkzeug\n\n\nNach einiger Zeit überlegen Sie sich,\ndass Sie ein System bräuchten, das Ihre Skizze umsetzt in tatsächliche Berechnungen.\nUnd zwar suchen Sie ein Projektmanagement-System das folgendes Desiderata erfüllt:\n\n1. Es führt die einzelnen Schritte Ihres Projekt, die \"Pipeline\" in der richtigen Reihenfolge\n2. Es aktualisiert veraltete Objekte, aber es berechnet *nicht* Modelle neu, die unverändert sind\n3. Es ist gut zu debuggen\n\nJa, von so einem Werkzeug träumen Sie.\n\n\nUnd tatsächlich, Ihr Traum geht in Erfüllung. Dieses System existiert.\nGenau genommen gibt es viele Systeme,\ndie sich anschicken, Ihre Wünsche zu erfüllen.\nWir schauen uns eines näher an, das speziell für R gemacht ist.\nDas [R-Paket `targets`](https://books.ropensci.org/targets/).\n\n\n\n### Targets\n\n\nEs lohnt sich, an dieser Stelle den [\"Walkthrough\" aus dem Benutzerhandbuch](https://books.ropensci.org/targets/walkthrough.html) von Targets durchzuarbeiten.\n\n\n\nFür ein Projekt ähnlich zu den, die \nwir in diesem Buch bearbeiten,\nist folgende `_targets.R`-Datei ein guter Start.\n\n\n\n\n::: {.cell hash='projektmgt_cache/html/unnamed-chunk-1_7e8518c2425ba9101f4ccad3051cab5b'}\n\n```{.r .cell-code}\nlibrary(targets)\n\n\n# Funktionen einlesen:\n#purrr::walk(list.files(path = \"funs\", pattern = \".R\", full.names = TRUE), source)\nsource(\"funs/def-recipe.R\")\nsource(\"funs/read-train-data.R\")\nsource(\"funs/read-test-data.R\")\n\n# Optionen, z.B. allgemein verfügbare Pakete in den Targets:tar_option_set(packages = c(\"readr\", \n                            \"dplyr\", \n                            \"ggplot2\", \n                            \"purrr\", \n                            \"easystats\", \n                            \"tidymodels\", \n                            \"textrecipes\"))\n\n# Definition der Pipeline:\nlist(\n  tar_target(data_train, read_train_data()),\n  tar_target(data_test, read_test_data()),\n  tar_target(recipe1, def_recipe(data_train)\n  ),\n  tar_target(model1,\n             logistic_reg(penalty = tune(), mixture = 1) %>%\n               set_mode(\"classification\") %>%\n               set_engine(\"glmnet\")\n             ),\n  tar_target(workflow1,\n             workflow() %>% add_recipe(recipe1) %>% add_model(model1)\n             ),\n  tar_target(grid1,\n             grid_regular(penalty(), levels = 3)\n             ),\n  tar_target(grid_fitted,\n             tune_grid(workflow1, \n                       resamples = vfold_cv(data_train, v = 2),\n                       grid = grid1)\n  ),\n  tar_target(best_hyperparams,\n             select_by_one_std_err(grid_fitted, metric = \"roc_auc\", penalty)\n             ),\n  tar_target(fit1,\n             workflow1 %>% finalize_workflow(best_hyperparams) %>% fit(data_train)),\n  tar_target(preds,\n             fit1 %>% \n               predict(data_test) %>% \n               bind_cols(data_test) %>% \n               mutate(c1 = factor(c1))),\n  tar_target(metrics1,\n             preds %>% metrics(truth = c1, .pred_class))\n)\n```\n:::\n\n\n\n\nDann kann man auf den Play-Button drücken und die ganze Pipeline wird berechnet:\n\n\n::: {.cell hash='projektmgt_cache/html/unnamed-chunk-2_91c7210b2a41b073823e1f7e25db19fc'}\n\n```{.r .cell-code}\ntar_make()\n```\n:::\n\n\nWenn die Pipeline aktuell ist, und nichts berechnet werden muss (und daher auch schon fehlerfrei durchgelaufen ist), sieht die Ausgabe so aus:\n\n```\n✔ skip target grid1\n✔ skip target model1\n✔ skip target data_train\n✔ skip target data_test\n✔ skip target recipe1\n✔ skip target workflow1\n✔ skip target grid_fitted\n✔ skip target best_hyperparams\n✔ skip target fit1\n✔ skip target preds\n✔ skip target metrics1\n✔ skip pipeline [0.121 seconds]\n```\n\n\nDie Pipeline kann man sich als DAG bzw. als Abhängigkeitsgraph visualisieren lassen:\n\n\n::: {.cell hash='projektmgt_cache/html/unnamed-chunk-3_bf2c3b476d39fcb1c9ed10952774a146'}\n\n```{.r .cell-code}\ntar_visnetwork()\n```\n:::\n\n\n\n![Abhängigkeitsgraph der Pipeline](img/tar-network1.png)\n\n\n\nEinzelne Objekte kann man sich komfortabel anschauen mit `tar_load(objekt)`,\nz.B. `tar_load(fit1)` usw.\n\n\n\n### Eine Pipeline als Spielwiese\n\n\n[Dieses Github-Repo](https://github.com/sebastiansauer/targets-playground) stellt Ihnen eine \"Spielwiese\" zur Verfügung,\nwo Sie sich mit Pipleines à la Targets vertraut machen können.\n\n\n\n\n## Publizieren \n\n\nSie haben eine super Analyse geschrieben, eine schicke Pipeline, und jetzt soll die Welt davon erfahren?\nEs gibt einige komfortable Möglichkeiten, Ihre Arbeit zu publizieren,\nz.B. als Blog mit [Quarto](https://quarto.org/).\n\n![Dieses Video](https://youtu.be/d3Xnvi2_HB4) zeigt Ihnen wie man einen Quarto-Blog in RStudio erstellt und ihn bei [Netlify](https://www.netlify.com/) publiziert.\n\nDas Hosten bzw. Deployen bei Netlify ist kostenlos (in der Basis-Variante).\n\nSie können alternativ [Github Page](https://youtu.be/-GA_Afz_jI4) als Hosting-Dienst verwenden. [Dieses Video]() gibt dazu eine Anleitung.\n\n\n\n## Komplexitätsmanagement\n\n\nProgrammieren ist faszinierend. Vor allem, wenn das Program funktioniert. \nGenau genommen ist es eigentlich nur dann faszinierend, ansonsten wird es anstrengend? aufregend? süchtig? faszinierend? nervig?\nWie auch immer: Bugs treten auf und mit steigender Komplexitit Ihrer Software steigen die Bugs nicht linear,\nsondern eher quadratisch oder gar exponentiell an.\n\nEs gibt viele Ansätze, sich gegen die Komplexität zu \"wehren\". \nDer beste ist vielleicht: Die Software so einfach wie möglich zu halten - und\nnur so komplex wie nötig. Sozusagen:\nDas beste Feature ist das, das Sie nicht implementieren.\n\n### Geben Sie gute Namen\n\nDaraus leitet sich ab, \ndass die zentralen Methoden, um der Fehler Herr zu werden im Komplexitätsmanagement liegen.\nDen Variablen (Objekten) gute, \"sprechende\" aber prägnante Namen zu geben, ist\nin diesem Lichte auch als Komplexitätsmanagement (Reduktion) zu verstehen.\n\nEin typischer Fehler, der mir immer mal wieder passiert, ist: Ich ändere den Namen eines Objekts,\naber vergesse, an *allen* Stellen im Code den Namen anzupassen.\nGlücklicherweise gibt es hier eine einfache Abhilfe: Replace-All.\n\n\n### Portionieren\n\nEine andere, zentrale Maßnahme ist es, den Code in handlichen \"Häppchen\" zu verpacken.\nStatt einer Skriptdatei mit zich Tausend Zeilen, wünschen Sie sich doch sicher ein Skript der Art:\n\n```r\nmache_1()\nmache_2()\nmache_3()\ngratuliere_fertig()\n```\n\nFunktionales Programmieren ist eine Umsetzung davon: Jedes Häppchen, jeder Schritt\nist eine Funktion. \nEine Funktion hat Input und Output; der Output ist dann der Input für die Funktion des nächsten Schrittes.\n`{targets}` ist eine Umsetzung dieser Idee.\n\n\n### Debugging mit einem Logger\n\nWenn das Kind in dem Brunnen gefallen ist, hilft nur ~~Heulen und Wehklagen~~ Das Problem finden und lösen.\nMit einem Logger kann man sich das Entwanzen, das Finden der Fehler, erleichtern.\nEin Logger schreibt Zwischenschritte in eine Log-Datei.\n\nHier ist ein Beispiel mit dem [`futile` Logger:](https://github.com/zatonovo/futile.logger).\nMein Problem war, dass ich eine dynamische Aufgabe für eine Statistik-Klausur programmiert hatte,\naber leider gab es einen Bug, den ich nicht gefunden habe^[StackOverflow hat mich dann gerettet].\n\nDie Lösung brachte ein Logger, mit dem ich den Wert zentraler Variablen im Verlauf des Durchlaufens des Codes - bis eben der Laufzeitfehler aufkam^[ERROR!].\n\nHier ist ein Ausschnitt der Syntax. \nZuerst initialisiert man den Logger mit einer Datei, hier `exams.log`.\nNeue Logging-Inhalte sollen an die bestehenden Logs angehängt werden (appender).\n\n\n\n::: {.cell hash='projektmgt_cache/html/unnamed-chunk-4_fe8110b01f736ef0a10bddbb897f2a81'}\n\n```{.r .cell-code}\nlibrary(futile.logger)\nflog.appender(appender.file(\"/Users/sebastiansaueruser/github-repos/rexams-exams/exams.log\"))\n```\n:::\n\n\nDann gebe ich eine Loggings vom Typ \"Info\" zum Protokoll:\n\n\n\n::: {.cell hash='projektmgt_cache/html/unnamed-chunk-5_2993e3dfd1b39a0f0b8021d7cafa1808'}\n\n```{.r .cell-code}\nflog.info(paste0(\"Ex: post-uncertainty1\"))\nflog.info(msg = paste0(\"Data set: \", d_name))\nflog.info(paste0(\"Preds chosen: \", stringr::str_c(preds_chosen, collapse = \", \")))\nflog.info(paste0(\"Output var: \", av))\n```\n:::\n\n\n\nDie Ergebnisse kann man dann in der Logging-Datei anschauen:\n\n```\nNFO [2023-01-05 11:27:51] Rhats: 1.004503053029\nINFO [2023-01-05 11:27:51] Sol: 0.18\nINFO [2023-01-05 11:27:51] Sol typeof: double\nINFO [2023-01-05 11:27:52] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:52] Data set: tips\nINFO [2023-01-05 11:27:52] Preds chosen: size, total_bill\nINFO [2023-01-05 11:27:52] Output var: tip\nINFO [2023-01-05 11:27:53] Rhats: 0.999004883794722\nINFO [2023-01-05 11:27:53] Rhats: 1.00021605674421\nINFO [2023-01-05 11:27:53] Rhats: 1.00091357638756\nINFO [2023-01-05 11:27:53] Sol: 0.32\nINFO [2023-01-05 11:27:53] Sol typeof: double\nINFO [2023-01-05 11:27:54] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:54] Data set: TeachingRatings\nINFO [2023-01-05 11:27:54] Preds chosen: prof, beauty\nINFO [2023-01-05 11:27:54] Output var: eval\nINFO [2023-01-05 11:27:55] Rhats: 0.999060308710712\nINFO [2023-01-05 11:27:55] Rhats: 0.999032305267221\nINFO [2023-01-05 11:27:55] Rhats: 0.999229003550072\nINFO [2023-01-05 11:27:55] Sol: 0\nINFO [2023-01-05 11:27:55] Sol typeof: double\nINFO [2023-01-05 11:27:56] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:56] Data set: gtcars\nINFO [2023-01-05 11:27:56] Preds chosen: mpg_c, year\nINFO [2023-01-05 11:27:56] Output var: msrp\nINFO [2023-01-05 11:28:00] Rhats: 0.99913061005524\nINFO [2023-01-05 11:28:00] Rhats: 0.998999786100339\nINFO [2023-01-05 11:28:00] Rhats: 0.999130286784586\nINFO [2023-01-05 11:28:01] Sol: 21959.35\nINFO [2023-01-05 11:28:01] Sol typeof: double\n```\n\nJa, das sieht nicht schön aus.\nAber es brachte mir die Lösung:\nMir fiel auf, \ndass der Fehler nur auftrat, wenn `sol` einen großen Wert hatte (1000 oder mehr).\nDanke, Logger!\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}