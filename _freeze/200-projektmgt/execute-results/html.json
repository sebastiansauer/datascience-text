{
  "hash": "4f178334b4f4d14d028aa8592da63e04",
  "result": {
    "markdown": "# Projektmanagement\n\n\n## Pipeline-Management\n\n### Am Anfang\n\n\nSie haben Großes vor! \nNaja, zumindest planen Sie ein neues Data-Science-Projekt.\n\nUnd, schlau wie Sie sind,\nstürzen Sie nicht sofort an die Tastatur,\num sich einige Modelle berechnen zu lassen. Nein!\nSie denken erst einmal nach.\nZum Beispiel,\nwie die einzelnen Analyseschritte aussehen,\nworin sie bestehen, und in welcher Abfolge sie zu berechnen sind,\ns. @fig-projekt1.\n\n\n![So könnte Ihr Projektplan am Anfang aussehen, man spricht auch von einer Pipeline](img/project1.JPG){#fig-projekt1 width=80%}\n\n\n:::callout-note\nDen Graph der einzelnen Analyseschritte in ihrer Abhängigkeit bezeichnet man als *Pipeline.\n:::\n\n\n\n\n### Sie träumen von einem Werkzeug\n\n\nNach einiger Zeit überlegen Sie sich,\ndass Sie ein System bräuchten, das Ihre Skizze umsetzt in tatsächliche Berechnungen.\nUnd zwar suchen Sie ein Projektmanagement-System das folgendes Desiderata erfüllt:\n\n1. Es führt die einzelnen Schritte Ihres Projekt, die \"Pipeline\" in der richtigen Reihenfolge\n2. Es aktualisiert veraltete Objekte, aber es berechnet *nicht* Modelle neu, die unverändert sind\n3. Es ist gut zu debuggen\n\nJa, von so einem Werkzeug träumen Sie.\n\n\nUnd tatsächlich, Ihr Traum geht in Erfüllung. Dieses System existiert.\nGenau genommen gibt es viele Systeme,\ndie sich anschicken, Ihre Wünsche zu erfüllen.\nWir schauen uns eines näher an, das speziell für R gemacht ist.\nDas [R-Paket `targets`](https://books.ropensci.org/targets/).\n\n\n\n### Targets\n\n\nEs lohnt sich, an dieser Stelle den [\"Walkthrough\" aus dem Benutzerhandbuch](https://books.ropensci.org/targets/walkthrough.html) von Targets durchzuarbeiten.\n\n\n\nFür ein Projekt ähnlich zu den, die \nwir in diesem Buch bearbeiten,\nist folgende `_targets.R`-Datei ein guter Start.\n\n\n\n\n::: {.cell hash='200-projektmgt_cache/html/unnamed-chunk-1_34a23fde8036e0d650ae79b66b5b5c91'}\n\n```{.r .cell-code}\nlibrary(targets)\n\n\n# Funktionen einlesen:\n#purrr::walk(list.files(path = \"funs\", pattern = \".R\", full.names = TRUE), source)\nsource(\"funs/def-recipe.R\")\nsource(\"funs/read-train-data.R\")\nsource(\"funs/read-test-data.R\")\n\n# Optionen, z.B. allgemein verfügbare Pakete in den Targets:tar_option_set(packages = c(\"readr\", \n                            \"dplyr\", \n                            \"ggplot2\", \n                            \"purrr\", \n                            \"easystats\", \n                            \"tidymodels\", \n                            \"textrecipes\"))\n\n# Definition der Pipeline:\nlist(\n  tar_target(data_train, read_train_data()),\n  tar_target(data_test, read_test_data()),\n  tar_target(recipe1, def_recipe(data_train)\n  ),\n  tar_target(model1,\n             logistic_reg(penalty = tune(), mixture = 1) %>%\n               set_mode(\"classification\") %>%\n               set_engine(\"glmnet\")\n             ),\n  tar_target(workflow1,\n             workflow() %>% add_recipe(recipe1) %>% add_model(model1)\n             ),\n  tar_target(grid1,\n             grid_regular(penalty(), levels = 3)\n             ),\n  tar_target(grid_fitted,\n             tune_grid(workflow1, \n                       resamples = vfold_cv(data_train, v = 2),\n                       grid = grid1)\n  ),\n  tar_target(best_hyperparams,\n             select_by_one_std_err(grid_fitted, metric = \"roc_auc\", penalty)\n             ),\n  tar_target(fit1,\n             workflow1 %>% finalize_workflow(best_hyperparams) %>% fit(data_train)),\n  tar_target(preds,\n             fit1 %>% \n               predict(data_test) %>% \n               bind_cols(data_test) %>% \n               mutate(c1 = factor(c1))),\n  tar_target(metrics1,\n             preds %>% metrics(truth = c1, .pred_class))\n)\n```\n:::\n\n\n\n\nDann kann man auf den Play-Button drücken und die ganze Pipeline wird berechnet:\n\n\n::: {.cell hash='200-projektmgt_cache/html/unnamed-chunk-2_3be315ec83a4e4573fec708fddff5fe4'}\n\n```{.r .cell-code}\ntar_make()\n```\n:::\n\n\nWenn die Pipeline aktuell ist, und nichts berechnet werden muss (und daher auch schon fehlerfrei durchgelaufen ist), sieht die Ausgabe so aus:\n\n```\n✔ skip target grid1\n✔ skip target model1\n✔ skip target data_train\n✔ skip target data_test\n✔ skip target recipe1\n✔ skip target workflow1\n✔ skip target grid_fitted\n✔ skip target best_hyperparams\n✔ skip target fit1\n✔ skip target preds\n✔ skip target metrics1\n✔ skip pipeline [0.121 seconds]\n```\n\n\nDie Pipeline kann man sich als DAG bzw. als Abhängigkeitsgraph visualisieren lassen:\n\n\n::: {.cell hash='200-projektmgt_cache/html/unnamed-chunk-3_983ad52e68d2b43f1d06791c6a7c6357'}\n\n```{.r .cell-code}\ntar_visnetwork()\n```\n:::\n\n\n\n![Abhängigkeitsgraph der Pipeline](img/tar-network1.png)\n\n\n\nEinzelne Objekte kann man sich komfortabel anschauen mit `tar_load(objekt)`,\nz.B. `tar_load(fit1)` usw.\n\n\n\n### Eine Pipeline als Spielwiese\n\n\n[Dieses Github-Repo](https://github.com/sebastiansauer/targets-playground) stellt Ihnen eine \"Spielwiese\" zur Verfügung,\nwo Sie sich mit Pipleines à la Targets vertraut machen können.\n\n\n\n## Zeit sparen\n\nEiner Maschine etwas beizubringen kann dauern ...\nEin einfaches Rechenbeispiel dazu:\n\n- Sie haben eine Kreuzvalidierung mit 10 Faltungen\n- und 3 Wiederholungen\n- und 3 Tuningparameter\n- mit je 10 Werten\n\nDas sind 10*3*3*10=900 Wiederholungen. \n\nLeider haben Sie noch in den ersten 10 Versuchen jeweils einen Bug,\nso dass sich die Rechenzeit noch einmal um den Faktor 10 erhöht...\n\nDie Rechenzeit kann also schnell ins astronomische steigen. Es braucht also Methoden, um Rechenzeit zu sparen.^[Allerdings haben lange Rechenzeiten auch Vorteile, wie [dieses XKCD-Cartoon](https://xkcd.com/303/) zeigt.]\nEinige Methoden zum Rechenzeit sparen sind:\n\n\n- *Cloud*: Cloud-Dienste in Anspruch nehmen (faktisch mietet man damit schnelle Rechner)\n- *Parallelisierung*: Mehrere Kerne des eigenen Computers nutzen\n- *Upgrade*: Kaufen Sie sich einen schnelleren Rechner...\n- *Cleveres Grid-Search*: Methoden wie [ANOVA Racing](https://finetune.tidymodels.org/reference/tune_race_anova.html) können die Rechenzeit - was das Tuning - betrifft - deutlich verringern. \n\n\n[Dieser Post](https://uliniemann.com/blog/2022-07-04-comparing-hyperparameter-tuning-strategies-with-tidymodels/) gibt einen Überblick zu Rechenzeiten bei verschiedenen Tuningparameter-Optionen mit Tidymodels.\n\n\nNatürlich ist die (mit Abstand) beste Methode: guten Code schreiben. Denn \"guter Code\" verringert die Wahrscheinlichkeit von Bugs, und damit die Gefahr, dass die ganze schöne Rechenzeit für die Katz war.\n\n\"Guter Code\" ist vielleicht primär von zwei Dingen abhängig: erstens einen guten Plan zu haben *bevor* man das Programmieren anfängt und zweitens gute Methoden des Projektmanagements.\n@hunt_pragmatic_2000 präsentieren eine weithin anerkannte Umsetzung, was \"guter\" Code bedeuten könnte.\n\n\n## Publizieren \n\n\nSie haben eine super Analyse geschrieben, eine schicke Pipeline, und jetzt soll die Welt davon erfahren?\nEs gibt einige komfortable Möglichkeiten, Ihre Arbeit zu publizieren,\nz.B. als Blog mit [Quarto](https://quarto.org/).\n\n[Dieses Video](https://youtu.be/d3Xnvi2_HB4) zeigt Ihnen wie man einen Quarto-Blog in RStudio erstellt und ihn bei [Netlify](https://www.netlify.com/) publiziert.\n\n\n\n{{< video https://youtu.be/d3Xnvi2_HB4 width=\"400\" height=\"300\" >}}\n\n\n\nDas Hosten bzw. Deployen bei Netlify ist kostenlos (in der Basis-Variante).\n\nSie können alternativ [Github Pages](https://pages.github.com/) als Hosting-Dienst verwenden. [Dieses Video](https://youtu.be/-GA_Afz_jI4) gibt dazu eine Anleitung.\n\n\n\n## Komplexitätsmanagement\n\n\nProgrammieren ist faszinierend. Vor allem, wenn das Programm funktioniert. \nGenau genommen ist es eigentlich nur dann faszinierend, ansonsten wird es anstrengend? aufregend? süchtig? faszinierend? nervig?\nWie auch immer: Bugs treten auf und mit steigender Komplexität Ihrer Software steigen die Bugs nicht linear,\nsondern eher quadratisch oder gar exponentiell an.\n\nEs gibt viele Ansätze, sich gegen die Komplexität zu \"wehren\". \nDer beste ist vielleicht: Die Software so einfach wie möglich zu halten - und\nnur so komplex wie nötig. Sozusagen:\nDas beste Feature ist das, das Sie nicht implementieren.\n\n\n\n\n### Geben Sie gute Namen\n\nDaraus leitet sich ab, \ndass die zentralen Methoden, um der Fehler Herr zu werden im Komplexitätsmanagement liegen.\nDen Variablen (Objekten) gute, \"sprechende\" aber prägnante Namen zu geben, ist\nin diesem Lichte auch als Komplexitätsmanagement (Reduktion) zu verstehen.\n\nEin typischer Fehler, der mir immer mal wieder passiert, ist: Ich ändere den Namen eines Objekts,\naber vergesse, an *allen* Stellen im Code den Namen anzupassen.\nGlücklicherweise gibt es hier eine einfache Abhilfe: Replace-All.\n\n\n### Portionieren\n\nEine andere, zentrale Maßnahme ist es, den Code in handlichen \"Häppchen\" zu verpacken.\nStatt einer Skriptdatei mit zich Tausend Zeilen, wünschen Sie sich doch sicher ein Skript der Art:\n\n```r\nmache_1()\nmache_2()\nmache_3()\ngratuliere_fertig()\n```\n\nSchaut man dann in `mache_1()` rein, sieht man wiederum übersichtlichen Code.\n\nFunktionales Programmieren ist eine Umsetzung davon: Jedes Häppchen, jeder Schritt\nist eine Funktion. \nEine Funktion hat Input und Output; der Output ist dann der Input für die Funktion des nächsten Schrittes.\n`{targets}` ist eine Umsetzung dieser Idee.\n\n\n### Debugging mit einem Logger\n\nWenn das Kind in dem Brunnen gefallen ist, hilft nur ~~Heulen und Wehklagen~~ Das Problem finden und lösen.\nMit einem Logger kann man sich das Entwanzen, das Finden der Fehler, erleichtern.\nEin Logger schreibt Zwischenschritte in eine Log-Datei.\n\nHier ist ein Beispiel mit dem [`futile` Logger:](https://github.com/zatonovo/futile.logger).\nMein Problem war, dass ich eine dynamische Aufgabe für eine Statistik-Klausur programmiert hatte,\naber leider gab es einen Bug, den ich nicht gefunden habe^[StackOverflow hat mich dann gerettet].\n\nDie Lösung brachte ein Logger, mit dem ich den Wert zentraler Variablen im Verlauf des Durchlaufens des Codes - bis eben der Laufzeitfehler aufkam^[ERROR!].\n\nHier ist ein Ausschnitt der Syntax. \nZuerst initialisiert man den Logger mit einer Datei, hier `exams.log`.\nNeue Logging-Inhalte sollen an die bestehenden Logs angehängt werden (appender).\n\n\n\n::: {.cell hash='200-projektmgt_cache/html/unnamed-chunk-4_e2291f99891a87d79bf8947b64220fa3'}\n\n```{.r .cell-code}\nlibrary(futile.logger)\nflog.appender(appender.file(\"/Users/sebastiansaueruser/github-repos/rexams-exams/exams.log\"))\n```\n:::\n\n\nDann gebe ich eine Loggings vom Typ \"Info\" zum Protokoll:\n\n\n\n::: {.cell hash='200-projektmgt_cache/html/unnamed-chunk-5_68960ee091f03b786b7672c4a2c8d96d'}\n\n```{.r .cell-code}\nflog.info(paste0(\"Ex: post-uncertainty1\"))\nflog.info(msg = paste0(\"Data set: \", d_name))\nflog.info(paste0(\"Preds chosen: \", stringr::str_c(preds_chosen, collapse = \", \")))\nflog.info(paste0(\"Output var: \", av))\n```\n:::\n\n\n\nDie Ergebnisse kann man dann in der Logging-Datei anschauen:\n\n```\nNFO [2023-01-05 11:27:51] Rhats: 1.004503053029\nINFO [2023-01-05 11:27:51] Sol: 0.18\nINFO [2023-01-05 11:27:51] Sol typeof: double\nINFO [2023-01-05 11:27:52] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:52] Data set: tips\nINFO [2023-01-05 11:27:52] Preds chosen: size, total_bill\nINFO [2023-01-05 11:27:52] Output var: tip\nINFO [2023-01-05 11:27:53] Rhats: 0.999004883794722\nINFO [2023-01-05 11:27:53] Rhats: 1.00021605674421\nINFO [2023-01-05 11:27:53] Rhats: 1.00091357638756\nINFO [2023-01-05 11:27:53] Sol: 0.32\nINFO [2023-01-05 11:27:53] Sol typeof: double\nINFO [2023-01-05 11:27:54] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:54] Data set: TeachingRatings\nINFO [2023-01-05 11:27:54] Preds chosen: prof, beauty\nINFO [2023-01-05 11:27:54] Output var: eval\nINFO [2023-01-05 11:27:55] Rhats: 0.999060308710712\nINFO [2023-01-05 11:27:55] Rhats: 0.999032305267221\nINFO [2023-01-05 11:27:55] Rhats: 0.999229003550072\nINFO [2023-01-05 11:27:55] Sol: 0\nINFO [2023-01-05 11:27:55] Sol typeof: double\nINFO [2023-01-05 11:27:56] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:56] Data set: gtcars\nINFO [2023-01-05 11:27:56] Preds chosen: mpg_c, year\nINFO [2023-01-05 11:27:56] Output var: msrp\nINFO [2023-01-05 11:28:00] Rhats: 0.99913061005524\nINFO [2023-01-05 11:28:00] Rhats: 0.998999786100339\nINFO [2023-01-05 11:28:00] Rhats: 0.999130286784586\nINFO [2023-01-05 11:28:01] Sol: 21959.35\nINFO [2023-01-05 11:28:01] Sol typeof: double\n```\n\nJa, das sieht nicht schön aus.\nAber es brachte mir die Lösung:\nMir fiel auf, \ndass der Fehler nur auftrat, wenn `sol` einen großen Wert hatte (1000 oder mehr).\nDanke, Logger!\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}