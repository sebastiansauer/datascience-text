{
  "hash": "ef32f8da22cad63d227c5b94f27b747d",
  "result": {
    "engine": "knitr",
    "markdown": "\n\n# Klassifikation von Hatespeech\n\n\n\n\n\n## Vorab\n\n\n### Lernziele\n\n\n- Sie k√∂nnen grundlegende Verfahren zur Klassifikation von Hatespeech einsetzen und erkl√§ren\n\n\n\n\n\n\n\n\n### Ben√∂tigte R-Pakete und Skripte\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(tidymodels)\nlibrary(tidytext)  # Textmiing\nlibrary(textrecipes)  # Textanalysen in Tidymodels-Rezepten\nlibrary(lsa)  # stopwords\nlibrary(discrim)  # naive bayes classification\nlibrary(naivebayes)\nlibrary(tictoc)  # Zeitmessung\nlibrary(fastrtext)  # Worteinbettungen\nlibrary(remoji)  # Emojis\nlibrary(tokenizers)  # Vektoren tokenisieren\nlibrary(tictoc)  # Zeitmessung\n\nsource(\"funs/helper-funs-recipes.R\")\n```\n:::\n\n\n\n## Daten\n\n\nF√ºr Maschinenlernen brauchen wir Trainingsdaten,\nDaten also, bei denen wir pro Beobachtung der Wert der Zielvariablen kennen.\nMan spricht auch von \"gelabelten\" Daten.\n\nWir nutzen die Daten von @germeval bzw. @wiegand-data.\nDie Daten sind unter CC-By-4.0 Int. lizensiert.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_raw <- \n  data_read(\"data/germeval2018.training.txt\",\n         header = FALSE,\n         quote = \"\")\n```\n:::\n\n\n\nDie Daten finden sich auch im Paket [pradadata](https://github.com/sebastiansauer/pradadata).\n\nDa die Daten keine Spaltenk√∂pfe haben, informieren wir die Funktion dazu mit `header = FALSE`.\n\nBenennen wir die die Spalten um:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(d_raw) <- c(\"text\", \"c1\", \"c2\")\n```\n:::\n\n\nDabei soll `c1` und `c2` f√ºr die 1. bzw. 2. Klassifikation stehen.\n\n\nIn `c1` finden sich diese Werte:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_raw %>% \n  count(c1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"c1\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"OFFENSE\",\"2\":\"1688\"},{\"1\":\"OTHER\",\"2\":\"3321\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nMit `c1` wurde klassifiziert,\nob beleidigende Sprache (offensive language) vorlag oder nicht [@risch-etal-2021-overview, S. 2], also `OFFENSE` bzw. `OTHER`:\n\n\n\n>   Task 1 was to decide whether a tweet includes some form of offensive language or not. The tweets had to be classiÔ¨Åed into the two classes OFFENSE and OTHER. The OFFENSE category covered abusive language, insults, as well as merely profane statements.\n\n\nUnd in `c2` finden sich die vier Auspr√§gungen `ABUSE`, `INSULT`, `PROFANITY` und `OTHER`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_raw %>% \n  count(c2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"c2\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"ABUSE\",\"2\":\"1022\"},{\"1\":\"INSULT\",\"2\":\"595\"},{\"1\":\"OTHER\",\"2\":\"3321\"},{\"1\":\"PROFANITY\",\"2\":\"71\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nIn `c2` ging es um eine *feinere Klassifikation* beleidigender Sprache [@risch-etal-2021-overview, S. 2]:\n\n>   The second task involved four categories, a nonoffensive OTHER class and three sub-categories of what is OFFENSE in Task 1. In the case of PROFANITY, profane words are used, however, the tweet does not want to insult anyone. This typically concerns the usage of swearwords (Schei√üe, Fuck etc.) and cursing (Zur H√∂lle! Verdammt! etc.). This can be often found in youth language. Swearwords and cursing may, but need not, co-occur with insults or abusive speech. Profane language may in fact be used in tweets with positive sentiment to express emphasis. Whenever profane words are not directed towards a speciÔ¨Åc person or group of persons and there are no separate cues of INSULT or ABUSE, then tweets are labeled as simple cases of PROFANITY.\n\n\n\n\nSind Texte, die als `OFFENSE` klassifiziert sind,\nauch (fast) immer nie als `OTHER`, sondern stattdessen als `ABUSE`, `INSULT` oder `PROFANITY` klassifiziert?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_raw %>% \n  filter(c1 == \"OFFENSE\", c2 != \"OTHER\") %>% \n  nrow() / nrow(d_raw)\n## [1] 0.3369934\n```\n:::\n\n\n\nIn ca. 2/3 der F√§lle wurden in beiden Klassifikation `OTHER` klassifiziert:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_raw %>% \n  filter(c1 == \"OTHER\", c2 == \"OTHER\") %>% \n  nrow() / nrow(d_raw)\n## [1] 0.6630066\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_raw %>% \n  filter(c1 != \"OTHER\", c2 != \"OTHER\") %>% \n  nrow() / nrow(d_raw)\n## [1] 0.3369934\n```\n:::\n\n\nEntsprechend in ca. 1/3 der F√§lle wurde jeweils nicht mit `OTHER` klassifiziert.\n\n\nWir begn√ºgen uns hier mit der ersten, gr√∂beren Klassifikation.\n\n\n\nF√ºgen wir abschlie√üend noch eine ID-Variable hinzu:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd1 <-\n  d_raw %>% \n  mutate(id = as.character(1:nrow(.)))\n```\n:::\n\n\n\nDie *ID-Variable* definieren als *Text* (nicht als Integer),\nda die Twitter-IDs zwar nat√ºrliche Zahlen sind,\naber zu gro√ü, um von R als Integer verarbeitet zu werden.\nFaktisch sind sie f√ºr uns auch nur nominal skalierte Variablen,\nso dass wir keinen Informationsverlust haben.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(d1, \"objects/d1.rds\")\n```\n:::\n\n\n\n\n## Feature Engineering\n\n\nReichern wir die Daten mit weiteren Features an,\nin der Hoffnung, damit eine bessere Klassifikation erzielen zu k√∂nnen.\n\n\n### Textl√§nge\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd2 <-\n  d1 %>% \n  mutate(text_length = str_length(text))\n\nhead(d2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"text\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"c1\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"c2\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"id\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"text_length\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\",\"2\":\"OTHER\",\"3\":\"OTHER\",\"4\":\"1\",\"5\":\"109\",\"_rn_\":\"1\"},{\"1\":\"@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\",\"2\":\"OTHER\",\"3\":\"OTHER\",\"4\":\"2\",\"5\":\"142\",\"_rn_\":\"2\"},{\"1\":\"@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\",\"2\":\"OTHER\",\"3\":\"OTHER\",\"4\":\"3\",\"5\":\"69\",\"_rn_\":\"3\"},{\"1\":\"@dushanwegner Amis h√§tten alles und jeden gew√§hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\",\"2\":\"OTHER\",\"3\":\"OTHER\",\"4\":\"4\",\"5\":\"140\",\"_rn_\":\"4\"},{\"1\":\"@spdde kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\",\"2\":\"OFFENSE\",\"3\":\"INSULT\",\"4\":\"5\",\"5\":\"136\",\"_rn_\":\"5\"},{\"1\":\"@Dirki_M Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\",\"2\":\"OTHER\",\"3\":\"OTHER\",\"4\":\"6\",\"5\":\"284\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n### Sentimentanalyse\n\nWir nutzen dazu `SentiWS` [@Remus2010].\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsentiws <- read_csv(\"https://osf.io/x89wq/?action=download\")\n## Rows: 3468 Columns: 4\n## ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Delimiter: \",\"\n## chr (3): neg_pos, word, inflections\n## dbl (1): value\n## \n## ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n## ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd2_long <-\n  d2 %>% \n  unnest_tokens(input = text, output = token)\n\nhead(d2_long)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"c1\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"c2\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"id\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"text_length\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"token\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"corinnamilborn\",\"_rn_\":\"1\"},{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"liebe\",\"_rn_\":\"2\"},{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"corinna\",\"_rn_\":\"3\"},{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"wir\",\"_rn_\":\"4\"},{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"w√ºrden\",\"_rn_\":\"5\"},{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"dich\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nJetzt filtern wir unsere Textdaten so,\ndass nur W√∂rter mit Sentimentwert √ºbrig bleiben:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd2_long_senti <- \n  d2_long %>%  \n  inner_join(sentiws %>% select(-inflections), by = c(\"token\" = \"word\"))\n## Warning in inner_join(., sentiws %>% select(-inflections), by = c(token = \"word\")): Detected an unexpected many-to-many relationship between `x` and `y`.\n## ‚Ñπ Row 1559 of `x` matches multiple rows in `y`.\n## ‚Ñπ Row 2572 of `y` matches multiple rows in `x`.\n## ‚Ñπ If a many-to-many relationship is expected, set `relationship =\n##   \"many-to-many\"` to silence this warning.\n\nhead(d2_long)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"c1\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"c2\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"id\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"text_length\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"token\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"corinnamilborn\",\"_rn_\":\"1\"},{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"liebe\",\"_rn_\":\"2\"},{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"corinna\",\"_rn_\":\"3\"},{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"wir\",\"_rn_\":\"4\"},{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"w√ºrden\",\"_rn_\":\"5\"},{\"1\":\"OTHER\",\"2\":\"OTHER\",\"3\":\"1\",\"4\":\"109\",\"5\":\"dich\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nSchlie√ülich berechnen wir die Sentimentwert pro Polarit√§t und pro Tweet:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd2_sentis <-\n  d2_long_senti %>% \n  group_by(id, neg_pos) %>% \n  summarise(senti_avg = mean(value))\n## `summarise()` has grouped output by 'id'. You can override using the `.groups`\n## argument.\n\nhead(d2_sentis)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"neg_pos\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"senti_avg\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"pos\",\"3\":\"0.0040\"},{\"1\":\"1012\",\"2\":\"neg\",\"3\":\"-0.2087\"},{\"1\":\"1013\",\"2\":\"neg\",\"3\":\"-0.0420\"},{\"1\":\"1015\",\"2\":\"neg\",\"3\":\"-0.0048\"},{\"1\":\"1021\",\"2\":\"pos\",\"3\":\"0.0845\"},{\"1\":\"1024\",\"2\":\"neg\",\"3\":\"-0.4787\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nDiese Tabelle bringen wir wieder eine breitere Form,\num sie dann wieder mit den Hauptdaten zu vereinigen.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd2_sentis_wide <-\n  d2_sentis %>% \n  pivot_wider(names_from = \"neg_pos\", values_from = \"senti_avg\")\n\nd2_sentis_wide %>% head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"pos\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"neg\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"0.0040\",\"3\":\"NA\"},{\"1\":\"1012\",\"2\":\"NA\",\"3\":\"-0.2087\"},{\"1\":\"1013\",\"2\":\"NA\",\"3\":\"-0.0420\"},{\"1\":\"1015\",\"2\":\"NA\",\"3\":\"-0.0048\"},{\"1\":\"1021\",\"2\":\"0.0845\",\"3\":\"NA\"},{\"1\":\"1024\",\"2\":\"0.0040\",\"3\":\"-0.4787\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd3 <-\n  d2 %>% \n  full_join(d2_sentis_wide)\n## Joining with `by = join_by(id)`\n\nhead(d3)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"text\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"c1\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"c2\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"id\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"text_length\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"pos\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"neg\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\",\"2\":\"OTHER\",\"3\":\"OTHER\",\"4\":\"1\",\"5\":\"109\",\"6\":\"0.004\",\"7\":\"NA\",\"_rn_\":\"1\"},{\"1\":\"@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\",\"2\":\"OTHER\",\"3\":\"OTHER\",\"4\":\"2\",\"5\":\"142\",\"6\":\"NA\",\"7\":\"-0.3466\",\"_rn_\":\"2\"},{\"1\":\"@ahrens_theo fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\",\"2\":\"OTHER\",\"3\":\"OTHER\",\"4\":\"3\",\"5\":\"69\",\"6\":\"NA\",\"7\":\"NA\",\"_rn_\":\"3\"},{\"1\":\"@dushanwegner Amis h√§tten alles und jeden gew√§hlt...nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\",\"2\":\"OTHER\",\"3\":\"OTHER\",\"4\":\"4\",\"5\":\"140\",\"6\":\"NA\",\"7\":\"NA\",\"_rn_\":\"4\"},{\"1\":\"@spdde kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\",\"2\":\"OFFENSE\",\"3\":\"INSULT\",\"4\":\"5\",\"5\":\"136\",\"6\":\"NA\",\"7\":\"NA\",\"_rn_\":\"5\"},{\"1\":\"@Dirki_M Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\",\"2\":\"OTHER\",\"3\":\"OTHER\",\"4\":\"6\",\"5\":\"284\",\"6\":\"0.004\",\"7\":\"-0.2042\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n:::callout-note\nDie Sentimentanalyse hier vernachl√§ssigt Flexionen der W√∂rter. \nDer  Autor f√ºhlt den Drang zu schreiben: \"Left as an exercise for the reader\" :-)\n:::\n\n\n### Schimpfw√∂rter\n\n\nZ√§hlen wir die Schimpfw√∂rter pro Text.\nDazu nutzen wir die Daten von [LDNOOBW](https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/blob/master/LICENSE), lizensiert nach CC-BY-4.0-Int.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nschimpf1 <- read_csv(\"https://raw.githubusercontent.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/master/de\", col_names = FALSE)\n## Rows: 66 Columns: 1\n## ‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Delimiter: \",\"\n## chr (1): X1\n## \n## ‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n## ‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n\n\nL√§nger aber noch ist die Liste aus dem [InsultWiki](https://www.insult.wiki/schimpfwort-liste), lizensiert CC0.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nschimpf2 <- \n  data_read(\"data/insult-de.txt\", header = FALSE) %>% \n  mutate_all(str_to_lower)\n```\n:::\n\n\n\n\nDie Daten finden sich auch im Paket [pradadata](https://github.com/sebastiansauer/pradadata).\n\nBinden wir die Listen zusammen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nschimpf <-\n  schimpf1 %>% \n  bind_rows(schimpf2) %>% \n  distinct() %>% \n  rename(word = \"V1\")\n\nnrow(schimpf)\n## [1] 6235\n```\n:::\n\n\n\nUm die Lesis vor (unn√∂tiger?) Kopfverschmutzung zu bewahren,\nsind diese Schimpfw√∂rter hier nicht abgedruckt.\n\nJetzt z√§hlen wir, ob unsere Tweets/Texte solcherlei W√∂rter enthalten.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_schimpf <- \nd2_long %>% \n  select(id, token) %>% \n  mutate(schimpf = token %in% schimpf$word)\n```\n:::\n\n\n\nWie viele Schimpfw√∂rter haben wir gefunden?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_schimpf %>% \n  count(schimpf)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"schimpf\"],\"name\":[1],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"FALSE\",\"2\":\"99105\"},{\"1\":\"TRUE\",\"2\":\"1112\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nEtwa ein Prozent der W√∂rter (ca. 1k) sind Schimpfw√∂rter in unserem Corpus.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_schimpf2 <-\n  d_schimpf %>% \n  group_by(id) %>% \n  summarise(schimpf_n = sum(schimpf))\n\nhead(d_schimpf2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"schimpf_n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"0\"},{\"1\":\"10\",\"2\":\"0\"},{\"1\":\"100\",\"2\":\"0\"},{\"1\":\"1000\",\"2\":\"0\"},{\"1\":\"1001\",\"2\":\"0\"},{\"1\":\"1002\",\"2\":\"0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_main <-\n  d3 %>% \n  full_join(d_schimpf2)\n## Joining with `by = join_by(id)`\n```\n:::\n\n\n\n:::callout-important\nNamen wie `final`, `main` oder `result` sind gef√§hrlich,\nda es unter Garantie ein \"final-final geben wird, oder der \"Haupt-Datensatz\" pl√∂tzlich nicht mehr so wichtig erscheint und so weiter.\n:::\n\n\n\n### Emojis\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nemj <- emoji(list_emoji(), pad = FALSE)\n\nhead(emj)\n## [1] \"üòÑ\" \"üòÉ\" \"üòÄ\" \"üòä\" \"‚ò∫Ô∏è\"  \"üòâ\"\n```\n:::\n\n\nDiese Liste umfasst knapp 900 Emojis, \ndas sind allerdings noch nicht alle, die es gibt.\n[Diese Liste](https://unicode.org/emoji/charts/full-emoji-list.html) umfasst mit gut 1800 Emojis\ngut das Doppelte.\n\n\nSelbstkuratierte Liste an \"wilden\" Emoji;\ndiese Liste ist inspiriert von [emojicombos.com](https://emojicombos.com/disgust).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwild_emojis <- \n  c(\n    emoji(find_emoji(\"gun\")),\n    emoji(find_emoji(\"bomb\")),\n    emoji(find_emoji(\"fist\")),\n    emoji(find_emoji(\"knife\"))[1],\n    emoji(find_emoji(\"ambulance\")),\n    emoji(find_emoji(\"fist\")),\n    emoji(find_emoji(\"skull\")),\n    \"‚ò†Ô∏è\",     \"üóë\",       \"üò†\",    \"üëπ\",    \"üí©\" ,\n    \"üñï\",    \"üëéÔ∏è\",\n    emoji(find_emoji(\"middle finger\")),    \"üò°\",    \"ü§¢\",    \"ü§Æ\",  \n    \"üòñ\",    \"üò£\",    \"üò©\",    \"üò®\",    \"üòù\",    \"üò≥\",    \"üò¨\",    \"üò±\",    \"üòµ\",\n       \"üò§\",    \"ü§¶‚Äç‚ôÄÔ∏è\",    \"ü§¶‚Äç\"\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwild_emojis_df <-\n  tibble(emoji = wild_emojis)\n\n#save(wild_emojis_df, file = \"data/wild_emojis.RData\")\n```\n:::\n\n\n\n\nAuf dieser Basis k√∂nnen wir einen Pr√§diktor erstellen,\nder z√§hlt, ob ein Tweet einen oder mehrere der \"wilden\" Emojis enth√§lt.\n\n\n## Workflow 1: TF-IDF + Naive-Bayes\n\n\n### Dummy-Rezept\n\n\nHier ist ein einfaches Beispiel,\num die Textvorbereitung mit `{textrecipes}` zu verdeutlichen.\n\nWir erstellen uns einen Dummy-Text:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndummy <- \n  tibble(text = c(\"Ich gehe heim und der die das nicht in ein and the\"))\n```\n:::\n\n\n\nDann tokenisieren wir den Text:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_dummy <-\n  recipe(text ~ 1, data = dummy) %>% \n  step_tokenize(text)\n  \nrec_dummy\n## \n## ‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## ‚îÄ‚îÄ Inputs\n## Number of variables by role\n## outcome: 1\n## \n## ‚îÄ‚îÄ Operations\n## ‚Ä¢ Tokenization for: text\n```\n:::\n\n\n\nDie Tokens kann man sich so zeigen lassen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_tokens(rec_dummy, text)\n## [[1]]\n##  [1] \"ich\"   \"gehe\"  \"heim\"  \"und\"   \"der\"   \"die\"   \"das\"   \"nicht\" \"in\"   \n## [10] \"ein\"   \"and\"   \"the\"\n```\n:::\n\n\n\nJetzt entfernen wir die Stopw√∂rter deutscher Sprache;\ndaf√ºr nutzen wir die Stopwort-Quelle `snowball`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_dummy <-\n  recipe(text ~ 1, data = dummy) %>% \n  step_tokenize(text) %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\")\n\nrec_dummy\n## \n## ‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## ‚îÄ‚îÄ Inputs\n## Number of variables by role\n## outcome: 1\n## \n## ‚îÄ‚îÄ Operations\n## ‚Ä¢ Tokenization for: text\n## ‚Ä¢ Stop word removal for: text\n```\n:::\n\n\n\nPr√ºfen wir die Tokens; \nsind die Stopw√∂rter wirklich entfernt?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_tokens(rec_dummy, text)\n## [[1]]\n## [1] \"gehe\" \"heim\" \"and\"  \"the\"\n```\n:::\n\n\n\nJa, die deutschen Stopw√∂rter sind entfernt. Die englischen nicht;\ndas macht Sinn!\n\n\n### Datenaufteilung\n\nDen Datensatz `d_main` kann man sich auch hier importieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#d_main <- read_rds(file = \"objects/chap-klassifik/d_main.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nd_split <- initial_split(d_main, strata = c1)\n\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n\n\n\n### Rezept\n\n\nRezept definieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1 <- \n  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% \n  update_role(id, new_role = \"id\") %>% \n  # step_mutate(text_copy = text) |> \n  step_tokenize(text) %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>% \n  step_stem(text) %>% \n  step_tokenfilter(text, max_tokens = 1e2) %>%  # wir behalten nur die h√§ufigsten Tokens\n  step_tfidf(text) \n\nrec1\n## \n## ‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## ‚îÄ‚îÄ Inputs\n## Number of variables by role\n## outcome:   1\n## predictor: 1\n## id:        1\n## \n## ‚îÄ‚îÄ Operations\n## ‚Ä¢ Tokenization for: text\n## ‚Ä¢ Stop word removal for: text\n## ‚Ä¢ Stemming for: text\n## ‚Ä¢ Text filtering for: text\n## ‚Ä¢ Term frequency-inverse document frequency with: text\n```\n:::\n\n\n\nPreppen. Und backen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec1_prepped <- prep(rec1)\n\nd_rec1 <- bake(rec1_prepped, new_data = NULL)\n\nhead(d_rec1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"c1\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"tfidf_text__macmik\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_2\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_ab\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_afd\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_amp\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_anna_iina\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_athinamala\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_beim\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_besser\"],\"name\":[11],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_bild\"],\"name\":[12],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_cdu\"],\"name\":[13],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_charlie_silv\"],\"name\":[14],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_csu\"],\"name\":[15],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_d\"],\"name\":[16],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_daf√ºr\"],\"name\":[17],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_dank\"],\"name\":[18],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_dass\"],\"name\":[19],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_deutsch\"],\"name\":[20],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_deutschen\"],\"name\":[21],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_deutschland\"],\"name\":[22],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_dumm\"],\"name\":[23],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_einfach\"],\"name\":[24],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_ellibisathid\"],\"name\":[25],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_endlich\"],\"name\":[26],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_ennof_\"],\"name\":[27],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_erst\"],\"name\":[28],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_eu\"],\"name\":[29],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_europa\"],\"name\":[30],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_feldenfrizz\"],\"name\":[31],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_fl√ºchtling\"],\"name\":[32],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_focusonlin\"],\"name\":[33],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_frage\"],\"name\":[34],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_frau\"],\"name\":[35],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_ganz\"],\"name\":[36],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_geht\"],\"name\":[37],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_gerad\"],\"name\":[38],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_gibt\"],\"name\":[39],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_gott\"],\"name\":[40],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_gr√ºnen\"],\"name\":[41],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_gt\"],\"name\":[42],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_gut\"],\"name\":[43],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_heut\"],\"name\":[44],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_immer\"],\"name\":[45],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_info2099\"],\"name\":[46],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_islam\"],\"name\":[47],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_ja\"],\"name\":[48],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_jahr\"],\"name\":[49],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_klar\"],\"name\":[50],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_kommt\"],\"name\":[51],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_krippmari\"],\"name\":[52],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_land\"],\"name\":[53],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_lassen\"],\"name\":[54],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_lbr\"],\"name\":[55],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_leben\"],\"name\":[56],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_leut\"],\"name\":[57],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_lifetrend\"],\"name\":[58],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_link\"],\"name\":[59],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_macht\"],\"name\":[60],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_machtjanix23\"],\"name\":[61],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_mal\"],\"name\":[62],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_md_franz\"],\"name\":[63],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_mehr\"],\"name\":[64],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_menschen\"],\"name\":[65],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_merkel\"],\"name\":[66],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_miriamozen\"],\"name\":[67],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_moslem\"],\"name\":[68],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_m√ºssen\"],\"name\":[69],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_nancypeggymandi\"],\"name\":[70],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_nasanas\"],\"name\":[71],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_nie\"],\"name\":[72],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_noherrman\"],\"name\":[73],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_norbinator2403\"],\"name\":[74],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_petpanther0\"],\"name\":[75],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_politik\"],\"name\":[76],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_recht\"],\"name\":[77],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_richtig\"],\"name\":[78],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_schmiddiemaik\"],\"name\":[79],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_schon\"],\"name\":[80],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_schulz\"],\"name\":[81],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_seit\"],\"name\":[82],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_sollten\"],\"name\":[83],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_spd\"],\"name\":[84],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_tagesschau\"],\"name\":[85],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_thomasgbau\"],\"name\":[86],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_troll_putin\"],\"name\":[87],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_trump\"],\"name\":[88],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_tun\"],\"name\":[89],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_t√ºrken\"],\"name\":[90],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_u\"],\"name\":[91],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_unser\"],\"name\":[92],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_viel\"],\"name\":[93],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_volk\"],\"name\":[94],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_w√§re\"],\"name\":[95],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_warum\"],\"name\":[96],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_welt\"],\"name\":[97],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_wer\"],\"name\":[98],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_willjrosenblatt\"],\"name\":[99],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_wohl\"],\"name\":[100],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_wurd\"],\"name\":[101],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_zeit\"],\"name\":[102],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"5\",\"2\":\"OFFENSE\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0.000000\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0.000000\",\"21\":\"0.000000\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0.000000\",\"38\":\"0\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0\",\"42\":\"0\",\"43\":\"0\",\"44\":\"0.000000\",\"45\":\"0.000000\",\"46\":\"0\",\"47\":\"0\",\"48\":\"0.000000\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0\",\"55\":\"0.0000000\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\",\"59\":\"0\",\"60\":\"0\",\"61\":\"0\",\"62\":\"0\",\"63\":\"0\",\"64\":\"0\",\"65\":\"0\",\"66\":\"0\",\"67\":\"0\",\"68\":\"0\",\"69\":\"0\",\"70\":\"0\",\"71\":\"0\",\"72\":\"0\",\"73\":\"0\",\"74\":\"0\",\"75\":\"0\",\"76\":\"0.000000\",\"77\":\"0\",\"78\":\"0\",\"79\":\"0\",\"80\":\"0\",\"81\":\"0\",\"82\":\"0.00000\",\"83\":\"0\",\"84\":\"3.671899\",\"85\":\"0.000000\",\"86\":\"0\",\"87\":\"0\",\"88\":\"0\",\"89\":\"0\",\"90\":\"0\",\"91\":\"0\",\"92\":\"0\",\"93\":\"0\",\"94\":\"0\",\"95\":\"0\",\"96\":\"0\",\"97\":\"0\",\"98\":\"0\",\"99\":\"0\",\"100\":\"0\",\"101\":\"0\",\"102\":\"0.000000\"},{\"1\":\"7\",\"2\":\"OFFENSE\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0.000000\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0.000000\",\"21\":\"0.000000\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\",\"35\":\"0\",\"36\":\"0\",\"37\":\"1.174937\",\"38\":\"0\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0\",\"42\":\"0\",\"43\":\"0\",\"44\":\"1.120382\",\"45\":\"0.000000\",\"46\":\"0\",\"47\":\"0\",\"48\":\"0.000000\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0\",\"55\":\"0.0000000\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\",\"59\":\"0\",\"60\":\"0\",\"61\":\"0\",\"62\":\"0\",\"63\":\"0\",\"64\":\"0\",\"65\":\"0\",\"66\":\"0\",\"67\":\"0\",\"68\":\"0\",\"69\":\"0\",\"70\":\"0\",\"71\":\"0\",\"72\":\"0\",\"73\":\"0\",\"74\":\"0\",\"75\":\"0\",\"76\":\"0.000000\",\"77\":\"0\",\"78\":\"0\",\"79\":\"0\",\"80\":\"0\",\"81\":\"0\",\"82\":\"0.00000\",\"83\":\"0\",\"84\":\"0.000000\",\"85\":\"0.000000\",\"86\":\"0\",\"87\":\"0\",\"88\":\"0\",\"89\":\"0\",\"90\":\"0\",\"91\":\"0\",\"92\":\"0\",\"93\":\"0\",\"94\":\"0\",\"95\":\"0\",\"96\":\"0\",\"97\":\"0\",\"98\":\"0\",\"99\":\"0\",\"100\":\"0\",\"101\":\"0\",\"102\":\"1.412771\"},{\"1\":\"9\",\"2\":\"OFFENSE\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"1.687779\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0.000000\",\"21\":\"0.000000\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0.000000\",\"38\":\"0\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0\",\"42\":\"0\",\"43\":\"0\",\"44\":\"0.000000\",\"45\":\"0.000000\",\"46\":\"0\",\"47\":\"0\",\"48\":\"0.000000\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0\",\"55\":\"0.0000000\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\",\"59\":\"0\",\"60\":\"0\",\"61\":\"0\",\"62\":\"0\",\"63\":\"0\",\"64\":\"0\",\"65\":\"0\",\"66\":\"0\",\"67\":\"0\",\"68\":\"0\",\"69\":\"0\",\"70\":\"0\",\"71\":\"0\",\"72\":\"0\",\"73\":\"0\",\"74\":\"0\",\"75\":\"0\",\"76\":\"0.000000\",\"77\":\"0\",\"78\":\"0\",\"79\":\"0\",\"80\":\"0\",\"81\":\"0\",\"82\":\"0.00000\",\"83\":\"0\",\"84\":\"0.000000\",\"85\":\"2.196699\",\"86\":\"0\",\"87\":\"0\",\"88\":\"0\",\"89\":\"0\",\"90\":\"0\",\"91\":\"0\",\"92\":\"0\",\"93\":\"0\",\"94\":\"0\",\"95\":\"0\",\"96\":\"0\",\"97\":\"0\",\"98\":\"0\",\"99\":\"0\",\"100\":\"0\",\"101\":\"0\",\"102\":\"0.000000\"},{\"1\":\"10\",\"2\":\"OFFENSE\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0.000000\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"3.397601\",\"21\":\"0.000000\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0.000000\",\"38\":\"0\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0\",\"42\":\"0\",\"43\":\"0\",\"44\":\"0.000000\",\"45\":\"0.000000\",\"46\":\"0\",\"47\":\"0\",\"48\":\"0.000000\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0\",\"55\":\"0.0000000\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\",\"59\":\"0\",\"60\":\"0\",\"61\":\"0\",\"62\":\"0\",\"63\":\"0\",\"64\":\"0\",\"65\":\"0\",\"66\":\"0\",\"67\":\"0\",\"68\":\"0\",\"69\":\"0\",\"70\":\"0\",\"71\":\"0\",\"72\":\"0\",\"73\":\"0\",\"74\":\"0\",\"75\":\"0\",\"76\":\"0.000000\",\"77\":\"0\",\"78\":\"0\",\"79\":\"0\",\"80\":\"0\",\"81\":\"0\",\"82\":\"0.00000\",\"83\":\"0\",\"84\":\"0.000000\",\"85\":\"0.000000\",\"86\":\"0\",\"87\":\"0\",\"88\":\"0\",\"89\":\"0\",\"90\":\"0\",\"91\":\"0\",\"92\":\"0\",\"93\":\"0\",\"94\":\"0\",\"95\":\"0\",\"96\":\"0\",\"97\":\"0\",\"98\":\"0\",\"99\":\"0\",\"100\":\"0\",\"101\":\"0\",\"102\":\"0.000000\"},{\"1\":\"12\",\"2\":\"OFFENSE\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0.000000\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0.000000\",\"21\":\"0.000000\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0.000000\",\"38\":\"0\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0\",\"42\":\"0\",\"43\":\"0\",\"44\":\"0.000000\",\"45\":\"1.108688\",\"46\":\"0\",\"47\":\"0\",\"48\":\"1.073983\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0\",\"55\":\"0.6122061\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\",\"59\":\"0\",\"60\":\"0\",\"61\":\"0\",\"62\":\"0\",\"63\":\"0\",\"64\":\"0\",\"65\":\"0\",\"66\":\"0\",\"67\":\"0\",\"68\":\"0\",\"69\":\"0\",\"70\":\"0\",\"71\":\"0\",\"72\":\"0\",\"73\":\"0\",\"74\":\"0\",\"75\":\"0\",\"76\":\"0.000000\",\"77\":\"0\",\"78\":\"0\",\"79\":\"0\",\"80\":\"0\",\"81\":\"0\",\"82\":\"0.00000\",\"83\":\"0\",\"84\":\"0.000000\",\"85\":\"0.000000\",\"86\":\"0\",\"87\":\"0\",\"88\":\"0\",\"89\":\"0\",\"90\":\"0\",\"91\":\"0\",\"92\":\"0\",\"93\":\"0\",\"94\":\"0\",\"95\":\"0\",\"96\":\"0\",\"97\":\"0\",\"98\":\"0\",\"99\":\"0\",\"100\":\"0\",\"101\":\"0\",\"102\":\"0.000000\"},{\"1\":\"17\",\"2\":\"OFFENSE\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0.000000\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0.000000\",\"21\":\"1.166537\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0.000000\",\"38\":\"0\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0\",\"42\":\"0\",\"43\":\"0\",\"44\":\"0.000000\",\"45\":\"0.000000\",\"46\":\"0\",\"47\":\"0\",\"48\":\"0.000000\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0\",\"55\":\"0.0000000\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\",\"59\":\"0\",\"60\":\"0\",\"61\":\"0\",\"62\":\"0\",\"63\":\"0\",\"64\":\"0\",\"65\":\"0\",\"66\":\"0\",\"67\":\"0\",\"68\":\"0\",\"69\":\"0\",\"70\":\"0\",\"71\":\"0\",\"72\":\"0\",\"73\":\"0\",\"74\":\"0\",\"75\":\"0\",\"76\":\"1.163786\",\"77\":\"0\",\"78\":\"0\",\"79\":\"0\",\"80\":\"0\",\"81\":\"0\",\"82\":\"1.25166\",\"83\":\"0\",\"84\":\"0.000000\",\"85\":\"0.000000\",\"86\":\"0\",\"87\":\"0\",\"88\":\"0\",\"89\":\"0\",\"90\":\"0\",\"91\":\"0\",\"92\":\"0\",\"93\":\"0\",\"94\":\"0\",\"95\":\"0\",\"96\":\"0\",\"97\":\"0\",\"98\":\"0\",\"99\":\"0\",\"100\":\"0\",\"101\":\"0\",\"102\":\"0.000000\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n### Modellspezifikation\n\nWir definiere einen Naive-Bayes-Algorithmus:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_spec <- naive_Bayes() %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"naivebayes\")\n\nnb_spec\n## Naive Bayes Model Specification (classification)\n## \n## Computational engine: naivebayes\n```\n:::\n\n\n\n\nUnd setzen auf die 5-fache Kreuzvalidierung.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nfolds1 <- vfold_cv(d_train, v = 5)\n```\n:::\n\n\n\n\n### Workflow\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1 <-\n  workflow() %>% \n  add_recipe(rec1) %>% \n  add_model(nb_spec)\n\nwf1\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: naive_Bayes()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 5 Recipe Steps\n## \n## ‚Ä¢ step_tokenize()\n## ‚Ä¢ step_stopwords()\n## ‚Ä¢ step_stem()\n## ‚Ä¢ step_tokenfilter()\n## ‚Ä¢ step_tfidf()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Naive Bayes Model Specification (classification)\n## \n## Computational engine: naivebayes\n```\n:::\n\n\n\n### Fitting\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit1 <-\n  fit_resamples(\n    wf1,\n    folds1,\n    control = control_resamples(save_pred = TRUE)\n  )\n```\n:::\n\n\nDie Vorhersagen speichern wir ab,\num die Performanz in den Faltungen des Hold-out-Samples zu berechnen.\n\n\nM√∂chte man sich die Zeit sparen, die Syntax wieder durchlaufen zu lassen,\nkann man das Objekt speichern. \nAber Vorsicht: Dabei kann es passieren, dass man mit veralteten Objekten arbeitet.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(fit1, \"objects/chap-klassifik/chap_classific_fit1.rds\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n### Performanz\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf1_performance <-\n  collect_metrics(fit1)\n\nwf1_performance\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_preds <-\n  collect_predictions(fit1)\n\nwf_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](080-klassifikation_files/figure-html/wf1-preds-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat_resampled(fit1, tidy = FALSE) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](080-klassifikation_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Nullmodell\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_classification <- \n  parsnip::null_model() %>%\n  set_engine(\"parsnip\") %>%\n  set_mode(\"classification\")\n\nnull_rs <- workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(null_classification) %>%\n  fit_resamples(\n    folds1\n  )\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nHier ist die Performanz des Nullmodells.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_rs %>%\n  collect_metrics()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(null_rs)\n## Warning: No value of `metric` was given; metric 'roc_auc' will be used.\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"penalty\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"0.0017433288\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8116297\",\"5\":\"10\",\"6\":\"0.008710636\",\"7\":\"Preprocessor1_Model22\"},{\"1\":\"0.0007880463\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8111630\",\"5\":\"10\",\"6\":\"0.008941393\",\"7\":\"Preprocessor1_Model21\"},{\"1\":\"0.0003562248\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8103737\",\"5\":\"10\",\"6\":\"0.009238082\",\"7\":\"Preprocessor1_Model20\"},{\"1\":\"0.0001610262\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8099159\",\"5\":\"10\",\"6\":\"0.009444783\",\"7\":\"Preprocessor1_Model19\"},{\"1\":\"0.0000000001\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8095907\",\"5\":\"10\",\"6\":\"0.009602864\",\"7\":\"Preprocessor1_Model01\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n\n## Workflow 2a: Textfeatures + Naive-Bayes\n\n\n\n\n### Rezept\n\n\nTesten wir die Funktionen, die wir im Folgenden nutzen, um Text-Features zu erzeugen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndummy <- c(\"hallo\", \"baby\", \"fatal\")\n\ncount_profane(dummy) \n## [1] 1\n\ncount_emo_words(dummy)\n## [1] 1\n\ndummy <- c(\"baby\", \"und\", \"üÜó\", \"üñï\")\n\ncount_emojis(dummy)\n## [1] 0\n\ncount_wild_emojis(dummy) \n## [1] 0\n```\n:::\n\n\nRezept definieren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2a <- \n  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% \n  update_role(id, new_role = \"id\") %>% \n  step_text_normalization(text) %>%   # UTF8-Normalisiuerung\n  step_mutate(text_copy = text,\n              profane_n = map_int(text, count_profane),\n              emo_words_n = map_int(text, count_emo_words),\n              emojis_n = map_int(text, count_emojis),\n              wild_emojis_n = map_int(text, count_wild_emojis)\n  ) %>% \n  step_textfeature(text_copy) %>% \n  step_tokenize(text, token = \"words\") %>% \n  #step_stem(text) %>% \n  step_tokenfilter(text, max_tokens = 1e2) %>%  # wir behalten nur die h√§ufigsten Tokens\n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") |> \n  step_tfidf(text)\nrec2a\n## \n## ‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## ‚îÄ‚îÄ Inputs\n## Number of variables by role\n## outcome:   1\n## predictor: 1\n## id:        1\n## \n## ‚îÄ‚îÄ Operations\n## ‚Ä¢ Text Normalization for: text\n## ‚Ä¢ Variable mutation for: text, map_int(text, count_profane), ...\n## ‚Ä¢ Text feature extraction for: text_copy\n## ‚Ä¢ Tokenization for: text\n## ‚Ä¢ Text filtering for: text\n## ‚Ä¢ Stop word removal for: text\n## ‚Ä¢ Term frequency-inverse document frequency with: text\n```\n:::\n\n\nEinige Hinweise zum Rezept:\n\n- Das Tokenisieren kommt erst nach den Textfeatures.\n- Da `textfeatures` die Spalte `text` \"aufisst\", legen wir eine Kopie der Spalte an.\n- Man darf nicht vergessen, jedem Step zu sagen, auf welche Spalten er sich beziehen soll (z.B. `text`).\n\nPreppen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2a_prepped <- prep(rec2a)\n```\n:::\n\n\nUnd backen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_rec2a <- bake(rec2a_prepped, new_data = NULL)\n```\n:::\n\n\n\nOder importieren aus der Konserve:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# write_rds(d_rec2a, file = \"objects/chap-klassifik/d_rec2a.rds\")\nd_rec2a <- read_rds(file = \"objects/chap-klassifik/d_rec2a.rds\")\ndim(d_rec2a)\n## [1] 3756   58\nhead(d_rec2a)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"c1\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"profane_n\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"emo_words_n\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"emojis_n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"wild_emojis_n\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_words\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_uq_words\"],\"name\":[8],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_charS\"],\"name\":[9],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_uq_charS\"],\"name\":[10],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_digits\"],\"name\":[11],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_hashtags\"],\"name\":[12],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_uq_hashtags\"],\"name\":[13],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_mentions\"],\"name\":[14],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_uq_mentions\"],\"name\":[15],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_commas\"],\"name\":[16],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_periods\"],\"name\":[17],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_exclaims\"],\"name\":[18],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_extraspaces\"],\"name\":[19],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_caps\"],\"name\":[20],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_lowers\"],\"name\":[21],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_urls\"],\"name\":[22],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_uq_urls\"],\"name\":[23],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_nonasciis\"],\"name\":[24],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_n_puncts\"],\"name\":[25],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_politeness\"],\"name\":[26],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_first_person\"],\"name\":[27],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_first_personp\"],\"name\":[28],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_second_person\"],\"name\":[29],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_second_personp\"],\"name\":[30],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_third_person\"],\"name\":[31],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_to_be\"],\"name\":[32],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"textfeature_text_copy_prepositions\"],\"name\":[33],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_afd\"],\"name\":[34],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_amp\"],\"name\":[35],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_d\"],\"name\":[36],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_dass\"],\"name\":[37],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_deutsche\"],\"name\":[38],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_deutschen\"],\"name\":[39],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_deutschland\"],\"name\":[40],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_geht\"],\"name\":[41],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_gibt\"],\"name\":[42],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_heute\"],\"name\":[43],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_immer\"],\"name\":[44],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_ja\"],\"name\":[45],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_krippmarie\"],\"name\":[46],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_land\"],\"name\":[47],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_lbr\"],\"name\":[48],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_mal\"],\"name\":[49],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_mehr\"],\"name\":[50],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_merkel\"],\"name\":[51],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_m√ºssen\"],\"name\":[52],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_schon\"],\"name\":[53],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_spd\"],\"name\":[54],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_u\"],\"name\":[55],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_unsere\"],\"name\":[56],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_welt\"],\"name\":[57],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tfidf_text_wer\"],\"name\":[58],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"5\",\"2\":\"OFFENSE\",\"3\":\"1\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"16\",\"8\":\"16\",\"9\":\"121\",\"10\":\"31\",\"11\":\"0\",\"12\":\"1\",\"13\":\"1\",\"14\":\"1\",\"15\":\"1\",\"16\":\"0\",\"17\":\"2\",\"18\":\"0\",\"19\":\"0\",\"20\":\"8\",\"21\":\"108\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"3\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0.000000\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0\",\"38\":\"0.000000\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0.000000\",\"42\":\"0\",\"43\":\"0.000000\",\"44\":\"0.000000\",\"45\":\"0.0000\",\"46\":\"0.000000\",\"47\":\"0\",\"48\":\"0.0000000\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"3.671899\",\"55\":\"0\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\"},{\"1\":\"7\",\"2\":\"OFFENSE\",\"3\":\"1\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"32\",\"8\":\"28\",\"9\":\"145\",\"10\":\"29\",\"11\":\"4\",\"12\":\"0\",\"13\":\"0\",\"14\":\"1\",\"15\":\"1\",\"16\":\"0\",\"17\":\"2\",\"18\":\"0\",\"19\":\"0\",\"20\":\"4\",\"21\":\"134\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"1\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0.000000\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0\",\"38\":\"0.000000\",\"39\":\"0\",\"40\":\"0\",\"41\":\"1.821262\",\"42\":\"0\",\"43\":\"1.673477\",\"44\":\"0.000000\",\"45\":\"0.0000\",\"46\":\"0.000000\",\"47\":\"0\",\"48\":\"0.0000000\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0.000000\",\"55\":\"0\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\"},{\"1\":\"9\",\"2\":\"OFFENSE\",\"3\":\"0\",\"4\":\"1\",\"5\":\"0\",\"6\":\"0\",\"7\":\"12\",\"8\":\"12\",\"9\":\"66\",\"10\":\"29\",\"11\":\"0\",\"12\":\"1\",\"13\":\"1\",\"14\":\"1\",\"15\":\"1\",\"16\":\"0\",\"17\":\"1\",\"18\":\"0\",\"19\":\"0\",\"20\":\"9\",\"21\":\"53\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"3\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"3.361147\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0\",\"38\":\"0.000000\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0.000000\",\"42\":\"0\",\"43\":\"0.000000\",\"44\":\"0.000000\",\"45\":\"0.0000\",\"46\":\"0.000000\",\"47\":\"0\",\"48\":\"0.0000000\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0.000000\",\"55\":\"0\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\"},{\"1\":\"10\",\"2\":\"OFFENSE\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"15\",\"8\":\"15\",\"9\":\"119\",\"10\":\"30\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"2\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"6\",\"21\":\"108\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"3\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0.000000\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0\",\"38\":\"3.604721\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0.000000\",\"42\":\"0\",\"43\":\"0.000000\",\"44\":\"0.000000\",\"45\":\"0.0000\",\"46\":\"0.000000\",\"47\":\"0\",\"48\":\"0.0000000\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0.000000\",\"55\":\"0\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\"},{\"1\":\"12\",\"2\":\"OFFENSE\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"26\",\"8\":\"25\",\"9\":\"134\",\"10\":\"39\",\"11\":\"2\",\"12\":\"0\",\"13\":\"0\",\"14\":\"1\",\"15\":\"1\",\"16\":\"0\",\"17\":\"3\",\"18\":\"0\",\"19\":\"0\",\"20\":\"12\",\"21\":\"111\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"6\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0.000000\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0\",\"38\":\"0.000000\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0.000000\",\"42\":\"0\",\"43\":\"0.000000\",\"44\":\"1.122775\",\"45\":\"1.0823\",\"46\":\"0.000000\",\"47\":\"0\",\"48\":\"0.6210228\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0.000000\",\"55\":\"0\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\"},{\"1\":\"27\",\"2\":\"OFFENSE\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"15\",\"8\":\"15\",\"9\":\"101\",\"10\":\"31\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"1\",\"15\":\"1\",\"16\":\"0\",\"17\":\"4\",\"18\":\"0\",\"19\":\"0\",\"20\":\"6\",\"21\":\"88\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"3\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0.000000\",\"35\":\"0\",\"36\":\"0\",\"37\":\"0\",\"38\":\"0.000000\",\"39\":\"0\",\"40\":\"0\",\"41\":\"0.000000\",\"42\":\"0\",\"43\":\"0.000000\",\"44\":\"0.000000\",\"45\":\"0.0000\",\"46\":\"3.671899\",\"47\":\"0\",\"48\":\"0.0000000\",\"49\":\"0\",\"50\":\"0\",\"51\":\"0\",\"52\":\"0\",\"53\":\"0\",\"54\":\"0.000000\",\"55\":\"0\",\"56\":\"0\",\"57\":\"0\",\"58\":\"0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n### Workflow\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf2a <-\n  workflow() %>% \n  add_recipe(rec2a) %>% \n  add_model(nb_spec)\n\nwf2a\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: naive_Bayes()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 7 Recipe Steps\n## \n## ‚Ä¢ step_text_normalization()\n## ‚Ä¢ step_mutate()\n## ‚Ä¢ step_textfeature()\n## ‚Ä¢ step_tokenize()\n## ‚Ä¢ step_tokenfilter()\n## ‚Ä¢ step_stopwords()\n## ‚Ä¢ step_tfidf()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Naive Bayes Model Specification (classification)\n## \n## Computational engine: naivebayes\n```\n:::\n\n\n\n### Fitting\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2a <-\n  fit_resamples(\n    wf2a,\n    resamples = vfold_cv(d_train, v = 5),\n    control = control_resamples(save_pred = TRUE)\n  )\n```\n:::\n\n\nDie Vorhersagen speichern wir ab,\num die Performanz in den Faltungen des Hold-out-Samples zu berechnen.\n\n\n:::.callout-caution\nM√∂chte man sich die Zeit sparen, die Syntax wieder durchlaufen zu lassen,\nkann man das Objekt speichern. \nAber Vorsicht: Dabei kann es passieren, dass man mit veralteten Objekten arbeitet. $\\square$\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(fit2a, \"objects/chap-klassifik/chap_classific_fit2a.rds\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n### Performanz\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf2a_performance <-\n  collect_metrics(fit2a)\n\nwf2a_performance\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwf_preds_2a <-\n  collect_predictions(fit2a)\n\nwf_preds_2a %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n```\n\n::: {.cell-output-display}\n![](080-klassifikation_files/figure-html/wf2a-preds-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat_resampled(fit2a, tidy = FALSE) %>% \n  autoplot(type = \"heatmap\")\n```\n\n::: {.cell-output-display}\n![](080-klassifikation_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Workflow 2b: Textfeatures + Lasso\n\n\n### Modell: Lasso\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"glmnet\")\n\nlasso_spec\n## Logistic Regression Model Specification (classification)\n## \n## Main Arguments:\n##   penalty = tune()\n##   mixture = 1\n## \n## Computational engine: glmnet\n```\n:::\n\n\n\n\nWir definieren die Auspr√§gungen von `penalty`, \ndie wir ausprobieren wollen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlambda_grid <- grid_regular(penalty(), levels = 3)  # hier nur 3 Werte, um Rechenzeit zu sparen\n```\n:::\n\n\n\n### Workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf2b <-\n  workflow() %>% \n  add_recipe(rec1) %>% \n  add_model(lasso_spec)\n\nwf2b\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: logistic_reg()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 5 Recipe Steps\n## \n## ‚Ä¢ step_tokenize()\n## ‚Ä¢ step_stopwords()\n## ‚Ä¢ step_stem()\n## ‚Ä¢ step_tokenfilter()\n## ‚Ä¢ step_tfidf()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Logistic Regression Model Specification (classification)\n## \n## Main Arguments:\n##   penalty = tune()\n##   mixture = 1\n## \n## Computational engine: glmnet\n```\n:::\n\n\n\nTunen und Fitten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\n\nfit2b <-\n  tune_grid(\n    wf2b,\n    folds1,\n    grid = lambda_grid,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nfit2b\n```\n:::\n\n\n\n:::.callout-caution\nVorsicht beim Abspeichern von Objekten: Da kann man leicht vergessen, zu updaten. $\\square$\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(fit2b, \"objects/chap-klassifik/chap_classific_fit2b.rds\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nHier ist die Performanz:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(fit2b) %>% \n  filter(.metric == \"roc_auc\") %>% \n  slice_max(mean, n = 3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(fit2b)\n```\n\n::: {.cell-output-display}\n![](080-klassifikation_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2b %>% \n  show_best(\"roc_auc\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"penalty\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1e-10\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.6433326\",\"5\":\"5\",\"6\":\"0.008664343\",\"7\":\"Preprocessor1_Model1\"},{\"1\":\"1e-05\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.6433326\",\"5\":\"5\",\"6\":\"0.008664343\",\"7\":\"Preprocessor1_Model2\"},{\"1\":\"1e+00\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.5000000\",\"5\":\"5\",\"6\":\"0.000000000\",\"7\":\"Preprocessor1_Model3\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchosen_auc <- \n  fit2b %>%\n  select_by_one_std_err(metric = \"roc_auc\", -penalty)\n```\n:::\n\n\n\n\nFinalisieren:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf2b_final <-\n  finalize_workflow(wf2b, chosen_auc)\n\nwf2b_final\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: logistic_reg()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 5 Recipe Steps\n## \n## ‚Ä¢ step_tokenize()\n## ‚Ä¢ step_stopwords()\n## ‚Ä¢ step_stem()\n## ‚Ä¢ step_tokenfilter()\n## ‚Ä¢ step_tfidf()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Logistic Regression Model Specification (classification)\n## \n## Main Arguments:\n##   penalty = 1e-05\n##   mixture = 1\n## \n## Computational engine: glmnet\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2b_final_train <-\n  fit(wf2b_final, d_train)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2b_final_train %>% \n  extract_fit_parsnip() %>% \n  tidy() %>% \n  arrange(-abs(estimate)) %>% \n  head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"penalty\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"tfidf_text_feldenfrizz\",\"2\":\"12.304611\",\"3\":\"1e-05\"},{\"1\":\"tfidf_text_schmiddiemaik\",\"2\":\"-11.823955\",\"3\":\"1e-05\"},{\"1\":\"tfidf_text__macmik\",\"2\":\"9.414012\",\"3\":\"1e-05\"},{\"1\":\"tfidf_text_md_franz\",\"2\":\"-4.398868\",\"3\":\"1e-05\"},{\"1\":\"tfidf_text_thomasgbau\",\"2\":\"-3.634176\",\"3\":\"1e-05\"},{\"1\":\"tfidf_text_athinamala\",\"2\":\"-3.184619\",\"3\":\"1e-05\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit2b_final_test <-\n  last_fit(wf2b_final, d_split)\n\ncollect_metrics(fit2b_final_test)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"accuracy\",\"2\":\"binary\",\"3\":\"0.6687949\",\"4\":\"Preprocessor1_Model1\"},{\"1\":\"roc_auc\",\"2\":\"binary\",\"3\":\"0.6469109\",\"4\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n### Vorhersage\n\n\n### Vohersagedaten\n\nPfad zu den Daten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntweet_data_path <- \"/Users/sebastiansaueruser/github-repos/hate-speech-data/data-raw/tweets/\"\n```\n:::\n\n\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntweet_data_files_names <- list.files(path = tweet_data_path,\n                                     pattern  = \"tweets-to-.*\\\\.rds$\")\nhead(tweet_data_files_names)\n## [1] \"tweets-to-Janine_Wissler_2021.rds\" \"tweets-to-Janine_Wissler_2022.rds\"\n## [3] \"tweets-to-MAStrackZi_2021.rds\"     \"tweets-to-MAStrackZi_2022.rds\"    \n## [5] \"tweets-to-schirdewan_2021.rds\"     \"tweets-to-schirdewan_2022.rds\"\n```\n:::\n\n\n\nWie viele Dateien sind es?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlength(tweet_data_files_names)\n## [1] 6\n```\n:::\n\n\n\nWir geben den Elementen des Vektors g√§ngige Namen,\ndas hilft uns gleich bei `map`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(tweet_data_files_names) <- \n  str_remove(tweet_data_files_names, \"\\\\.rds$\")  # Datei-Suffix entfernen \n```\n:::\n\n\n\n\n\n\nOK, weiter: So k√∂nnen wir *eine* der Datendateien einlesen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_raw <-\n  read_rds(file = paste0(tweet_data_path, tweet_data_files_names[1])) \n\nd <- \n  d_raw %>% \n  select(id, author_id, created_at, public_metrics) %>% \n  unnest_wider(public_metrics)\n\nhead(d)\n```\n:::\n\n\n\nUnd so lesen wir alle ein:\n\n\nZun√§chst erstellen wir uns eine Helper-Funktion:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread_and_select <- function(file_name, path_to_tweet_data = tweet_data_path) {\n  \n  out <- \n    read_rds(file = paste0(path_to_tweet_data, file_name)) %>% \n    select(id, author_id, created_at, text, public_metrics) %>% \n    unnest_wider(public_metrics)\n  \n  cat(\"Data file was read.\\n\")\n  \n  return(out)\n}\n```\n:::\n\n\nTesten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd1 <- read_and_select(tweet_data_files_names[1])\n\nhead(d1)\n```\n:::\n\n\n\n\nDie Funktion `read_and_select`  mappen wir auf alle Datendateien:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic()\nds <-\n  tweet_data_files_names %>% \n  map_dfr(read_and_select, .id = \"dataset\")\ntoc()\n```\n:::\n\n\n\n`214.531 sec elapsed`\n\nDa wir den Elementen von `tweet_data_files_names` Namen gegeben haben, \nfinden wir diese Namen praktischerweise wieder in `ds`.\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\nVielleicht ist es zum Entwickeln besser,\nmit einem kleineren Datensatz einstweilen zu arbeiten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nds_short <- read_rds(file = \"/Users/sebastiansaueruser/github-repos/hate-speech-data/objects/ds_short.rds\")  # 300kb\n\nds <- ds_short\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n### Vokabular erstellen\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nds_long <-\n  ds %>% \n  select(text) %>% \n  unnest_tokens(input = text, output = word)\n```\n:::\n\n\nPuh, das hat gedauert!\n\nSpeichern wir uns diese Daten daher auf die Festplatte:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(ds_long, file = paste0(tweet_data_path, \"ds_long.rds\"))\n```\n:::\n\n\nEntfernen wir daraus die Duplikate,\num uns ein Vokabular zu erstellen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nds_voc <-\n  ds_long %>% \n  distinct(word)\n\nhead(ds_voc)\n```\n:::\n\n\nInsgesamt umfasst `nrow(ds_voc)` W√∂rter.\n\nUnd das resultierende Objekt speichern wir wieder ab:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(ds_voc, file = paste0(\"objects/\", \"ds_voc.rds\"))\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## Worteinbettungen erstellen\n\n>    üë®‚Äçüè´ Hey ChatGPT, beschreibe Das FastText-Modell f√ºr Worteinbettungen.\n\n>    ü§ñ Ja, Moment...\n\n\n\n### Was ist das FastText-Modell? {#sec-fasttext}\n\nDas [FastText-Modell](https://fasttext.cc/) f√ºr Worteinbettungen (auch als Word Embeddings bezeichnet) ist ein NLP-Modell, das von Facebook AI Research entwickelt wurde. Es ist eine Erweiterung des klassischen Word2Vec-Modells und zielt darauf ab, Worte in Vektoren umzuwandeln, um semantische Informationen √ºber W√∂rter zu erfassen. Der Hauptunterschied zwischen FastText und Word2Vec besteht darin, wie sie Worte darstellen.\n\nHier sind einige wichtige Merkmale und Unterschiede des FastText-Modells:\n\nSubword-Informationen: W√§hrend Word2Vec auf ganzen W√∂rtern basiert, behandelt FastText W√∂rter als eine Sammlung von Subw√∂rtern (n-Grammen). Diese Subw√∂rter sind buchst√§bliche Teile eines Wortes, die f√ºr die Analyse verwendet werden. Zum Beispiel, f√ºr das Wort \"apple\" k√∂nnte FastText die Subw√∂rter \"ap,\" \"app,\" \"ppl,\" \"ple\" usw. ber√ºcksichtigen. Dies erm√∂glicht es dem Modell, semantische Informationen auf Buchstabenebene zu erfassen und seltene W√∂rter oder W√∂rter, die nicht im Trainingskorpus enthalten sind, besser zu behandeln.\n\n\n\nPre-trained Modelle: Es stehen vorab trainierte FastText-Modelle in vielen Sprachen zur Verf√ºgung. Diese vortrainierten Modelle k√∂nnen in verschiedenen NLP-Anwendungen verwendet werden, ohne von Grund auf neu trainiert werden zu m√ºssen.\n\nDer Trainingsprozess f√ºr ein FastText-Modell umfasst das Lernen von Wortdarstellungen anhand gro√üer Textkorpora. Die resultierenden Wortvektoren k√∂nnen verwendet werden, um semantische Beziehungen zwischen W√∂rtern zu erkunden, √Ñhnlichkeiten zu berechnen oder als Eingabe f√ºr maschinelle Lernmodelle in verschiedenen nat√ºrlichsprachlichen Verarbeitungsaufgaben zu dienen. Insgesamt hat FastText aufgrund seiner F√§higkeit zur Ber√ºcksichtigung von Subw√∂rtern und seiner Effizienz bei der Verarbeitung gro√üer Vokabulare in der NLP-Gemeinschaft an Popularit√§t gewonnen.^[Der Text dieses Abschnitts wurde von ChatGPT 3.5 erstellt, 2023-10-29.]\n\n\n### Ein Fast-Text-Modell trainieren\n\n\nDefiniere die Konstanten f√ºr das fastText-Modell:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntexts <- ds %>% pull(text)\ntexts <- tolower(texts)\n```\n:::\n\n\n\nWir k√∂nnen uns ein FastText-Modell f√ºr Worteinbettungen basierend auf unseren Daten berechnen lassen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#writeLines(text = texts, con = out_file_txt)\n#execute(commands = c(\"skipgram\", \"-input\", tmp_file_txt, \"-output\", out_file_model, \"-verbose\", 1))  # execute berechnet ein FastText-Mdlell\n```\n:::\n\n\nIm Standard werden 100 Dimensionen berechnet.\n\nHier ist schon ein vorab gespeichertes Modell, basierend auf den Twitter-Daten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nout_file_txt <- \"/Users/sebastiansaueruser/datasets/Twitter/twitter-polit-model.vec\"\nout_file_model <- \"/Users/sebastiansaueruser/datasets/Twitter/twitter-polit-model.bin\"\n\nfile.exists(out_file_txt)\n## [1] TRUE\nfile.exists(out_file_model)\n## [1] TRUE\n```\n:::\n\n\n\n\n```\nRead 22M words\nNumber of words:  130328\nNumber of labels: 0\nProgress: 100.0% words/sec/thread:   49218 lr:  0.000000 avg.loss:  1.720812 ETA:   0h 0m 0s\n```\n\nJetzt laden wir das Modell von der Festplatte:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntwitter_fasttext_model <- load_model(out_file_model)\ndict <- get_dictionary(twitter_fasttext_model)\n```\n:::\n\n\nDas W√∂rterbuch umfasst 130328 (verschiedene) W√∂rter.\n\n\nSchauen wir uns einige Begriffe aus dem Vokabular an:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprint(head(dict, 10))\n##  [1] \"</s>\"            \"die\"             \"und\"             \"der\"            \n##  [5] \"sie\"             \"das\"             \"nicht\"           \"in\"             \n##  [9] \"ist\"             \"@_friedrichmerz\"\n```\n:::\n\n\nHier sind die ersten paar Elemente des Vektors f√ºr `menschen`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvec1 <- get_word_vectors(twitter_fasttext_model, c(\"menschen\"))\nvec1[1:10]\n```\n:::\n\n\n\n\n```\n [1]  0.14156282  0.44875699  0.23911817 -0.02580349  0.29811972  0.03870077\n [7]  0.06518744  0.22527063  0.28198120  0.39931887\n ```\n\n\nErstellen wir uns einen Tibble, der \nals erste Spalte das Vokabular und in den √ºbrigen 100 Spalten die Dimensionen enth√§lt:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_embedding_twitter <-\n  tibble(\n    word = dict\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwords_vecs_twitter <-\n  get_word_vectors(twitter_fasttext_model)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nword_embedding_twitter <-\n  word_embedding_twitter %>% \n  bind_cols(words_vecs_twitter)\n\nnames(word_embedding_twitter) <- \n  c(\"word\", \n    paste0(\"v\", sprintf(\"%03d\", 1:100)))  # Namen versch√∂nern mit fortlaufender Nummer von 0 bis 100\n```\n:::\n\n\n\nUnd als Worteinbettungsdatei abspeichern:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(word_embedding_twitter, file = paste0(tweet_data_path, \"word_embedding_twitter.rds\"))\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"word\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"v001\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"v002\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"v003\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"v004\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"<\\/s>\",\"2\":\"0.17330834\",\"3\":\"0.07820062\",\"4\":\"-0.05277666\",\"5\":\"0.0862241\"},{\"1\":\"die\",\"2\":\"0.48641139\",\"3\":\"0.03693734\",\"4\":\"-0.01204743\",\"5\":\"0.1565817\"},{\"1\":\"und\",\"2\":\"0.39090732\",\"3\":\"-0.02645574\",\"4\":\"0.11355034\",\"5\":\"0.1545031\"},{\"1\":\"der\",\"2\":\"0.37105647\",\"3\":\"-0.33681911\",\"4\":\"0.05018367\",\"5\":\"0.2029566\"},{\"1\":\"sie\",\"2\":\"0.45957077\",\"3\":\"0.04141690\",\"4\":\"0.23099238\",\"5\":\"0.1809430\"},{\"1\":\"das\",\"2\":\"0.07037771\",\"3\":\"-0.07423849\",\"4\":\"0.04087655\",\"5\":\"0.1506333\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n### Aufbereiten\n\nAm besten nur die Spalten (unseres Twitter-Datensatzes) behalten,\ndie wir zum Modellieren nutzen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nds_short2 <-\n  ds_short %>% \n  select(text, id)\n```\n:::\n\n\n\nWir definieren ein Rezept `rec_word_embed` (basierend auf `rec1`):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_word_embed <- \n  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% \n  update_role(id, new_role = \"id\") %>% \n  step_tokenize(text) %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>% \n  step_stem(text) %>% \n  step_tokenfilter(text, max_tokens = 1e2) %>%  # wir behalten nur die h√§ufigsten Tokens\n  step_word_embeddings(text, embeddings = word_embedding_twitter)\n```\n:::\n\n\n\nDann preppen und backen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec_word_embed_prepped <-\n  prep(rec_word_embed)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nds_baked_rec1a <- bake(rec_word_embed_prepped, new_data = ds_short2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nds_baked_rec1a %>% `[`(1:10, 1:10)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"id\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"wordembed_text_v001\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wordembed_text_v002\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wordembed_text_v003\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wordembed_text_v004\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wordembed_text_v005\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wordembed_text_v006\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wordembed_text_v007\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wordembed_text_v008\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wordembed_text_v009\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"NA\",\"2\":\"0.23893653\",\"3\":\"0.014598664\",\"4\":\"-0.2222376\",\"5\":\"0.48163152\",\"6\":\"0.20162874\",\"7\":\"-0.12450162\",\"8\":\"0.23333058\",\"9\":\"-0.226192281\",\"10\":\"-0.027382970\"},{\"1\":\"NA\",\"2\":\"0.32377085\",\"3\":\"0.695485767\",\"4\":\"0.4336860\",\"5\":\"0.28993332\",\"6\":\"-0.17770833\",\"7\":\"-0.74807747\",\"8\":\"1.49294108\",\"9\":\"1.064348385\",\"10\":\"0.820613639\"},{\"1\":\"NA\",\"2\":\"0.21142043\",\"3\":\"0.783711389\",\"4\":\"-1.3797138\",\"5\":\"0.28518000\",\"6\":\"0.33366236\",\"7\":\"-0.24040961\",\"8\":\"0.19629040\",\"9\":\"0.084888689\",\"10\":\"-0.186157003\"},{\"1\":\"NA\",\"2\":\"0.71277493\",\"3\":\"-0.304109801\",\"4\":\"-0.4309491\",\"5\":\"0.05916093\",\"6\":\"0.04967718\",\"7\":\"0.10116307\",\"8\":\"0.34288836\",\"9\":\"0.004611025\",\"10\":\"0.875826895\"},{\"1\":\"NA\",\"2\":\"0.00000000\",\"3\":\"0.000000000\",\"4\":\"0.0000000\",\"5\":\"0.00000000\",\"6\":\"0.00000000\",\"7\":\"0.00000000\",\"8\":\"0.00000000\",\"9\":\"0.000000000\",\"10\":\"0.000000000\"},{\"1\":\"NA\",\"2\":\"0.00000000\",\"3\":\"0.000000000\",\"4\":\"0.0000000\",\"5\":\"0.00000000\",\"6\":\"0.00000000\",\"7\":\"0.00000000\",\"8\":\"0.00000000\",\"9\":\"0.000000000\",\"10\":\"0.000000000\"},{\"1\":\"NA\",\"2\":\"0.61656542\",\"3\":\"-0.006150134\",\"4\":\"-0.7271604\",\"5\":\"-0.10712643\",\"6\":\"0.96813375\",\"7\":\"-0.03373864\",\"8\":\"0.08099335\",\"9\":\"0.201609042\",\"10\":\"1.104397699\"},{\"1\":\"NA\",\"2\":\"0.04866463\",\"3\":\"-0.441774538\",\"4\":\"-0.3122953\",\"5\":\"0.05295798\",\"6\":\"0.78680488\",\"7\":\"0.09914146\",\"8\":\"0.01339768\",\"9\":\"-0.094183717\",\"10\":\"0.029520422\"},{\"1\":\"NA\",\"2\":\"0.00000000\",\"3\":\"0.000000000\",\"4\":\"0.0000000\",\"5\":\"0.00000000\",\"6\":\"0.00000000\",\"7\":\"0.00000000\",\"8\":\"0.00000000\",\"9\":\"0.000000000\",\"10\":\"0.000000000\"},{\"1\":\"NA\",\"2\":\"0.21170381\",\"3\":\"-0.291642219\",\"4\":\"-0.3079664\",\"5\":\"-0.17432338\",\"6\":\"0.52147198\",\"7\":\"-0.06467295\",\"8\":\"0.21021771\",\"9\":\"-0.425262958\",\"10\":\"0.006601942\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nIst das nicht komfortabel?\nDas Textrezept √ºbernimmt die Arbeit f√ºr uns,\nmit den richtigen Features zu arbeiten,\nund die Wort-Einbettungen f√ºr die richtigen W√∂rter bereitzustellen.\n\nWer dem Frieden nicht traut,\ndem sei geraten, nachzupr√ºfen ü§ì.\n\n\n\n## Workflow 3: Worteinbettungen + Lasso\n\n### Daten aufteilen\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_split <- initial_split(d2, strata = c1)\n\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n\n### Hilfsfunktionen\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsource(\"funs/helper-funs-recipes.R\")\n```\n:::\n\n\n\n\n\n\n### Rezept mit Worteinbettungen\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2 <- \n  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% \n  update_role(id, new_role = \"id\") %>% \n  step_text_normalization(text) %>% \n  step_mutate(text_copy = text,\n              profane_n = map_int(text, count_profane),\n              emo_words_n = map_int(text, count_emo_words),\n              emojis_n = map_int(text, count_emojis),\n              wild_emojis_n = map_int(text, count_wild_emojis)\n  ) %>% \n  step_textfeature(text_copy) %>% \n  step_tokenize(text, token = \"words\") %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>% \n  step_word_embeddings(text, embeddings = word_embedding_twitter)\n \nrec2\n## \n## ‚îÄ‚îÄ Recipe ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## \n## ‚îÄ‚îÄ Inputs\n## Number of variables by role\n## outcome:   1\n## predictor: 1\n## id:        1\n## \n## ‚îÄ‚îÄ Operations\n## ‚Ä¢ Text Normalization for: text\n## ‚Ä¢ Variable mutation for: text, map_int(text, count_profane), ...\n## ‚Ä¢ Text feature extraction for: text_copy\n## ‚Ä¢ Tokenization for: text\n## ‚Ä¢ Stop word removal for: text\n## ‚Ä¢ Word embeddings aggregated from: text\n```\n:::\n\n\n\n\n\nJetzt preppen:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2_prepped <- prep(rec2)\n```\n:::\n\n\n\n\n\nVielleicht macht es Sinn, sich das Objekt zur sp√§teren\nVerwendung abzuspeichern.^[Aber Vorsicht beim Abspeichern, man k√∂nnte versehentlich mit einer veralteten Version weiterarbeiten.]\n`Feather` verarbeitet nur Dataframes,\ndaher nutzen wir hier RDS.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(rec2_prepped, file = \"~/datasets/Twitter/klassifik-rec2-prepped.rds\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2_prepped <- read_rds(\"/Users/sebastiansaueruser/github-repos/hate-speech-data/objects/rec2_prepped.rds\")\n```\n:::\n\n\n\n\n\nDas Element `rec2_prepped` ist recht gro√ü:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformat(object.size(rec2_prepped), units  = \"Mb\")\n## [1] \"113.8 Mb\"\n```\n:::\n\n\nJetzt k√∂nnen wir das pr√§parierte (\"gepreppte\") Rezept \"backen\":\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2_baked <- bake(rec2_prepped, new_data = NULL)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrec2_baked %>% \n  select(1:15) %>% \n  glimpse()\n## Rows: 3,756\n## Columns: 15\n## $ id                                  <fct> 5, 9, 10, 17, 27, 33, 42, 44, 48, ‚Ä¶\n## $ c1                                  <fct> OFFENSE, OFFENSE, OFFENSE, OFFENSE‚Ä¶\n## $ profane_n                           <int> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n## $ emo_words_n                         <int> 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1‚Ä¶\n## $ emojis_n                            <int> 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0‚Ä¶\n## $ wild_emojis_n                       <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n## $ textfeature_text_copy_n_words       <int> 16, 12, 15, 19, 15, 33, 30, 31, 6,‚Ä¶\n## $ textfeature_text_copy_n_uq_words    <int> 16, 12, 15, 17, 15, 32, 29, 29, 6,‚Ä¶\n## $ textfeature_text_copy_n_charS       <int> 121, 66, 119, 112, 101, 196, 171, ‚Ä¶\n## $ textfeature_text_copy_n_uq_charS    <int> 31, 29, 30, 36, 31, 35, 42, 35, 23‚Ä¶\n## $ textfeature_text_copy_n_digits      <int> 0, 0, 0, 4, 0, 0, 0, 1, 0, 4, 2, 0‚Ä¶\n## $ textfeature_text_copy_n_hashtags    <int> 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n## $ textfeature_text_copy_n_uq_hashtags <int> 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n## $ textfeature_text_copy_n_mentions    <int> 1, 1, 0, 0, 1, 1, 5, 1, 0, 1, 1, 1‚Ä¶\n## $ textfeature_text_copy_n_uq_mentions <int> 1, 1, 0, 0, 1, 1, 5, 1, 0, 1, 1, 1‚Ä¶\n```\n:::\n\n\n\nDas Rezept beinhaltet also einige Textfeatures plus die FastText-Worteinbettungen.\n\n### Fitting 3 {#sec-klassifik-fit3}\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf3 <-\n  workflow() %>% \n  add_recipe(rec2) %>% \n  add_model(lasso_spec)\n\nwf3\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: logistic_reg()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 6 Recipe Steps\n## \n## ‚Ä¢ step_text_normalization()\n## ‚Ä¢ step_mutate()\n## ‚Ä¢ step_textfeature()\n## ‚Ä¢ step_tokenize()\n## ‚Ä¢ step_stopwords()\n## ‚Ä¢ step_word_embeddings()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Logistic Regression Model Specification (classification)\n## \n## Main Arguments:\n##   penalty = tune()\n##   mixture = 1\n## \n## Computational engine: glmnet\n```\n:::\n\n\n\n\n\n\nTunen und Fitten:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\n\ntic()\nfit3 <-\n  tune_grid(\n    wf3,\n    folds1,\n    grid = lambda_grid,\n    control = control_resamples(save_pred = TRUE)\n  )\n(toc)\nfit3\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#write_rds(fit3, \"objects/chap-klassifik/chap_classific_fit3.rds\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\nHier ist die Performanz:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(fit3)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(fit3)\n```\n\n::: {.cell-output-display}\n![](080-klassifikation_files/figure-html/unnamed-chunk-53-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3 %>% \n  show_best(\"roc_auc\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"penalty\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[7],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"0.0017433288\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8116297\",\"5\":\"10\",\"6\":\"0.008710636\",\"7\":\"Preprocessor1_Model22\"},{\"1\":\"0.0007880463\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8111630\",\"5\":\"10\",\"6\":\"0.008941393\",\"7\":\"Preprocessor1_Model21\"},{\"1\":\"0.0003562248\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8103737\",\"5\":\"10\",\"6\":\"0.009238082\",\"7\":\"Preprocessor1_Model20\"},{\"1\":\"0.0001610262\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8099159\",\"5\":\"10\",\"6\":\"0.009444783\",\"7\":\"Preprocessor1_Model19\"},{\"1\":\"0.0000000001\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8095907\",\"5\":\"10\",\"6\":\"0.009602864\",\"7\":\"Preprocessor1_Model01\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nchosen_auc_fit3 <- \n  fit3 %>%\n  select_by_one_std_err(metric = \"roc_auc\", -penalty)\n```\n:::\n\n\n\n\nFinalisieren:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwf3_final <-\n  finalize_workflow(wf3, chosen_auc_fit3)\n\nwf3_final\n## ‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n## Preprocessor: Recipe\n## Model: logistic_reg()\n## \n## ‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## 6 Recipe Steps\n## \n## ‚Ä¢ step_text_normalization()\n## ‚Ä¢ step_mutate()\n## ‚Ä¢ step_textfeature()\n## ‚Ä¢ step_tokenize()\n## ‚Ä¢ step_stopwords()\n## ‚Ä¢ step_word_embeddings()\n## \n## ‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n## Logistic Regression Model Specification (classification)\n## \n## Main Arguments:\n##   penalty = 0.00853167852417281\n##   mixture = 1\n## \n## Computational engine: glmnet\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n#fit3_final_train <-  # die Berechnung kann dauern ...\n  fit(wf3_final, d_train)\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3_final_train %>% \n  extract_fit_parsnip() %>% \n  tidy() %>% \n  arrange(-abs(estimate)) %>% \n  head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"term\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"estimate\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"penalty\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"(Intercept)\",\"2\":\"1.3359975\",\"3\":\"0.008531679\"},{\"1\":\"profane_n\",\"2\":\"-0.5669547\",\"3\":\"0.008531679\"},{\"1\":\"wordembed_text_v055\",\"2\":\"0.2084922\",\"3\":\"0.008531679\"},{\"1\":\"textfeature_text_copy_n_exclaims\",\"2\":\"-0.1848394\",\"3\":\"0.008531679\"},{\"1\":\"wordembed_text_v089\",\"2\":\"-0.1844506\",\"3\":\"0.008531679\"},{\"1\":\"wordembed_text_v054\",\"2\":\"0.1759950\",\"3\":\"0.008531679\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfit3_final_test <-\n  last_fit(wf3_final, d_split)  # dauert etwas\n```\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\nUnd endlich: Wie gut ist die Performanz?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(fit3_final_test)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"accuracy\",\"2\":\"binary\",\"3\":\"0.7454110\",\"4\":\"Preprocessor1_Model1\"},{\"1\":\"roc_auc\",\"2\":\"binary\",\"3\":\"0.8055475\",\"4\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\nAm Ende so eines Arbeitsganges,\nbei dem man wieder (und wieder) die gleichen Funktionen kopiert,\nund nur aufpassen muss, aus `fit2` an der richtigen Stelle `fit3` zu machen:\nDa blickt man jedem Umbau dieses Codes zu einer Funktion freudig ins Gesicht.\n\nEin anderes Problem,\nf√ºr das hier keine elegante L√∂sung pr√§sentiert wird,\nsind die langen Berechnungszeiten, die, wenn man Pech hat, auch noch\nmehrfach wiederholt werden m√ºssen.\n\nDie Gefahr mit dem Abspeichern via `write_rds` ist klar:\nMan riskiert, sp√§ter ein veraltetes Objekt zu laden.\n\nZu diesen Punkten sp√§ter mehr.\n\n\n\n## Fallstudien\n\n\n\nJulia Silge stellt eine sch√∂ne [Fallstudie](https://juliasilge.com/blog/spam-email/) zur Klassifikation von Spam-Mails bereit. In der Fallstudie geht es nicht um Feature Engineering, sondern um Modellierung.\n\n[ChatGPT generierten Text automatisch erkennen -- ](https://juliasilge.com/blog/gpt-detectors/) wie gut geht das? \nDie Maschine erkennt sich selbst, im besten (oder schlechtesten?) Fall. Die Fallstudie zeigt, naja, so mittel, zumindest in den Daten in der Fallstudie.\n\n\n[OpenAIs Word-Einbettungen](https://platform.openai.com/docs/guides/embeddings) werden in [dieser Fallstudie](https://juliasilge.com/blog/horror-embeddings/) verwendet. Sehr sch√∂n!\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}