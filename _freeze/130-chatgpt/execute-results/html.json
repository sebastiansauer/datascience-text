{
  "hash": "aa72653ed6e17634d63d7dae825f4884",
  "result": {
    "engine": "knitr",
    "markdown": "# ChatGPT-API\n\n\n## Vorab\n\n### Lernziele\n\n\n- Sie k√∂nnen g√§ngige Anfragen an die OpenAI-ChatGPT-API senden.\n\n\n\n### Ben√∂tigte Software (R+Python)\n\n\n::: {.cell hash='130-chatgpt_cache/html/unnamed-chunk-1_3979c45c124d20b5bb9af602f9916c34'}\n\n```{.r .cell-code}\nlibrary(stringr)\nlibrary(httr)  # Wrapper um curl\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport os\n```\n:::\n\n\n\n\n### Spielzeug-Daten\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets <- c(\n'@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?', '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.')\n```\n:::\n\n\n\n\n\n## Grundlagen\n\n\n### ChatGPT ist auch ein Transformer\n\n>    üë®‚Äçüè´ Bist du ein Transformer?\n\n>    ü§ñ Ja, ich bin ein Modell, das auf der GPT-3.5-Architektur von OpenAI basiert, und diese Architektur wird als \"Transformer\" bezeichnet. Der Begriff \"Transformer\" bezieht sich auf die spezifische Architektur des neuronalen Netzwerks, die von Vaswani et al. in ihrem Paper \"Attention is All You Need\" vorgestellt wurde. Die Transformer-Architektur hat sich als √§u√üerst leistungsf√§hig f√ºr nat√ºrliche Sprachverarbeitungsaufgaben erwiesen und bildet die Grundlage f√ºr Modelle wie GPT (Generative Pre-trained Transformer), einschlie√ülich GPT-3.5, auf dem meine F√§higkeiten basieren.\n\n[Quelle: ChatGPT-3.5, 2023-11-23]\n\n\n\n\n\n\n### Alles ist API\n\nDie Python- (oder R-)Pakete zum Zugriff zur ChatGPT-API sind letztlich nur Wrapper um den \"direkten\" Zugriff auf die API.\n\n\n:::{#def-api}\n### API (Application Programming Interface)\nEine API stellt genormte Befehle zur Verf√ºgung, um von einem Dienst (√ºber eine Webseite) Daten abzufragen oder einzustellen. $\\square$\n:::\n\n### `curl` \n\n\n\n`curl` ist eine g√§ngige Methode (auf der Kommondozeile), um Daten von einer Webseite abzufragen (oder einzustellen).\n\nLaut [Dokumentation der API](https://platform.openai.com/examples) lautet der CURL-Befehl wie folgt (Pseudocode):\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{zsh}}\n#| eval: false\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n  \"model\": \"gpt-3.5-turbo\",\n  \"messages\": [{\"role\": \"user\", \"content\": \"Was ist die Frage zur Antwort '42'?\"}] ,\n  \"temperature\": 0,\n  \"max_tokens\": 256\n}'\n```\n````\n:::\n\n\n\nEntscheidend ist der \"Endpunkt\" der URL: `completions`.\n\n\n::: {.callout-note}\nOpenAi stellt eine Reihe von spezialisierten Diensten zur Verf√ºgung, z.B. zur [Sentimentanalyse von Tweets](https://platform.openai.com/examples/default-tweet-classifier) oder, nat√ºrlich, [Textgeneration](https://platform.openai.com/docs/guides/text-generation), und vieles mehr. $\\square$\n:::\n\nObige Syntax √ºbersetzt sich so nach Python:\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# This code is for v1 of the openai package: pypi.org/project/openai\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[],\n  temperature=0,\n  max_tokens=256\n)\n```\n:::\n\n\n\n\n### Prompting\n\nAls Prompt kann man z.B. √ºbergeben (bezeichnet als \"System\"):\n\n>    üßë‚Äçü¶∞ You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative.\nUSER\n\nDann kommt der zu klassifizierende Textschnipsel (bezeichent als \"user\"):\n\n>    üìÑ I loved the new Batman movie!\n\n\nUnd schlie√ülich antwortet der Bot:\n\n>    ü§ñ positive\n\n\n\nEs ist g√ºnstig, dem Bot zu sagen, in welcher Sprache der Tweet ist. \nAu√üerdem ist es n√ºtzlich, den Prompt (die Anweisung) bereits in der Zielsprache zu formulieren.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprompt_stem <- \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: \"\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprompts <- \n  str_c(prompt_stem, tweets)\n\nprompts\n## [1] \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\"                                 \n## [2] \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\"\n```\n:::\n\n\n\n\n### Anmelden an der API\n\nDie API erlaubt nur Zugriffe angemeldeter Nutzer.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nOPENAI_API_KEY <- Sys.getenv(\"OPENAI_API_KEY\")\n```\n:::\n\n\nDamit eine Environment-Variable `OPENAI_API_KEY` ausgelesen werden kann, muss sie in `.Rprofile` definiert sein.\nAlternativ kann man aber die Variable auch auf anderen Wegen definieren, etwa aus einer Textdatei einlesen.\n\n\n:::{.callout-important}\nLassen Sie sensible Daten, wie API-Keys, niemals auf √∂ffentlichen Ordnern oder Repos (etwa auf Github) herumliegen. \nStellen Sie sich vor, Sie haben bei dem Dienst ihre Kreditkarte hinterlege und ein √ºbelwollender Dritter nutzt kostenpflichtige Dienste mit sehr hohem Budget. ü§Ø $\\square$\n:::\n\n\n## Wrapper um curl\n\nDieser Abschnitt basiert auf einem [Blogpost bei R-Bloggers von Rasmus B√•√•th](https://www.r-bloggers.com/2023/03/call-chatgpt-or-really-any-other-api-from-r/).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresponse <- POST(\n  # curl https://api.openai.com/v1/chat/completions \n  url = \"https://api.openai.com/v1/chat/completions\", \n  # -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  add_headers(Authorization = \n                paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\"))),\n  # -H \"Content-Type: application/json\"\n  content_type_json(),\n  # -d '{\n  #   \"model\": \"gpt-3.5-turbo\",\n  #   \"messages\": [{\"role\": \"user\", \"content\": \"What is a banana?\"}] \n  # }'\n  encode = \"json\",\n  body = list(\n    model = \"gpt-3.5-turbo\",\n    messages = list(list(role = \"user\", content = prompts[1]))\n  ))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncontent(response)\n```\n:::\n\n\n\n````\n$object\n[1] \"chat.completion\"\n\n$created\n[1] 1700753610\n\n$model\n[1] \"gpt-3.5-turbo-0613\"\n\n$choices\n$choices[[1]]\n$choices[[1]]$index\n[1] 0\n\n$choices[[1]]$message\n$choices[[1]]$message$role\n[1] \"assistant\"\n\n$choices[[1]]$message$content\n[1] \"Das Sentiment dieses Tweets ist positiv. \"\n\n$choices[[1]]$finish_reason\n[1] \"stop\"\n\n$usage\n$usage$prompt_tokens\n[1] 76\n\n$usage$completion_tokens\n[1] 10\n\n$usage$total_tokens\n[1] 86\n````\n\n\nDer f√ºr uns entscheidende Punkt ist:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr_trim(content(response)$choices[[1]]$message$content)\n```\n:::\n\n\n````\nDas Sentiment dieses Tweets ist positiv. \n````\n\n\n### Curl-Wrapper in eine Funktion gebracht\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nask_chatgpt <- function(prompt) {\nresponse <- POST(\n  # curl https://api.openai.com/v1/chat/completions \n  url = \"https://api.openai.com/v1/chat/completions\", \n  # -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  add_headers(Authorization = \n                paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\"))),\n  # -H \"Content-Type: application/json\"\n  content_type_json(),\n  # -d '{\n  #   \"model\": \"gpt-3.5-turbo\",\n  #   \"messages\": [{\"role\": \"user\", \"content\": \"What is a banana?\"}] \n  # }'\n  encode = \"json\",\n  body = list(\n    model = \"gpt-3.5-turbo\",\n    messages = list(list(role = \"user\", content = prompt))\n  ))\n  str_trim(content(response)$choices[[1]]$message$content)\n}\n```\n:::\n\n\n\n\n### Schleife\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprompts |> \n  sapply(ask_chatgpt)\n```\n:::\n\n\n`sapply` ist sehr √§hnlich wie `map` aus `{purrr}`, braucht aber kein Extrapaket.\n\n\n```\nNach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar? \n\n\"positiv\" \n \nNach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir. \n\n \"neutral\"\n````\n\n\n\n\n\n## Einfache Anfrage an die OpenAI-API\n\n::: callout-important\n\nDer API-Aufruf von ChatGPT kostet Geld üí∏. $\\square$\n:::\n\n\n### Authentifizierung\n\n\nWir m√ºssen uns zun√§chst bei der API anmelden:\n\n\n:::{.panel-tabset}\n\n\n### R\n\n::: {.cell}\n\n```{.r .cell-code}\nopenai_key_r <- Sys.getenv(\"OPENAI_API_KEY\")\n```\n:::\n\n\n### Python\n\n\n::: {.cell}\n\n```{.python .cell-code}\nopenai_key_py = os.environ.get(\"OPENAI_API_KEY\")\n```\n:::\n\n\n\n:::\n\n:::callout-caution\nSpeichern Sie *keine* sensiblen Daten in geteilten Ordner/Repos. Achten Sie auch auf Log-Dateien wir `.Rhistory`, in der u.U. Ihre sensiblen Daten enthalten sein k√∂nnen. $\\square$\n:::\n\nEine sichere Variante als das unverschl√ºsselte Speichern von Passw√∂rtern ist es, sensible Daten mit einem Passwort zu sch√ºtzen. \nDazu kann man z.B. in R das Paket `keyring` nutzen.\nDieses Paket greift auf die Schl√ºsselbundverwaltung Ihres Betriebssystems zur√ºck (sowohl Windows, Mac, als auch (einige?) Linux-Distrubitionen).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(keyring)\nopenai_key_r <- key_get(\"OPENAI_API_KEY\")\n```\n:::\n\n\n\n\n### Setup\n\n\n::: {.cell}\n\n```{.python .cell-code}\nsentiment_scores = []\nsentiment_analysis = []\ntext = '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.'\n```\n:::\n\n\n\n### Anfrage an die API\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprompt = f\"Analysiere das Sentiment des folgenden Texts: \\n{text}\"\n\nresponse = openai.Completion.create(\n        prompt=prompt,\n        engine=\"davinci\",\n        max_tokens=100,\n        temperature=0.5,\n    )\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Vertiefung\n\n\nMit etwas Zusatzaufwand kann man den Kontext bzw. den Verlauf der Konversation mit dem Bot ber√ºcksichtigen, wie [dieser Post zeigt](https://blog.devgenius.io/how-to-maintain-conversation-flow-in-with-chatgpts-api-in-r-part-17-of-r-for-applied-d010cca1326a).\n\nDie OpenAI-API bietet ebenfalls Fine-Tuning an, wie [in diesem Post](https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model) beschrieben.\n\n\n## Aufgaben\n\n\nSchauen Sie sich die Aufgaben mit dem [Tag 'Transformer' auf dem Datenwerk](https://datenwerk.netlify.app/#category=transformer) an.\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}