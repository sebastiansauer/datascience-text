{
  "hash": "f3b34c6026956ddce9c13b7b3db9f094",
  "result": {
    "markdown": "# Fallstudie Hatespeech\n\n\n\n\nWir sagen vorher, welche Tweets an führende deutsche Politikis Hassrede bzw. hasserfüllte Rede enthalten.\n\n\n## Vorab\n\n\n\n\n### Lernziele\n\n\n- Sie können grundlegende Verfahren zur Klassifikation von Hatespeech einsetzen und erklären\n- Sie können mit echten Daten umgehen im Sinne eines Projektmanagement von Data Science\n\n\n\n\n\n\n\n\n### Benötigte R-Pakete\n\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-1_855718cab53ea91450e645bd1750a2d3'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(easystats)\nlibrary(tidytext)\nlibrary(textrecipes)\nlibrary(tictoc)  # Zeitmessung\nlibrary(beepr)  # piebt, wenn fertig\nlibrary(remoji)  # Emojis\nlibrary(feather)  # Daten speichern\nlibrary(pradadata)  # Hilfsdaten wie Schimpfwoerter\nlibrary(lubridate)  # Datum und Zeit\nlibrary(tokenizers)\nlibrary(feather)  # feather data\nlibrary(pradadata)  # helper data\nlibrary(remoji)  # processing emojis\n```\n:::\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-2_2cb42f375072c02ae17db11def530d80'}\n\n:::\n\n\n\n## Daten\n\n\n### Train- und Testdaten\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-3_aa6813e565f02e67f9cca0c4cc4c9896'}\n\n```{.r .cell-code}\nd1 <- read_rds(\"objects/d1.rds\")  # Traindaten einlesen\n```\n:::\n\n\n\nIn Train- und Test-Datensatz aufsplitten:\n\n\n::: {.cell hash='070-hatespeech2_cache/html/d-split-d1_252c1f96c26fa49f9e6e8f397eb35e12'}\n\n```{.r .cell-code}\nd_split <- initial_split(d1, strata = c1)\n\nd_train <- training(d_split)\nd_test <- testing(d_split)\n```\n:::\n\n\n\n\n\n\n\n### Vorhersagedaten\n\nWir importieren die Tweets führender deutscher Politikis.\n\nFür diese Daten haben wir keine Werte der Zielvariablen. \nWir können nur vorhersagen,\naber nicht unsere Modellgüte berechnen.\nDiese Daten bezeichnen wir als *Vorhersagedaten*.\n\n\n\nPfad zu den Daten:\n\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-4_02118b77711c32a1299f5813b2239f8f'}\n\n```{.r .cell-code}\ntweet_data_path <- \"/Users/sebastiansaueruser/github-repos/hate-speech/data-raw/tweets-small\"\n\nfile.exists(tweet_data_path)\n## [1] TRUE\n```\n:::\n\n\n\nDie Nutzungsrechte von Twitter erlauben nicht, diese Daten öffentlich zu teilen.\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-5_81145bb243160ca8fafae1251262362c'}\n\n```{.r .cell-code}\ntweet_data_files_names <-\n  list.files(\n    path = tweet_data_path,\n    full.names = TRUE,\n    pattern = \".rds\")\n\n\nnames(tweet_data_files_names) <-  \n  list.files(\n    path = tweet_data_path,\n    full.names = FALSE,\n    pattern = \".rds\") %>% \n  str_remove(\".rds$\") %>% \n  str_remove(\"^tweets-to-\")\n\ntweet_data_files_names\n##                                                                                                    BMWK_2021 \n##           \"/Users/sebastiansaueruser/github-repos/hate-speech/data-raw/tweets-small/tweets-to-BMWK_2021.rds\" \n##                                                                                          Janine_Wissler_2021 \n## \"/Users/sebastiansaueruser/github-repos/hate-speech/data-raw/tweets-small/tweets-to-Janine_Wissler_2021.rds\" \n##                                                                                          Janine_Wissler_2022 \n## \"/Users/sebastiansaueruser/github-repos/hate-speech/data-raw/tweets-small/tweets-to-Janine_Wissler_2022.rds\"\n```\n:::\n\n\n\n\nSo lesen wir alle Dateien aus diesem Ordner ein.\nZunächst erstellen wir uns eine Helper-Funktion:\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/source-fun-read-and-select_d1ca239a945d8daa86f9406cfe8ca07f'}\n\n```{.r .cell-code}\nsource(\"funs/read-and-select.R\")\n```\n:::\n\n\n\n\nDie Funktion `read_and_select`  mappen wir auf alle Datendateien:\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/map-read-and-select_66f64b08bb15aba99b5ce905f58bc228'}\n\n```{.r .cell-code}\ntic()\nds <-\n  tweet_data_files_names %>% \n  map_dfr(read_and_select, .id = \"dataset\")\n## Data file was read.\n## Data file was read.\n## Data file was read.\ntoc()\n## 2.381 sec elapsed\n```\n:::\n\n\n\nEin Blick zur Probe:\n\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-6_303d1f8d5edd2674e89bf3f58b2cbd60'}\n\n```{.r .cell-code}\nds %>% \n  glimpse()\n## Rows: 10,310\n## Columns: 9\n## $ dataset       <chr> \"BMWK_2021\", \"BMWK_2021\", \"BMWK_2021\", \"BMWK_2021\", \"BMW…\n## $ id            <chr> \"1476982045268185091\", \"1476948509706407942\", \"147694476…\n## $ author_id     <chr> \"749510675811139585\", \"146337393\", \"841768687245918208\",…\n## $ created_at    <chr> \"2021-12-31T18:22:15.000Z\", \"2021-12-31T16:08:59.000Z\", …\n## $ text          <chr> \"@BMWi_Bund @twittlik @Pendolino70 @nextmove_de Richtig.…\n## $ retweet_count <int> 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n## $ reply_count   <int> 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0,…\n## $ like_count    <int> 0, 0, 1, 0, 0, 1, 1, 3, 3, 0, 3, 0, 0, 1, 0, 0, 1, 2, 1,…\n## $ quote_count   <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n```\n:::\n\n\n\n\nDa wir den Elementen von `tweet_data_files_names` Namen gegeben haben, \nfinden wir diese Namen praktischerweise wieder in `ds`.\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-7_2bfc18bfba183f6cdb08fc4dbba116a1'}\n\n:::\n\n\n\n\n\nEine Alternative zum Format RDS besteht im Format [Feather](https://github.com/wesm/feather):\n\n>   Feather: fast, interoperable data frame storage\nFeather provides binary columnar serialization for data frames. \nIt is designed to make reading and writing data frames efficient, and to make sharing data across data analysis languages easy. \n\n\n\n\n\n### Worteinbettungen\n\nWie in @sec-fasttext dargestellt, importieren wir unser FastText-Modell.\n\n\n::: {.cell hash='070-hatespeech2_cache/html/read-fastext-twitter_011b9efe8fef62d7b2a5481a8ccfc704'}\n\n```{.r .cell-code}\nword_embedding_twitter <- read_rds(file = \"/Users/sebastiansaueruser/datasets/Twitter/word_embedding_twitter.rds\")\n```\n:::\n\n\n\nWie viel Speicher benötigt das Worteinbettungsobjekt?\n\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-8_01cb88b8fc952e11164965d3d6a64013'}\n\n```{.r .cell-code}\nformat(object.size(word_embedding_twitter), units = \"Mb\")\n## [1] \"108.3 Mb\"\n```\n:::\n\n\n\n\n### Hilfsdaten\n\n\n::: {.cell hash='070-hatespeech2_cache/html/load-helper-data_f2a721a5af010856cb3f469346308f1b'}\n\n```{.r .cell-code}\ndata(\"schimpwoerter\")\n## Warning in data(\"schimpwoerter\"): data set 'schimpwoerter' not found\ndata(\"sentiws\")\ndata(\"wild_emojis\")\n```\n:::\n\n\n\n\n## Aufbereiten der Vorhersagedaten\n\n### Hilfsfunktionen\n\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/source-helper-funs-recipe_ee4e79c44a533f0904e04435d62cbdbd'}\n\n```{.r .cell-code}\nsource(\"funs/helper-funs-recipes.R\")\n```\n:::\n\n\n\n## Rezept\n\n\nDa wir schon ein Rezept \"trainiert\" haben,\nkönnen wir die Test-Daten einfach mit dem Rezept \"backen\".\n\nStreng genommen müssten wir nicht mal das tun,\ndenn `tidymodels` würde das beim Vorhersagen für uns übernehmen.\nAber es ist nützlich, die Daten in aufbereiteter Form zu sehen,\nbzw. sie direkt zugänglich zu haben.\n\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/rec2_f1739f8f2d1f6854728c1ce49b46bcf9'}\n\n```{.r .cell-code}\nrec2 <- \n  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% \n  update_role(id, new_role = \"id\") %>% \n  step_text_normalization(text) %>% \n  step_mutate(text_copy = text,\n              profane_n = map_int(text_copy, count_profane, profane_list = schimpfwoerter$word),\n              emo_words_n = map_int(text_copy, count_emo_words, emo_list = sentiws$word),\n              emojis_n = map_int(text_copy, count_emojis, emoji_list = emoji(list_emoji(), pad = FALSE)),\n              wild_emojis_n = map_int(text_copy, count_wild_emojis, wild_emoji_list = wild_emojis$emojis)\n  ) %>% \n  step_textfeature(text_copy) %>% \n  step_tokenize(text, token = \"tweets\") %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>% \n  step_word_embeddings(text, embeddings = word_embedding_twitter)\n \nrec2\n```\n:::\n\n\n\n### Preppen und Backen\n\nPreppen:\n\n\n::: {.cell hash='070-hatespeech2_cache/html/rec2-prepped-baked_2fdf5209b4d666185aaca825ba4bd2f6'}\n\n```{.r .cell-code}\ntic()\nrec2_prepped <- prep(rec2)\ntoc()\n```\n:::\n\n\n\n```\n29.377 sec elapsed\n```\n\nBraucht ganz schön Zeit ...\n\n\n\n\nZur Sicherheit speichern wir auch dieses Objekt ab.\n\n\n::: {.cell hash='070-hatespeech2_cache/html/read-rec2-prepped_8719dd50698c2285f4cf0938968d9b71'}\n\n```{.r .cell-code}\n# write_rds(rec2_prepped, \"objects/rec2_prepped.rds\")\nrec2_prepped <- read_rds(\"/Users/sebastiansaueruser/datasets/Twitter/hate-classific/rec2_prepped.rds\")\n```\n:::\n\n\n\n\nAls nächstes kommt das Backen der Vorhersagedaten.\nDas ist die Stelle, an der zum ersten Mal die neuen Daten (die Vorhersagedaten) ins Spiel kommen.\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/bake-rec2_51662861d475e8c20a7bb372ceeac71b'}\n\n```{.r .cell-code}\ntic()\nd_predict_baken <-\n  bake(rec2_prepped, new_data = ds)\n\nd_predict_baken$id <- ds$id\ntoc()\nbeepr::beep()\n```\n:::\n\n\nPuh, das Backen dauert - bei großen Datensätzen - gefühlt ewig!\nDaher ist das `beep`en praktisch:\nEs klingelt, wenn die Berechnung fertig ist.\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/read-predict-baken_6706990d5126e86ff68c52e0051fb5fb'}\n\n:::\n\n\n\nZur Erinnerung: `d_predict_baken` ist der \"gebackene\" Testdatensatz.\nDer Testdatensatz also,\nauf dem die ganzen Operationen der Vorverarbeitung angewandt wurden.\n\n\n\n\n### Git Large File System\n\n\nWenn Sie Ihre Arbeit mit einem Versionierungssystem schützen - und Sie sollten es tun - \ndann verwenden Sie vermutlich Git.\nGit ist für Textdateien ausgelegt - was bei Quellcode ja auch Sinn macht,\nund für Quellcode ist Git gemacht.\nAllerdings will man manchmal auch binäre Dateien sichern,\netwa Daten im RDS-Format.\nSolche binären Formante funktionieren nicht wirklich aus der Sicht von Git,\nsie lassen sich nicht zeilenweise nachverfolgen.\nKurz gesagt sollte man sie aus diesem Grund nicht in Git nachverfolgen.\nEine bequeme Lösung ist das[ *Large File System* von Github (git lfs)](https://git-lfs.github.com/),\ndas diese großen Dateien außerhalb des Git-Index verwaltet.\nTrotzdem sieht es für Nutzis aus wie immer,\nist also sehr komfortabel.\nDazu ist es nötig, [git lfs](https://www.veit-schiele.de/dienstleistungen/technische-dokumentation/git/git-lfs) zu installieren.\n\n\n\n\n### Metadaten\n\n\nMetadaten wieder hinzufügen:\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/re-add-metadata3_64f34bb89b35dfcd83be725b9d00a8c4'}\n\n```{.r .cell-code}\nd_predict2 <-\n  d_predict_baken %>% \n  left_join(ds, by = \"id\") %>% \n  relocate(dataset, id, author_id, created_at, text, retweet_count, reply_count, quote_count, .after = id) %>% \n  mutate(id = as.integer(id))\n## Warning: There was 1 warning in `mutate()`.\n## ℹ In argument: `id = as.integer(id)`.\n## Caused by warning:\n## ! NAs introduced by coercion to integer range\n```\n:::\n\n\nLeider müssen wir `id` in Integer umwandeln,\ndas wir dies im Rezept auch so gemacht hatten.\nDabei geht die Spalte kaputt, bzw. die Daten werden NA,\nda die resultierende Integerzahl zu groß für R ist.\nAber nicht so schlimm: Wir fügen sie später wieder hinzu.\n\n\nSpaltennamen mal anschauen:\n\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-9_99861a76ed8c541fe00f43cbe0965e96'}\n\n```{.r .cell-code}\nnames(d_predict2)[1:33]\n##  [1] \"dataset\"                             \"id\"                                 \n##  [3] \"author_id\"                           \"created_at\"                         \n##  [5] \"text\"                                \"retweet_count\"                      \n##  [7] \"reply_count\"                         \"quote_count\"                        \n##  [9] \"profane_n\"                           \"emo_words_n\"                        \n## [11] \"emojis_n\"                            \"wild_emojis_n\"                      \n## [13] \"textfeature_text_copy_n_words\"       \"textfeature_text_copy_n_uq_words\"   \n## [15] \"textfeature_text_copy_n_charS\"       \"textfeature_text_copy_n_uq_charS\"   \n## [17] \"textfeature_text_copy_n_digits\"      \"textfeature_text_copy_n_hashtags\"   \n## [19] \"textfeature_text_copy_n_uq_hashtags\" \"textfeature_text_copy_n_mentions\"   \n## [21] \"textfeature_text_copy_n_uq_mentions\" \"textfeature_text_copy_n_commas\"     \n## [23] \"textfeature_text_copy_n_periods\"     \"textfeature_text_copy_n_exclaims\"   \n## [25] \"textfeature_text_copy_n_extraspaces\" \"textfeature_text_copy_n_caps\"       \n## [27] \"textfeature_text_copy_n_lowers\"      \"textfeature_text_copy_n_urls\"       \n## [29] \"textfeature_text_copy_n_uq_urls\"     \"textfeature_text_copy_n_nonasciis\"  \n## [31] \"textfeature_text_copy_n_puncts\"      \"textfeature_text_copy_politeness\"   \n## [33] \"textfeature_text_copy_first_person\"\n```\n:::\n\n\n\n\n## Vorhersagen\n\nWir beziehen uns auf das Modell von @sec-klassifik-fit3.\n\n\n::: {.cell hash='070-hatespeech2_cache/html/read-fit3-fit3-final_4c36ba8a7964ffcede1d4aad275b5414'}\n\n```{.r .cell-code}\nfit3 <- read_rds(\"/Users/sebastiansaueruser/github-repos/datascience-text/objects/chap_classific_fit3.rds\")\n\nfit3_final_train <- read_rds(\"/Users/sebastiansaueruser/datasets/Twitter/hate-classific/fit3_final_train.rds\")\n```\n:::\n\n\n\n\n\nUnd nutzen dann die [predict](https://parsnip.tidymodels.org/reference/predict.model_fit.html)-Methode von `{tidymodels}`:\n\n\n::: {.cell hash='070-hatespeech2_cache/html/predict-fit3_543125cf78e44cd466d406cb93290ea7'}\n\n```{.r .cell-code}\ntic()\nd_predicted_values <- predict(fit3_final_train, d_predict2)\ntoc()\nbeep()\n```\n:::\n\n\n\n\nPuh, hier ist mein Rechner abgestürzt,\nals ich es mit ca. 2 Millionen Tweets versucht habe!\n\nBesser, wir probieren erstmal mit einem winzigen Teil der Daten,\nob unsere Funktion \"im Prinzip\" oder \"grundsätzlich\" funktioniert:\n\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/predict-fit3-tiny_461c6eef3be99cb0c83929fa6231a21f'}\n\n```{.r .cell-code}\nd_predicted_values_tiny <- predict(fit3_final_train, head(d_predict2))\n## Error:\n## ! Can't convert `data$id` <integer> to match type of `id` <character>.\n\nd_predicted_values_tiny\n## Error in eval(expr, envir, enclos): object 'd_predicted_values_tiny' not found\n```\n:::\n\n\n\nFunktioniert! Gut! Also weiter.\n\n\n\nPasst!\n\n\n\n\n## Ergebnisse\n\n### Hass-Proxis pro Politiki insgesamt\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/res-summary1_960f2a3c3e887fb5c9b1548322dad5c9'}\n\n```{.r .cell-code}\nres_summary1 <- \nd_predict2 %>% \n  group_by(dataset) %>% \n  summarise(emo_words_n_mean = mean(emo_words_n),\n            profane_words_count_mean = mean(profane_n),\n            wild_emojis_n_mean = mean(wild_emojis_n),\n            exclaims_n_mean = mean(textfeature_text_copy_n_exclaims))\n\n\nres_summary1_long <-\n  res_summary1 %>% \n    pivot_longer(-dataset, names_to = \"hate_proxy\", values_to = \"prop\")\n```\n:::\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-10_a5c63109d18f4ccb38fffdef9df7c8ca'}\n\n```{.r .cell-code}\nres_summary1_long %>% \n  ggplot(aes(x = prop, y = hate_proxy)) +\n  geom_col() +\n  facet_wrap(~ dataset)\n```\n\n::: {.cell-output-display}\n![](070-hatespeech2_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Hass-Proxis pro Politiki im Zeitverlauf\n\n\n\n::: {.cell hash='070-hatespeech2_cache/html/res-summary2_4c37ff9d1127a8c76651c32c44a53bd0'}\n\n```{.r .cell-code}\nres_summary2 <- \nd_predict2 %>%\n  select(created_at, profane_n, dataset, emo_words_n, wild_emojis_n, textfeature_text_copy_n_exclaims) %>% \n  mutate(month = ymd_hms(created_at) %>% round_date(unit = \"month\")) %>% \n  group_by(month, dataset) %>% \n  summarise(emo_words_n_mean = mean(emo_words_n),\n            profane_words_count_mean = mean(profane_n),\n            wild_emojis_n_mean = mean(wild_emojis_n),\n            exclaims_n_mean = mean(textfeature_text_copy_n_exclaims)) %>% \n  rowwise() %>% \n  mutate(hate_proxy = mean(c_across(emo_words_n_mean:exclaims_n_mean))) %>% \n  ungroup()\n## `summarise()` has grouped output by 'month'. You can override using the\n## `.groups` argument.\n  \nres_summary2 %>% \n  head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"month\"],\"name\":[1],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"dataset\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"emo_words_n_mean\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"profane_words_count_mean\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"wild_emojis_n_mean\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"exclaims_n_mean\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"hate_proxy\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2021-04-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"0.00\"},{\"1\":\"2021-05-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"1\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"0.25\"},{\"1\":\"2021-06-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"1\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"0.25\"},{\"1\":\"2021-09-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"0.00\"},{\"1\":\"2021-10-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"0.00\"},{\"1\":\"2021-11-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"0\",\"4\":\"0\",\"5\":\"0\",\"6\":\"0\",\"7\":\"0.00\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nLangifizieren fürs Plotten:\n\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-11_b5d075100c7a2cccb8948ba4fe76fd05'}\n\n```{.r .cell-code}\nres_summary2_long <- \n  res_summary2 %>% \n  pivot_longer(emo_words_n_mean:hate_proxy)\n\nres_summary2_long %>% \n  head()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"month\"],\"name\":[1],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"dataset\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"name\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"value\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2021-04-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"emo_words_n_mean\",\"4\":\"0\"},{\"1\":\"2021-04-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"profane_words_count_mean\",\"4\":\"0\"},{\"1\":\"2021-04-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"wild_emojis_n_mean\",\"4\":\"0\"},{\"1\":\"2021-04-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"exclaims_n_mean\",\"4\":\"0\"},{\"1\":\"2021-04-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"hate_proxy\",\"4\":\"0\"},{\"1\":\"2021-05-01\",\"2\":\"Janine_Wissler_2021\",\"3\":\"emo_words_n_mean\",\"4\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-12_bad8a736437b00fa78891f718581fe8b'}\n\n```{.r .cell-code}\nres_summary2_long %>% \n  count(month)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"month\"],\"name\":[1],\"type\":[\"dttm\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2021-04-01\",\"2\":\"5\"},{\"1\":\"2021-05-01\",\"2\":\"5\"},{\"1\":\"2021-06-01\",\"2\":\"5\"},{\"1\":\"2021-09-01\",\"2\":\"5\"},{\"1\":\"2021-10-01\",\"2\":\"5\"},{\"1\":\"2021-11-01\",\"2\":\"5\"},{\"1\":\"2021-12-01\",\"2\":\"5\"},{\"1\":\"2022-06-01\",\"2\":\"5\"},{\"1\":\"2022-09-01\",\"2\":\"5\"},{\"1\":\"2022-11-01\",\"2\":\"5\"},{\"1\":\"<NA>\",\"2\":\"5\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell hash='070-hatespeech2_cache/html/unnamed-chunk-13_55e0cbf2062c465288625a4a0b1111ad'}\n\n```{.r .cell-code}\nres_summary2_long %>% \n  ggplot() +\n  aes(x = month, y = value) +\n  facet_grid(dataset  ~ name) +\n  geom_point() +\n  geom_line(group=1, alpha = .7)\n## Warning: Removed 5 rows containing missing values (`geom_point()`).\n## Warning: Removed 5 rows containing missing values (`geom_line()`).\n```\n\n::: {.cell-output-display}\n![](070-hatespeech2_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}