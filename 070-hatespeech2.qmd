# Fallstudie Hatespeech




Wir sagen vorher, welche Tweets an führende deutsche Politikis Hassrede bzw. hasserfüllte Rede enthalten.


## Vorab




### Lernziele


- Sie können grundlegende Verfahren zur Klassifikation von Hatespeech einsetzen und erklären
- Sie können mit echten Daten umgehen im Sinne eines Projektmanagement von Data Science








### Benötigte R-Pakete

```{r}
#| message: false
library(tidyverse)
library(tidymodels)
library(easystats)
library(tidytext)
library(textrecipes)
library(tictoc)  # Zeitmessung
library(beepr)  # piebt, wenn fertig
library(remoji)  # Emojis
library(feather)  # Daten speichern
library(pradadata)  # Hilfsdaten wie Schimpfwoerter
library(lubridate)  # Datum und Zeit
library(tokenizers)
library(feather)  # feather data
library(pradadata)  # helper data
library(remoji)  # processing emojis
```


```{r}
#| echo: false
theme_set(theme_minimal())
```


## Daten


### Train- und Testdaten


```{r}
d1 <- read_rds("objects/d1.rds")  # Traindaten einlesen
```


In Train- und Test-Datensatz aufsplitten:

```{r d-split-d1}
d_split <- initial_split(d1, strata = c1)

d_train <- training(d_split)
d_test <- testing(d_split)
```






### Vorhersagedaten

Wir importieren die Tweets führender deutscher Politikis.

Für diese Daten haben wir keine Werte der Zielvariablen. 
Wir können nur vorhersagen,
aber nicht unsere Modellgüte berechnen.
Diese Daten bezeichnen wir als *Vorhersagedaten*.



Pfad zu den Daten:

```{r}
tweet_data_path <- "/Users/sebastiansaueruser/github-repos/hate-speech/data-raw/tweets-small"

file.exists(tweet_data_path)
```


Die Nutzungsrechte von Twitter erlauben nicht, diese Daten öffentlich zu teilen.


```{r}
tweet_data_files_names <-
  list.files(
    path = tweet_data_path,
    full.names = TRUE,
    pattern = ".rds")


names(tweet_data_files_names) <-  
  list.files(
    path = tweet_data_path,
    full.names = FALSE,
    pattern = ".rds") %>% 
  str_remove(".rds$") %>% 
  str_remove("^tweets-to-")

tweet_data_files_names
```



So lesen wir alle Dateien aus diesem Ordner ein.
Zunächst erstellen wir uns eine Helper-Funktion:


```{r source-fun-read-and-select}
source("funs/read-and-select.R")
```



Die Funktion `read_and_select`  mappen wir auf alle Datendateien:


```{r map-read-and-select}
#| eval: true
tic()
ds <-
  tweet_data_files_names %>% 
  map_dfr(read_and_select, .id = "dataset")
toc()
```


Ein Blick zur Probe:

```{r}
ds %>% 
  glimpse()
```



Da wir den Elementen von `tweet_data_files_names` Namen gegeben haben, 
finden wir diese Namen praktischerweise wieder in `ds`.


```{r}
#| echo: false
#| eval: false
#write_rds(ds, file = paste0(tweet_data_path, "ds.rds"))
#write_feather(ds, path = paste0(tweet_data_path, "ds.feather"))
```




Eine Alternative zum Format RDS besteht im Format [Feather](https://github.com/wesm/feather):

>   Feather: fast, interoperable data frame storage
Feather provides binary columnar serialization for data frames. 
It is designed to make reading and writing data frames efficient, and to make sharing data across data analysis languages easy. 





### Worteinbettungen

Wie in @sec-fasttext dargestellt, importieren wir unser FastText-Modell.

```{r read-fastext-twitter}
#| eval: true
word_embedding_twitter <- read_rds(file = "/Users/sebastiansaueruser/datasets/Twitter/word_embedding_twitter.rds")
```


Wie viel Speicher benötigt das Worteinbettungsobjekt?

```{r}
format(object.size(word_embedding_twitter), units = "Mb")
```



### Hilfsdaten

```{r load-helper-data}
data("schimpwoerter")
data("sentiws")
data("wild_emojis")
```



## Aufbereiten der Vorhersagedaten

### Hilfsfunktionen



```{r source-helper-funs-recipe}
source("funs/helper-funs-recipes.R")
```


## Rezept


Da wir schon ein Rezept "trainiert" haben,
können wir die Test-Daten einfach mit dem Rezept "backen".

Streng genommen müssten wir nicht mal das tun,
denn `tidymodels` würde das beim Vorhersagen für uns übernehmen.
Aber es ist nützlich, die Daten in aufbereiteter Form zu sehen,
bzw. sie direkt zugänglich zu haben.



```{r rec2}
#| eval: false
rec2 <- 
  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% 
  update_role(id, new_role = "id") %>% 
  step_text_normalization(text) %>% 
  step_mutate(text_copy = text,
              profane_n = map_int(text_copy, count_profane, profane_list = schimpfwoerter$word),
              emo_words_n = map_int(text_copy, count_emo_words, emo_list = sentiws$word),
              emojis_n = map_int(text_copy, count_emojis, emoji_list = emoji(list_emoji(), pad = FALSE)),
              wild_emojis_n = map_int(text_copy, count_wild_emojis, wild_emoji_list = wild_emojis$emojis)
  ) %>% 
  step_textfeature(text_copy) %>% 
  step_tokenize(text, token = "tweets") %>% 
  step_stopwords(text, language = "de", stopword_source = "snowball") %>% 
  step_word_embeddings(text, embeddings = word_embedding_twitter)
 
rec2
```


### Preppen und Backen

Preppen:

```{r rec2-prepped-baked}
#| eval: false
tic()
rec2_prepped <- prep(rec2)
toc()
```


```
29.377 sec elapsed
```

Braucht ganz schön Zeit ...




Zur Sicherheit speichern wir auch dieses Objekt ab.

```{r read-rec2-prepped}
#| echo: true
#| eval: false
# write_rds(rec2_prepped, "objects/rec2_prepped.rds")
rec2_prepped <- read_rds("/Users/sebastiansaueruser/datasets/Twitter/hate-classific/rec2_prepped.rds")
```



Als nächstes kommt das Backen der Vorhersagedaten.
Das ist die Stelle, an der zum ersten Mal die neuen Daten (die Vorhersagedaten) ins Spiel kommen.


```{r bake-rec2}
#| eval: false
tic()
d_predict_baken <-
  bake(rec2_prepped, new_data = ds)

d_predict_baken$id <- ds$id
toc()
beepr::beep()
```

Puh, das Backen dauert - bei großen Datensätzen - gefühlt ewig!
Daher ist das `beep`en praktisch:
Es klingelt, wenn die Berechnung fertig ist.


```{r read-predict-baken}
#| echo: false
d_predict_baken <- read_rds(file = "objects/d_predict_baken.rds")
```


Zur Erinnerung: `d_predict_baken` ist der "gebackene" Testdatensatz.
Der Testdatensatz also,
auf dem die ganzen Operationen der Vorverarbeitung angewandt wurden.




### Git Large File System


Wenn Sie Ihre Arbeit mit einem Versionierungssystem schützen - und Sie sollten es tun - 
dann verwenden Sie vermutlich Git.
Git ist für Textdateien ausgelegt - was bei Quellcode ja auch Sinn macht,
und für Quellcode ist Git gemacht.
Allerdings will man manchmal auch binäre Dateien sichern,
etwa Daten im RDS-Format.
Solche binären Formante funktionieren nicht wirklich aus der Sicht von Git,
sie lassen sich nicht zeilenweise nachverfolgen.
Kurz gesagt sollte man sie aus diesem Grund nicht in Git nachverfolgen.
Eine bequeme Lösung ist das[ *Large File System* von Github (git lfs)](https://git-lfs.github.com/),
das diese großen Dateien außerhalb des Git-Index verwaltet.
Trotzdem sieht es für Nutzis aus wie immer,
ist also sehr komfortabel.
Dazu ist es nötig, [git lfs](https://www.veit-schiele.de/dienstleistungen/technische-dokumentation/git/git-lfs) zu installieren.




### Metadaten


Metadaten wieder hinzufügen:


```{r re-add-metadata3}
d_predict2 <-
  d_predict_baken %>% 
  left_join(ds, by = "id") %>% 
  relocate(dataset, id, author_id, created_at, text, retweet_count, reply_count, quote_count, .after = id) %>% 
  mutate(id = as.integer(id))
```

Leider müssen wir `id` in Integer umwandeln,
das wir dies im Rezept auch so gemacht hatten.
Dabei geht die Spalte kaputt, bzw. die Daten werden NA,
da die resultierende Integerzahl zu groß für R ist.
Aber nicht so schlimm: Wir fügen sie später wieder hinzu.


Spaltennamen mal anschauen:

```{r}
names(d_predict2)[1:33]
```



## Vorhersagen

Wir beziehen uns auf das Modell von @sec-klassifik-fit3.

```{r read-fit3-fit3-final}
fit3 <- read_rds("/Users/sebastiansaueruser/github-repos/datascience-text/objects/chap_classific_fit3.rds")

fit3_final_train <- read_rds("/Users/sebastiansaueruser/datasets/Twitter/hate-classific/fit3_final_train.rds")
```




Und nutzen dann die [predict](https://parsnip.tidymodels.org/reference/predict.model_fit.html)-Methode von `{tidymodels}`:

```{r predict-fit3}
#| eval: false
tic()
d_predicted_values <- predict(fit3_final_train, d_predict2)
toc()
beep()
```



Puh, hier ist mein Rechner abgestürzt,
als ich es mit ca. 2 Millionen Tweets versucht habe!

Besser, wir probieren erstmal mit einem winzigen Teil der Daten,
ob unsere Funktion "im Prinzip" oder "grundsätzlich" funktioniert:



```{r predict-fit3-tiny, error = TRUE}
d_predicted_values_tiny <- predict(fit3_final_train, head(d_predict2))

d_predicted_values_tiny
```


Funktioniert! Gut! Also weiter.



Passt!




## Ergebnisse

### Hass-Proxis pro Politiki insgesamt


```{r res-summary1}
res_summary1 <- 
d_predict2 %>% 
  group_by(dataset) %>% 
  summarise(emo_words_n_mean = mean(emo_words_n),
            profane_words_count_mean = mean(profane_n),
            wild_emojis_n_mean = mean(wild_emojis_n),
            exclaims_n_mean = mean(textfeature_text_copy_n_exclaims))


res_summary1_long <-
  res_summary1 %>% 
    pivot_longer(-dataset, names_to = "hate_proxy", values_to = "prop")
```


```{r}
res_summary1_long %>% 
  ggplot(aes(x = prop, y = hate_proxy)) +
  geom_col() +
  facet_wrap(~ dataset)
```




### Hass-Proxis pro Politiki im Zeitverlauf


```{r res-summary2}
res_summary2 <- 
d_predict2 %>%
  select(created_at, profane_n, dataset, emo_words_n, wild_emojis_n, textfeature_text_copy_n_exclaims) %>% 
  mutate(month = ymd_hms(created_at) %>% round_date(unit = "month")) %>% 
  group_by(month, dataset) %>% 
  summarise(emo_words_n_mean = mean(emo_words_n),
            profane_words_count_mean = mean(profane_n),
            wild_emojis_n_mean = mean(wild_emojis_n),
            exclaims_n_mean = mean(textfeature_text_copy_n_exclaims)) %>% 
  rowwise() %>% 
  mutate(hate_proxy = mean(c_across(emo_words_n_mean:exclaims_n_mean))) %>% 
  ungroup()
  
res_summary2 %>% 
  head()
```

Langifizieren fürs Plotten:

```{r}
res_summary2_long <- 
  res_summary2 %>% 
  pivot_longer(emo_words_n_mean:hate_proxy)

res_summary2_long %>% 
  head()
```

```{r}
res_summary2_long %>% 
  count(month)
```


```{r}
res_summary2_long %>% 
  ggplot() +
  aes(x = month, y = value) +
  facet_grid(dataset  ~ name) +
  geom_point() +
  geom_line(group=1, alpha = .7)
```



## Vertiefung


@siegel_sentiment-analyse_2020 bieten einen Einstieg in die Sentimentanalyse deutschsprachiger Texte, auch mit einem Blick auf das Erkennen von Aggression.
