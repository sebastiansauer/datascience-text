---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Klassifikation von Hatespeech





## Vorab


### Lernziele


- Sie k√∂nnen grundlegende Verfahren zur Klassifikation von Hatespeech einsetzen und erkl√§ren








### Ben√∂tigte R-Pakete

```{r}
#| message: false
library(tidyverse)
library(rio)
library(tidymodels)
library(tidytext)
library(textrecipes)
library(lsa)  # stopwords
library(discrim)  # naive bayes classification
library(naivebayes)
```


## Daten


Wir nutzen die Daten von @wiegand_germeval bzw. @wiegand-data.
Die Daten sind unter CC-By-4.0 Int. lizensiert.

```{r}
d_raw <- 
  import("data/germeval2018.training.txt",
         header = FALSE)
```


Da die Daten keine Spaltenk√∂pfe haben, informieren wir die Funktion dazu mit `header = FALSE`.

Benennen wir die die Spalten um:

```{r}
names(d_raw) <- c("text", "c1", "c2")
```

Dabei soll `c1` und `c2` f√ºr die 1. bzw. 2. Klassifikation stehen.


In `c1` finden sich diese Werte:

```{r}
d_raw %>% 
  count(c1)
```

Hier wurde klassifiziert,
ob beleidigende Sprache (offensive language) vorlag oder nicht [@isch-etal-2021-overview, S. 2]:


>   Task 1 was to decide whether a tweet includes some form of offensive language or not. The tweets had to be classiÔ¨Åed into the two classes OFFENSE and OTHER. The OFFENSE category covered abusive language, insults, as well as merely profane statements.


Und in `c2` finden sich folgende Auspr√§gungen:

```{r}
d_raw %>% 
  count(c2)
```


In `c2` ging es um eine feinere Klassifikation beleidigender Sprache [@isch-etal-2021-overview, S. 2]:

>   The second task involved four categories, a nonoffensive OTHER class and three sub-categories of what is OFFENSE in Task 1. In the case of PROFANITY, profane words are used, however, the tweet does not want to insult anyone. This typically concerns the usage of swearwords (Schei√üe, Fuck etc.) and cursing (Zur H√∂lle! Verdammt! etc.). This can be often found in youth language. Swearwords and cursing may, but need not, co-occur with insults or abusive speech. Profane language may in fact be used in tweets with positive sentiment to express emphasis. Whenever profane words are not directed towards a speciÔ¨Åc person or group of persons and there are no separate cues of INSULT or ABUSE, then tweets are labeled as simple cases of PROFANITY.




Sind Texte, die als `OFFENSE` klassifiziert sind,
auch (fast) immer als `ABUSE`, `INSULT` oder `PROFANITY` klassifiziert?


```{r}
d_raw %>% 
  filter(c1 == "OTHER", c2 == "OTHER") %>% 
  nrow() / nrow(d_raw)
```

In ca. 2/3 der F√§lle wurden in beiden Klassifikation `OTHER` klassifiziert.

```{r}
d_raw %>% 
  filter(c1 != "OTHER", c2 != "OTHER") %>% 
  nrow() / nrow(d_raw)
```

Entsprechend in ca. 1/3 der F√§lle wurde jeweils nicht mit `OTHER` klassifiziert.


Wir begn√ºgen uns hier mit der ersten, gr√∂beren Klassifikation.


## Feature Engineering


Reichern wir die Daten mit weiteren Features an,
in der Hoffnung, damit eine bessere Klassifikation erzielen zu k√∂nnen.


### Textl√§nge




```{r}
d2 <-
  d_raw %>% 
  mutate(text_length = str_length(text)) %>% 
  mutate(id = 1:nrow(.))

head(d2)
```



### Sentimentanalyse

Wir nutzen dazu `SentiWS` [@Remus2010].

```{r}
sentiws <- read_csv("https://osf.io/x89wq/?action=download")
```




```{r}
d2_long <-
  d2 %>% 
  unnest_tokens(input = text, output = token)

head(d2_long)
```

Jetzt filtern wir unsere Textdaten so,
dass nur W√∂rter mit Sentimentwert √ºbrig bleiben:

```{r}
d2_long_senti <- 
  d2_long %>%  
  inner_join(sentiws %>% select(-inflections), by = c("token" = "word"))

head(d2_long)
```


Schlie√ülich berechnen wir die Sentimentwert pro Polarit√§t und pro Tweet:

```{r}
d2_sentis <-
  d2_long %>% 
  group_by(id, neg_pos) %>% 
  summarise(senti_avg = mean(value))

head(d2_sentis)
```


Diese Tabelle bringen wir wieder eine breitere Form,
um sie dann wieder mit den Hauptdaten zu vereinigen.


```{r}
d2_sentis_wide <-
  d2_sentis %>% 
  pivot_wider(names_from = "neg_pos", values_from = "senti_avg")

d2_sentis_wide %>% head()
```


```{r}
d3 <-
  d2 %>% 
  full_join(d2_sentis_wide)

head(d3)
```


:::callout-note
Die Sentimentanalyse hier vernachl√§ssigt Flexionen der W√∂rter. 
Der  Autor f√ºhlt den Drang zu schreiben: "Left as an exercise for the reader" :-)
:::


### Schimpfw√∂rter


Z√§hlen wir die Schimpfw√∂rter pro Text.
Dazu nutzen wir die Daten von [LDNOOBW](https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/blob/master/LICENSE), lizensiert nach CC-BY-4.0-Int.




```{r}
schimpf1 <- import("https://raw.githubusercontent.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/master/de", format = ",", header = FALSE)
```


L√§nger aber noch ist die Liste aus dem [InsultWiki](https://www.insult.wiki/schimpfwort-liste), lizensiert CC0.


```{r}
schimpf2 <- 
  import("data/insult-de.txt", header = FALSE) %>% 
  mutate_all(str_to_lower)
```


Binden wir die Listen zusammen:

```{r}
schimpf <-
  schimpf1 %>% 
  bind_rows(schimpf2) %>% 
  distinct() %>% 
  rename(word = "V1")

nrow(schimpf)
```


Um die Lesis vor (unn√∂tiger?) Kopfverschmutzung zu bewahren,
sind diese Schimpfw√∂rter hier nicht abgedruckt.

Jetzt z√§hlen wir, ob unsere Tweets/Texte solcherlei W√∂rter enthalten.


```{r}
d_schimpf <- 
d2_long %>% 
  select(id, token) %>% 
  mutate(schimpf = token %in% schimpf$word)
  
d_schimpf %>% 
  filter(schimpf)
```


Wie viele Schimpfw√∂rter haben wir gefunden?

```{r}
d_schimpf %>% 
  count(schimpf)
```


Etwa ein Prozent der W√∂rter sind Schimpfw√∂rter in unserem Corpus.


```{r}
d_schimpf2 <-
  d_schimpf %>% 
  group_by(id) %>% 
  summarise(schimpf_n = sum(schimpf))

head(d_schimpf2)
```


```{r}
d_main <-
  d3 %>% 
  full_join(d_schimpf2)
```

### Worteinbettungen

Hier k√∂nnte ein sch√∂ner Abschnitt stehen √ºber Worteinbettungen in deutscher Sprache,
allerdings ist dieses Schmankerl au√üen vorgelassen zum √úbungsnutzen der Lesis 
üèãÔ∏èüôÇ.





## Datenaufbereitung


### Worth√§ufigkeiten



## Modell 1: Naive-Bayes


### Dummy-Rezept


Hier ist ein einfaches Beispiel,
um die Textvorbereitung mit `{textrecipes}` zu verdeutlichen.

Wir erstellen uns einen Dummy-Text:

```{r}
dummy <- 
  tibble(text = c("Ich gehe heim und der die das nicht in ein and the"))
```


Dann tokenisieren wir den Text:

```{r}
rec_dummy <-
  recipe(text ~ 1, data = dummy) %>% 
  step_tokenize(text)
  
rec_dummy
```


Die Tokens kann man sich so zeigen lassen:

```{r}
show_tokens(rec_dummy, text)
```


Jetzt entfernen wir die Stopw√∂rter deutscher Sprache;
daf√ºr nutzen wir die Stopwort-Quelle `snowball`:


```{r}
rec_dummy <-
  recipe(text ~ 1, data = dummy) %>% 
  step_tokenize(text) %>% 
  step_stopwords(text, language = "de", stopword_source = "snowball")

rec_dummy
```


Pr√ºfen wir die Tokens; 
sind die Stopw√∂rter wirklich entfernt?

```{r}
show_tokens(rec_dummy, text)
```


Ja, die deutschen Stopw√∂rter sind entfernt. Die englischen nicht;
das macht Sinn!


### Datenaufteilung


```{r}
d_split <- initial_split(d_main, strata = c1)

d_train <- training(d_split)
d_test <- testing(d_split)
```



### Rezept 1


```{r}
rec1 <- 
  recipe(c1 ~ text, data = select(d_main, text, c1)) %>% 
  step_tokenize(text) %>% 
  step_stopwords(text, language = "de", stopword_source = "snowball") %>% 
  step_stem(text) %>% 
  step_tokenfilter(text, max_tokens = 1e1) %>% 
  step_tfidf(text)

rec1
```



```{r}
d_rec1 <- bake(prep(rec1), new_data = NULL)

head(d_rec1)
```



### Modellspezifikation 1

Wir definiere einen Naive-Bayes-Algorithmus:

```{r}
nb_spec <- naive_Bayes() %>%
  set_mode("classification") %>%
  set_engine("naivebayes")

nb_spec
```



Und setzen auf die klassische zehnfache Kreuzvalidierung.


```{r}
set.seed(42)
folds1 <- vfold_cv(d_train)

folds1
```



### Workflow 1


```{r}
wf1 <-
  workflow() %>% 
  add_recipe(rec1) %>% 
  add_model(nb_spec)

wf1
```


### Fitting 1


```{r}
fit1 <-
  fit_resamples(
    wf1,
    folds1,
    control = control_resamples(save_pred = TRUE)
  )
```



### Performanz 1

```{r}
wf1_performance <-
  collect_metrics(fit1)

wf1_performance
```



```{r}
wf_preds <-
  collect_predictions(fit1)

wf_preds %>% 
  group_by(id) %>% 
  roc_curve(truth = c1, .pred_OFFENSE) %>% 
  autoplot()
```


```{r}
conf_mat_resampled(fit1, tidy = FALSE) %>% 
  autoplot(type = "heatmap")
```




## Nullmodell


```{r}
null_classification <- 
  parsnip::null_model() %>%
  set_engine("parsnip") %>%
  set_mode("classification")

null_rs <- workflow() %>%
  add_recipe(rec1) %>%
  add_model(null_classification) %>%
  fit_resamples(
    folds1
  )
```


Hier ist die Performanz des Nullmodells.

```{r}
null_rs %>%
  collect_metrics()
```





## Modell 2: Lasso



```{r}
lasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%
  set_mode("classification") %>%
  set_engine("glmnet")

lasso_spec
```



Wir definieren die Auspr√§gungen von `penalty`, 
die wir ausprobieren wollen:


```{r}
lambda_grid <- grid_regular(penalty(), levels = 30)
```



```{r}
wf2 <-
  workflow() %>% 
  add_recipe(rec1) %>% 
  add_model(lasso_spec)

wf2
```


Tunen und Fitten:

```{r}
set.seed(42)

fit2 <-
  tune_grid(
    wf2,
    folds1,
    grid = lambda_grid,
    control = control_resamples(save_pred = TRUE)
  )

fit2
```



Hier ist die Performanz:

```{r}
collect_metrics(fit2)
```


```{r}
autoplot(fit2)
```



```{r}
fit2 %>% 
  show_best("roc_auc")
```



```{r}
chosen_auc <- 
  fit2 %>%
  select_by_one_std_err(metric = "roc_auc", -penalty)
```



Finalisieren:


```{r}
wf2_final <-
  finalize_workflow(wf2, chosen_auc)

wf2_final
```



```{r}
fit2_final_train <-
  fit(wf2_final, d_train)
```


```{r}
fit2_final_train %>% 
  extract_fit_parsnip() %>% 
  tidy() %>% 
  arrange(-abs(estimate))
  
```



```{r}
fit2_final_test <-
  last_fit(wf2_final, d_split)

collect_metrics(fit2_final_test)
```

