[
  {
    "objectID": "120-transformer.html#vorab",
    "href": "120-transformer.html#vorab",
    "title": "\n16¬† Transformer\n",
    "section": "\n16.1 Vorab",
    "text": "16.1 Vorab\n\n16.1.1 Lernziele\n\nSie k√∂nnen die grundlegende Architektur eines Transformer-Modells beschreiben.\nSie k√∂nnen Transformer-Modelle mit der API von Hugging-Face berechnen.\n\n16.1.2 Begleitliteratur\nDer Blogpost von Jay Alammar gibt einen illustrierten √úberblick √ºber Transformer.\n\n16.1.3 Ben√∂tigte Software\nWir ben√∂tigen Python, R sowei einige im Folgenden aufgef√ºhrte Python-Module.\n\nimport pandas as pd\nimport os\n\nF√ºr den Sch√ºleraustausch von R nach Python nutzen wir das R-Paket reticulate:\n\nlibrary(reticulate)\n\nAu√üerdem starte ich die ‚Äúrichtige‚Äù Python-Version, wo die ben√∂tigten Pakete (in der richtigen Version) installiert sind:\n\n#use_virtualenv(\"r-tensorflow\")\n\nCheck:\n\npy_available()\n## [1] TRUE\n\nWelche Python-Version nutzt reticulate gerade?\n\npy_config()\n## python:         /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/bin/python\n## libpython:      /Users/sebastiansaueruser/.pyenv/versions/3.8.16/lib/libpython3.8.dylib\n## pythonhome:     /Users/sebastiansaueruser/.virtualenvs/r-tensorflow:/Users/sebastiansaueruser/.virtualenvs/r-tensorflow\n## version:        3.8.16 (default, Sep 15 2023, 17:53:02)  [Clang 14.0.3 (clang-1403.0.22.14.1)]\n## numpy:          /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/lib/python3.8/site-packages/numpy\n## numpy_version:  1.24.3\n## \n## NOTE: Python version was forced by VIRTUAL_ENV",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#√ºberblick",
    "href": "120-transformer.html#√ºberblick",
    "title": "\n16¬† Transformer\n",
    "section": "\n16.2 √úberblick",
    "text": "16.2 √úberblick\nTransformer sind eine Architekturvariante neuronaler Netze. Sie stellen die Grundlage vieler aktueller gro√üer Sprachmodelle1; da sie einige Vorz√ºge gegen√ºber Vorg√§ngermodellen aufweisen, haben sie einen zentralen Platz f√ºr verschiedenen Aufgaben des NLP eingenommen.\nIm Jahr 2017 erschien ein Paper auf Arxive mit dem Titel ‚ÄúAttention is all you need‚Äù, Vaswani u.¬†a. (2023)2. Transformer basieren auf einer bestimmten Art von ‚ÄúAufmerksamkeit‚Äù, genannt Selbst-Aufmerksamkeit (self-attention). Nat√ºrlich ist damit eine bestimmte Architektur im neuronalen Netzwerk gemeint, kein kognitivpsychologiches Konstruktr; allerdings lehnt sich die Methode an Konzepte der Kognitionspsychologie vage an.\nSelf-Attention weist zwei gro√üe Verteile auf: Erstens erlaubt es parallele Verarbeitung, was viele Vorg√§ngermodelle nicht erlaubten. Zweitens kann es den Kontext eines Tokens, also den Text um ein bestimmtes Wort herum, deutlich besser ‚Äúim Blick‚Äù (oder in der Aufmerksamkeit) behalten als viele Vorg√§ngermodelle.\nGerade f√ºr Daten mit sequenziellem Charakter, wie Text oder Sprache, sind Transformer-Modelle gut geeignet3.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#grundkonzepte",
    "href": "120-transformer.html#grundkonzepte",
    "title": "\n16¬† Transformer\n",
    "section": "\n16.3 Grundkonzepte",
    "text": "16.3 Grundkonzepte",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#einf√ºhrung-in-hugging-face",
    "href": "120-transformer.html#einf√ºhrung-in-hugging-face",
    "title": "\n16¬† Transformer\n",
    "section": "\n16.4 Einf√ºhrung in Hugging Face ü§ó",
    "text": "16.4 Einf√ºhrung in Hugging Face ü§ó\nDieser Abschnitt orientiert sich an Tunstall u.¬†a. (2022). Die Syntax zu allen Kapiteln des Buchs findet sich praktischerweise in diesem Github-Repo.\nBei ü§ó liegt der Schwerpunkt klar bei Python, nicht bei R. Allerdings erlaubt RStudio ein einfaches Wechseln zwischen R und Python: Funktionen und Daten aus Python k√∂nnen einfach mit dem $-Operator angesprochen werden. In diesem Post wirds das demonstriert.\nSchauen wir uns das einf√ºhrende Beispiel aus Tunstall u.¬†a. (2022). an.\n\n16.4.1 Hugging Face mit R\nHier ein ein Text-Schnipsel, dessen Sentiment wir detektieren wollen:\n\ntext &lt;- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\nUnd hier in der Python-Version:\n\ntext_py = r.text\n\nDann importieren wir die n√∂tigen Module:\n\n\nPython\nR\n\n\n\n\n#import tensorflow\nfrom transformers import pipeline\n\nNat√ºrlich m√ºssen Python-Module installiert sein, bevor man sie nutzen kann, genau so wie R-Pakete.\n\n\nMan kann die die Python-Module auch √ºber R starten:\n\ntransformers &lt;- reticulate::import(\"transformers\")\n\n\n\n\n\n16.4.2 Einfache Pipeline\n{.panel-tabset}\n\n16.4.3 Python\nWir bereiten das Modell vor; im Default wird distilbert-base-uncased-finetuned-sst-2-english verwendet.\n\nclassifier = pipeline(\"text-classification\")\n## No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n## Using a pipeline without specifying a model name and revision in production is not recommended.\n## All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n## \n## All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#germeval-out-of-the-box-mit-hugging-face",
    "href": "120-transformer.html#germeval-out-of-the-box-mit-hugging-face",
    "title": "\n16¬† Transformer\n",
    "section": "\n16.5 Germeval Out-of-the-Box mit Hugging Face",
    "text": "16.5 Germeval Out-of-the-Box mit Hugging Face\nZuert importieren wir die Daten.\n\n\nR\nPython\n\n\n\n\ndata(germeval_train, package = \"pradadata\")\ntext &lt;- germeval_train$text[1:2]\ntext[1:2]\n## [1] \"@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\"                                 \n## [2] \"@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\"\n\n\n\n\ngermeval_train_py = r.text\n\n\n\n\n\n16.5.1 Standard-Pipeline\n\nclassifier = pipeline(\"text-classification\")\n## No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n## Using a pipeline without specifying a model name and revision in production is not recommended.\n## All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n## \n## All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\noutputs2 = classifier(germeval_train_py)\noutputs2\n## [{'label': 'NEGATIVE', 'score': 0.9950070381164551}, {'label': 'NEGATIVE', 'score': 0.9954568147659302}]\n\nTja, vielleicht sollten wir ein Modell verwenden, das die deutsche Sprache versteht?\n\n16.5.2 Man spricht Deutsh\nAuf Hugging Face gibt es eine Menge von Modellen. Welches nehm ich nur? DISTILBERT oder BERT-Varianten d√ºrfte kein schlechter Start sein.\n\n#classifier = pipeline(\"text-classification\", model=\"distilbert-base-german-cased\")\n\n\nclassifier = pipeline(\n  \"text-classification\", model=\"oliverguhr/german-sentiment-bert\")\n## All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n## \n## All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n\n\noutputs3 = classifier(germeval_train_py)\ndf = pd.DataFrame(outputs3)    \ndf.head()\n##       label     score\n## 0   neutral  0.987253\n## 1  negative  0.918047\n\n\ndf_r &lt;- py$pd\nhead(df_r)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#openai-api",
    "href": "120-transformer.html#openai-api",
    "title": "\n16¬† Transformer\n",
    "section": "\n16.6 OpenAI-API",
    "text": "16.6 OpenAI-API\n\n\n\n\n\n\nWichtig\n\n\n\nDer API-Aufruf von ChatGPT kostet Geld üí∏. \\(\\square\\)\n\n\n\n16.6.1 Authentifizierung\nWir m√ºssen uns bei der API anmelden:\n\n\nR\nPython\n\n\n\n\nopenai_key_r &lt;- Sys.getenv(\"OPENAI_API_KEY\")\n\n\n\n\nopenai_key_py = os.environ.get(\"OPENAI_API_KEY\")\n\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nSpeichern Sie keine sensiblen Daten in geteilten Ordner/Repos. Achten Sie auf Log-Dateien wir .Rhistory, in der u.U. Ihre sensiblen Daten enthalten sein k√∂nnen. \\(\\square\\)\n\n\nEine sichere Variante als das unverschl√ºsselte Speichenr von Passw√∂rtern ist es, sensible Daten mit einem Passwort zu sch√ºtzen. Dazu kann man z.B. in R das Paket keyring nutzen.\n\nlibrary(keyring)\nopenai_key_r &lt;- key_get(\"OPENAI_API_KEY\")\n\n\n16.6.2 Setup\n\nsentiment_scores = []\nsentiment_analysis = []\ntext = '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.'\n\n\n16.6.3 Anfrage an die API\n\nprompt = f\"Analysiere das Sentiment des folgenden Texts: \\n{text}\"\n\nresponse = openai.Completion.create(\n        prompt=prompt,\n        engine=\"davinci\",\n        max_tokens=100,\n        temperature=0.5,\n    )",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#vertiefung",
    "href": "120-transformer.html#vertiefung",
    "title": "\n16¬† Transformer\n",
    "section": "\n16.7 Vertiefung",
    "text": "16.7 Vertiefung\nDer Originalartikel von Vaswani u.¬†a. (2023) gibt einen guten Einblick in die Konzepte; der Anspruch ist auf mittlerem Niveau. Von den Hugging-Face-Machern gibt es ein Buch, das - ebenfalls auf mittlerem Niveau - einen Einblick in Transformer-Modelle im Hugging-Face-√ñkosystem gew√§hrt (Tunstall u.¬†a. 2022). Rothman (2022) scheint gute Freunde bei Google zu haben, wenn man sein Buch √ºber Transformer liest, jedenfalls sind die Modelle jener Firma in dem Buch gut gefeatured. G√©ron (2023a) Standardwerk zu Scikit-Learn bietet auch einen Einblick in Attention-Konzepte (Kap. 16). √úbrigens ist das Buch (3. Auflage) jetzt auch in deutscher Sprache erh√§ltlich (G√©ron 2023b).\n\n\n\n\nG√©ron, Aur√©lien. 2023a. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Third edition. Beijing Boston Farnham Sebastopol Tokyo: O‚ÄôReilly.\n\n\n‚Äî‚Äî‚Äî. 2023b. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras und TensorFlow: Konzepte, Tools und Techniken f√ºr intelligente Systeme. √úbersetzt von Kristian Rother und Thomas Demmig. 3., aktualisierte und erweiterte Auflage. Heidelberg: O‚ÄôReilly.\n\n\nRothman, Denis. 2022. Transformers for Natural Language Processing: Build, Train, and Fine-Tune Deep Neural Network Architectures for NLP with Python, Hugging Face, and OpenAI¬¥s GPT3, ChatGPT, and GPT-4. Second edition. Expert Insight. Birmingham Mumbai: Packt.\n\n\nTunstall, Lewis, Leandro von Werra, Thomas Wolf, und Aur√©lien G√©ron. 2022. Natural Language Processing with Transformers: Building Language Applications with Hugging Face. Revised edition. Sebastopol: O‚ÄôReilly.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, und Illia Polosukhin. 2023. ‚ÄûAttention Is All You Need‚Äú. 1. August 2023. https://doi.org/10.48550/arXiv.1706.03762.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#pipeline-management",
    "href": "200-projektmgt.html#pipeline-management",
    "title": "\n17¬† Projektmanagement\n",
    "section": "\n17.1 Pipeline-Management",
    "text": "17.1 Pipeline-Management\n\n17.1.1 Am Anfang\nSie haben Gro√ües vor! Naja, zumindest planen Sie ein neues Data-Science-Projekt.\nUnd, schlau wie Sie sind, st√ºrzen Sie nicht sofort an die Tastatur, um sich einige Modelle berechnen zu lassen. Nein! Sie denken erst einmal nach. Zum Beispiel, wie die einzelnen Analyseschritte aussehen, worin sie bestehen, und in welcher Abfolge sie zu berechnen sind, s. Abbildung¬†17.1.\n\n\n\n\n\nAbbildung¬†17.1: So k√∂nnte Ihr Projektplan am Anfang aussehen, man spricht auch von einer Pipeline\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDen Graph der einzelnen Analyseschritte in ihrer Abh√§ngigkeit bezeichnet man als *Pipeline.\n\n\n\n17.1.2 Sie tr√§umen von einem Werkzeug\nNach einiger Zeit √ºberlegen Sie sich, dass Sie ein System br√§uchten, das Ihre Skizze umsetzt in tats√§chliche Berechnungen. Und zwar suchen Sie ein Projektmanagement-System das folgendes Desiderata erf√ºllt:\n\nEs f√ºhrt die einzelnen Schritte Ihres Projekt, die ‚ÄúPipeline‚Äù in der richtigen Reihenfolge\nEs aktualisiert veraltete Objekte, aber es berechnet nicht Modelle neu, die unver√§ndert sind\nEs ist gut zu debuggen\n\nJa, von so einem Werkzeug tr√§umen Sie.\nUnd tats√§chlich, Ihr Traum geht in Erf√ºllung. Dieses System existiert. Genau genommen gibt es viele Systeme, die sich anschicken, Ihre W√ºnsche zu erf√ºllen. Wir schauen uns eines n√§her an, das speziell f√ºr R gemacht ist. Das R-Paket targets.\n\n17.1.3 Targets\nEs lohnt sich, an dieser Stelle den ‚ÄúWalkthrough‚Äù aus dem Benutzerhandbuch von Targets durchzuarbeiten.\nF√ºr ein Projekt √§hnlich zu den, die wir in diesem Buch bearbeiten, ist folgende _targets.R-Datei ein guter Start.\n\nlibrary(targets)\n\n\n# Funktionen einlesen:\n#purrr::walk(list.files(path = \"funs\", pattern = \".R\", full.names = TRUE), source)\nsource(\"funs/def-recipe.R\")\nsource(\"funs/read-train-data.R\")\nsource(\"funs/read-test-data.R\")\n\n# Optionen, z.B. allgemein verf√ºgbare Pakete in den Targets:tar_option_set(packages = c(\"readr\", \n                            \"dplyr\", \n                            \"ggplot2\", \n                            \"purrr\", \n                            \"easystats\", \n                            \"tidymodels\", \n                            \"textrecipes\"))\n\n# Definition der Pipeline:\nlist(\n  tar_target(data_train, read_train_data()),\n  tar_target(data_test, read_test_data()),\n  tar_target(recipe1, def_recipe(data_train)\n  ),\n  tar_target(model1,\n             logistic_reg(penalty = tune(), mixture = 1) %&gt;%\n               set_mode(\"classification\") %&gt;%\n               set_engine(\"glmnet\")\n             ),\n  tar_target(workflow1,\n             workflow() %&gt;% add_recipe(recipe1) %&gt;% add_model(model1)\n             ),\n  tar_target(grid1,\n             grid_regular(penalty(), levels = 3)\n             ),\n  tar_target(grid_fitted,\n             tune_grid(workflow1, \n                       resamples = vfold_cv(data_train, v = 2),\n                       grid = grid1)\n  ),\n  tar_target(best_hyperparams,\n             select_by_one_std_err(grid_fitted, metric = \"roc_auc\", penalty)\n             ),\n  tar_target(fit1,\n             workflow1 %&gt;% finalize_workflow(best_hyperparams) %&gt;% fit(data_train)),\n  tar_target(preds,\n             fit1 %&gt;% \n               predict(data_test) %&gt;% \n               bind_cols(data_test) %&gt;% \n               mutate(c1 = factor(c1))),\n  tar_target(metrics1,\n             preds %&gt;% metrics(truth = c1, .pred_class))\n)\n\nDann kann man auf den Play-Button dr√ºcken und die ganze Pipeline wird berechnet:\n\ntar_make()\n\nWenn die Pipeline aktuell ist, und nichts berechnet werden muss (und daher auch schon fehlerfrei durchgelaufen ist), sieht die Ausgabe so aus:\n‚úî skip target grid1\n‚úî skip target model1\n‚úî skip target data_train\n‚úî skip target data_test\n‚úî skip target recipe1\n‚úî skip target workflow1\n‚úî skip target grid_fitted\n‚úî skip target best_hyperparams\n‚úî skip target fit1\n‚úî skip target preds\n‚úî skip target metrics1\n‚úî skip pipeline [0.121 seconds]\nDie Pipeline kann man sich als DAG bzw. als Abh√§ngigkeitsgraph visualisieren lassen:\n\ntar_visnetwork()\n\n\n\nAbh√§ngigkeitsgraph der Pipeline\n\nEinzelne Objekte kann man sich komfortabel anschauen mit tar_load(objekt), z.B. tar_load(fit1) usw.\n\n17.1.4 Eine Pipeline als Spielwiese\nDieses Github-Repo stellt Ihnen eine ‚ÄúSpielwiese‚Äù zur Verf√ºgung, wo Sie sich mit Pipleines √† la Targets vertraut machen k√∂nnen.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#zeit-sparen",
    "href": "200-projektmgt.html#zeit-sparen",
    "title": "\n17¬† Projektmanagement\n",
    "section": "\n17.2 Zeit sparen",
    "text": "17.2 Zeit sparen\nEiner Maschine etwas beizubringen kann dauern ‚Ä¶ Ein einfaches Rechenbeispiel dazu:\n\nSie haben eine Kreuzvalidierung mit 10 Faltungen\nund 3 Wiederholungen\nund 3 Tuningparameter\nmit je 10 Werten\n\nDas sind 1033*10=900 Wiederholungen.\nLeider haben Sie noch in den ersten 10 Versuchen jeweils einen Bug, so dass sich die Rechenzeit noch einmal um den Faktor 10 erh√∂ht‚Ä¶\nDie Rechenzeit kann also schnell ins astronomische steigen. Es braucht also Methoden, um Rechenzeit zu sparen.1 Einige Methoden zum Rechenzeit sparen sind:\n\n\nCloud: Cloud-Dienste in Anspruch nehmen (faktisch mietet man damit schnelle Rechner)\n\nParallelisierung: Mehrere Kerne des eigenen Computers nutzen\n\nUpgrade: Kaufen Sie sich einen schnelleren Rechner‚Ä¶\n\nCleveres Grid-Search: Methoden wie ANOVA Racing k√∂nnen die Rechenzeit - was das Tuning - betrifft - deutlich verringern.\n\nDieser Post gibt einen √úberblick zu Rechenzeiten bei verschiedenen Tuningparameter-Optionen mit Tidymodels.\nNat√ºrlich ist die (mit Abstand) beste Methode: guten Code schreiben. Denn ‚Äúguter Code‚Äù verringert die Wahrscheinlichkeit von Bugs, und damit die Gefahr, dass die ganze sch√∂ne Rechenzeit f√ºr die Katz war.\n‚ÄúGuter Code‚Äù ist vielleicht prim√§r von zwei Dingen abh√§ngig: erstens einen guten Plan zu haben bevor man das Programmieren anf√§ngt und zweitens gute Methoden des Projektmanagements. Hunt und Thomas (2000) pr√§sentieren eine weithin anerkannte Umsetzung, was ‚Äúguter‚Äù Code bedeuten k√∂nnte.\n\n\nQuelle: imgflip.com",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#publizieren",
    "href": "200-projektmgt.html#publizieren",
    "title": "\n17¬† Projektmanagement\n",
    "section": "\n17.3 Publizieren",
    "text": "17.3 Publizieren\nSie haben eine super Analyse geschrieben, eine schicke Pipeline, und jetzt soll die Welt davon erfahren? Es gibt einige komfortable M√∂glichkeiten, Ihre Arbeit zu publizieren, z.B. als Blog mit Quarto.\nDieses Video zeigt Ihnen wie man einen Quarto-Blog in RStudio erstellt und ihn bei Netlify publiziert.\n\nDas Hosten bzw. Deployen bei Netlify ist kostenlos (in der Basis-Variante).\nSie k√∂nnen alternativ Github Pages als Hosting-Dienst verwenden. Dieses Video gibt dazu eine Anleitung.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#komplexit√§tsmanagement",
    "href": "200-projektmgt.html#komplexit√§tsmanagement",
    "title": "\n17¬† Projektmanagement\n",
    "section": "\n17.4 Komplexit√§tsmanagement",
    "text": "17.4 Komplexit√§tsmanagement\nProgrammieren ist faszinierend. Vor allem, wenn das Programm funktioniert. Genau genommen ist es eigentlich nur dann faszinierend, ansonsten wird es anstrengend? aufregend? s√ºchtig? faszinierend? nervig? Wie auch immer: Bugs treten auf und mit steigender Komplexit√§t Ihrer Software steigen die Bugs nicht linear, sondern eher quadratisch oder gar exponentiell an.\nEs gibt viele Ans√§tze, sich gegen die Komplexit√§t zu ‚Äúwehren‚Äù. Der beste ist vielleicht: Die Software so einfach wie m√∂glich zu halten - und nur so komplex wie n√∂tig. Sozusagen: Das beste Feature ist das, das Sie nicht implementieren.\n\n17.4.1 Geben Sie gute Namen\nDaraus leitet sich ab, dass die zentralen Methoden, um der Fehler Herr zu werden im Komplexit√§tsmanagement liegen. Den Variablen (Objekten) ‚Äúgute‚Äù, ‚Äúsprechende‚Äù, aber pr√§gnante Namen zu geben, ist in diesem Lichte auch als Komplexit√§tsmanagement (Reduktion) zu verstehen.\nEin typischer Fehler, der mir immer mal wieder passiert, ist: Ich √§ndere den Namen eines Objekts, aber vergesse, an allen Stellen im Code den Namen anzupassen. Gl√ºcklicherweise gibt es hier eine einfache Abhilfe: Replace-All.\nDer zwar einfache Weg, mehrere √§hnliche Objekte durchzunummerieren (workflow2a, recipe1, ‚Ä¶). ist zwar einfach, aber insgesamt nicht zu empfehlen: Es ist nicht leicht, immer genau zu wissen, was der Inhalt hinter der Nummer 2a etc. ist. √Ñndert man au√üerdem die Reihenfolge (oder schiebt ein Objekt dazwischen ein), macht die Nummerierung keinen Sinn mehr (oder man muss m√ºhselig die Nummern √§ndern, was fehleranf√§llig und nervig ist).\n\n17.4.2 Portionieren\nEine andere, zentrale Ma√ünahme ist es, den Code in handlichen ‚ÄúH√§ppchen‚Äù zu verpacken. Statt einer Skriptdatei mit zich Tausend Zeilen, w√ºnschen Sie sich doch sicher ein Skript der Art:\nmache_1()\nmache_2()\nmache_3()\ngratuliere_fertig()\nSchaut man dann in mache_1() rein, sieht man wiederum √ºbersichtlichen Code.\nFunktionales Programmieren ist eine Umsetzung davon: Jedes H√§ppchen, jeder Schritt ist eine Funktion. Eine Funktion hat Input und Output; der Output ist dann der Input f√ºr die Funktion des n√§chsten Schrittes. targets ist eine Umsetzung dieser Idee.\n\n17.4.3 Debugging mit einem Logger\nWenn das Kind in dem Brunnen gefallen ist, hilft nur Heulen und Wehklagen Das Problem finden und l√∂sen. Mit einem Logger kann man sich das Entwanzen, das Finden der Fehler, erleichtern. Ein Logger schreibt Zwischenschritte in eine Log-Datei.\nHier ist ein Beispiel mit dem futile Logger:. Mein Problem war, dass ich eine dynamische Aufgabe f√ºr eine Statistik-Klausur programmiert hatte, aber leider gab es einen Bug, den ich nicht gefunden habe2.\nDie L√∂sung brachte ein Logger, mit dem ich den Wert zentraler Variablen im Verlauf des Durchlaufens des Codes - bis eben der Laufzeitfehler aufkam3.\nHier ist ein Ausschnitt der Syntax. Zuerst initialisiert man den Logger mit einer Datei, hier exams.log. Neue Logging-Inhalte sollen an die bestehenden Logs angeh√§ngt werden (appender).\n\nlibrary(futile.logger)\nflog.appender(appender.file(\"/Users/sebastiansaueruser/github-repos/rexams-exams/exams.log\"))\n\nDann gebe ich eine Loggings vom Typ ‚ÄúInfo‚Äù zum Protokoll:\n\nflog.info(paste0(\"Ex: post-uncertainty1\"))\nflog.info(msg = paste0(\"Data set: \", d_name))\nflog.info(paste0(\"Preds chosen: \", stringr::str_c(preds_chosen, collapse = \", \")))\nflog.info(paste0(\"Output var: \", av))\n\nDie Ergebnisse kann man dann in der Logging-Datei anschauen:\nNFO [2023-01-05 11:27:51] Rhats: 1.004503053029\nINFO [2023-01-05 11:27:51] Sol: 0.18\nINFO [2023-01-05 11:27:51] Sol typeof: double\nINFO [2023-01-05 11:27:52] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:52] Data set: tips\nINFO [2023-01-05 11:27:52] Preds chosen: size, total_bill\nINFO [2023-01-05 11:27:52] Output var: tip\nINFO [2023-01-05 11:27:53] Rhats: 0.999004883794722\nINFO [2023-01-05 11:27:53] Rhats: 1.00021605674421\nINFO [2023-01-05 11:27:53] Rhats: 1.00091357638756\nINFO [2023-01-05 11:27:53] Sol: 0.32\nINFO [2023-01-05 11:27:53] Sol typeof: double\nINFO [2023-01-05 11:27:54] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:54] Data set: TeachingRatings\nINFO [2023-01-05 11:27:54] Preds chosen: prof, beauty\nINFO [2023-01-05 11:27:54] Output var: eval\nINFO [2023-01-05 11:27:55] Rhats: 0.999060308710712\nINFO [2023-01-05 11:27:55] Rhats: 0.999032305267221\nINFO [2023-01-05 11:27:55] Rhats: 0.999229003550072\nINFO [2023-01-05 11:27:55] Sol: 0\nINFO [2023-01-05 11:27:55] Sol typeof: double\nINFO [2023-01-05 11:27:56] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:56] Data set: gtcars\nINFO [2023-01-05 11:27:56] Preds chosen: mpg_c, year\nINFO [2023-01-05 11:27:56] Output var: msrp\nINFO [2023-01-05 11:28:00] Rhats: 0.99913061005524\nINFO [2023-01-05 11:28:00] Rhats: 0.998999786100339\nINFO [2023-01-05 11:28:00] Rhats: 0.999130286784586\nINFO [2023-01-05 11:28:01] Sol: 21959.35\nINFO [2023-01-05 11:28:01] Sol typeof: double\nJa, das sieht nicht sch√∂n aus. Aber es brachte mir die L√∂sung: Mir fiel auf, dass der Fehler nur auftrat, wenn sol einen gro√üen Wert hatte (1000 oder mehr). Danke, Logger!\n\n\n\n\nHunt, Andrew, und David Thomas. 2000. The Pragmatic Programmer from Journeyman to Master. Reading, Mass.: Addison-Wesley.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "300-fallstudien.html#quellen-f√ºr-textdaten",
    "href": "300-fallstudien.html#quellen-f√ºr-textdaten",
    "title": "18¬† Fallstudien",
    "section": "18.1 Quellen f√ºr Textdaten",
    "text": "18.1 Quellen f√ºr Textdaten\nDer MonkeyLearn Blog liefert eine Reihe von Quellen zu API, die Textdaten bereitstellen.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>Fallstudien</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alkomah, Fatimah, and Xiaogang Ma. 2022. ‚ÄúA Literature\nReview of Textual Hate Speech Detection Methods and\nDatasets.‚Äù Information 13 (6, 6): 273. https://doi.org/10.3390/info13060273.\n\n\nAlmeida, Felipe, and Geraldo Xex√©o. 2019. ‚ÄúWord\nEmbeddings: A Survey.‚Äù ArXiv,\nJanuary. https://www.semanticscholar.org/paper/Word-Embeddings%3A-A-Survey-Almeida-Xex%C3%A9o/e28e81a8cb6655aebb72357538f7b7a360366a29.\n\n\nCamacho-Collados, Jose, and Mohammad Taher Pilehvar. 2020.\n‚ÄúEmbeddings in Natural Language Processing.‚Äù\nIn Proceedings of the 28th International Conference on\nComputational Linguistics: Tutorial\nAbstracts, 10‚Äì15. Barcelona, Spain (Online):\nInternational Committee for Computational Linguistics. https://doi.org/10.18653/v1/2020.coling-tutorials.2.\n\n\nCasta√±o-Pulgar√≠n, Sergio Andr√©s, Natalia Su√°rez-Betancur, Luz Magnolia\nTilano Vega, and Harvey Mauricio Herrera L√≥pez. 2021. ‚ÄúInternet,\nSocial Media and Online Hate Speech. Systematic\nReview.‚Äù Aggression and Violent Behavior 58 (May):\n101608. https://doi.org/10.1016/j.avb.2021.101608.\n\n\nChollet, Fran√ßois. 2021. Deep Learning with\nPython. Second edition. Shelter Island,\nNY: Manning.\n\n\nChollet, Fran√ßois, Tomasz Kalinowski, and J. J. Allaire. 2022a. Deep\nLearning with R. Second edition. Shelter Island,\nNY: Manning.\n\n\n‚Äî‚Äî‚Äî. 2022b. Deep Learning with R. Second edition.\nShelter Island, NY: Manning Publications Co.\n\n\nGallatin, Kyle, and Chris Albon. 2023. Machine Learning with\nPython Cookbook: Practical Solutions from Preprocessing to\nDeep Learning. Beijing Boston Farnham Sebastopol\nTokyo: O‚ÄôReilly Media.\n\n\nGeorge, Alexandra. 2022. Python Text Mining: Perform Text\nProcessing, Word Embedding, Text Classification and Machine\nTranslation. Delhi: BPB Publications.\n\n\nG√©ron, Aur√©lien. 2023. Praxiseinstieg Machine Learning mit\nScikit-Learn, Keras und TensorFlow: Konzepte, Tools und Techniken f√ºr\nintelligente Systeme. Translated by Kristian Rother and Thomas\nDemmig. 3., aktualisierte und erweiterte Auflage.\nHeidelberg: O‚ÄôReilly.\n\n\nHunt, Andrew, and David Thomas. 2000. The Pragmatic Programmer from\nJourneyman to Master. Reading, Mass.:\nAddison-Wesley.\n\n\nHvitfeldt, Emil, and Julia Silge. 2021. Supervised Machine\nLearning for Text Analysis in R.\n1st ed. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2021. An Introduction to Statistical Learning: With Applications in\nR. Second edition. Springer Texts in Statistics.\nNew York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nK√∂nig, Tim, Wolf J. Sch√ºnemann, Alexander Brand, Julian Freyberg, and\nMichael Gertz. 2022. ‚ÄúThe EPINetz Twitter Politicians\nDataset 2021. A New Resource for the Study of the German\nTwittersphere and Its Application for the 2021 Federal\nElections.‚Äù Politische Vierteljahresschrift 63 (3):\n529‚Äì47. https://doi.org/10.1007/s11615-022-00405-7.\n\n\nKulkarni, Akshay, and Adarsha Shivananda. 2021. Natural Language\nProcessing Recipes: Unlocking Text Data with Machine Learning and Deep\nLearning Using Python. Second edition. New\nYork: Apress.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLex, Alexander, Nils Gehlenborg, Hendrik Strobelt, Romain Vuillemot, and\nHanspeter Pfister. 2014. ‚ÄúUpSet:\nVisualization of Intersecting Sets.‚Äù IEEE\nTransactions on Visualization and Computer Graphics 20 (12):\n1983‚Äì92. https://doi.org/10.1109/TVCG.2014.2346248.\n\n\nLiu, Zhiyuan, Yankai Lin, and Maosong Sun, eds. 2023. Representation\nLearning for Natural Language Processing.\nSingapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-1600-9.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013.\n‚ÄúEfficient Estimation of Word\nRepresentations in Vector Space.‚Äù September\n6, 2013. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014.\n‚ÄúGloVe: Global Vectors for Word\nRepresentation.‚Äù In Proceedings of the 2014 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), 1532‚Äì43. Doha, Qatar:\nAssociation for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.\n\n\nPilehvar, Mohammad Taher, and Jose Camacho-Collados. 2021.\nEmbeddings in Natural Language Processing:\nTheory and Advances in Vector\nRepresentations of Meaning. Synthesis\nLectures on Human Language Technologies.\nCham: Springer International Publishing. https://doi.org/10.1007/978-3-031-02177-0.\n\n\nRemus, Robert, Uwe Quasthoff, and Gerhard Heyer. 2010.\n‚ÄúSentiWS - a Publicly Available German-Language\nResource for Sentiment Analysis.‚Äù Proceedings of the 7th\nInternational Language Ressources and Evaluation (LREC‚Äô10),\n1168‚Äì71.\n\n\nRhys, Hefin. 2020. Machine Learning with\nR, the Tidyverse, and Mlr. Shelter Island,\nNY: Manning publications.\n\n\nRisch, Julian, Anke Stoll, Lena Wilms, and Michael Wiegand. 2021.\n‚ÄúOverview of the GermEval 2021 Shared Task on the\nIdentification of Toxic, Engaging, and Fact-Claiming Comments.‚Äù\nIn Proceedings of the GermEval 2021 Shared Task on the\nIdentification of Toxic, Engaging, and Fact-Claiming Comments,\n1‚Äì12. Duesseldorf, Germany: Association for\nComputational Linguistics. https://aclanthology.org/2021.germeval-1.1.\n\n\nShannon, C. E. 1948. ‚ÄúA Mathematical Theory of\nCommunication.‚Äù Bell System Technical Journal 27 (3):\n379‚Äì423. https://doi.org/10.1002/j.1538-7305.1948.tb01338.x.\n\n\nSiegel, Melanie, and Melpomeni Alexa. 2020. Sentiment-Analyse\ndeutschsprachiger Meinungs√§u√üerungen: Grundlagen, Methoden und\npraktische Umsetzung. Wiesbaden: Springer\nFachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-29699-5.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with\nR: A Tidy Approach. First edition. Beijing ;\nBoston: O‚ÄôReilly. https://www.tidytextmining.com/.\n\n\nStone, James V. 2019. ‚ÄúInformation Theory: A\nTutorial Introduction.‚Äù June 13, 2019. http://arxiv.org/abs/1802.05968.\n\n\nWickham, Hadley, and Garrett Grolemund. 2016. R for Data\nScience: Visualize, Model,\nTransform, Tidy, and Import\nData. O‚ÄôReilly Media. https://r4ds.had.co.nz/index.html.\n\n\nWiegand, Michael. 2019a. ‚ÄúGermEval-2018 Corpus\n(DE).‚Äù heiDATA. https://doi.org/10.11588/data/0B5VML.\n\n\n‚Äî‚Äî‚Äî. 2019b. ‚ÄúGermEval-2018 Corpus\n(DE).‚Äù heiDATA. https://doi.org/10.11588/data/0B5VML.\n\n\n‚Äî‚Äî‚Äî. 2019c. ‚ÄúGermEval-2018-Data-master.‚Äù In\nGermEval-2018 Corpus (DE).\nheiDATA. https://doi.org/10.11588/data/0B5VML/XIUWJ7.\n\n\n‚ÄúWord Embeddings in NLP: A Complete\nGuide.‚Äù 2023. Turing. 2023. https://www.turing.com/kb/guide-on-word-embeddings-in-nlp.\n\n\nYamada, Ikuya, and Hiroyuki Shindo. 2019. ‚ÄúNeural Attentive\nBag-of-Entities Model for Text Classification.‚Äù In\nProceedings of the 23th SIGNLL Conference on\nComputational Natural Language Learning, 563‚Äì73. Association\nfor Computational Linguistics.",
    "crumbs": [
      "Abschluss",
      "References"
    ]
  },
  {
    "objectID": "105-python-r.html#lernsteuerung",
    "href": "105-python-r.html#lernsteuerung",
    "title": "\n13¬† Python üíñ R\n",
    "section": "\n13.1 Lernsteuerung",
    "text": "13.1 Lernsteuerung\n\n13.1.1 Lernziele\n\nSie wissen, wo und wie Sie sich die Grundlagen von Python aneignen k√∂nnen.\nSie k√∂nnen Python aus RStudio heraus verwenden.\nSie k√∂nnen grundlegende Funktionen zur Verwaltung Ihrer Python-Installation wie das Hinzuf√ºgen von Modulen.\n\n13.1.2 Begleitliteratur\nEs gibt viele Lehrb√ºcher zu Python. Mein Rat ist, das zu w√§hlen, das es in Ihrer Lieblingsbibliothek gibt. ü§ì Solange es einigerma√üen uptodate ist und Ihnen die didaktische Aufmachung zusagt.\nHier ist eine Auswahl an Einstiegsb√ºcher in deutscher Sprache: Bekannt ist z.B. Downey (2021); vergleichsweise aktuell ist Inden (2023); auch ganz nett ist Barry (2017).\n\n\n\n\n\n\nRap-Battle von R und Python üé§\n\n\n\n\n\n(Beat im Hintergrund‚Ä¶)\nPython:\nYo, I‚Äôm Python, the snake that‚Äôs striking, Clean syntax, got your code reciting. Versatile, dynamic, no need for stressing, From web apps to scripts, I‚Äôm truly impressing.\nPandas roll deep, handling data so fine, NumPy‚Äôs my crew, doing math in every line. Machine learning skills, yeah, I got the game, TensorFlow and PyTorch, ain‚Äôt that my fame?\nIndentation‚Äôs the key, my style‚Äôs so clean, Readability supreme, in every code scene. Fluent in libraries, got Matplotlib on the beat, Visualizing data, making it all sweet.\nR:\nHold up, Python, slow down the hype, I‚Äôm R, in statistics, I‚Äôm the type. Dataframes and vectors, I pioneered the game, ggplot2‚Äôs my art, visuals never the same.\nTidyverse, my squad, we stay organized, Read and manipulate, got data mesmerized. Shiny apps shining, interactive delight, In the world of data, I‚Äôm taking flight.\nBase R or dplyr, I got the choices, Statistical models, hear the data‚Äôs voices. In the realm of data science, I hold my own, From regression to clustering, my skills are honed.\nPython:\nR, you‚Äôre cool with stats, I give you that, But in the industry, I‚Äôm where it‚Äôs at. Django and Flask, web frameworks so sleek, Building APIs, from strong to boutique.\nJupyter Notebooks, my interactive stage, Collaborating with data at every page. Anaconda‚Äôs my lair, where I thrive, In the world of programming, I‚Äôm the hive.\nR:\nPython, you‚Äôre flashy, I won‚Äôt deny, But in data analysis, I reach for the sky. RMarkdown‚Äôs my rhyme, in reports so sweet, Knitting documents, making it elite.\nCRAN repository, where packages reside, Shiny dashboards, taking users on a ride. I might be niche, but my stats are profound, In the world of data, I wear the crown.\n(Beat fades out‚Ä¶)\nQuelle: ChatGPT 3.5, 2023-11-23",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Python üíñ R</span>"
    ]
  },
  {
    "objectID": "105-python-r.html#python-aus-rstudio",
    "href": "105-python-r.html#python-aus-rstudio",
    "title": "\n13¬† Python üíñ R\n",
    "section": "\n13.2 Python aus RStudio",
    "text": "13.2 Python aus RStudio\nRStudio bietet die M√∂glichkeit, R und Python gleichzeitig in einem Notebook zu verwenden. Und nicht nur das:\n\nMan kann Objekte (Daten) zwischen den beiden Sprachen tauschen\nMan kann aus R Python-Funktionen verwenden.\n\nSie haben zwei M√∂glichkeiten, Python in RStudio zu nutzen:\n\n√ñffnen Sie ein reines Python-Skript.\nF√ºgen Sie Python-Chunks in ein Notebook (d.h. Quarto-Doc) ein.\n\n\n\nQuelle: Imgflip",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Python üíñ R</span>"
    ]
  },
  {
    "objectID": "105-python-r.html#einstieg-in-python",
    "href": "105-python-r.html#einstieg-in-python",
    "title": "\n13¬† Python üíñ R\n",
    "section": "\n13.4 Einstieg in Python",
    "text": "13.4 Einstieg in Python\n\n13.4.1 Hallo, üêç\n\n```{python}\nprint(\"Hello! Here's üêç\")\n\npython_list = [1,2,3]  # im Standard Integer\npython_list\n```\n## Hello! Here's üêç\n## [1, 2, 3]\n\n\n13.4.2 Objektaustausch zwischen R und Python\nIn R ein Python-Objekt ansprechen, das geht mit py$:\n\npy$python_list\n## [1] 1 2 3\n\nr_vec &lt;- c(1L,2L,3L)  # Integer aktiv gew√§hlt, da R im Standard  Float w√§hlt\nr_vec\n## [1] 1 2 3\n\nIn Python ein R-Objekt ansprechen, das geht mit r.:\n\nr.r_vec\n## [1, 2, 3]",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Python üíñ R</span>"
    ]
  },
  {
    "objectID": "105-python-r.html#python-setup",
    "href": "105-python-r.html#python-setup",
    "title": "\n13¬† Python üíñ R\n",
    "section": "\n13.3 Python-Setup",
    "text": "13.3 Python-Setup\n\n13.3.1 Python installieren\n\n\nDownload et al.\npyenv\n\n\n\nMan kann Python kostenlos herunterladen bei https://www.python.org/downloads/. Hier ist eine Anleitung von Wikihow. Bei Unix-Betriebssystemen werden h√§ufig Paketmanager verwendet.\n\n\nWelche Versionen gibt‚Äôs?\n\npyenv install --list\n\n\npyenv install 3.12.0a3\n\n\n\n\n\n13.3.2 Welche Python-Version l√§uft gerade?\nIn R l√§uft gerade folgende Python-Version:\n\nlibrary(reticulate)\npy_config()\n## python:         /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/bin/python\n## libpython:      /Users/sebastiansaueruser/.pyenv/versions/3.8.16/lib/libpython3.8.dylib\n## pythonhome:     /Users/sebastiansaueruser/.virtualenvs/r-tensorflow:/Users/sebastiansaueruser/.virtualenvs/r-tensorflow\n## version:        3.8.16 (default, Sep 15 2023, 17:53:02)  [Clang 14.0.3 (clang-1403.0.22.14.1)]\n## numpy:          /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/lib/python3.8/site-packages/numpy\n## numpy_version:  1.24.3\n## \n## NOTE: Python version was forced by VIRTUAL_ENV\n\nAus der reticulate-Doku:\n\nBy default, reticulate uses an isolated python virtual environment named ‚Äúr-reticulate‚Äù.\n\nCheck: Ist Python gestartet und bereit?\n\npy_available()\n## [1] TRUE\n\nWir k√∂nnen die Kommandozeile auch aus Notebooks heraus ansprechen.\n\n```{zsh}\npython --version\n```\n## Python 3.8.16\n\nAber Achtung: Die gezeigt Version ist nicht unbedingt diejenige, die im Notebook oder im interaktiven R verwendet wird.\nRStudio zeigt Ihnen, welche Python-Versionen verf√ºgbar sind unter Tools &gt; Global Options &gt; Python.\n\n13.3.3 Versionen wechseln\n\n13.3.3.1 RStudio\nRStudio bietet in den Optionen per GUI die M√∂glichkeit, eine bestimmte Version von Python auszuw√§hlen. Zumeist sind mehrere Versionen auf einem Computer vorhanden.\nNat√ºrlich kann man auch via R virtuelle Environments (venvs) nutzen, wie es in Python √ºblich ist:\n\nuse_virtualenv(\"r-tensorflow\")\n\nOder man legt sich solche venvs an:\n\n\nR\npyenv\n\n\n\n\nreticulate::virtualenv_create(\"scikit-llm\")\n\n\n\nMit pyenv virtualenv legt man eine neue venv mit Namen my_venv an:\n\npyenv virtualenv 3.11.1 test_venv\n\n\n\n\n\n13.3.3.2 Pyenv\nMit pyenv kann man komfortabel zwischen mehreren installierten Python-Versionen wechseln.\nUm Python-Module zu installieren via pyenv bietet sich dieser (Kommondozeilen-)Befehl an:\npyenv exec pip install &lt;name-des-moduls&gt;.\n\nBeispiel 13.1 Um das Modul spacy zu installieren, schreibt man pyenv exec pip install spacy. \\(\\square\\)\n\nin der Shell ist gerade folgende Python-Version aktiviert:\n\n\nR\nShell\n\n\n\n\nsystem2(command = \"pyenv\",\n        args = \"version\")\n\n\n\n\npyenv version\n## 3.11.1 (set by /Users/sebastiansaueruser/.python-version)\n\n\n\n\n\nDie ‚Äúaktuelle‚Äù Python-Version ist nicht (unbedingt) die Python-Version, die in R aktiv ist. \\(\\square\\)\n\n\n```{zsh}\npyenv versions\n```\n##   system\n##   3.8.1\n##   3.8.16\n##   3.9.16\n## * 3.11.1 (set by /Users/sebastiansaueruser/.python-version)\n\n\n\n\n\n\n\nVorsicht\n\n\n\nEs werden nur Python-Versionen angezeigt, die im Pfad (in der Shell) definiert sind. \\(\\square\\)\n\n\n\n13.3.4 Liste installierter Module\nDie Liste installierter Module bezieht sich auf die aktuell aktivierte Version von Python.\n\n\nR\nShell\nPython\n\n\n\n\npy_list_packages()\n\n\n  \n\n\n\n\n\n\npip list\n## Package                       Version\n## ----------------------------- ------------\n## absl-py                       1.4.0\n## aiohttp                       3.9.0\n## aiosignal                     1.3.1\n## annotated-types               0.6.0\n## anyio                         3.7.1\n## array-record                  0.4.0\n## astunparse                    1.6.3\n## async-timeout                 4.0.3\n## attrs                         23.1.0\n## cachetools                    5.3.1\n## certifi                       2023.7.22\n## charset-normalizer            3.3.0\n## click                         8.1.7\n## distro                        1.8.0\n## dm-tree                       0.1.8\n## etils                         1.3.0\n## exceptiongroup                1.2.0\n## filelock                      3.13.1\n## flatbuffers                   23.5.26\n## frozenlist                    1.4.0\n## fsspec                        2023.10.0\n## gast                          0.4.0\n## google-api-core               2.14.0\n## google-auth                   2.23.4\n## google-auth-oauthlib          1.0.0\n## google-cloud-aiplatform       1.36.4\n## google-cloud-bigquery         3.13.0\n## google-cloud-core             2.3.3\n## google-cloud-resource-manager 1.10.4\n## google-cloud-storage          2.13.0\n## google-crc32c                 1.5.0\n## google-pasta                  0.2.0\n## google-resumable-media        2.6.0\n## googleapis-common-protos      1.60.0\n## grpc-google-iam-v1            0.12.7\n## grpcio                        1.59.3\n## grpcio-status                 1.59.3\n## h11                           0.14.0\n## h5py                          3.9.0\n## httpcore                      1.0.2\n## httpx                         0.25.1\n## huggingface                   0.0.1\n## huggingface-hub               0.19.4\n## idna                          3.4\n## importlib-metadata            6.8.0\n## importlib-resources           6.1.0\n## joblib                        1.3.2\n## keras                         2.13.1\n## libclang                      16.0.6\n## Markdown                      3.4.4\n## MarkupSafe                    2.1.3\n## multidict                     6.0.4\n## numpy                         1.24.3\n## oauthlib                      3.2.2\n## openai                        1.3.5\n## opt-einsum                    3.3.0\n## packaging                     23.2\n## pandas                        2.0.3\n## Pillow                        10.0.1\n## pip                           23.2.1\n## promise                       2.3\n## proto-plus                    1.22.3\n## protobuf                      4.25.1\n## psutil                        5.9.5\n## pyasn1                        0.5.0\n## pyasn1-modules                0.3.0\n## pydantic                      2.5.2\n## pydantic_core                 2.14.5\n## pydot                         1.4.2\n## pyparsing                     3.1.1\n## python-dateutil               2.8.2\n## pytz                          2023.3.post1\n## PyYAML                        6.0.1\n## regex                         2023.10.3\n## requests                      2.31.0\n## requests-oauthlib             1.3.1\n## rsa                           4.9\n## safetensors                   0.4.0\n## scikit-learn                  1.3.2\n## scipy                         1.10.1\n## setuptools                    68.2.2\n## shapely                       2.0.2\n## six                           1.16.0\n## sniffio                       1.3.0\n## tensorboard                   2.13.0\n## tensorboard-data-server       0.7.1\n## tensorflow                    2.13.1\n## tensorflow-datasets           4.9.2\n## tensorflow-estimator          2.13.0\n## tensorflow-hub                0.14.0\n## tensorflow-io-gcs-filesystem  0.34.0\n## tensorflow-metadata           1.14.0\n## termcolor                     2.3.0\n## threadpoolctl                 3.2.0\n## tokenizers                    0.15.0\n## toml                          0.10.2\n## tqdm                          4.66.1\n## transformers                  4.35.2\n## typing_extensions             4.8.0\n## tzdata                        2023.3\n## urllib3                       2.0.6\n## Werkzeug                      3.0.0\n## wheel                         0.41.2\n## wrapt                         1.15.0\n## yarl                          1.9.3\n## zipp                          3.17.0\n## \n## [notice] A new release of pip is available: 23.2.1 -&gt; 23.3.1\n## [notice] To update, run: pip install --upgrade pip\n\n\n\n\nimport os\nos.system(\"pip list\")\n## 0\n\n\n\n\nDie Version eines bestimmten installierten Moduls bekommt man einfach mit grep:\n\n!pip list | grep openai\n\nDas Ausrufezeichen ! zeigt Shell-Code in einem Python-Chunk an. Der Balken | ist eine Pfeife wie |&gt; in R.\n\n13.3.5 Module installieren\n\n\nShell\nR\n\n\n\nMit dem Kommandozeilen-Befehl pip kann man Pythonmodule installieren.\n\npip install module-name\n\nDabei steht module-name f√ºr den Namen des zu installierenden Moduls, z.B. openai.\nUnd auch wieder l√∂schen\n\npip uninstall module-name\n\n\n\nOder via R:\n\npy_install(\"openai\")",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Python üíñ R</span>"
    ]
  },
  {
    "objectID": "105-python-r.html#hello",
    "href": "105-python-r.html#hello",
    "title": "\n13¬† Python üíñ R\n",
    "section": "\n13.5 Hello, üêç",
    "text": "13.5 Hello, üêç\n\n```{python}\nprint(\"Hello! Here's üêç\")\n\npython_list = [1,2,3]\npython_list\n```\n## Hello! Here's üêç\n## [1, 2, 3]\n\n\n13.5.1 Objektaustausch zwischen R und Python\nIn R ein Python-Objekt ansprechen, das geht mit py$:\n\npy$python_list\n## [1] 1 2 3\n\nr_vec &lt;- c(1,2,3)\nr_vec\n## [1] 1 2 3\n\nIn Python ein R-Objekt ansprechen, das geht mit r.:\n\nr.r_vec\n## [1.0, 2.0, 3.0]",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Python üíñ R</span>"
    ]
  },
  {
    "objectID": "105-python-r.html#vertiefung",
    "href": "105-python-r.html#vertiefung",
    "title": "\n13¬† Python üíñ R\n",
    "section": "\n13.5 Vertiefung",
    "text": "13.5 Vertiefung\nEs gibt viele Onlinekurse, um Python zu lernen, z.B. Googles Crashkurs bei Coursera; √ºberhaupt bietet Coursera eine Menge Onlinekurse zu dem Thema Python. Andere Anbieter bieten das auch, etwa edx. https://www.learnpython.org/ bietet einen E-Learning-Kurs.\n\n\n\n\nBarry, Paul. 2017. Python von Kopf bis Fu√ü. √úbersetzt von J√∏rgen W. Lang. Zweite Auflage. Von Kopf bis Fu√ü. Beijing Boston Farnham Sebastopol Tokyo: O‚ÄôReilly.\n\n\nDowney, Allen B. 2021. Think Python: systematisch programmieren lernen mit Python. √úbersetzt von Peter Klicman. 1. Auflage. Heidelberg: O‚ÄôReilly.\n\n\nInden, Michael. 2023. Python lernen: kurz & gut. 1. Auflage. O‚ÄôReillys Taschenbibliothek. Heidelberg: O‚ÄôReilly.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>13</span>¬† <span class='chapter-title'>Python üíñ R</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#vorab",
    "href": "130-chatgpt.html#vorab",
    "title": "\n17¬† ChatGPT-API\n",
    "section": "\n17.1 Vorab",
    "text": "17.1 Vorab\n\n17.1.1 Lernziele\n\nSie k√∂nnen g√§ngige Anfragen an die OpenAI-ChatGPT-API senden.\n\n17.1.2 Ben√∂tigte Software\n\nlibrary(stringr)\nlibrary(httr)  # Wrapper um curl\n\n\n17.1.3 Spielzeug-Daten\n\ntweets &lt;- c(\n'@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?', '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.')",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#grundlagen",
    "href": "130-chatgpt.html#grundlagen",
    "title": "\n17¬† ChatGPT-API\n",
    "section": "\n17.2 Grundlagen",
    "text": "17.2 Grundlagen\n\n17.2.1 ChatGPT ist auch ein Transformer\n\nüë®‚Äçüè´ Bist du ein Transformer?\n\n\nü§ñ Ja, ich bin ein Modell, das auf der GPT-3.5-Architektur von OpenAI basiert, und diese Architektur wird als ‚ÄúTransformer‚Äù bezeichnet. Der Begriff ‚ÄúTransformer‚Äù bezieht sich auf die spezifische Architektur des neuronalen Netzwerks, die von Vaswani et al.¬†in ihrem Paper ‚ÄúAttention is All You Need‚Äù vorgestellt wurde. Die Transformer-Architektur hat sich als √§u√üerst leistungsf√§hig f√ºr nat√ºrliche Sprachverarbeitungsaufgaben erwiesen und bildet die Grundlage f√ºr Modelle wie GPT (Generative Pre-trained Transformer), einschlie√ülich GPT-3.5, auf dem meine F√§higkeiten basieren.\n\n[Quelle: ChatGPT-3.5, 2023-11-23]\n\n17.2.2 Alles ist API\nDie Python- (oder R-)Pakete zum Zugriff zur ChatGPT-API sind letztlich nur Wrapper um den ‚Äúdirekten‚Äù Zugriff auf die API.\n\nDefinition 17.1 (API (Application Programming Interface)) Eine API stellt genormte Befehle zur Verf√ºgung, um von einem Dienst (√ºber eine Webseite) Daten abzufragen oder einzustellen. \\(\\square\\)\n\n\n17.2.3 curl\n\ncurl ist eine g√§ngige Methode (auf der Kommondozeile), um Daten von einer Webseite abzufragen (oder einzustellen).\nLaut Dokumentation der API lautet der CURL-Befehl wie folgt (Pseudocode):\n\n```{zsh}\n#| eval: false\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n  \"model\": \"gpt-3.5-turbo\",\n  \"messages\": [{\"role\": \"user\", \"content\": \"Was ist die Frage zur Antwort '42'?\"}] ,\n  \"temperature\": 0,\n  \"max_tokens\": 256\n}'\n```\n\nEntscheidend ist der ‚ÄúEndpunkt‚Äù der URL: completions.\n\n\n\n\n\n\nHinweis\n\n\n\nOpenAi stellt eine Reihe von spezialisierten Diensten zur Verf√ºgung, z.B. zur Sentimentanalyse von Tweets oder, nat√ºrlich, Textgeneration, und vieles mehr. \\(\\square\\)\n\n\nObige Syntax √ºbersetzt sich so nach Python:\n\n# This code is for v1 of the openai package: pypi.org/project/openai\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[],\n  temperature=0,\n  max_tokens=256\n)\n\n\n17.2.4 Prompting\nAls Prompt kann man z.B. √ºbergeben (bezeichnet als ‚ÄúSystem‚Äù):\n\nüßë‚Äçü¶∞ You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative. USER\n\nDann kommt der zu klassifizierende Textschnipsel (bezeichent als ‚Äúuser‚Äù):\n\nüìÑ I loved the new Batman movie!\n\nUnd schlie√ülich antwortet der Bot:\n\nü§ñ positive\n\nEs ist g√ºnstig, dem Bot zu sagen, in welcher Sprache der Tweet ist. Au√üerdem ist es n√ºtzlich, den Prompt (die Anweisung) bereits in der Zielsprache zu formulieren.\n\nprompt_stem &lt;- \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: \"\n\n\nprompts &lt;- \n  str_c(prompt_stem, tweets)\n\nprompts\n## [1] \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\"                                 \n## [2] \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\"\n\n\n17.2.5 Anmelden an der API\nDie API erlaubt nur Zugriffe angemeldeter Nutzer.\n\nOPENAI_API_KEY &lt;- Sys.getenv(\"OPENAI_API_KEY\")\n\nDamit eine Environment-Variable OPENAI_API_KEY ausgelesen werden kann, muss sie in .Rprofile definiert sein. Alternativ kann man aber die Variable auch auf anderen Wegen definieren, etwa aus einer Textdatei einlesen.\n\n\n\n\n\n\nWichtig\n\n\n\nLassen Sie sensible Daten, wie API-Keys, niemals auf √∂ffentlichen Ordnern oder Repos (etwa auf Github) herumliegen. Stellen Sie sich vor, Sie haben bei dem Dienst ihre Kreditkarte hinterlege und ein √ºbelwollender Dritter nutzt kostenpflichtige Dienste mit sehr hohem Budget. ü§Ø \\(\\square\\)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#wrapper-um-curl",
    "href": "130-chatgpt.html#wrapper-um-curl",
    "title": "\n17¬† ChatGPT-API\n",
    "section": "\n17.3 Wrapper um curl",
    "text": "17.3 Wrapper um curl\nDieser Abschnitt basiert auf einem Blogpost bei R-Bloggers von Rasmus B√•√•th.\n\nresponse &lt;- POST(\n  # curl https://api.openai.com/v1/chat/completions \n  url = \"https://api.openai.com/v1/chat/completions\", \n  # -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  add_headers(Authorization = \n                paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\"))),\n  # -H \"Content-Type: application/json\"\n  content_type_json(),\n  # -d '{\n  #   \"model\": \"gpt-3.5-turbo\",\n  #   \"messages\": [{\"role\": \"user\", \"content\": \"What is a banana?\"}] \n  # }'\n  encode = \"json\",\n  body = list(\n    model = \"gpt-3.5-turbo\",\n    messages = list(list(role = \"user\", content = prompts[1]))\n  ))\n\n\ncontent(response)\n\n$object\n[1] \"chat.completion\"\n\n$created\n[1] 1700753610\n\n$model\n[1] \"gpt-3.5-turbo-0613\"\n\n$choices\n$choices[[1]]\n$choices[[1]]$index\n[1] 0\n\n$choices[[1]]$message\n$choices[[1]]$message$role\n[1] \"assistant\"\n\n$choices[[1]]$message$content\n[1] \"Das Sentiment dieses Tweets ist positiv. \"\n\n$choices[[1]]$finish_reason\n[1] \"stop\"\n\n$usage\n$usage$prompt_tokens\n[1] 76\n\n$usage$completion_tokens\n[1] 10\n\n$usage$total_tokens\n[1] 86\nDer f√ºr uns entscheidende Punkt ist:\n\nstr_trim(content(response)$choices[[1]]$message$content)\n\nDas Sentiment dieses Tweets ist positiv. \n\n17.3.1 Curl-Wrapper in eine Funktion gebracht\n\nask_chatgpt &lt;- function(prompt) {\nresponse &lt;- POST(\n  # curl https://api.openai.com/v1/chat/completions \n  url = \"https://api.openai.com/v1/chat/completions\", \n  # -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  add_headers(Authorization = \n                paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\"))),\n  # -H \"Content-Type: application/json\"\n  content_type_json(),\n  # -d '{\n  #   \"model\": \"gpt-3.5-turbo\",\n  #   \"messages\": [{\"role\": \"user\", \"content\": \"What is a banana?\"}] \n  # }'\n  encode = \"json\",\n  body = list(\n    model = \"gpt-3.5-turbo\",\n    messages = list(list(role = \"user\", content = prompt))\n  ))\n  str_trim(content(response)$choices[[1]]$message$content)\n}\n\n\n17.3.2 Schleife\n\nprompts |&gt; \n  sapply(ask_chatgpt)\n\nNach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar? \n\n\"positiv\" \n \nNach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir. \n\n \"neutral\"",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#vertiefung",
    "href": "130-chatgpt.html#vertiefung",
    "title": "\n17¬† ChatGPT-API\n",
    "section": "\n17.4 Vertiefung",
    "text": "17.4 Vertiefung\nMit etwas Zusatzaufwand kann man den Kontext bzw. den Verlauf der Konversation mit dem Bot ber√ºcksichtigen, wie dieser Post zeigt.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#aufgaben",
    "href": "130-chatgpt.html#aufgaben",
    "title": "\n17¬† ChatGPT-API\n",
    "section": "\n17.5 Aufgaben",
    "text": "17.5 Aufgaben\nSchauen Sie sich die Aufgaben mit dem Tag ‚ÄòTransformer‚Äô auf dem Datenwerk an.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>ChatGPT-API</span>"
    ]
  }
]