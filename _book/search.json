[
  {
    "objectID": "125-fallstudie-keras1.html#lernsteuerung",
    "href": "125-fallstudie-keras1.html#lernsteuerung",
    "title": "\n16  Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.1 Lernsteuerung",
    "text": "16.1 Lernsteuerung\n\n16.1.1 Lernziele\nNach Abschluss dieses Kapitels …\n\nein einfaches neuronales Netzwerk mit Keras erstellen zur Klassifikation von Hate-Speech.\n\n16.1.2 Überblick\nIn diesem Kapitel nutzen wir grundlegende Methoden neuronaler Netze, um Hate-Speech vorherzusagen. Dabei findet der Datensatz GermEval Verwendung. Zunächst verwenden wir den schon aufbereiteten Datensatz, das macht es uns einfacher. Dieser aufbereitete Datensatz ist schon “numerisiert”1. Der Text der Tweets ist schon in numerische Prädiktoren umgewandelt. Dabei fanden einfache (deutschsprachige) Wordvektoren (wikipedia2vec) Verwendung. In diesem Kapitel arbeiten wir mit ausschließlich mit Python.\n\n16.1.3 Benötigte R-Pakete\n\n# keines :-)\n\n\n16.1.4 Python-Check\n\nreticulate::py_available()\n## [1] FALSE\nreticulate::py_config()\n## python:         /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/bin/python\n## libpython:      /Users/sebastiansaueruser/.pyenv/versions/3.8.16/lib/libpython3.8.dylib\n## pythonhome:     /Users/sebastiansaueruser/.virtualenvs/r-tensorflow:/Users/sebastiansaueruser/.virtualenvs/r-tensorflow\n## version:        3.8.16 (default, Sep 15 2023, 17:53:02)  [Clang 14.0.3 (clang-1403.0.22.14.1)]\n## numpy:          /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/lib/python3.8/site-packages/numpy\n## numpy_version:  1.24.3\n## \n## NOTE: Python version was forced by VIRTUAL_ENV\n\n\n16.1.5 Benötigte Python-Module\n\nimport keras\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import accuracy_score\n\n\n16.1.6 Benötigte Daten\n\nd_train_baked = pd.read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n\nd_train_num = d_train_baked.select_dtypes(include='number')\n\nd_train2 = d_train_baked.loc[:, \"emo_count\":\"wordembed_text_V101\"]\n\nX_train = d_train2.values\n\nd_train_baked[\"y\"] = d_train_baked[\"c1\"].map({\"OTHER\" : 0, \"OFFENSE\" : 1})\n\ny_train = d_train_baked.loc[:, \"y\"].values\n\n\nprint(y_train[:6])\n## [0 0 0 0 1 0]\n\n\nd_train2.info()\n## &lt;class 'pandas.core.frame.DataFrame'&gt;\n## RangeIndex: 5009 entries, 0 to 5008\n## Columns: 119 entries, emo_count to wordembed_text_V101\n## dtypes: float64(119)\n## memory usage: 4.5 MB\n\n\nprint(d_train2.head())\n##    emo_count  schimpf_count  ...  wordembed_text_V100  wordembed_text_V101\n## 0   0.574594      -0.450067  ...            -0.449265            -0.277801\n## 1  -1.111107      -0.450067  ...             0.974438             0.223422\n## 2   0.186402      -0.450067  ...             0.407285             0.470835\n## 3   0.201551      -0.450067  ...            -0.681155             0.351565\n## 4   0.168223      -0.450067  ...            -0.674108             0.543312\n## \n## [5 rows x 119 columns]\n\n\nd_test_baked = pd.read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")\n\nd_test_num = d_test_baked.select_dtypes(include='number')\n\nd_test2 = d_test_baked.loc[:, \"emo_count\":\"wordembed_text_V101\"]\n\nX_test = d_test2.values\n\n\nd_test_baked[\"y\"] = d_test_baked[\"c1\"].map({\"OTHER\" : 0, \"OFFENSE\" : 1})\n\ny_test = d_test_baked.loc[:, \"y\"].values\n\n\nprint(y_test[:5])\n## [0 0 0 0 1]",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "125-fallstudie-keras1.html#pipeline-1",
    "href": "125-fallstudie-keras1.html#pipeline-1",
    "title": "\n16  Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.2 Pipeline 1",
    "text": "16.2 Pipeline 1\n\n16.2.1 Modeldefinition\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n\n16.2.2 Fit\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n## Epoch 1/10\n## \n 1/79 [..............................] - ETA: 50s - loss: 0.9867 - accuracy: 0.3281\n31/79 [==========&gt;...................] - ETA: 0s - loss: 0.7538 - accuracy: 0.5605 \n64/79 [=======================&gt;......] - ETA: 0s - loss: 0.6511 - accuracy: 0.6438\n79/79 [==============================] - 1s 5ms/step - loss: 0.6308 - accuracy: 0.6608 - val_loss: 0.5610 - val_accuracy: 0.7146\n## Epoch 2/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.5424 - accuracy: 0.7344\n33/79 [===========&gt;..................] - ETA: 0s - loss: 0.5209 - accuracy: 0.7372\n66/79 [========================&gt;.....] - ETA: 0s - loss: 0.5005 - accuracy: 0.7536\n79/79 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7506 - val_loss: 0.5514 - val_accuracy: 0.7242\n## Epoch 3/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.5258 - accuracy: 0.7500\n38/79 [=============&gt;................] - ETA: 0s - loss: 0.4706 - accuracy: 0.7710\n76/79 [===========================&gt;..] - ETA: 0s - loss: 0.4752 - accuracy: 0.7706\n79/79 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7696 - val_loss: 0.5570 - val_accuracy: 0.7214\n## Epoch 4/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.4033 - accuracy: 0.7812\n26/79 [========&gt;.....................] - ETA: 0s - loss: 0.4373 - accuracy: 0.7957\n58/79 [=====================&gt;........] - ETA: 0s - loss: 0.4539 - accuracy: 0.7802\n79/79 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7804 - val_loss: 0.5521 - val_accuracy: 0.7251\n## Epoch 5/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.3376 - accuracy: 0.8438\n36/79 [============&gt;.................] - ETA: 0s - loss: 0.4263 - accuracy: 0.8056\n70/79 [=========================&gt;....] - ETA: 0s - loss: 0.4403 - accuracy: 0.7871\n79/79 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7876 - val_loss: 0.5564 - val_accuracy: 0.7248\n## Epoch 6/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.4872 - accuracy: 0.7656\n36/79 [============&gt;.................] - ETA: 0s - loss: 0.4134 - accuracy: 0.8025\n74/79 [===========================&gt;..] - ETA: 0s - loss: 0.4221 - accuracy: 0.8017\n79/79 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8010 - val_loss: 0.5611 - val_accuracy: 0.7293\n## Epoch 7/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.3458 - accuracy: 0.8281\n37/79 [=============&gt;................] - ETA: 0s - loss: 0.4071 - accuracy: 0.8133\n76/79 [===========================&gt;..] - ETA: 0s - loss: 0.4111 - accuracy: 0.8106\n79/79 [==============================] - 0s 2ms/step - loss: 0.4103 - accuracy: 0.8095 - val_loss: 0.5615 - val_accuracy: 0.7237\n## Epoch 8/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.3264 - accuracy: 0.8906\n36/79 [============&gt;.................] - ETA: 0s - loss: 0.3999 - accuracy: 0.8099\n73/79 [==========================&gt;...] - ETA: 0s - loss: 0.3946 - accuracy: 0.8161\n79/79 [==============================] - 0s 3ms/step - loss: 0.3972 - accuracy: 0.8145 - val_loss: 0.5697 - val_accuracy: 0.7240\n## Epoch 9/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.5248 - accuracy: 0.7500\n30/79 [==========&gt;...................] - ETA: 0s - loss: 0.3842 - accuracy: 0.8234\n54/79 [===================&gt;..........] - ETA: 0s - loss: 0.3815 - accuracy: 0.8238\n79/79 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.8245\n79/79 [==============================] - 0s 3ms/step - loss: 0.3835 - accuracy: 0.8245 - val_loss: 0.5771 - val_accuracy: 0.7194\n## Epoch 10/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.3683 - accuracy: 0.8906\n34/79 [===========&gt;..................] - ETA: 0s - loss: 0.3684 - accuracy: 0.8332\n69/79 [=========================&gt;....] - ETA: 0s - loss: 0.3715 - accuracy: 0.8338\n79/79 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8343 - val_loss: 0.5747 - val_accuracy: 0.7240\n## &lt;keras.src.callbacks.History object at 0x1348ee6a0&gt;",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "125-fallstudie-keras1.html#pipeline-2",
    "href": "125-fallstudie-keras1.html#pipeline-2",
    "title": "\n16  Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.3 Pipeline 2",
    "text": "16.3 Pipeline 2\nWir fügen eine zweite Hidden Layer hinzu.\n\n16.3.1 Modeldefinition\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(units=32, activation='relu'))  # Second hidden layer\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n\n16.3.2 Fit\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=8, validation_data=(X_test, y_test))\n## Epoch 1/10\n## \n  1/627 [..............................] - ETA: 7:56 - loss: 0.8802 - accuracy: 0.2500\n 24/627 [&gt;.............................] - ETA: 1s - loss: 0.6753 - accuracy: 0.5625  \n 46/627 [=&gt;............................] - ETA: 1s - loss: 0.6326 - accuracy: 0.6223\n 69/627 [==&gt;...........................] - ETA: 1s - loss: 0.6348 - accuracy: 0.6322\n 87/627 [===&gt;..........................] - ETA: 1s - loss: 0.6249 - accuracy: 0.6422\n108/627 [====&gt;.........................] - ETA: 1s - loss: 0.6119 - accuracy: 0.6574\n127/627 [=====&gt;........................] - ETA: 1s - loss: 0.6047 - accuracy: 0.6663\n151/627 [======&gt;.......................] - ETA: 1s - loss: 0.5974 - accuracy: 0.6714\n175/627 [=======&gt;......................] - ETA: 1s - loss: 0.5827 - accuracy: 0.6836\n204/627 [========&gt;.....................] - ETA: 0s - loss: 0.5769 - accuracy: 0.6887\n220/627 [=========&gt;....................] - ETA: 1s - loss: 0.5718 - accuracy: 0.6926\n247/627 [==========&gt;...................] - ETA: 0s - loss: 0.5667 - accuracy: 0.6974\n272/627 [============&gt;.................] - ETA: 0s - loss: 0.5615 - accuracy: 0.7008\n304/627 [=============&gt;................] - ETA: 0s - loss: 0.5599 - accuracy: 0.7027\n334/627 [==============&gt;...............] - ETA: 0s - loss: 0.5587 - accuracy: 0.7051\n368/627 [================&gt;.............] - ETA: 0s - loss: 0.5576 - accuracy: 0.7062\n406/627 [==================&gt;...........] - ETA: 0s - loss: 0.5535 - accuracy: 0.7112\n444/627 [====================&gt;.........] - ETA: 0s - loss: 0.5504 - accuracy: 0.7154\n483/627 [======================&gt;.......] - ETA: 0s - loss: 0.5433 - accuracy: 0.7220\n521/627 [=======================&gt;......] - ETA: 0s - loss: 0.5416 - accuracy: 0.7207\n557/627 [=========================&gt;....] - ETA: 0s - loss: 0.5430 - accuracy: 0.7202\n583/627 [==========================&gt;...] - ETA: 0s - loss: 0.5395 - accuracy: 0.7228\n604/627 [===========================&gt;..] - ETA: 0s - loss: 0.5400 - accuracy: 0.7225\n627/627 [==============================] - 3s 3ms/step - loss: 0.5392 - accuracy: 0.7237 - val_loss: 0.5449 - val_accuracy: 0.7279\n## Epoch 2/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.8083 - accuracy: 0.3750\n 37/627 [&gt;.............................] - ETA: 0s - loss: 0.4249 - accuracy: 0.8007\n 68/627 [==&gt;...........................] - ETA: 0s - loss: 0.4277 - accuracy: 0.8033\n 97/627 [===&gt;..........................] - ETA: 0s - loss: 0.4349 - accuracy: 0.7990\n124/627 [====&gt;.........................] - ETA: 0s - loss: 0.4391 - accuracy: 0.7944\n151/627 [======&gt;.......................] - ETA: 0s - loss: 0.4454 - accuracy: 0.7839\n189/627 [========&gt;.....................] - ETA: 0s - loss: 0.4497 - accuracy: 0.7817\n227/627 [=========&gt;....................] - ETA: 0s - loss: 0.4435 - accuracy: 0.7852\n265/627 [===========&gt;..................] - ETA: 0s - loss: 0.4409 - accuracy: 0.7892\n300/627 [=============&gt;................] - ETA: 0s - loss: 0.4432 - accuracy: 0.7871\n328/627 [==============&gt;...............] - ETA: 0s - loss: 0.4402 - accuracy: 0.7896\n355/627 [===============&gt;..............] - ETA: 0s - loss: 0.4426 - accuracy: 0.7873\n379/627 [=================&gt;............] - ETA: 0s - loss: 0.4452 - accuracy: 0.7856\n409/627 [==================&gt;...........] - ETA: 0s - loss: 0.4491 - accuracy: 0.7824\n443/627 [====================&gt;.........] - ETA: 0s - loss: 0.4499 - accuracy: 0.7824\n466/627 [=====================&gt;........] - ETA: 0s - loss: 0.4530 - accuracy: 0.7806\n490/627 [======================&gt;.......] - ETA: 0s - loss: 0.4550 - accuracy: 0.7798\n512/627 [=======================&gt;......] - ETA: 0s - loss: 0.4541 - accuracy: 0.7822\n544/627 [=========================&gt;....] - ETA: 0s - loss: 0.4528 - accuracy: 0.7845\n567/627 [==========================&gt;...] - ETA: 0s - loss: 0.4525 - accuracy: 0.7844\n595/627 [===========================&gt;..] - ETA: 0s - loss: 0.4573 - accuracy: 0.7828\n614/627 [============================&gt;.] - ETA: 0s - loss: 0.4571 - accuracy: 0.7832\n627/627 [==============================] - 2s 3ms/step - loss: 0.4570 - accuracy: 0.7828 - val_loss: 0.5505 - val_accuracy: 0.7330\n## Epoch 3/10\n## \n  1/627 [..............................] - ETA: 5s - loss: 0.2443 - accuracy: 0.8750\n 28/627 [&gt;.............................] - ETA: 1s - loss: 0.4087 - accuracy: 0.8214\n 59/627 [=&gt;............................] - ETA: 0s - loss: 0.4097 - accuracy: 0.8284\n 93/627 [===&gt;..........................] - ETA: 0s - loss: 0.4114 - accuracy: 0.8239\n129/627 [=====&gt;........................] - ETA: 0s - loss: 0.4044 - accuracy: 0.8236\n167/627 [======&gt;.......................] - ETA: 0s - loss: 0.3981 - accuracy: 0.8271\n201/627 [========&gt;.....................] - ETA: 0s - loss: 0.3968 - accuracy: 0.8252\n238/627 [==========&gt;...................] - ETA: 0s - loss: 0.4052 - accuracy: 0.8204\n276/627 [============&gt;.................] - ETA: 0s - loss: 0.4119 - accuracy: 0.8130\n313/627 [=============&gt;................] - ETA: 0s - loss: 0.4103 - accuracy: 0.8143\n351/627 [===============&gt;..............] - ETA: 0s - loss: 0.4129 - accuracy: 0.8141\n382/627 [=================&gt;............] - ETA: 0s - loss: 0.4164 - accuracy: 0.8105\n414/627 [==================&gt;...........] - ETA: 0s - loss: 0.4176 - accuracy: 0.8092\n453/627 [====================&gt;.........] - ETA: 0s - loss: 0.4144 - accuracy: 0.8110\n492/627 [======================&gt;.......] - ETA: 0s - loss: 0.4134 - accuracy: 0.8110\n530/627 [========================&gt;.....] - ETA: 0s - loss: 0.4141 - accuracy: 0.8099\n569/627 [==========================&gt;...] - ETA: 0s - loss: 0.4175 - accuracy: 0.8071\n604/627 [===========================&gt;..] - ETA: 0s - loss: 0.4165 - accuracy: 0.8073\n627/627 [==============================] - 1s 2ms/step - loss: 0.4168 - accuracy: 0.8079 - val_loss: 0.5702 - val_accuracy: 0.7364\n## Epoch 4/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.3432 - accuracy: 0.8750\n 38/627 [&gt;.............................] - ETA: 0s - loss: 0.3686 - accuracy: 0.8487\n 77/627 [==&gt;...........................] - ETA: 0s - loss: 0.3528 - accuracy: 0.8442\n115/627 [====&gt;.........................] - ETA: 0s - loss: 0.3494 - accuracy: 0.8511\n148/627 [======&gt;.......................] - ETA: 0s - loss: 0.3585 - accuracy: 0.8497\n176/627 [=======&gt;......................] - ETA: 0s - loss: 0.3541 - accuracy: 0.8494\n202/627 [========&gt;.....................] - ETA: 0s - loss: 0.3566 - accuracy: 0.8465\n227/627 [=========&gt;....................] - ETA: 0s - loss: 0.3640 - accuracy: 0.8398\n251/627 [===========&gt;..................] - ETA: 0s - loss: 0.3602 - accuracy: 0.8436\n272/627 [============&gt;.................] - ETA: 0s - loss: 0.3618 - accuracy: 0.8419\n299/627 [=============&gt;................] - ETA: 0s - loss: 0.3590 - accuracy: 0.8436\n330/627 [==============&gt;...............] - ETA: 0s - loss: 0.3646 - accuracy: 0.8402\n359/627 [================&gt;.............] - ETA: 0s - loss: 0.3653 - accuracy: 0.8381\n392/627 [=================&gt;............] - ETA: 0s - loss: 0.3698 - accuracy: 0.8342\n424/627 [===================&gt;..........] - ETA: 0s - loss: 0.3741 - accuracy: 0.8317\n463/627 [=====================&gt;........] - ETA: 0s - loss: 0.3751 - accuracy: 0.8310\n501/627 [======================&gt;.......] - ETA: 0s - loss: 0.3805 - accuracy: 0.8281\n536/627 [========================&gt;.....] - ETA: 0s - loss: 0.3798 - accuracy: 0.8265\n575/627 [==========================&gt;...] - ETA: 0s - loss: 0.3772 - accuracy: 0.8285\n611/627 [============================&gt;.] - ETA: 0s - loss: 0.3770 - accuracy: 0.8292\n627/627 [==============================] - 1s 2ms/step - loss: 0.3772 - accuracy: 0.8283 - val_loss: 0.5810 - val_accuracy: 0.7307\n## Epoch 5/10\n## \n  1/627 [..............................] - ETA: 0s - loss: 0.1820 - accuracy: 0.8750\n 36/627 [&gt;.............................] - ETA: 0s - loss: 0.3277 - accuracy: 0.8542\n 66/627 [==&gt;...........................] - ETA: 0s - loss: 0.3250 - accuracy: 0.8485\n102/627 [===&gt;..........................] - ETA: 0s - loss: 0.3419 - accuracy: 0.8444\n141/627 [=====&gt;........................] - ETA: 0s - loss: 0.3309 - accuracy: 0.8520\n176/627 [=======&gt;......................] - ETA: 0s - loss: 0.3294 - accuracy: 0.8565\n212/627 [=========&gt;....................] - ETA: 0s - loss: 0.3270 - accuracy: 0.8561\n248/627 [==========&gt;...................] - ETA: 0s - loss: 0.3297 - accuracy: 0.8543\n283/627 [============&gt;.................] - ETA: 0s - loss: 0.3299 - accuracy: 0.8529\n321/627 [==============&gt;...............] - ETA: 0s - loss: 0.3295 - accuracy: 0.8567\n359/627 [================&gt;.............] - ETA: 0s - loss: 0.3301 - accuracy: 0.8569\n394/627 [=================&gt;............] - ETA: 0s - loss: 0.3256 - accuracy: 0.8595\n430/627 [===================&gt;..........] - ETA: 0s - loss: 0.3281 - accuracy: 0.8581\n465/627 [=====================&gt;........] - ETA: 0s - loss: 0.3281 - accuracy: 0.8575\n502/627 [=======================&gt;......] - ETA: 0s - loss: 0.3304 - accuracy: 0.8566\n541/627 [========================&gt;.....] - ETA: 0s - loss: 0.3331 - accuracy: 0.8551\n579/627 [==========================&gt;...] - ETA: 0s - loss: 0.3321 - accuracy: 0.8554\n617/627 [============================&gt;.] - ETA: 0s - loss: 0.3344 - accuracy: 0.8539\n627/627 [==============================] - 2s 2ms/step - loss: 0.3357 - accuracy: 0.8537 - val_loss: 0.6400 - val_accuracy: 0.7251\n## Epoch 6/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.1641 - accuracy: 1.0000\n 32/627 [&gt;.............................] - ETA: 0s - loss: 0.2799 - accuracy: 0.8906\n 67/627 [==&gt;...........................] - ETA: 0s - loss: 0.2984 - accuracy: 0.8750\n103/627 [===&gt;..........................] - ETA: 0s - loss: 0.2972 - accuracy: 0.8726\n140/627 [=====&gt;........................] - ETA: 0s - loss: 0.2884 - accuracy: 0.8768\n178/627 [=======&gt;......................] - ETA: 0s - loss: 0.2843 - accuracy: 0.8778\n217/627 [=========&gt;....................] - ETA: 0s - loss: 0.2831 - accuracy: 0.8785\n255/627 [===========&gt;..................] - ETA: 0s - loss: 0.2786 - accuracy: 0.8824\n294/627 [=============&gt;................] - ETA: 0s - loss: 0.2890 - accuracy: 0.8771\n328/627 [==============&gt;...............] - ETA: 0s - loss: 0.2911 - accuracy: 0.8761\n365/627 [================&gt;.............] - ETA: 0s - loss: 0.2903 - accuracy: 0.8767\n401/627 [==================&gt;...........] - ETA: 0s - loss: 0.2947 - accuracy: 0.8753\n425/627 [===================&gt;..........] - ETA: 0s - loss: 0.2919 - accuracy: 0.8768\n454/627 [====================&gt;.........] - ETA: 0s - loss: 0.2952 - accuracy: 0.8744\n482/627 [======================&gt;.......] - ETA: 0s - loss: 0.2942 - accuracy: 0.8753\n504/627 [=======================&gt;......] - ETA: 0s - loss: 0.2924 - accuracy: 0.8757\n529/627 [========================&gt;.....] - ETA: 0s - loss: 0.2958 - accuracy: 0.8729\n563/627 [=========================&gt;....] - ETA: 0s - loss: 0.2964 - accuracy: 0.8728\n596/627 [===========================&gt;..] - ETA: 0s - loss: 0.3010 - accuracy: 0.8708\n620/627 [============================&gt;.] - ETA: 0s - loss: 0.3010 - accuracy: 0.8714\n627/627 [==============================] - 1s 2ms/step - loss: 0.3011 - accuracy: 0.8712 - val_loss: 0.6551 - val_accuracy: 0.7225\n## Epoch 7/10\n## \n  1/627 [..............................] - ETA: 0s - loss: 0.2258 - accuracy: 0.8750\n 39/627 [&gt;.............................] - ETA: 0s - loss: 0.2356 - accuracy: 0.9006\n 78/627 [==&gt;...........................] - ETA: 0s - loss: 0.2326 - accuracy: 0.9087\n115/627 [====&gt;.........................] - ETA: 0s - loss: 0.2389 - accuracy: 0.9022\n151/627 [======&gt;.......................] - ETA: 0s - loss: 0.2420 - accuracy: 0.9007\n187/627 [=======&gt;......................] - ETA: 0s - loss: 0.2483 - accuracy: 0.8997\n224/627 [=========&gt;....................] - ETA: 0s - loss: 0.2505 - accuracy: 0.8996\n263/627 [===========&gt;..................] - ETA: 0s - loss: 0.2518 - accuracy: 0.8969\n301/627 [=============&gt;................] - ETA: 0s - loss: 0.2529 - accuracy: 0.8953\n335/627 [===============&gt;..............] - ETA: 0s - loss: 0.2518 - accuracy: 0.8951\n371/627 [================&gt;.............] - ETA: 0s - loss: 0.2509 - accuracy: 0.8972\n406/627 [==================&gt;...........] - ETA: 0s - loss: 0.2523 - accuracy: 0.8950\n440/627 [====================&gt;.........] - ETA: 0s - loss: 0.2533 - accuracy: 0.8952\n478/627 [=====================&gt;........] - ETA: 0s - loss: 0.2528 - accuracy: 0.8954\n516/627 [=======================&gt;......] - ETA: 0s - loss: 0.2502 - accuracy: 0.8958\n554/627 [=========================&gt;....] - ETA: 0s - loss: 0.2536 - accuracy: 0.8940\n591/627 [===========================&gt;..] - ETA: 0s - loss: 0.2572 - accuracy: 0.8921\n627/627 [==============================] - 1s 2ms/step - loss: 0.2594 - accuracy: 0.8918 - val_loss: 0.7071 - val_accuracy: 0.7152\n## Epoch 8/10\n## \n  1/627 [..............................] - ETA: 0s - loss: 0.2814 - accuracy: 0.8750\n 39/627 [&gt;.............................] - ETA: 0s - loss: 0.1919 - accuracy: 0.9327\n 76/627 [==&gt;...........................] - ETA: 0s - loss: 0.2038 - accuracy: 0.9243\n109/627 [====&gt;.........................] - ETA: 0s - loss: 0.2043 - accuracy: 0.9232\n142/627 [=====&gt;........................] - ETA: 0s - loss: 0.2076 - accuracy: 0.9252\n174/627 [=======&gt;......................] - ETA: 0s - loss: 0.2146 - accuracy: 0.9224\n209/627 [=========&gt;....................] - ETA: 0s - loss: 0.2242 - accuracy: 0.9145\n246/627 [==========&gt;...................] - ETA: 0s - loss: 0.2240 - accuracy: 0.9146\n282/627 [============&gt;.................] - ETA: 0s - loss: 0.2214 - accuracy: 0.9140\n309/627 [=============&gt;................] - ETA: 0s - loss: 0.2186 - accuracy: 0.9138\n343/627 [===============&gt;..............] - ETA: 0s - loss: 0.2201 - accuracy: 0.9147\n371/627 [================&gt;.............] - ETA: 0s - loss: 0.2196 - accuracy: 0.9144\n403/627 [==================&gt;...........] - ETA: 0s - loss: 0.2204 - accuracy: 0.9128\n435/627 [===================&gt;..........] - ETA: 0s - loss: 0.2201 - accuracy: 0.9138\n467/627 [=====================&gt;........] - ETA: 0s - loss: 0.2207 - accuracy: 0.9141\n499/627 [======================&gt;.......] - ETA: 0s - loss: 0.2237 - accuracy: 0.9123\n531/627 [========================&gt;.....] - ETA: 0s - loss: 0.2236 - accuracy: 0.9127\n564/627 [=========================&gt;....] - ETA: 0s - loss: 0.2219 - accuracy: 0.9138\n597/627 [===========================&gt;..] - ETA: 0s - loss: 0.2210 - accuracy: 0.9135\n627/627 [==============================] - 1s 2ms/step - loss: 0.2209 - accuracy: 0.9132 - val_loss: 0.7906 - val_accuracy: 0.7132\n## Epoch 9/10\n## \n  1/627 [..............................] - ETA: 0s - loss: 0.1598 - accuracy: 0.8750\n 35/627 [&gt;.............................] - ETA: 0s - loss: 0.1510 - accuracy: 0.9500\n 70/627 [==&gt;...........................] - ETA: 0s - loss: 0.1789 - accuracy: 0.9446\n106/627 [====&gt;.........................] - ETA: 0s - loss: 0.1788 - accuracy: 0.9410\n144/627 [=====&gt;........................] - ETA: 0s - loss: 0.1787 - accuracy: 0.9392\n183/627 [=======&gt;......................] - ETA: 0s - loss: 0.1751 - accuracy: 0.9406\n222/627 [=========&gt;....................] - ETA: 0s - loss: 0.1737 - accuracy: 0.9392\n259/627 [===========&gt;..................] - ETA: 0s - loss: 0.1734 - accuracy: 0.9397\n296/627 [=============&gt;................] - ETA: 0s - loss: 0.1761 - accuracy: 0.9392\n332/627 [==============&gt;...............] - ETA: 0s - loss: 0.1758 - accuracy: 0.9371\n368/627 [================&gt;.............] - ETA: 0s - loss: 0.1778 - accuracy: 0.9358\n404/627 [==================&gt;...........] - ETA: 0s - loss: 0.1772 - accuracy: 0.9363\n442/627 [====================&gt;.........] - ETA: 0s - loss: 0.1781 - accuracy: 0.9350\n482/627 [======================&gt;.......] - ETA: 0s - loss: 0.1817 - accuracy: 0.9323\n521/627 [=======================&gt;......] - ETA: 0s - loss: 0.1816 - accuracy: 0.9331\n557/627 [=========================&gt;....] - ETA: 0s - loss: 0.1820 - accuracy: 0.9329\n592/627 [===========================&gt;..] - ETA: 0s - loss: 0.1857 - accuracy: 0.9299\n627/627 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.9279 - val_loss: 0.8707 - val_accuracy: 0.7138\n## Epoch 10/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.0998 - accuracy: 1.0000\n 33/627 [&gt;.............................] - ETA: 0s - loss: 0.1329 - accuracy: 0.9735\n 66/627 [==&gt;...........................] - ETA: 0s - loss: 0.1332 - accuracy: 0.9659\n 99/627 [===&gt;..........................] - ETA: 0s - loss: 0.1331 - accuracy: 0.9646\n131/627 [=====&gt;........................] - ETA: 0s - loss: 0.1375 - accuracy: 0.9647\n165/627 [======&gt;.......................] - ETA: 0s - loss: 0.1376 - accuracy: 0.9644\n200/627 [========&gt;.....................] - ETA: 0s - loss: 0.1394 - accuracy: 0.9619\n235/627 [==========&gt;...................] - ETA: 0s - loss: 0.1397 - accuracy: 0.9612\n271/627 [===========&gt;..................] - ETA: 0s - loss: 0.1425 - accuracy: 0.9576\n302/627 [=============&gt;................] - ETA: 0s - loss: 0.1461 - accuracy: 0.9545\n337/627 [===============&gt;..............] - ETA: 0s - loss: 0.1473 - accuracy: 0.9533\n374/627 [================&gt;.............] - ETA: 0s - loss: 0.1479 - accuracy: 0.9539\n410/627 [==================&gt;...........] - ETA: 0s - loss: 0.1478 - accuracy: 0.9552\n442/627 [====================&gt;.........] - ETA: 0s - loss: 0.1477 - accuracy: 0.9542\n476/627 [=====================&gt;........] - ETA: 0s - loss: 0.1480 - accuracy: 0.9530\n510/627 [=======================&gt;......] - ETA: 0s - loss: 0.1476 - accuracy: 0.9529\n544/627 [=========================&gt;....] - ETA: 0s - loss: 0.1493 - accuracy: 0.9520\n577/627 [==========================&gt;...] - ETA: 0s - loss: 0.1516 - accuracy: 0.9504\n615/627 [============================&gt;.] - ETA: 0s - loss: 0.1531 - accuracy: 0.9484\n627/627 [==============================] - 1s 2ms/step - loss: 0.1541 - accuracy: 0.9477 - val_loss: 0.9387 - val_accuracy: 0.7053\n## &lt;keras.src.callbacks.History object at 0x13512a3d0&gt;\n\n\n16.3.3 Modellgüte\n\ny_pred = (model.predict(X_test) &gt; 0.5).astype(\"int32\")\n## \n  1/111 [..............................] - ETA: 9s\n 51/111 [============&gt;.................] - ETA: 0s\n 99/111 [=========================&gt;....] - ETA: 0s\n111/111 [==============================] - 0s 1ms/step\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test Accuracy: {accuracy}\")\n## Test Accuracy: 0.7052661381653454",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#vorab",
    "href": "120-transformer.html#vorab",
    "title": "\n17  Transformer\n",
    "section": "\n17.1 Vorab",
    "text": "17.1 Vorab\n\n17.1.1 Lernziele\n\nSie können die grundlegende Architektur eines Transformer-Modells beschreiben.\nSie können Transformer-Modelle mit der API von Hugging-Face berechnen.\n\n17.1.2 Begleitliteratur\nDer Blogpost von Jay Alammar gibt einen illustrierten Überblick über Transformer.\n\n17.1.3 Benötigte Software\nWir benötigen Python, R sowei einige im Folgenden aufgeführte Python-Module.\n\nimport pandas as pd\nimport os\n\nFür den Schüleraustausch von R nach Python nutzen wir das R-Paket reticulate:\n\nlibrary(reticulate)\n\nAußerdem starte ich die “richtige” Python-Version, wo die benötigten Pakete (in der richtigen Version) installiert sind:\n\n#use_virtualenv(\"r-tensorflow\")\n\nCheck:\n\npy_available()\n## [1] TRUE\n\nWelche Python-Version nutzt reticulate gerade?\n\npy_config()\n## python:         /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/bin/python\n## libpython:      /Users/sebastiansaueruser/.pyenv/versions/3.8.16/lib/libpython3.8.dylib\n## pythonhome:     /Users/sebastiansaueruser/.virtualenvs/r-tensorflow:/Users/sebastiansaueruser/.virtualenvs/r-tensorflow\n## version:        3.8.16 (default, Sep 15 2023, 17:53:02)  [Clang 14.0.3 (clang-1403.0.22.14.1)]\n## numpy:          /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/lib/python3.8/site-packages/numpy\n## numpy_version:  1.24.3\n## \n## NOTE: Python version was forced by VIRTUAL_ENV",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#überblick",
    "href": "120-transformer.html#überblick",
    "title": "\n17  Transformer\n",
    "section": "\n17.2 Überblick",
    "text": "17.2 Überblick\nTransformer sind eine Architekturvariante neuronaler Netze. Sie stellen die Grundlage vieler aktueller großer Sprachmodelle1; da sie einige Vorzüge gegenüber Vorgängermodellen aufweisen, haben sie einen zentralen Platz für verschiedenen Aufgaben des NLP eingenommen.\nIm Jahr 2017 erschien ein Paper auf Arxive mit dem Titel “Attention is all you need”, Vaswani u. a. (2023)2. Transformer basieren auf einer bestimmten Art von “Aufmerksamkeit”, genannt Selbst-Aufmerksamkeit (self-attention). Natürlich ist damit eine bestimmte Architektur im neuronalen Netzwerk gemeint, kein kognitivpsychologiches Konstruktr; allerdings lehnt sich die Methode an Konzepte der Kognitionspsychologie vage an.\nSelf-Attention weist zwei große Verteile auf: Erstens erlaubt es parallele Verarbeitung, was viele Vorgängermodelle nicht erlaubten. Zweitens kann es den Kontext eines Tokens, also den Text um ein bestimmtes Wort herum, deutlich besser “im Blick” (oder in der Aufmerksamkeit) behalten als viele Vorgängermodelle.\nGerade für Daten mit sequenziellem Charakter, wie Text oder Sprache, sind Transformer-Modelle gut geeignet3.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#grundkonzepte",
    "href": "120-transformer.html#grundkonzepte",
    "title": "\n17  Transformer\n",
    "section": "\n17.3 Grundkonzepte",
    "text": "17.3 Grundkonzepte",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#einführung-in-hugging-face",
    "href": "120-transformer.html#einführung-in-hugging-face",
    "title": "\n17  Transformer\n",
    "section": "\n17.4 Einführung in Hugging Face 🤗",
    "text": "17.4 Einführung in Hugging Face 🤗\nDieser Abschnitt orientiert sich an Tunstall u. a. (2022). Die Syntax zu allen Kapiteln des Buchs findet sich praktischerweise in diesem Github-Repo.\nBei 🤗 liegt der Schwerpunkt klar bei Python, nicht bei R. Allerdings erlaubt RStudio ein einfaches Wechseln zwischen R und Python: Funktionen und Daten aus Python können einfach mit dem $-Operator angesprochen werden. In diesem Post wirds das demonstriert.\nSchauen wir uns das einführende Beispiel aus Tunstall u. a. (2022). an.\n\n17.4.1 Hugging Face mit R\nHier ein ein Text-Schnipsel, dessen Sentiment wir detektieren wollen:\n\ntext &lt;- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\nUnd hier in der Python-Version:\n\ntext_py = r.text\n\nDann importieren wir die nötigen Module:\n\n\nPython\nR\n\n\n\n\n#import tensorflow\nfrom transformers import pipeline\n\nNatürlich müssen Python-Module installiert sein, bevor man sie nutzen kann, genau so wie R-Pakete.\n\n\nMan kann die die Python-Module auch über R starten:\n\ntransformers &lt;- reticulate::import(\"transformers\")\n\n\n\n\n\n17.4.2 Einfache Pipeline\n{.panel-tabset}\n\n17.4.3 Python\nWir bereiten das Modell vor; im Default wird distilbert-base-uncased-finetuned-sst-2-english verwendet.\n\nclassifier = pipeline(\"text-classification\")\n## No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n## Using a pipeline without specifying a model name and revision in production is not recommended.\n## All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n## \n## All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#germeval-out-of-the-box-mit-hugging-face",
    "href": "120-transformer.html#germeval-out-of-the-box-mit-hugging-face",
    "title": "\n17  Transformer\n",
    "section": "\n17.5 Germeval Out-of-the-Box mit Hugging Face",
    "text": "17.5 Germeval Out-of-the-Box mit Hugging Face\nZuert importieren wir die Daten.\n\n\nR\nPython\n\n\n\n\ndata(germeval_train, package = \"pradadata\")\ntext &lt;- germeval_train$text[1:2]\ntext[1:2]\n## [1] \"@corinnamilborn Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar?\"                                 \n## [2] \"@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.\"\n\n\n\n\ngermeval_train_py = r.text\n\n\n\n\n\n17.5.1 Standard-Pipeline\n\nclassifier = pipeline(\"text-classification\")\n## No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n## Using a pipeline without specifying a model name and revision in production is not recommended.\n## All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n## \n## All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\noutputs2 = classifier(germeval_train_py)\noutputs2\n## [{'label': 'NEGATIVE', 'score': 0.9950070381164551}, {'label': 'NEGATIVE', 'score': 0.9954568147659302}]\n\nTja, vielleicht sollten wir ein Modell verwenden, das die deutsche Sprache versteht?\n\n17.5.2 Man spricht Deutsh\nAuf Hugging Face gibt es eine Menge von Modellen. Welches nehm ich nur? DISTILBERT oder BERT-Varianten dürfte kein schlechter Start sein.\n\n#classifier = pipeline(\"text-classification\", model=\"distilbert-base-german-cased\")\n\n\nclassifier = pipeline(\n  \"text-classification\", model=\"oliverguhr/german-sentiment-bert\")\n## All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n## \n## All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n\n\noutputs3 = classifier(germeval_train_py)\ndf = pd.DataFrame(outputs3)    \ndf.head()\n##       label     score\n## 0   neutral  0.987253\n## 1  negative  0.918047\n\n\ndf_r &lt;- py$pd\nhead(df_r)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#openai-api",
    "href": "120-transformer.html#openai-api",
    "title": "\n17  Transformer\n",
    "section": "\n17.6 OpenAI-API",
    "text": "17.6 OpenAI-API\n\n\n\n\n\n\nWichtig\n\n\n\nDer API-Aufruf von ChatGPT kostet Geld 💸. \\(\\square\\)\n\n\n\n17.6.1 Authentifizierung\nWir müssen uns bei der API anmelden:\n\n\nR\nPython\n\n\n\n\nopenai_key_r &lt;- Sys.getenv(\"OPENAI_API_KEY\")\n\n\n\n\nopenai_key_py = os.environ.get(\"OPENAI_API_KEY\")\n\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nSpeichern Sie keine sensiblen Daten in geteilten Ordner/Repos. Achten Sie auf Log-Dateien wir .Rhistory, in der u.U. Ihre sensiblen Daten enthalten sein können. \\(\\square\\)\n\n\nEine sichere Variante als das unverschlüsselte Speichenr von Passwörtern ist es, sensible Daten mit einem Passwort zu schützen. Dazu kann man z.B. in R das Paket keyring nutzen.\n\nlibrary(keyring)\nopenai_key_r &lt;- key_get(\"OPENAI_API_KEY\")\n\n\n17.6.2 Setup\n\nsentiment_scores = []\nsentiment_analysis = []\ntext = '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.'\n\n\n17.6.3 Anfrage an die API\n\nprompt = f\"Analysiere das Sentiment des folgenden Texts: \\n{text}\"\n\nresponse = openai.Completion.create(\n        prompt=prompt,\n        engine=\"davinci\",\n        max_tokens=100,\n        temperature=0.5,\n    )",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#vertiefung",
    "href": "120-transformer.html#vertiefung",
    "title": "\n17  Transformer\n",
    "section": "\n17.7 Vertiefung",
    "text": "17.7 Vertiefung\nDer Originalartikel von Vaswani u. a. (2023) gibt einen guten Einblick in die Konzepte; der Anspruch ist auf mittlerem Niveau. Von den Hugging-Face-Machern gibt es ein Buch, das - ebenfalls auf mittlerem Niveau - einen Einblick in Transformer-Modelle im Hugging-Face-Ökosystem gewährt (Tunstall u. a. 2022). Rothman (2022) scheint gute Freunde bei Google zu haben, wenn man sein Buch über Transformer liest, jedenfalls sind die Modelle jener Firma in dem Buch gut gefeatured. Géron (2023a) Standardwerk zu Scikit-Learn bietet auch einen Einblick in Attention-Konzepte (Kap. 16). Übrigens ist das Buch (3. Auflage) jetzt auch in deutscher Sprache erhältlich (Géron 2023b).\n\n\n\n\nGéron, Aurélien. 2023a. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Third edition. Beijing Boston Farnham Sebastopol Tokyo: O’Reilly.\n\n\n———. 2023b. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras und TensorFlow: Konzepte, Tools und Techniken für intelligente Systeme. Übersetzt von Kristian Rother und Thomas Demmig. 3., aktualisierte und erweiterte Auflage. Heidelberg: O’Reilly.\n\n\nRothman, Denis. 2022. Transformers for Natural Language Processing: Build, Train, and Fine-Tune Deep Neural Network Architectures for NLP with Python, Hugging Face, and OpenAI´s GPT3, ChatGPT, and GPT-4. Second edition. Expert Insight. Birmingham Mumbai: Packt.\n\n\nTunstall, Lewis, Leandro von Werra, Thomas Wolf, und Aurélien Géron. 2022. Natural Language Processing with Transformers: Building Language Applications with Hugging Face. Revised edition. Sebastopol: O’Reilly.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, und Illia Polosukhin. 2023. „Attention Is All You Need“. 1. August 2023. https://doi.org/10.48550/arXiv.1706.03762.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#vorab",
    "href": "130-chatgpt.html#vorab",
    "title": "\n18  ChatGPT-API\n",
    "section": "\n18.1 Vorab",
    "text": "18.1 Vorab\n\n18.1.1 Lernziele\n\nSie können gängige Anfragen an die OpenAI-ChatGPT-API senden.\n\n18.1.2 Benötigte Software\n\nlibrary(stringr)\nlibrary(httr)  # Wrapper um curl\n\n\n18.1.3 Spielzeug-Daten\n\ntweets &lt;- c(\n'@corinnamilborn Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar?', '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.')",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#grundlagen",
    "href": "130-chatgpt.html#grundlagen",
    "title": "\n18  ChatGPT-API\n",
    "section": "\n18.2 Grundlagen",
    "text": "18.2 Grundlagen\n\n18.2.1 ChatGPT ist auch ein Transformer\n\n👨‍🏫 Bist du ein Transformer?\n\n\n🤖 Ja, ich bin ein Modell, das auf der GPT-3.5-Architektur von OpenAI basiert, und diese Architektur wird als “Transformer” bezeichnet. Der Begriff “Transformer” bezieht sich auf die spezifische Architektur des neuronalen Netzwerks, die von Vaswani et al. in ihrem Paper “Attention is All You Need” vorgestellt wurde. Die Transformer-Architektur hat sich als äußerst leistungsfähig für natürliche Sprachverarbeitungsaufgaben erwiesen und bildet die Grundlage für Modelle wie GPT (Generative Pre-trained Transformer), einschließlich GPT-3.5, auf dem meine Fähigkeiten basieren.\n\n[Quelle: ChatGPT-3.5, 2023-11-23]\n\n18.2.2 Alles ist API\nDie Python- (oder R-)Pakete zum Zugriff zur ChatGPT-API sind letztlich nur Wrapper um den “direkten” Zugriff auf die API.\n\nDefinition 18.1 (API (Application Programming Interface)) Eine API stellt genormte Befehle zur Verfügung, um von einem Dienst (über eine Webseite) Daten abzufragen oder einzustellen. \\(\\square\\)\n\n\n18.2.3 curl\n\ncurl ist eine gängige Methode (auf der Kommondozeile), um Daten von einer Webseite abzufragen (oder einzustellen).\nLaut Dokumentation der API lautet der CURL-Befehl wie folgt (Pseudocode):\n\n```{zsh}\n#| eval: false\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n  \"model\": \"gpt-3.5-turbo\",\n  \"messages\": [{\"role\": \"user\", \"content\": \"Was ist die Frage zur Antwort '42'?\"}] ,\n  \"temperature\": 0,\n  \"max_tokens\": 256\n}'\n```\n\nEntscheidend ist der “Endpunkt” der URL: completions.\n\n\n\n\n\n\nHinweis\n\n\n\nOpenAi stellt eine Reihe von spezialisierten Diensten zur Verfügung, z.B. zur Sentimentanalyse von Tweets oder, natürlich, Textgeneration, und vieles mehr. \\(\\square\\)\n\n\nObige Syntax übersetzt sich so nach Python:\n\n# This code is for v1 of the openai package: pypi.org/project/openai\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[],\n  temperature=0,\n  max_tokens=256\n)\n\n\n18.2.4 Prompting\nAls Prompt kann man z.B. übergeben (bezeichnet als “System”):\n\n🧑‍🦰 You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative. USER\n\nDann kommt der zu klassifizierende Textschnipsel (bezeichent als “user”):\n\n📄 I loved the new Batman movie!\n\nUnd schließlich antwortet der Bot:\n\n🤖 positive\n\nEs ist günstig, dem Bot zu sagen, in welcher Sprache der Tweet ist. Außerdem ist es nützlich, den Prompt (die Anweisung) bereits in der Zielsprache zu formulieren.\n\nprompt_stem &lt;- \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: \"\n\n\nprompts &lt;- \n  str_c(prompt_stem, tweets)\n\nprompts\n## [1] \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @corinnamilborn Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar?\"                                 \n## [2] \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.\"\n\n\n18.2.5 Anmelden an der API\nDie API erlaubt nur Zugriffe angemeldeter Nutzer.\n\nOPENAI_API_KEY &lt;- Sys.getenv(\"OPENAI_API_KEY\")\n\nDamit eine Environment-Variable OPENAI_API_KEY ausgelesen werden kann, muss sie in .Rprofile definiert sein. Alternativ kann man aber die Variable auch auf anderen Wegen definieren, etwa aus einer Textdatei einlesen.\n\n\n\n\n\n\nWichtig\n\n\n\nLassen Sie sensible Daten, wie API-Keys, niemals auf öffentlichen Ordnern oder Repos (etwa auf Github) herumliegen. Stellen Sie sich vor, Sie haben bei dem Dienst ihre Kreditkarte hinterlege und ein übelwollender Dritter nutzt kostenpflichtige Dienste mit sehr hohem Budget. 🤯 \\(\\square\\)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#wrapper-um-curl",
    "href": "130-chatgpt.html#wrapper-um-curl",
    "title": "\n18  ChatGPT-API\n",
    "section": "\n18.3 Wrapper um curl",
    "text": "18.3 Wrapper um curl\nDieser Abschnitt basiert auf einem Blogpost bei R-Bloggers von Rasmus Bååth.\n\nresponse &lt;- POST(\n  # curl https://api.openai.com/v1/chat/completions \n  url = \"https://api.openai.com/v1/chat/completions\", \n  # -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  add_headers(Authorization = \n                paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\"))),\n  # -H \"Content-Type: application/json\"\n  content_type_json(),\n  # -d '{\n  #   \"model\": \"gpt-3.5-turbo\",\n  #   \"messages\": [{\"role\": \"user\", \"content\": \"What is a banana?\"}] \n  # }'\n  encode = \"json\",\n  body = list(\n    model = \"gpt-3.5-turbo\",\n    messages = list(list(role = \"user\", content = prompts[1]))\n  ))\n\n\ncontent(response)\n\n$object\n[1] \"chat.completion\"\n\n$created\n[1] 1700753610\n\n$model\n[1] \"gpt-3.5-turbo-0613\"\n\n$choices\n$choices[[1]]\n$choices[[1]]$index\n[1] 0\n\n$choices[[1]]$message\n$choices[[1]]$message$role\n[1] \"assistant\"\n\n$choices[[1]]$message$content\n[1] \"Das Sentiment dieses Tweets ist positiv. \"\n\n$choices[[1]]$finish_reason\n[1] \"stop\"\n\n$usage\n$usage$prompt_tokens\n[1] 76\n\n$usage$completion_tokens\n[1] 10\n\n$usage$total_tokens\n[1] 86\nDer für uns entscheidende Punkt ist:\n\nstr_trim(content(response)$choices[[1]]$message$content)\n\nDas Sentiment dieses Tweets ist positiv. \n\n18.3.1 Curl-Wrapper in eine Funktion gebracht\n\nask_chatgpt &lt;- function(prompt) {\nresponse &lt;- POST(\n  # curl https://api.openai.com/v1/chat/completions \n  url = \"https://api.openai.com/v1/chat/completions\", \n  # -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  add_headers(Authorization = \n                paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\"))),\n  # -H \"Content-Type: application/json\"\n  content_type_json(),\n  # -d '{\n  #   \"model\": \"gpt-3.5-turbo\",\n  #   \"messages\": [{\"role\": \"user\", \"content\": \"What is a banana?\"}] \n  # }'\n  encode = \"json\",\n  body = list(\n    model = \"gpt-3.5-turbo\",\n    messages = list(list(role = \"user\", content = prompt))\n  ))\n  str_trim(content(response)$choices[[1]]$message$content)\n}\n\n\n18.3.2 Schleife\n\nprompts |&gt; \n  sapply(ask_chatgpt)\n\nNach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @corinnamilborn Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar? \n\n\"positiv\" \n \nNach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir. \n\n \"neutral\"",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#vertiefung",
    "href": "130-chatgpt.html#vertiefung",
    "title": "\n18  ChatGPT-API\n",
    "section": "\n18.4 Vertiefung",
    "text": "18.4 Vertiefung\nMit etwas Zusatzaufwand kann man den Kontext bzw. den Verlauf der Konversation mit dem Bot berücksichtigen, wie dieser Post zeigt.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#aufgaben",
    "href": "130-chatgpt.html#aufgaben",
    "title": "\n18  ChatGPT-API\n",
    "section": "\n18.5 Aufgaben",
    "text": "18.5 Aufgaben\nSchauen Sie sich die Aufgaben mit dem Tag ‘Transformer’ auf dem Datenwerk an.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#pipeline-management",
    "href": "200-projektmgt.html#pipeline-management",
    "title": "\n19  Projektmanagement\n",
    "section": "\n19.1 Pipeline-Management",
    "text": "19.1 Pipeline-Management\n\n19.1.1 Am Anfang\nSie haben Großes vor! Naja, zumindest planen Sie ein neues Data-Science-Projekt.\nUnd, schlau wie Sie sind, stürzen Sie nicht sofort an die Tastatur, um sich einige Modelle berechnen zu lassen. Nein! Sie denken erst einmal nach. Zum Beispiel, wie die einzelnen Analyseschritte aussehen, worin sie bestehen, und in welcher Abfolge sie zu berechnen sind, s. Abbildung 19.1.\n\n\n\n\n\nAbbildung 19.1: So könnte Ihr Projektplan am Anfang aussehen, man spricht auch von einer Pipeline\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDen Graph der einzelnen Analyseschritte in ihrer Abhängigkeit bezeichnet man als *Pipeline.\n\n\n\n19.1.2 Sie träumen von einem Werkzeug\nNach einiger Zeit überlegen Sie sich, dass Sie ein System bräuchten, das Ihre Skizze umsetzt in tatsächliche Berechnungen. Und zwar suchen Sie ein Projektmanagement-System das folgendes Desiderata erfüllt:\n\nEs führt die einzelnen Schritte Ihres Projekt, die “Pipeline” in der richtigen Reihenfolge\nEs aktualisiert veraltete Objekte, aber es berechnet nicht Modelle neu, die unverändert sind\nEs ist gut zu debuggen\n\nJa, von so einem Werkzeug träumen Sie.\nUnd tatsächlich, Ihr Traum geht in Erfüllung. Dieses System existiert. Genau genommen gibt es viele Systeme, die sich anschicken, Ihre Wünsche zu erfüllen. Wir schauen uns eines näher an, das speziell für R gemacht ist. Das R-Paket targets.\n\n19.1.3 Targets\nEs lohnt sich, an dieser Stelle den “Walkthrough” aus dem Benutzerhandbuch von Targets durchzuarbeiten.\nFür ein Projekt ähnlich zu den, die wir in diesem Buch bearbeiten, ist folgende _targets.R-Datei ein guter Start.\n\nlibrary(targets)\n\n\n# Funktionen einlesen:\n#purrr::walk(list.files(path = \"funs\", pattern = \".R\", full.names = TRUE), source)\nsource(\"funs/def-recipe.R\")\nsource(\"funs/read-train-data.R\")\nsource(\"funs/read-test-data.R\")\n\n# Optionen, z.B. allgemein verfügbare Pakete in den Targets:tar_option_set(packages = c(\"readr\", \n                            \"dplyr\", \n                            \"ggplot2\", \n                            \"purrr\", \n                            \"easystats\", \n                            \"tidymodels\", \n                            \"textrecipes\"))\n\n# Definition der Pipeline:\nlist(\n  tar_target(data_train, read_train_data()),\n  tar_target(data_test, read_test_data()),\n  tar_target(recipe1, def_recipe(data_train)\n  ),\n  tar_target(model1,\n             logistic_reg(penalty = tune(), mixture = 1) %&gt;%\n               set_mode(\"classification\") %&gt;%\n               set_engine(\"glmnet\")\n             ),\n  tar_target(workflow1,\n             workflow() %&gt;% add_recipe(recipe1) %&gt;% add_model(model1)\n             ),\n  tar_target(grid1,\n             grid_regular(penalty(), levels = 3)\n             ),\n  tar_target(grid_fitted,\n             tune_grid(workflow1, \n                       resamples = vfold_cv(data_train, v = 2),\n                       grid = grid1)\n  ),\n  tar_target(best_hyperparams,\n             select_by_one_std_err(grid_fitted, metric = \"roc_auc\", penalty)\n             ),\n  tar_target(fit1,\n             workflow1 %&gt;% finalize_workflow(best_hyperparams) %&gt;% fit(data_train)),\n  tar_target(preds,\n             fit1 %&gt;% \n               predict(data_test) %&gt;% \n               bind_cols(data_test) %&gt;% \n               mutate(c1 = factor(c1))),\n  tar_target(metrics1,\n             preds %&gt;% metrics(truth = c1, .pred_class))\n)\n\nDann kann man auf den Play-Button drücken und die ganze Pipeline wird berechnet:\n\ntar_make()\n\nWenn die Pipeline aktuell ist, und nichts berechnet werden muss (und daher auch schon fehlerfrei durchgelaufen ist), sieht die Ausgabe so aus:\n✔ skip target grid1\n✔ skip target model1\n✔ skip target data_train\n✔ skip target data_test\n✔ skip target recipe1\n✔ skip target workflow1\n✔ skip target grid_fitted\n✔ skip target best_hyperparams\n✔ skip target fit1\n✔ skip target preds\n✔ skip target metrics1\n✔ skip pipeline [0.121 seconds]\nDie Pipeline kann man sich als DAG bzw. als Abhängigkeitsgraph visualisieren lassen:\n\ntar_visnetwork()\n\n\n\nAbhängigkeitsgraph der Pipeline\n\nEinzelne Objekte kann man sich komfortabel anschauen mit tar_load(objekt), z.B. tar_load(fit1) usw.\n\n19.1.4 Eine Pipeline als Spielwiese\nDieses Github-Repo stellt Ihnen eine “Spielwiese” zur Verfügung, wo Sie sich mit Pipleines à la Targets vertraut machen können.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#zeit-sparen",
    "href": "200-projektmgt.html#zeit-sparen",
    "title": "\n19  Projektmanagement\n",
    "section": "\n19.2 Zeit sparen",
    "text": "19.2 Zeit sparen\nEiner Maschine etwas beizubringen kann dauern … Ein einfaches Rechenbeispiel dazu:\n\nSie haben eine Kreuzvalidierung mit 10 Faltungen\nund 3 Wiederholungen\nund 3 Tuningparameter\nmit je 10 Werten\n\nDas sind 1033*10=900 Wiederholungen.\nLeider haben Sie noch in den ersten 10 Versuchen jeweils einen Bug, so dass sich die Rechenzeit noch einmal um den Faktor 10 erhöht…\nDie Rechenzeit kann also schnell ins astronomische steigen. Es braucht also Methoden, um Rechenzeit zu sparen.1 Einige Methoden zum Rechenzeit sparen sind:\n\n\nCloud: Cloud-Dienste in Anspruch nehmen (faktisch mietet man damit schnelle Rechner)\n\nParallelisierung: Mehrere Kerne des eigenen Computers nutzen\n\nUpgrade: Kaufen Sie sich einen schnelleren Rechner…\n\nCleveres Grid-Search: Methoden wie ANOVA Racing können die Rechenzeit - was das Tuning - betrifft - deutlich verringern.\n\nDieser Post gibt einen Überblick zu Rechenzeiten bei verschiedenen Tuningparameter-Optionen mit Tidymodels.\nNatürlich ist die (mit Abstand) beste Methode: guten Code schreiben. Denn “guter Code” verringert die Wahrscheinlichkeit von Bugs, und damit die Gefahr, dass die ganze schöne Rechenzeit für die Katz war.\n“Guter Code” ist vielleicht primär von zwei Dingen abhängig: erstens einen guten Plan zu haben bevor man das Programmieren anfängt und zweitens gute Methoden des Projektmanagements. Hunt und Thomas (2000) präsentieren eine weithin anerkannte Umsetzung, was “guter” Code bedeuten könnte.\n\n\nQuelle: imgflip.com",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#publizieren",
    "href": "200-projektmgt.html#publizieren",
    "title": "\n19  Projektmanagement\n",
    "section": "\n19.3 Publizieren",
    "text": "19.3 Publizieren\nSie haben eine super Analyse geschrieben, eine schicke Pipeline, und jetzt soll die Welt davon erfahren? Es gibt einige komfortable Möglichkeiten, Ihre Arbeit zu publizieren, z.B. als Blog mit Quarto.\nDieses Video zeigt Ihnen wie man einen Quarto-Blog in RStudio erstellt und ihn bei Netlify publiziert.\n\nDas Hosten bzw. Deployen bei Netlify ist kostenlos (in der Basis-Variante).\nSie können alternativ Github Pages als Hosting-Dienst verwenden. Dieses Video gibt dazu eine Anleitung.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#komplexitätsmanagement",
    "href": "200-projektmgt.html#komplexitätsmanagement",
    "title": "\n19  Projektmanagement\n",
    "section": "\n19.4 Komplexitätsmanagement",
    "text": "19.4 Komplexitätsmanagement\nProgrammieren ist faszinierend. Vor allem, wenn das Programm funktioniert. Genau genommen ist es eigentlich nur dann faszinierend, ansonsten wird es anstrengend? aufregend? süchtig? faszinierend? nervig? Wie auch immer: Bugs treten auf und mit steigender Komplexität Ihrer Software steigen die Bugs nicht linear, sondern eher quadratisch oder gar exponentiell an.\nEs gibt viele Ansätze, sich gegen die Komplexität zu “wehren”. Der beste ist vielleicht: Die Software so einfach wie möglich zu halten - und nur so komplex wie nötig. Sozusagen: Das beste Feature ist das, das Sie nicht implementieren.\n\n19.4.1 Geben Sie gute Namen\nDaraus leitet sich ab, dass die zentralen Methoden, um der Fehler Herr zu werden im Komplexitätsmanagement liegen. Den Variablen (Objekten) “gute”, “sprechende”, aber prägnante Namen zu geben, ist in diesem Lichte auch als Komplexitätsmanagement (Reduktion) zu verstehen.\nEin typischer Fehler, der mir immer mal wieder passiert, ist: Ich ändere den Namen eines Objekts, aber vergesse, an allen Stellen im Code den Namen anzupassen. Glücklicherweise gibt es hier eine einfache Abhilfe: Replace-All.\nDer zwar einfache Weg, mehrere ähnliche Objekte durchzunummerieren (workflow2a, recipe1, …). ist zwar einfach, aber insgesamt nicht zu empfehlen: Es ist nicht leicht, immer genau zu wissen, was der Inhalt hinter der Nummer 2a etc. ist. Ändert man außerdem die Reihenfolge (oder schiebt ein Objekt dazwischen ein), macht die Nummerierung keinen Sinn mehr (oder man muss mühselig die Nummern ändern, was fehleranfällig und nervig ist).\n\n19.4.2 Portionieren\nEine andere, zentrale Maßnahme ist es, den Code in handlichen “Häppchen” zu verpacken. Statt einer Skriptdatei mit zich Tausend Zeilen, wünschen Sie sich doch sicher ein Skript der Art:\nmache_1()\nmache_2()\nmache_3()\ngratuliere_fertig()\nSchaut man dann in mache_1() rein, sieht man wiederum übersichtlichen Code.\nFunktionales Programmieren ist eine Umsetzung davon: Jedes Häppchen, jeder Schritt ist eine Funktion. Eine Funktion hat Input und Output; der Output ist dann der Input für die Funktion des nächsten Schrittes. targets ist eine Umsetzung dieser Idee.\n\n19.4.3 Debugging mit einem Logger\nWenn das Kind in dem Brunnen gefallen ist, hilft nur Heulen und Wehklagen Das Problem finden und lösen. Mit einem Logger kann man sich das Entwanzen, das Finden der Fehler, erleichtern. Ein Logger schreibt Zwischenschritte in eine Log-Datei.\nHier ist ein Beispiel mit dem futile Logger:. Mein Problem war, dass ich eine dynamische Aufgabe für eine Statistik-Klausur programmiert hatte, aber leider gab es einen Bug, den ich nicht gefunden habe2.\nDie Lösung brachte ein Logger, mit dem ich den Wert zentraler Variablen im Verlauf des Durchlaufens des Codes - bis eben der Laufzeitfehler aufkam3.\nHier ist ein Ausschnitt der Syntax. Zuerst initialisiert man den Logger mit einer Datei, hier exams.log. Neue Logging-Inhalte sollen an die bestehenden Logs angehängt werden (appender).\n\nlibrary(futile.logger)\nflog.appender(appender.file(\"/Users/sebastiansaueruser/github-repos/rexams-exams/exams.log\"))\n\nDann gebe ich eine Loggings vom Typ “Info” zum Protokoll:\n\nflog.info(paste0(\"Ex: post-uncertainty1\"))\nflog.info(msg = paste0(\"Data set: \", d_name))\nflog.info(paste0(\"Preds chosen: \", stringr::str_c(preds_chosen, collapse = \", \")))\nflog.info(paste0(\"Output var: \", av))\n\nDie Ergebnisse kann man dann in der Logging-Datei anschauen:\nNFO [2023-01-05 11:27:51] Rhats: 1.004503053029\nINFO [2023-01-05 11:27:51] Sol: 0.18\nINFO [2023-01-05 11:27:51] Sol typeof: double\nINFO [2023-01-05 11:27:52] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:52] Data set: tips\nINFO [2023-01-05 11:27:52] Preds chosen: size, total_bill\nINFO [2023-01-05 11:27:52] Output var: tip\nINFO [2023-01-05 11:27:53] Rhats: 0.999004883794722\nINFO [2023-01-05 11:27:53] Rhats: 1.00021605674421\nINFO [2023-01-05 11:27:53] Rhats: 1.00091357638756\nINFO [2023-01-05 11:27:53] Sol: 0.32\nINFO [2023-01-05 11:27:53] Sol typeof: double\nINFO [2023-01-05 11:27:54] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:54] Data set: TeachingRatings\nINFO [2023-01-05 11:27:54] Preds chosen: prof, beauty\nINFO [2023-01-05 11:27:54] Output var: eval\nINFO [2023-01-05 11:27:55] Rhats: 0.999060308710712\nINFO [2023-01-05 11:27:55] Rhats: 0.999032305267221\nINFO [2023-01-05 11:27:55] Rhats: 0.999229003550072\nINFO [2023-01-05 11:27:55] Sol: 0\nINFO [2023-01-05 11:27:55] Sol typeof: double\nINFO [2023-01-05 11:27:56] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:56] Data set: gtcars\nINFO [2023-01-05 11:27:56] Preds chosen: mpg_c, year\nINFO [2023-01-05 11:27:56] Output var: msrp\nINFO [2023-01-05 11:28:00] Rhats: 0.99913061005524\nINFO [2023-01-05 11:28:00] Rhats: 0.998999786100339\nINFO [2023-01-05 11:28:00] Rhats: 0.999130286784586\nINFO [2023-01-05 11:28:01] Sol: 21959.35\nINFO [2023-01-05 11:28:01] Sol typeof: double\nJa, das sieht nicht schön aus. Aber es brachte mir die Lösung: Mir fiel auf, dass der Fehler nur auftrat, wenn sol einen großen Wert hatte (1000 oder mehr). Danke, Logger!\n\n\n\n\nHunt, Andrew, und David Thomas. 2000. The Pragmatic Programmer from Journeyman to Master. Reading, Mass.: Addison-Wesley.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "300-fallstudien.html#quellen-für-textdaten",
    "href": "300-fallstudien.html#quellen-für-textdaten",
    "title": "20  Fallstudien",
    "section": "20.1 Quellen für Textdaten",
    "text": "20.1 Quellen für Textdaten\nDer MonkeyLearn Blog liefert eine Reihe von Quellen zu API, die Textdaten bereitstellen.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Fallstudien</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alkomah, Fatimah, and Xiaogang Ma. 2022. “A Literature\nReview of Textual Hate Speech Detection Methods and\nDatasets.” Information 13 (6, 6): 273. https://doi.org/10.3390/info13060273.\n\n\nAlmeida, Felipe, and Geraldo Xexéo. 2019. “Word\nEmbeddings: A Survey.” ArXiv,\nJanuary. https://www.semanticscholar.org/paper/Word-Embeddings%3A-A-Survey-Almeida-Xex%C3%A9o/e28e81a8cb6655aebb72357538f7b7a360366a29.\n\n\nBarry, Paul. 2017. Python von Kopf bis Fuß. Translated by\nJørgen W. Lang. Zweite Auflage. Von Kopf bis Fuß. Beijing Boston\nFarnham Sebastopol Tokyo: O’Reilly.\n\n\nCamacho-Collados, Jose, and Mohammad Taher Pilehvar. 2020.\n“Embeddings in Natural Language Processing.”\nIn Proceedings of the 28th International Conference on\nComputational Linguistics: Tutorial\nAbstracts, 10–15. Barcelona, Spain (Online):\nInternational Committee for Computational Linguistics. https://doi.org/10.18653/v1/2020.coling-tutorials.2.\n\n\nCastaño-Pulgarín, Sergio Andrés, Natalia Suárez-Betancur, Luz Magnolia\nTilano Vega, and Harvey Mauricio Herrera López. 2021. “Internet,\nSocial Media and Online Hate Speech. Systematic\nReview.” Aggression and Violent Behavior 58 (May):\n101608. https://doi.org/10.1016/j.avb.2021.101608.\n\n\nChollet, François. 2021. Deep Learning with\nPython. Second edition. Shelter Island,\nNY: Manning.\n\n\nChollet, François, Tomasz Kalinowski, and J. J. Allaire. 2022a. Deep\nLearning with R. Second edition. Shelter Island,\nNY: Manning.\n\n\n———. 2022b. Deep Learning with R. Second edition.\nShelter Island, NY: Manning Publications Co.\n\n\nDowney, Allen B. 2021. Think Python: systematisch programmieren\nlernen mit Python. Translated by Peter Klicman. 1. Auflage.\nHeidelberg: O’Reilly.\n\n\nGallatin, Kyle, and Chris Albon. 2023. Machine Learning with\nPython Cookbook: Practical Solutions from Preprocessing to\nDeep Learning. Beijing Boston Farnham Sebastopol\nTokyo: O’Reilly Media.\n\n\nGeorge, Alexandra. 2022. Python Text Mining: Perform Text\nProcessing, Word Embedding, Text Classification and Machine\nTranslation. Delhi: BPB Publications.\n\n\nGéron, Aurélien. 2023a. Hands-on Machine Learning with\nScikit-Learn, Keras, and\nTensorFlow: Concepts, Tools, and Techniques to Build\nIntelligent Systems. Third edition. Beijing Boston Farnham\nSebastopol Tokyo: O’Reilly.\n\n\n———. 2023b. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras\nund TensorFlow: Konzepte, Tools und Techniken für intelligente\nSysteme. Translated by Kristian Rother and Thomas Demmig. 3.,\naktualisierte und erweiterte Auflage. Heidelberg:\nO’Reilly.\n\n\n———. 2023c. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras\nund TensorFlow: Konzepte, Tools und Techniken für intelligente\nSysteme. Translated by Kristian Rother and Thomas Demmig. 3.,\naktualisierte und erweiterte Auflage. Heidelberg:\nO’Reilly.\n\n\nHunt, Andrew, and David Thomas. 2000. The Pragmatic Programmer from\nJourneyman to Master. Reading, Mass.:\nAddison-Wesley.\n\n\nHvitfeldt, Emil, and Julia Silge. 2021. Supervised Machine\nLearning for Text Analysis in R.\n1st ed. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nInden, Michael. 2023. Python lernen: kurz & gut. 1.\nAuflage. O’Reillys Taschenbibliothek. Heidelberg:\nO’Reilly.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2021. An Introduction to Statistical Learning: With Applications in\nR. Second edition. Springer Texts in Statistics.\nNew York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nKönig, Tim, Wolf J. Schünemann, Alexander Brand, Julian Freyberg, and\nMichael Gertz. 2022. “The EPINetz Twitter Politicians\nDataset 2021. A New Resource for the Study of the German\nTwittersphere and Its Application for the 2021 Federal\nElections.” Politische Vierteljahresschrift 63 (3):\n529–47. https://doi.org/10.1007/s11615-022-00405-7.\n\n\nKulkarni, Akshay, and Adarsha Shivananda. 2021. Natural Language\nProcessing Recipes: Unlocking Text Data with Machine Learning and Deep\nLearning Using Python. Second edition. New\nYork: Apress.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLex, Alexander, Nils Gehlenborg, Hendrik Strobelt, Romain Vuillemot, and\nHanspeter Pfister. 2014. “UpSet:\nVisualization of Intersecting Sets.” IEEE\nTransactions on Visualization and Computer Graphics 20 (12):\n1983–92. https://doi.org/10.1109/TVCG.2014.2346248.\n\n\nLiu, Zhiyuan, Yankai Lin, and Maosong Sun, eds. 2023. Representation\nLearning for Natural Language Processing.\nSingapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-1600-9.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013.\n“Efficient Estimation of Word\nRepresentations in Vector Space.” September\n6, 2013. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014.\n“GloVe: Global Vectors for Word\nRepresentation.” In Proceedings of the 2014 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), 1532–43. Doha, Qatar:\nAssociation for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.\n\n\nPilehvar, Mohammad Taher, and Jose Camacho-Collados. 2021.\nEmbeddings in Natural Language Processing:\nTheory and Advances in Vector\nRepresentations of Meaning. Synthesis\nLectures on Human Language Technologies.\nCham: Springer International Publishing. https://doi.org/10.1007/978-3-031-02177-0.\n\n\nRemus, Robert, Uwe Quasthoff, and Gerhard Heyer. 2010.\n“SentiWS - a Publicly Available German-Language\nResource for Sentiment Analysis.” Proceedings of the 7th\nInternational Language Ressources and Evaluation (LREC’10),\n1168–71.\n\n\nRhys, Hefin. 2020. Machine Learning with\nR, the Tidyverse, and Mlr. Shelter Island,\nNY: Manning publications.\n\n\nRisch, Julian, Anke Stoll, Lena Wilms, and Michael Wiegand. 2021.\n“Overview of the GermEval 2021 Shared Task on the\nIdentification of Toxic, Engaging, and Fact-Claiming Comments.”\nIn Proceedings of the GermEval 2021 Shared Task on the\nIdentification of Toxic, Engaging, and Fact-Claiming Comments,\n1–12. Duesseldorf, Germany: Association for\nComputational Linguistics. https://aclanthology.org/2021.germeval-1.1.\n\n\nRothman, Denis. 2022. Transformers for Natural Language Processing:\nBuild, Train, and Fine-Tune Deep Neural Network Architectures for\nNLP with Python, Hugging Face,\nand OpenAI´s GPT3, ChatGPT, and\nGPT-4. Second edition. Expert Insight.\nBirmingham Mumbai: Packt.\n\n\nShannon, C. E. 1948. “A Mathematical Theory of\nCommunication.” Bell System Technical Journal 27 (3):\n379–423. https://doi.org/10.1002/j.1538-7305.1948.tb01338.x.\n\n\nSiegel, Melanie, and Melpomeni Alexa. 2020. Sentiment-Analyse\ndeutschsprachiger Meinungsäußerungen: Grundlagen, Methoden und\npraktische Umsetzung. Wiesbaden: Springer\nFachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-29699-5.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with\nR: A Tidy Approach. First edition. Beijing ;\nBoston: O’Reilly. https://www.tidytextmining.com/.\n\n\nStone, James V. 2019. “Information Theory: A\nTutorial Introduction.” June 13, 2019. http://arxiv.org/abs/1802.05968.\n\n\nTunstall, Lewis, Leandro von Werra, Thomas Wolf, and Aurélien Géron.\n2022. Natural Language Processing with Transformers: Building\nLanguage Applications with Hugging Face. Revised edition.\nSebastopol: O’Reilly.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2023.\n“Attention Is All You Need.” August 1, 2023.\nhttps://doi.org/10.48550/arXiv.1706.03762.\n\n\nWickham, Hadley, and Garrett Grolemund. 2016. R for Data\nScience: Visualize, Model,\nTransform, Tidy, and Import\nData. O’Reilly Media. https://r4ds.had.co.nz/index.html.\n\n\nWiegand, Michael. 2019a. “GermEval-2018 Corpus\n(DE).” heiDATA. https://doi.org/10.11588/data/0B5VML.\n\n\n———. 2019b. “GermEval-2018 Corpus\n(DE).” heiDATA. https://doi.org/10.11588/data/0B5VML.\n\n\n———. 2019c. “GermEval-2018-Data-master.” In\nGermEval-2018 Corpus (DE).\nheiDATA. https://doi.org/10.11588/data/0B5VML/XIUWJ7.\n\n\n“Word Embeddings in NLP: A Complete\nGuide.” 2023. Turing. 2023. https://www.turing.com/kb/guide-on-word-embeddings-in-nlp.\n\n\nYamada, Ikuya, and Hiroyuki Shindo. 2019. “Neural Attentive\nBag-of-Entities Model for Text Classification.” In\nProceedings of the 23th SIGNLL Conference on\nComputational Natural Language Learning, 563–73. Association\nfor Computational Linguistics.",
    "crumbs": [
      "Abschluss",
      "References"
    ]
  }
]