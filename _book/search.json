[
  {
    "objectID": "125-fallstudie-keras1.html#lernsteuerung",
    "href": "125-fallstudie-keras1.html#lernsteuerung",
    "title": "\n16  Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.1 Lernsteuerung",
    "text": "16.1 Lernsteuerung\n\n16.1.1 Lernziele\nNach Abschluss dieses Kapitels …\n\nein einfaches neuronales Netzwerk mit Keras erstellen zur Klassifikation von Hate-Speech.\n\n16.1.2 Überblick\nIn diesem Kapitel nutzen wir grundlegende Methoden neuronaler Netze, um Hate-Speech vorherzusagen. Dabei findet der Datensatz GermEval Verwendung. Zunächst verwenden wir den schon aufbereiteten Datensatz, das macht es uns einfacher. Dieser aufbereitete Datensatz ist schon “numerisiert”1. Der Text der Tweets ist schon in numerische Prädiktoren umgewandelt. Dabei fanden einfache (deutschsprachige) Wordvektoren (wikipedia2vec) Verwendung. In diesem Kapitel arbeiten wir mit ausschließlich mit Python.\n\n16.1.3 Benötigte R-Pakete\n\n# keines :-)\n\n\n16.1.4 Python-Check\n\nreticulate::py_available()\n## [1] FALSE\nreticulate::py_config()\n## python:         /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/bin/python\n## libpython:      /Users/sebastiansaueruser/.pyenv/versions/3.8.16/lib/libpython3.8.dylib\n## pythonhome:     /Users/sebastiansaueruser/.virtualenvs/r-tensorflow:/Users/sebastiansaueruser/.virtualenvs/r-tensorflow\n## version:        3.8.16 (default, Sep 15 2023, 17:53:02)  [Clang 14.0.3 (clang-1403.0.22.14.1)]\n## numpy:          /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/lib/python3.8/site-packages/numpy\n## numpy_version:  1.24.3\n## \n## NOTE: Python version was forced by VIRTUAL_ENV\n\n\n16.1.5 Benötigte Python-Module\n\nimport keras\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import accuracy_score",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "125-fallstudie-keras1.html#pipeline-mit-1-hidden-layer",
    "href": "125-fallstudie-keras1.html#pipeline-mit-1-hidden-layer",
    "title": "\n16  Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.2 Pipeline mit 1 Hidden Layer",
    "text": "16.2 Pipeline mit 1 Hidden Layer\n\n16.2.1 Daten\n\nd_train_baked = pd.read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n\nd_train_num = d_train_baked.select_dtypes(include='number')\n\nd_train2 = d_train_baked.loc[:, \"emo_count\":\"wordembed_text_V101\"]\n\nX_train = d_train2.values\n\nd_train_baked[\"y\"] = d_train_baked[\"c1\"].map({\"OTHER\" : 0, \"OFFENSE\" : 1})\n\ny_train = d_train_baked.loc[:, \"y\"].values\n\nHead von y_train:\n\nprint(y_train[:6])\n## [0 0 0 0 1 0]\n\nInfo zum Objekt:\n\nd_train2.info()\n## &lt;class 'pandas.core.frame.DataFrame'&gt;\n## RangeIndex: 5009 entries, 0 to 5008\n## Columns: 119 entries, emo_count to wordembed_text_V101\n## dtypes: float64(119)\n## memory usage: 4.5 MB\n\nHead von y_train2:\n\nprint(d_train2.head())\n##    emo_count  schimpf_count  ...  wordembed_text_V100  wordembed_text_V101\n## 0   0.574594      -0.450067  ...            -0.449265            -0.277801\n## 1  -1.111107      -0.450067  ...             0.974438             0.223422\n## 2   0.186402      -0.450067  ...             0.407285             0.470835\n## 3   0.201551      -0.450067  ...            -0.681155             0.351565\n## 4   0.168223      -0.450067  ...            -0.674108             0.543312\n## \n## [5 rows x 119 columns]\n\n\nd_test_baked = pd.read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")\n\nd_test_num = d_test_baked.select_dtypes(include='number')\n\nd_test2 = d_test_baked.loc[:, \"emo_count\":\"wordembed_text_V101\"]\n\nX_test = d_test2.values\n\n\nd_test_baked[\"y\"] = d_test_baked[\"c1\"].map({\"OTHER\" : 0, \"OFFENSE\" : 1})\n\ny_test = d_test_baked.loc[:, \"y\"].values\n\n\nprint(y_test[:5])\n## [0 0 0 0 1]\n\n\n16.2.2 Modeldefinition\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n\n16.2.3 Fit\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n## Epoch 1/10\n## \n 1/79 [..............................] - ETA: 57s - loss: 0.9031 - accuracy: 0.4688\n32/79 [===========&gt;..................] - ETA: 0s - loss: 0.7415 - accuracy: 0.5435 \n66/79 [========================&gt;.....] - ETA: 0s - loss: 0.6537 - accuracy: 0.6264\n79/79 [==============================] - 1s 5ms/step - loss: 0.6366 - accuracy: 0.6396 - val_loss: 0.5578 - val_accuracy: 0.7166\n## Epoch 2/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.5155 - accuracy: 0.7969\n36/79 [============&gt;.................] - ETA: 0s - loss: 0.5192 - accuracy: 0.7374\n70/79 [=========================&gt;....] - ETA: 0s - loss: 0.5059 - accuracy: 0.7473\n79/79 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7479 - val_loss: 0.5491 - val_accuracy: 0.7262\n## Epoch 3/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.5058 - accuracy: 0.7344\n36/79 [============&gt;.................] - ETA: 0s - loss: 0.4703 - accuracy: 0.7726\n71/79 [=========================&gt;....] - ETA: 0s - loss: 0.4771 - accuracy: 0.7658\n79/79 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7678 - val_loss: 0.5540 - val_accuracy: 0.7273\n## Epoch 4/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.4064 - accuracy: 0.7969\n36/79 [============&gt;.................] - ETA: 0s - loss: 0.4464 - accuracy: 0.7860\n73/79 [==========================&gt;...] - ETA: 0s - loss: 0.4523 - accuracy: 0.7815\n79/79 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7820 - val_loss: 0.5623 - val_accuracy: 0.7240\n## Epoch 5/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.3533 - accuracy: 0.8438\n35/79 [============&gt;.................] - ETA: 0s - loss: 0.4413 - accuracy: 0.7915\n71/79 [=========================&gt;....] - ETA: 0s - loss: 0.4400 - accuracy: 0.7931\n79/79 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7944 - val_loss: 0.5607 - val_accuracy: 0.7248\n## Epoch 6/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.3845 - accuracy: 0.8281\n34/79 [===========&gt;..................] - ETA: 0s - loss: 0.4141 - accuracy: 0.8051\n70/79 [=========================&gt;....] - ETA: 0s - loss: 0.4201 - accuracy: 0.7998\n79/79 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7978 - val_loss: 0.5656 - val_accuracy: 0.7251\n## Epoch 7/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.4457 - accuracy: 0.7812\n24/79 [========&gt;.....................] - ETA: 0s - loss: 0.4157 - accuracy: 0.8027\n57/79 [====================&gt;.........] - ETA: 0s - loss: 0.4115 - accuracy: 0.8062\n79/79 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8065 - val_loss: 0.5689 - val_accuracy: 0.7282\n## Epoch 8/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.3460 - accuracy: 0.8906\n32/79 [===========&gt;..................] - ETA: 0s - loss: 0.3959 - accuracy: 0.8184\n67/79 [========================&gt;.....] - ETA: 0s - loss: 0.3945 - accuracy: 0.8190\n79/79 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8169 - val_loss: 0.5731 - val_accuracy: 0.7268\n## Epoch 9/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.4085 - accuracy: 0.7969\n21/79 [======&gt;.......................] - ETA: 0s - loss: 0.3617 - accuracy: 0.8549\n49/79 [=================&gt;............] - ETA: 0s - loss: 0.3765 - accuracy: 0.8339\n76/79 [===========================&gt;..] - ETA: 0s - loss: 0.3832 - accuracy: 0.8283\n79/79 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8271 - val_loss: 0.5836 - val_accuracy: 0.7268\n## Epoch 10/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.2995 - accuracy: 0.8906\n26/79 [========&gt;.....................] - ETA: 0s - loss: 0.3683 - accuracy: 0.8335\n52/79 [==================&gt;...........] - ETA: 0s - loss: 0.3717 - accuracy: 0.8287\n78/79 [============================&gt;.] - ETA: 0s - loss: 0.3725 - accuracy: 0.8305\n79/79 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8305 - val_loss: 0.5840 - val_accuracy: 0.7265\n## &lt;keras.src.callbacks.History object at 0x137a43ac0&gt;\n\n\n16.2.4 Fazit\nSchon mit diesem einfachen Netzwerk, das sich schnell berechnen lässt, übertreffen wir auf Anhieb die Modellgüte (Gesamtgenauigkeit) der Shallow-Learners aus früheren Kapiteln.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "125-fallstudie-keras1.html#pipeline-mit-2-hidden-layers",
    "href": "125-fallstudie-keras1.html#pipeline-mit-2-hidden-layers",
    "title": "\n16  Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.3 Pipeline mit 2 Hidden Layers",
    "text": "16.3 Pipeline mit 2 Hidden Layers\nWir verwenden die gleichen Daten wie oben.\nWir fügen eine zweite Hidden Layer hinzu. Außerdem verändern wir die Batch-Size.\n\n16.3.1 Modeldefinition\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(units=32, activation='relu'))  # Second hidden layer\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n\n16.3.2 Fit\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=8, validation_data=(X_test, y_test))\n## Epoch 1/10\n## \n  1/627 [..............................] - ETA: 8:54 - loss: 0.6587 - accuracy: 0.5000\n 28/627 [&gt;.............................] - ETA: 1s - loss: 0.6542 - accuracy: 0.6384  \n 56/627 [=&gt;............................] - ETA: 1s - loss: 0.6259 - accuracy: 0.6562\n 86/627 [===&gt;..........................] - ETA: 0s - loss: 0.6204 - accuracy: 0.6570\n119/627 [====&gt;.........................] - ETA: 0s - loss: 0.6080 - accuracy: 0.6691\n153/627 [======&gt;.......................] - ETA: 0s - loss: 0.6012 - accuracy: 0.6748\n189/627 [========&gt;.....................] - ETA: 0s - loss: 0.5924 - accuracy: 0.6779\n224/627 [=========&gt;....................] - ETA: 0s - loss: 0.5813 - accuracy: 0.6864\n255/627 [===========&gt;..................] - ETA: 0s - loss: 0.5744 - accuracy: 0.6926\n291/627 [============&gt;.................] - ETA: 0s - loss: 0.5744 - accuracy: 0.6942\n327/627 [==============&gt;...............] - ETA: 0s - loss: 0.5726 - accuracy: 0.6957\n332/627 [==============&gt;...............] - ETA: 0s - loss: 0.5713 - accuracy: 0.6969\n366/627 [================&gt;.............] - ETA: 0s - loss: 0.5658 - accuracy: 0.7018\n401/627 [==================&gt;...........] - ETA: 0s - loss: 0.5634 - accuracy: 0.7042\n438/627 [===================&gt;..........] - ETA: 0s - loss: 0.5616 - accuracy: 0.7072\n473/627 [=====================&gt;........] - ETA: 0s - loss: 0.5554 - accuracy: 0.7106\n509/627 [=======================&gt;......] - ETA: 0s - loss: 0.5552 - accuracy: 0.7110\n545/627 [=========================&gt;....] - ETA: 0s - loss: 0.5522 - accuracy: 0.7149\n582/627 [==========================&gt;...] - ETA: 0s - loss: 0.5497 - accuracy: 0.7174\n617/627 [============================&gt;.] - ETA: 0s - loss: 0.5499 - accuracy: 0.7180\n627/627 [==============================] - 3s 3ms/step - loss: 0.5477 - accuracy: 0.7181 - val_loss: 0.5593 - val_accuracy: 0.7214\n## Epoch 2/10\n## \n  1/627 [..............................] - ETA: 0s - loss: 0.1919 - accuracy: 1.0000\n 36/627 [&gt;.............................] - ETA: 0s - loss: 0.4186 - accuracy: 0.8194\n 71/627 [==&gt;...........................] - ETA: 0s - loss: 0.4415 - accuracy: 0.8046\n105/627 [====&gt;.........................] - ETA: 0s - loss: 0.4356 - accuracy: 0.8036\n141/627 [=====&gt;........................] - ETA: 0s - loss: 0.4379 - accuracy: 0.7979\n175/627 [=======&gt;......................] - ETA: 0s - loss: 0.4489 - accuracy: 0.7893\n211/627 [=========&gt;....................] - ETA: 0s - loss: 0.4469 - accuracy: 0.7885\n246/627 [==========&gt;...................] - ETA: 0s - loss: 0.4488 - accuracy: 0.7881\n282/627 [============&gt;.................] - ETA: 0s - loss: 0.4509 - accuracy: 0.7877\n317/627 [==============&gt;...............] - ETA: 0s - loss: 0.4441 - accuracy: 0.7898\n354/627 [===============&gt;..............] - ETA: 0s - loss: 0.4508 - accuracy: 0.7871\n389/627 [=================&gt;............] - ETA: 0s - loss: 0.4538 - accuracy: 0.7831\n425/627 [===================&gt;..........] - ETA: 0s - loss: 0.4540 - accuracy: 0.7815\n460/627 [=====================&gt;........] - ETA: 0s - loss: 0.4549 - accuracy: 0.7793\n491/627 [======================&gt;.......] - ETA: 0s - loss: 0.4589 - accuracy: 0.7777\n525/627 [========================&gt;.....] - ETA: 0s - loss: 0.4598 - accuracy: 0.7769\n561/627 [=========================&gt;....] - ETA: 0s - loss: 0.4598 - accuracy: 0.7790\n593/627 [===========================&gt;..] - ETA: 0s - loss: 0.4589 - accuracy: 0.7789\n623/627 [============================&gt;.] - ETA: 0s - loss: 0.4577 - accuracy: 0.7791\n627/627 [==============================] - 2s 3ms/step - loss: 0.4568 - accuracy: 0.7796 - val_loss: 0.5706 - val_accuracy: 0.7285\n## Epoch 3/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.4661 - accuracy: 0.5000\n 36/627 [&gt;.............................] - ETA: 0s - loss: 0.4126 - accuracy: 0.7847\n 70/627 [==&gt;...........................] - ETA: 0s - loss: 0.4173 - accuracy: 0.7929\n100/627 [===&gt;..........................] - ETA: 0s - loss: 0.4206 - accuracy: 0.8025\n132/627 [=====&gt;........................] - ETA: 0s - loss: 0.4117 - accuracy: 0.8078\n167/627 [======&gt;.......................] - ETA: 0s - loss: 0.4155 - accuracy: 0.8046\n202/627 [========&gt;.....................] - ETA: 0s - loss: 0.4129 - accuracy: 0.8069\n233/627 [==========&gt;...................] - ETA: 0s - loss: 0.4146 - accuracy: 0.8063\n267/627 [===========&gt;..................] - ETA: 0s - loss: 0.4173 - accuracy: 0.8034\n298/627 [=============&gt;................] - ETA: 0s - loss: 0.4177 - accuracy: 0.8054\n326/627 [==============&gt;...............] - ETA: 0s - loss: 0.4154 - accuracy: 0.8067\n357/627 [================&gt;.............] - ETA: 0s - loss: 0.4143 - accuracy: 0.8074\n380/627 [=================&gt;............] - ETA: 0s - loss: 0.4139 - accuracy: 0.8076\n407/627 [==================&gt;...........] - ETA: 0s - loss: 0.4154 - accuracy: 0.8050\n428/627 [===================&gt;..........] - ETA: 0s - loss: 0.4137 - accuracy: 0.8055\n458/627 [====================&gt;.........] - ETA: 0s - loss: 0.4140 - accuracy: 0.8051\n489/627 [======================&gt;.......] - ETA: 0s - loss: 0.4164 - accuracy: 0.8037\n517/627 [=======================&gt;......] - ETA: 0s - loss: 0.4159 - accuracy: 0.8044\n548/627 [=========================&gt;....] - ETA: 0s - loss: 0.4174 - accuracy: 0.8043\n574/627 [==========================&gt;...] - ETA: 0s - loss: 0.4170 - accuracy: 0.8051\n600/627 [===========================&gt;..] - ETA: 0s - loss: 0.4162 - accuracy: 0.8067\n626/627 [============================&gt;.] - ETA: 0s - loss: 0.4140 - accuracy: 0.8075\n627/627 [==============================] - 2s 3ms/step - loss: 0.4140 - accuracy: 0.8075 - val_loss: 0.6027 - val_accuracy: 0.7248\n## Epoch 4/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.3053 - accuracy: 0.7500\n 32/627 [&gt;.............................] - ETA: 0s - loss: 0.3231 - accuracy: 0.8672\n 62/627 [=&gt;............................] - ETA: 0s - loss: 0.3515 - accuracy: 0.8407\n 93/627 [===&gt;..........................] - ETA: 0s - loss: 0.3484 - accuracy: 0.8562\n120/627 [====&gt;.........................] - ETA: 0s - loss: 0.3372 - accuracy: 0.8583\n153/627 [======&gt;.......................] - ETA: 0s - loss: 0.3312 - accuracy: 0.8603\n183/627 [=======&gt;......................] - ETA: 0s - loss: 0.3439 - accuracy: 0.8518\n212/627 [=========&gt;....................] - ETA: 0s - loss: 0.3443 - accuracy: 0.8532\n226/627 [=========&gt;....................] - ETA: 0s - loss: 0.3461 - accuracy: 0.8507\n245/627 [==========&gt;...................] - ETA: 0s - loss: 0.3511 - accuracy: 0.8495\n269/627 [===========&gt;..................] - ETA: 0s - loss: 0.3523 - accuracy: 0.8494\n288/627 [============&gt;.................] - ETA: 0s - loss: 0.3567 - accuracy: 0.8455\n317/627 [==============&gt;...............] - ETA: 0s - loss: 0.3589 - accuracy: 0.8442\n346/627 [===============&gt;..............] - ETA: 0s - loss: 0.3659 - accuracy: 0.8396\n376/627 [================&gt;.............] - ETA: 0s - loss: 0.3672 - accuracy: 0.8371\n397/627 [=================&gt;............] - ETA: 0s - loss: 0.3673 - accuracy: 0.8369\n425/627 [===================&gt;..........] - ETA: 0s - loss: 0.3697 - accuracy: 0.8350\n447/627 [====================&gt;.........] - ETA: 0s - loss: 0.3711 - accuracy: 0.8353\n467/627 [=====================&gt;........] - ETA: 0s - loss: 0.3726 - accuracy: 0.8362\n492/627 [======================&gt;.......] - ETA: 0s - loss: 0.3726 - accuracy: 0.8364\n511/627 [=======================&gt;......] - ETA: 0s - loss: 0.3726 - accuracy: 0.8371\n537/627 [========================&gt;.....] - ETA: 0s - loss: 0.3756 - accuracy: 0.8350\n568/627 [==========================&gt;...] - ETA: 0s - loss: 0.3755 - accuracy: 0.8343\n595/627 [===========================&gt;..] - ETA: 0s - loss: 0.3756 - accuracy: 0.8334\n622/627 [============================&gt;.] - ETA: 0s - loss: 0.3751 - accuracy: 0.8336\n627/627 [==============================] - 2s 3ms/step - loss: 0.3753 - accuracy: 0.8333 - val_loss: 0.6474 - val_accuracy: 0.7101\n## Epoch 5/10\n## \n  1/627 [..............................] - ETA: 0s - loss: 0.4109 - accuracy: 0.7500\n 37/627 [&gt;.............................] - ETA: 0s - loss: 0.3228 - accuracy: 0.8818\n 70/627 [==&gt;...........................] - ETA: 0s - loss: 0.3331 - accuracy: 0.8643\n106/627 [====&gt;.........................] - ETA: 0s - loss: 0.3080 - accuracy: 0.8774\n144/627 [=====&gt;........................] - ETA: 0s - loss: 0.3092 - accuracy: 0.8724\n180/627 [=======&gt;......................] - ETA: 0s - loss: 0.3196 - accuracy: 0.8611\n216/627 [=========&gt;....................] - ETA: 0s - loss: 0.3272 - accuracy: 0.8559\n247/627 [==========&gt;...................] - ETA: 0s - loss: 0.3281 - accuracy: 0.8548\n274/627 [============&gt;.................] - ETA: 0s - loss: 0.3275 - accuracy: 0.8540\n295/627 [=============&gt;................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8504\n314/627 [==============&gt;...............] - ETA: 0s - loss: 0.3297 - accuracy: 0.8527\n335/627 [===============&gt;..............] - ETA: 0s - loss: 0.3285 - accuracy: 0.8537\n365/627 [================&gt;.............] - ETA: 0s - loss: 0.3286 - accuracy: 0.8565\n393/627 [=================&gt;............] - ETA: 0s - loss: 0.3289 - accuracy: 0.8569\n423/627 [===================&gt;..........] - ETA: 0s - loss: 0.3304 - accuracy: 0.8561\n453/627 [====================&gt;.........] - ETA: 0s - loss: 0.3323 - accuracy: 0.8551\n482/627 [======================&gt;.......] - ETA: 0s - loss: 0.3368 - accuracy: 0.8527\n512/627 [=======================&gt;......] - ETA: 0s - loss: 0.3374 - accuracy: 0.8525\n547/627 [=========================&gt;....] - ETA: 0s - loss: 0.3359 - accuracy: 0.8544\n581/627 [==========================&gt;...] - ETA: 0s - loss: 0.3340 - accuracy: 0.8552\n617/627 [============================&gt;.] - ETA: 0s - loss: 0.3361 - accuracy: 0.8539\n627/627 [==============================] - 2s 2ms/step - loss: 0.3359 - accuracy: 0.8537 - val_loss: 0.6784 - val_accuracy: 0.7129\n## Epoch 6/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.1333 - accuracy: 1.0000\n 37/627 [&gt;.............................] - ETA: 0s - loss: 0.2734 - accuracy: 0.8784\n 74/627 [==&gt;...........................] - ETA: 0s - loss: 0.2664 - accuracy: 0.8953\n108/627 [====&gt;.........................] - ETA: 0s - loss: 0.2676 - accuracy: 0.8831\n145/627 [=====&gt;........................] - ETA: 0s - loss: 0.2765 - accuracy: 0.8767\n182/627 [=======&gt;......................] - ETA: 0s - loss: 0.2808 - accuracy: 0.8805\n213/627 [=========&gt;....................] - ETA: 0s - loss: 0.2856 - accuracy: 0.8762\n248/627 [==========&gt;...................] - ETA: 0s - loss: 0.2890 - accuracy: 0.8755\n279/627 [============&gt;.................] - ETA: 0s - loss: 0.2914 - accuracy: 0.8768\n309/627 [=============&gt;................] - ETA: 0s - loss: 0.2889 - accuracy: 0.8786\n329/627 [==============&gt;...............] - ETA: 0s - loss: 0.2903 - accuracy: 0.8784\n347/627 [===============&gt;..............] - ETA: 0s - loss: 0.2896 - accuracy: 0.8779\n367/627 [================&gt;.............] - ETA: 0s - loss: 0.2911 - accuracy: 0.8764\n392/627 [=================&gt;............] - ETA: 0s - loss: 0.2906 - accuracy: 0.8753\n418/627 [===================&gt;..........] - ETA: 0s - loss: 0.2951 - accuracy: 0.8747\n447/627 [====================&gt;.........] - ETA: 0s - loss: 0.2958 - accuracy: 0.8753\n470/627 [=====================&gt;........] - ETA: 0s - loss: 0.2948 - accuracy: 0.8771\n501/627 [======================&gt;.......] - ETA: 0s - loss: 0.2992 - accuracy: 0.8743\n533/627 [========================&gt;.....] - ETA: 0s - loss: 0.2989 - accuracy: 0.8748\n570/627 [==========================&gt;...] - ETA: 0s - loss: 0.2995 - accuracy: 0.8750\n606/627 [===========================&gt;..] - ETA: 0s - loss: 0.2992 - accuracy: 0.8744\n627/627 [==============================] - 2s 3ms/step - loss: 0.2980 - accuracy: 0.8746 - val_loss: 0.6883 - val_accuracy: 0.7189\n## Epoch 7/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.2289 - accuracy: 1.0000\n 30/627 [&gt;.............................] - ETA: 1s - loss: 0.1825 - accuracy: 0.9583\n 57/627 [=&gt;............................] - ETA: 1s - loss: 0.1969 - accuracy: 0.9364\n 76/627 [==&gt;...........................] - ETA: 1s - loss: 0.1903 - accuracy: 0.9391\n101/627 [===&gt;..........................] - ETA: 1s - loss: 0.2084 - accuracy: 0.9295\n133/627 [=====&gt;........................] - ETA: 0s - loss: 0.2183 - accuracy: 0.9295\n158/627 [======&gt;.......................] - ETA: 0s - loss: 0.2289 - accuracy: 0.9217\n186/627 [=======&gt;......................] - ETA: 0s - loss: 0.2223 - accuracy: 0.9267\n213/627 [=========&gt;....................] - ETA: 0s - loss: 0.2283 - accuracy: 0.9255\n239/627 [==========&gt;...................] - ETA: 0s - loss: 0.2371 - accuracy: 0.9179\n270/627 [===========&gt;..................] - ETA: 0s - loss: 0.2388 - accuracy: 0.9171\n301/627 [=============&gt;................] - ETA: 0s - loss: 0.2454 - accuracy: 0.9128\n333/627 [==============&gt;...............] - ETA: 0s - loss: 0.2507 - accuracy: 0.9088\n365/627 [================&gt;.............] - ETA: 0s - loss: 0.2482 - accuracy: 0.9106\n396/627 [=================&gt;............] - ETA: 0s - loss: 0.2515 - accuracy: 0.9056\n426/627 [===================&gt;..........] - ETA: 0s - loss: 0.2526 - accuracy: 0.9040\n459/627 [====================&gt;.........] - ETA: 0s - loss: 0.2537 - accuracy: 0.9022\n490/627 [======================&gt;.......] - ETA: 0s - loss: 0.2545 - accuracy: 0.9003\n522/627 [=======================&gt;......] - ETA: 0s - loss: 0.2552 - accuracy: 0.8997\n553/627 [=========================&gt;....] - ETA: 0s - loss: 0.2553 - accuracy: 0.8996\n586/627 [===========================&gt;..] - ETA: 0s - loss: 0.2591 - accuracy: 0.8974\n620/627 [============================&gt;.] - ETA: 0s - loss: 0.2612 - accuracy: 0.8964\n627/627 [==============================] - 2s 2ms/step - loss: 0.2609 - accuracy: 0.8962 - val_loss: 0.7289 - val_accuracy: 0.7152\n## Epoch 8/10\n## \n  1/627 [..............................] - ETA: 0s - loss: 0.2016 - accuracy: 0.8750\n 39/627 [&gt;.............................] - ETA: 0s - loss: 0.1916 - accuracy: 0.9519\n 75/627 [==&gt;...........................] - ETA: 0s - loss: 0.2067 - accuracy: 0.9317\n109/627 [====&gt;.........................] - ETA: 0s - loss: 0.2097 - accuracy: 0.9255\n125/627 [====&gt;.........................] - ETA: 0s - loss: 0.2040 - accuracy: 0.9290\n142/627 [=====&gt;........................] - ETA: 0s - loss: 0.2028 - accuracy: 0.9278\n165/627 [======&gt;.......................] - ETA: 0s - loss: 0.2021 - accuracy: 0.9258\n190/627 [========&gt;.....................] - ETA: 0s - loss: 0.2058 - accuracy: 0.9257\n211/627 [=========&gt;....................] - ETA: 0s - loss: 0.2065 - accuracy: 0.9259\n234/627 [==========&gt;...................] - ETA: 0s - loss: 0.2115 - accuracy: 0.9252\n259/627 [===========&gt;..................] - ETA: 0s - loss: 0.2183 - accuracy: 0.9213\n283/627 [============&gt;.................] - ETA: 0s - loss: 0.2159 - accuracy: 0.9231\n308/627 [=============&gt;................] - ETA: 0s - loss: 0.2170 - accuracy: 0.9225\n331/627 [==============&gt;...............] - ETA: 0s - loss: 0.2183 - accuracy: 0.9226\n358/627 [================&gt;.............] - ETA: 0s - loss: 0.2184 - accuracy: 0.9214\n388/627 [=================&gt;............] - ETA: 0s - loss: 0.2218 - accuracy: 0.9188\n421/627 [===================&gt;..........] - ETA: 0s - loss: 0.2238 - accuracy: 0.9175\n455/627 [====================&gt;.........] - ETA: 0s - loss: 0.2256 - accuracy: 0.9170\n485/627 [======================&gt;.......] - ETA: 0s - loss: 0.2263 - accuracy: 0.9160\n512/627 [=======================&gt;......] - ETA: 0s - loss: 0.2263 - accuracy: 0.9155\n533/627 [========================&gt;.....] - ETA: 0s - loss: 0.2239 - accuracy: 0.9172\n557/627 [=========================&gt;....] - ETA: 0s - loss: 0.2243 - accuracy: 0.9165\n581/627 [==========================&gt;...] - ETA: 0s - loss: 0.2242 - accuracy: 0.9163\n610/627 [============================&gt;.] - ETA: 0s - loss: 0.2253 - accuracy: 0.9152\n627/627 [==============================] - 2s 3ms/step - loss: 0.2258 - accuracy: 0.9152 - val_loss: 0.8327 - val_accuracy: 0.6937\n## Epoch 9/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.1488 - accuracy: 1.0000\n 34/627 [&gt;.............................] - ETA: 0s - loss: 0.1648 - accuracy: 0.9706\n 59/627 [=&gt;............................] - ETA: 1s - loss: 0.1746 - accuracy: 0.9513\n 90/627 [===&gt;..........................] - ETA: 0s - loss: 0.1658 - accuracy: 0.9528\n110/627 [====&gt;.........................] - ETA: 0s - loss: 0.1710 - accuracy: 0.9477\n135/627 [=====&gt;........................] - ETA: 0s - loss: 0.1700 - accuracy: 0.9463\n170/627 [=======&gt;......................] - ETA: 0s - loss: 0.1739 - accuracy: 0.9426\n204/627 [========&gt;.....................] - ETA: 0s - loss: 0.1777 - accuracy: 0.9400\n240/627 [==========&gt;...................] - ETA: 0s - loss: 0.1774 - accuracy: 0.9406\n271/627 [===========&gt;..................] - ETA: 0s - loss: 0.1780 - accuracy: 0.9414\n304/627 [=============&gt;................] - ETA: 0s - loss: 0.1796 - accuracy: 0.9404\n335/627 [===============&gt;..............] - ETA: 0s - loss: 0.1770 - accuracy: 0.9410\n367/627 [================&gt;.............] - ETA: 0s - loss: 0.1786 - accuracy: 0.9390\n402/627 [==================&gt;...........] - ETA: 0s - loss: 0.1780 - accuracy: 0.9384\n434/627 [===================&gt;..........] - ETA: 0s - loss: 0.1828 - accuracy: 0.9335\n469/627 [=====================&gt;........] - ETA: 0s - loss: 0.1851 - accuracy: 0.9315\n500/627 [======================&gt;.......] - ETA: 0s - loss: 0.1865 - accuracy: 0.9310\n535/627 [========================&gt;.....] - ETA: 0s - loss: 0.1868 - accuracy: 0.9301\n568/627 [==========================&gt;...] - ETA: 0s - loss: 0.1894 - accuracy: 0.9294\n604/627 [===========================&gt;..] - ETA: 0s - loss: 0.1912 - accuracy: 0.9280\n627/627 [==============================] - 2s 3ms/step - loss: 0.1926 - accuracy: 0.9275 - val_loss: 0.8951 - val_accuracy: 0.7143\n## Epoch 10/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.4191 - accuracy: 0.7500\n 35/627 [&gt;.............................] - ETA: 0s - loss: 0.1559 - accuracy: 0.9536\n 63/627 [==&gt;...........................] - ETA: 0s - loss: 0.1439 - accuracy: 0.9643\n 99/627 [===&gt;..........................] - ETA: 0s - loss: 0.1418 - accuracy: 0.9646\n129/627 [=====&gt;........................] - ETA: 0s - loss: 0.1377 - accuracy: 0.9632\n164/627 [======&gt;.......................] - ETA: 0s - loss: 0.1360 - accuracy: 0.9604\n198/627 [========&gt;.....................] - ETA: 0s - loss: 0.1369 - accuracy: 0.9621\n231/627 [==========&gt;...................] - ETA: 0s - loss: 0.1409 - accuracy: 0.9605\n266/627 [===========&gt;..................] - ETA: 0s - loss: 0.1423 - accuracy: 0.9586\n303/627 [=============&gt;................] - ETA: 0s - loss: 0.1435 - accuracy: 0.9571\n340/627 [===============&gt;..............] - ETA: 0s - loss: 0.1466 - accuracy: 0.9555\n377/627 [=================&gt;............] - ETA: 0s - loss: 0.1508 - accuracy: 0.9532\n408/627 [==================&gt;...........] - ETA: 0s - loss: 0.1513 - accuracy: 0.9522\n444/627 [====================&gt;.........] - ETA: 0s - loss: 0.1544 - accuracy: 0.9507\n482/627 [======================&gt;.......] - ETA: 0s - loss: 0.1568 - accuracy: 0.9502\n516/627 [=======================&gt;......] - ETA: 0s - loss: 0.1575 - accuracy: 0.9494\n554/627 [=========================&gt;....] - ETA: 0s - loss: 0.1601 - accuracy: 0.9483\n590/627 [===========================&gt;..] - ETA: 0s - loss: 0.1594 - accuracy: 0.9481\n622/627 [============================&gt;.] - ETA: 0s - loss: 0.1589 - accuracy: 0.9488\n627/627 [==============================] - 1s 2ms/step - loss: 0.1596 - accuracy: 0.9483 - val_loss: 1.0364 - val_accuracy: 0.7044\n## &lt;keras.src.callbacks.History object at 0x13828df40&gt;\n\n\n16.3.3 Modellgüte\n\ny_pred = (model.predict(X_test) &gt; 0.5).astype(\"int32\")\n## \n  1/111 [..............................] - ETA: 10s\n 50/111 [============&gt;.................] - ETA: 0s \n107/111 [===========================&gt;..] - ETA: 0s\n111/111 [==============================] - 0s 951us/step\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test Accuracy: {accuracy}\")\n## Test Accuracy: 0.7044167610419027\n\n\n16.3.4 Fazit\nDie Modellgüte der 2. Pipeline ist etwas geringer als in der ersten. Die zweite Hidden-Layer muss also nicht zur Modellgüte positiv beitragen. Ähnliches gilt für die Batch-Size; wobei eigentlich kleine Batch-Sizes für diesen eher kleinen Datensatz sinnvoll sein sollten …",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "125-fallstudie-keras1.html#pipeline-mit-word-embedding",
    "href": "125-fallstudie-keras1.html#pipeline-mit-word-embedding",
    "title": "\n16  Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.4 Pipeline mit Word Embedding",
    "text": "16.4 Pipeline mit Word Embedding\nDiese Pipeline orientiert sich an diesem Beispiel von Tensorflow.\n\n16.4.1 Daten\n\nimport pandas as pd\n\ntrain_file_path = \"https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_train.csv\"\n\nd_train = pd.read_csv(train_file_path)\n\ntest_file_path = \"https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_test.csv\"\n\nd_test = pd.read_csv(test_file_path)\n\nPrädiktor-Dataframes als Arrays:\n\nX_train = d_train[\"text\"].values\n\nX_test = d_test[\"text\"].values\n\n\n16.4.2 Module\ntensorflow-hub ist übrigens NICHT mehr nötig. Das Paket ist jetzt Teil von tensorflow.\n\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "125-fallstudie-keras1.html#gpu",
    "href": "125-fallstudie-keras1.html#gpu",
    "title": "\n16  Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.5 GPU",
    "text": "16.5 GPU\nTesten, ob eine GPU verfügbar ist:\n\ntf.config.list_physical_devices('GPU') \n## []\n\n\nprint(\"TF Version: \", tf.__version__)\n## TF Version:  2.13.1\nprint(\"Eager mode: \", tf.executing_eagerly())\n## Eager mode:  True\nprint(\"Hub version: \", hub.__version__)\n## Hub version:  0.14.0\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n## GPU is NOT AVAILABLE\n\nTja, leider nein.\n\n16.5.1 Wort-Einbettungen\n\nembedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\nhub_layer = hub.KerasLayer(embedding, input_shape=[], \n                           dtype=tf.string, trainable=True)\n\n\n16.5.2 Modell\n\nmodel = tf.keras.Sequential()\nmodel.add(hub_layer)\nmodel.add(tf.keras.layers.Dense(16, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1))\n\nmodel.summary()\n## Model: \"sequential_2\"\n## _________________________________________________________________\n##  Layer (type)                Output Shape              Param #   \n## =================================================================\n##  keras_layer (KerasLayer)    (None, 50)                48190600  \n##                                                                  \n##  dense_5 (Dense)             (None, 16)                816       \n##                                                                  \n##  dense_6 (Dense)             (None, 1)                 17        \n##                                                                  \n## =================================================================\n## Total params: 48191433 (183.84 MB)\n## Trainable params: 48191433 (183.84 MB)\n## Non-trainable params: 0 (0.00 Byte)\n## _________________________________________________________________\n\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n\n16.5.3 Trainieren\n\nmodel.fit(X_train, y_train, \nepochs=10, \nbatch_size=8, \nvalidation_data=(X_test, y_test),\nverbose = 1)\n\nEpoch 1/10\n627/627 [==============================] - 490s 781ms/step - loss: 0.6232 - accuracy: 0.6638 - val_loss: 0.6093 - val_accuracy: 0.6628\nEpoch 2/10\n627/627 [==============================] - 477s 760ms/step - loss: 0.4541 - accuracy: 0.7686 - val_loss: 0.6536 - val_accuracy: 0.6761\nEpoch 3/10\n627/627 [==============================] - 482s 769ms/step - loss: 0.2762 - accuracy: 0.8794 - val_loss: 0.8118 - val_accuracy: 0.6526\nEpoch 4/10\n627/627 [==============================] - 521s 831ms/step - loss: 0.1671 - accuracy: 0.9367 - val_loss: 1.0416 - val_accuracy: 0.6467\nEpoch 5/10\n627/627 [==============================] - 456s 727ms/step - loss: 0.0936 - accuracy: 0.9689 - val_loss: 1.2981 - val_accuracy: 0.6486\nEpoch 6/10\n627/627 [==============================] - 455s 726ms/step - loss: 0.0478 - accuracy: 0.9872 - val_loss: 1.5631 - val_accuracy: 0.6297\nEpoch 7/10\n627/627 [==============================] - 456s 727ms/step - loss: 0.0240 - accuracy: 0.9954 - val_loss: 1.8281 - val_accuracy: 0.6285\nEpoch 8/10\n627/627 [==============================] - 455s 726ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 2.0636 - val_accuracy: 0.6334\nEpoch 9/10\n627/627 [==============================] - 459s 732ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 2.2470 - val_accuracy: 0.6291\nEpoch 10/10\n627/627 [==============================] - 455s 727ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 2.3786 - val_accuracy: 0.6277\n&lt;keras.src.callbacks.History object at 0x148309730&gt;\n```\n\n\n### Modellgüte\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny_pred = (model.predict(X_test) &gt; 0.5).astype(\"int32\")\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test Accuracy: {accuracy}\")\n```\n:::\n\n111/111 [==============================] - 17s 151ms/step Test Accuracy: 0.6276896942242356 ````\n\n16.5.4 Fazit\nNaja, dafür dass es englische Wortvektoren waren, gar nicht so schlecht 🤣",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#lernsteuerung",
    "href": "110-nn-theo1.html#lernsteuerung",
    "title": "\n15  Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.1 Lernsteuerung",
    "text": "15.1 Lernsteuerung\n\n15.1.1 Lernziele\nNach Abschluss dieses Kapitels …\n\nkönnen Sie die theoretischen Grundlagen eines einfachen neuronalen Netzwerks erklären.\n\n15.1.2 Überblick\nDieses Kapitel führt in die Grundlagen (einfacher) neuronaler Netze ein. Die Darstellung orientiert sich an James u. a. (2021). Viele der gezeigten Abbildungen stammen aus James u. a. (2021).1\n\n15.1.3 Benötigte R-Pakete\n\nlibrary(dplyr)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#netzwerke-mit-einer-einzelnen-zwischenschicht",
    "href": "110-nn-theo1.html#netzwerke-mit-einer-einzelnen-zwischenschicht",
    "title": "\n15  Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.2 Netzwerke mit einer einzelnen Zwischenschicht",
    "text": "15.2 Netzwerke mit einer einzelnen Zwischenschicht\nEin neuronales Netzwerk besteht auf\n\neinem Input-Vektor mit \\(p\\) Variablen \\(X=(X_1, X_2, \\ldots, X_p)\\)\n\neiner nicht-linearen Funktion \\(f(X)\\)\n\nsagt einen Output-Vektor \\(Y\\) vorher.\n\nAbbildung 15.1 zeigt ein einfaches sog. Feed-Forward-Neuronales-Netzwerk, um eine quantitative Output-Variable \\(Y\\) vorherzusagen anhand von 4 Prädiktoren. Das Netzwerk besteht aus drei “Schichten”, der Eingabeschicht (Input Layer), der Zwischenschicht (Hidden Layer) und der Ausgabeschicht (Output Layer). Jeder Kreis symbolisiert ein “Neuron”. In der Zwischenschicht in Abbildung 15.1 gibt es \\(K=5\\) Neuronen in der Zwischenschicht.\n\n\n\n\n\n\nKünstliche Neurone\n\n\n\nDie Idee der “Neurone” war namensgebend für Neuronale Netze. Ein biologisches Neuron gibt die Erregung (“feuert”) nur dann, wenn es über eine Schwelle erregt (aktiviert) wird. Analog sind “künstliche Neurone” in einem Neuronalen Netzwerk konzipiert. Sicherlich tun wir der gewaltigen Komplexität biologischer Neurone Unrecht, wenn wir die gedanklichen bescheidenen Einheiten künstlicher Neuronalen Netze auch als Neurone bezeichnen. Die (ursprüngliche ausschließlich vernendete) Logistische Funktion (mit sigmoiden Verlauf) setzt den “An-Aus-Mechanismen” biologischer Neurone um: Diese feuern nur oberhalb einer gewissen Aktivierung (und dann mit konstanter Stärke unabhängig von der Aktivierung).\\(\\square\\)\n\n\n\n\n\n\n\nAbbildung 15.1: Ein neuronales Netzwerk mit einer Zwischenschicht\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nEinfach gesprochen besteht ein neuronales Netzwerk aus einem System linearen Gleichungen, die aber jedes Mal noch durch eine einfache nicht-lineare Funktion gejagt werden. \\(\\square\\)\n\n\nEine häufige Wahl für \\(g\\) ist die ReLU-Funktion (rectified linear unit), die ähnlich zum sigmoiden Verlauf des logististischen Funktion ist, s. Abbildung 15.2.\n\n\n\n\n\nAbbildung 15.2: ReLU und sigmoide Funktion\n\n\nDieses Netzwerk (als Ganzes) hat folgende Struktur, s. Gleichung 15.1.\n\\[\\begin{align}\nf(X) &= \\beta_0 + \\sum_{k=1}^K \\beta_k h_k(X) \\\\\n     &= \\beta_0 + \\sum_{k=1}^K \\beta_k g(w_{k0} + \\sum_{j=1}^p w_{kj} X_j)\n\\end{align} \\tag{15.1}\\]\nJedes Neuron der Zwischenschicht erfährt eine Aktivierung (##eq-nn1-akt):\n\\[A_k = h_k(X) = g(w_{k0} + \\sum_{j=1}^p w_{kj} X_j) \\tag{15.2}\\]\nDie Aktivierung eines Neurons ähnelt einer multiplen Regression, nur dass “zum Schluss” noch die nicht-lineare Sahnehaube drauf kommt.\nWichtig ist, dass \\(g\\) eine nicht-lineare Funktion ist, denn sonst würde das ganze Netzwerk “nur” ein lineares Gleichungssystem sein. Die nicht-lineare Funktion erlaubt aber ein viel flexibleres Verhalten, als es einer linearen Funktion möglich wäre.\n“Fitten” eines neuronalen Netzwerk bedeutet, genau wie bei allen anderen Methoden des Maschinenlernens, die Parameter zu schätzen (berechnen). Wie bei jeder Methode des (überwachten) Maschinenlernen braucht es eine Fehlerfunktion, die minimiert wird. Für quantitative Y-Variablen wird zumeist die quadratische Fehlerfunktion verwendet, s. Gleichung 15.3.\n\\[\\sum_{i=1}^n(y_i - f(x_i)) \\tag{15.3}\\]",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#multilayer-netzwerke",
    "href": "110-nn-theo1.html#multilayer-netzwerke",
    "title": "\n15  Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.3 Multilayer-Netzwerke",
    "text": "15.3 Multilayer-Netzwerke\nNetzwerke mit mehreren Zwischenschichten bezeichnet man als Multi-Layer-Netzwerke. Theoretisch könnte ein Netzwerk mit nur einer Zwischenschicht, aber einer großen Zahl an Neuronen, fast alle denkbaren (oder zumindest sehr viele) Funktionen simulieren. Aber in der Praxis ist es einfacher, mehrere Schichten mit mittlerer Neuronen-Anzahl zu implementieren.\nAbbildung 15.3 zeigt ein Multilayer-Netzwerk, um die MNIST-Ziffern vorherzusagen. Im Gegensatz zu Abbildung 15.1 …\n\nbesitzt es zwei Zwischenschichten, \\(L_1\\) (256 Neurone) und \\(L_2\\) (128 Neurone).\nhat es 10 Ausgabe-Neurone in der Output-Layer, die den 10 Ziffern (0-9) entsprechen sollen.\n\n\n\n\n\n\nAbbildung 15.3: Multilayer-Netzwerk, um die MNIST-Ziffern vorherzusagen\n\n\nDie Aktivierung \\(A\\) der \\(k^{(1)}\\) Neurone in der ersten Zwischenschicht gleicht dem einfachen Netzwerk oben (vgl. Gleichung 15.1 und Gleichung 15.2), s. Gleichung 15.4:\n\\[\\begin{align}\nA_k^{(1)} &= h_k^{(1)}(X)\\\\\n          &= g(w_{k0}^{(1)} + \\sum_{j=1}^p w_{kj}^{(1)} X_j)\n\\end{align} \\tag{15.4}\\]\nfür alle \\(k_1, k_2, \\ldots, K_1\\) Neurone der ersten Zwischenschicht. Für die zweite Zwischenschicht, \\(L_2\\) gilt das analog: Die Aktivierung der Neurone der vorherigen Schicht werden als Input verwendet und auf dieser Basis wird die Aktivierung des jeweiligen Neurons der aktuellen Schicht berechnet, s. Gleichung 15.5:\n\\[\\begin{align}\nA_l^{(2)} &= h_l^{(2)}(X)\\\\\n          &= g(w_{l0}^{(2)} + \\sum_{j=2}^p w_{lj}^{(1)} X_j)\n\\end{align} \\tag{15.5}\\]\nfür alle \\(l = 1, 2, \\ldots, K2\\) Neurone der zweiten Zwischenschicht.\nDa sammeln sich schnell eine große Zahl an Parametern.\n\\(\\newcommand{\\matr}[1]{#1}\\)\n\\(\\matr{W_1}\\) in Abbildung 15.3 repräsentiert die Matrix mit allen (“Regressions”-)Gewichten (und “Intercepts”) on der Input-Layer zur ersten Zwischenschicht. Diese Matrix umfasst \\(785\\times256=200\\,960\\) Koeffizienten (785=784 “Regressions-”Gewichte plus 1 Intercept-Term, auch “Bias” genannt).\nEntsprechend weist jedes Neuron der zweiten Zwischenschicht ein Gewicht zu jedem Neuron der ersten Zwischenschicht auf. Daher hat \\(\\matr{W_2}\\) die Dimensionen \\(257 \\times 128 = 32\\,896\\).\nJetzt gelangen wir zur Output-Layer; dort gibt es 10 Ausgabe-Neuronen. Hier sind zwei Schritte nötig. Schritt 1 besteht darin für jedes der 10 Neurone ein lineares Modell zu berechnen, basierend auf den Gewichten der vorherigen Zwischenschicht:\n\\[\\begin{aligned}\nZ_m &= \\beta_{m0} +   \\sum_{l=1}^{K_2} \\beta_{ml} h_l^{(2)}(X) \\\\\n&= \\beta_{m0} +   \\sum_{l=1}^{K_2} \\beta_{ml} A_l^{(2)}\n\\end{aligned} \\tag{15.6}\\]\nmit \\(m = 0,1, \\ldots, 9\\). Diese \\(129 \\times 10 = 1290\\) Koeffizienten sind in der Matrix \\(\\matr{B}\\) gespeichert.\nSchritt 2 fehlt noch. Wir möchten ja, dass die Ausgabe für jede Ziffer in einer Wahrscheinlichkeit besteht, das kann man mit der Softmax-Aktivierung erreichen (Gleichung 15.7):\n\\[f_m(X) = Pr(Y=m|X) = \\frac{e^{Z_m}}{\\sum_{l=0}^9 e^{Z_l}}, \\tag{15.7}\\]\nmit \\(m=0,1, \\ldots, 9\\).\nDie zu minimierende Funktion (“Loss Function”) ist im Falle qualitativer Variablen keine metrische Quadratfunktion, sondern man miniert die Kreuzentropie, vgl. Gleichung 6.2.\nDas Netzwerk hat insgesamt über 200k Parameter! Und das bei gerade mal 60k Bildern. Wenn da das Modell keine Overfitting-Party macht, weiß ich auch nicht.\nGegenmaßnahmen zum Overfitting sind also dringend nötig, besonders bei neuronalen Netzwerken.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#mathematik-neuronaler-netzwerke",
    "href": "110-nn-theo1.html#mathematik-neuronaler-netzwerke",
    "title": "\n15  Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.4 Mathematik neuronaler Netzwerke",
    "text": "15.4 Mathematik neuronaler Netzwerke\nNeuronale Netzwerke basierend auf zwei Konzepte: Lineare Algebra und Ableiten (Infinitesimalrechnung).\n\n15.4.1 Punktprodukt\nIm YouTube-Kanal von 3b1b gibt es eine exzellente Einführung in die lineare Algebra.\nDie zentrale Operation ist das Dot Product (Skalar- oder Punktprodukt), s. Abbildung 15.5.\nIm einfachen Fall (der euklidischen Ebene) gilt:\n\\(\\vec a \\cdot \\vec b = \\begin{pmatrix} a_1 \\\\ a_2 \\end{pmatrix} \\cdot \\begin{pmatrix} b_1 \\\\ b_2 \\end{pmatrix} = a_1 b_1 + a_2 b_2.\\)\n\nBeispiel 15.1 (Einfaches Punktprodukt) Gegeben seien zwei Vektoren \\(\\vec x=(1,2,3)\\) und \\(\\vec y=(1,2,3)\\). Das Punktprodukt von \\(x\\) und \\(y\\) ist die Summe der Produkte der jeweilige Paare, s. Abbildung 15.4 (a).\n\\(\\vec x \\cdot \\vec y = 1\\cdot1 + 2\\cdot 2 + 3 \\cdot 3 = 1 +3+ 9 = 13. \\qquad \\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Schema des Punktprodukts\n\n\n\n\n\n\n\n\n\n(b) Mehrfaches Punktprodukt: Matrixmultiplikation\n\n\n\n\n\n\nAbbildung 15.4\n\n\nGeometrisch gesprochen entspricht das Punktprodukt dem Ausmaß, in dem zwei Vektoren in die gleiche Richtung zeigen:\n\n\n\n\nDie Vektoren zeigen in die gleiche Richtung: Maximales Punktprodukt (gleich dem Produkt der Vektorlängen)\n\n\n\n\nMinimales Punktprodukt (Null), da die Vektoren orthogonal zueinander stehen\n\n\n\n\nMittleres Punktprodukt, proportional zur Größe des Winkels \\(\\phi\\) und dem Produkt der Vektorlängen\n\n\n\nBildquelle: Martin Thoma, Wikipedia, CC-BY 3.0\n\n\n\n\n\n\nHinweis\n\n\n\nEine (etwas ausführlichere) geometrische Erklärung findet sich z.B. bei Math is Fun. Für Einsteiger interessant ist auch die Erklärung von Kalid Azad. Eine 3D-Darstellung von Vektoren findet sich hier. \\(\\square\\)\n\n\nIn R kann man das Punktprodukt mit dem %*%-Operator berechnen\n\nx &lt;- c(1,2,3)\ny &lt;- c(1,2,3)\n\ndot_xy &lt;- x %*% y\ndot_xy\n##      [,1]\n## [1,]   14\n\nIm Paket geometry gibt es alternativ eine entsprechende Funktion, dot:\n\ngeometry::dot(x, y)\n## [1] 14\n\n\nDefinition 15.1 (Punktprodukt) Das Produkt zweier Vektoren \\(\\mathbf{a}\\) und \\(\\mathbf{b}\\) ist so definiert, Gleichung 15.8. \\[{\\displaystyle \\mathbf {a} \\cdot \\mathbf {b} =\\sum _{i=1}^{n}a_{i}b_{i}=a_{1}b_{1}+a_{2}b_{2}+\\cdots +a_{n}b_{n}} \\qquad \\square \\tag{15.8}\\]\n\n\n15.4.2 Matrixmultiplikation\nMultiplizert man zwei Matrizen, so kann man das als mehrfaches Punktprodukt auffassen, s. Abbildung 15.5.\n\n\n\n\n\nAbbildung 15.5: Berechnung des Punktprodukts\n\n\n\n\n\n\n\n\nTipp\n\n\n\nProbieren Sie diesen Matrizenrechner aus zur Berechnung des Punktprodukts bzw. der Matrizenmultiplikation. \\(\\square\\)\n\n\n\n15.4.3 Regression als Matrixmultiplikation\nDie (einfache oder multiple) Regression kann man als Matrixmultiplikation auffassen. Schauen wir uns dazu ein einfaches Beispiel an.\nDer Datensatz d besteht auf einer Outcome-Variable, y sowie einem Prädiktor, x; drei Beobachtungen umfasst die Tabelle, s. Tabelle 15.1. Eine Regression mit einem Prädiktor hat zwei Koeffizienten, \\(\\beta_0, \\beta_1\\).\n\n\n\nd &lt;-\n  data.frame(\n    x = c(1, 2, 3),\n    y = c(1.1, 2.2, 2.9),\n    b0 = c(1,1,1)\n  )\n\nlm1 &lt;- lm(y ~ x, data = d)\n\n\n\n\n\nTabelle 15.1: Datensatz d\n\n\n\n\n\n\nx\ny\nb0\n\n\n\n1\n1.1\n1\n\n\n2\n2.2\n1\n\n\n3\n2.9\n1\n\n\n\n\n\n\n\n\n\n\n\nSpeichern wir uns die Modellkoeffizienten, \\(\\beta_0, \\beta_1\\) in einem Objekt \\(\\mathbf{\\beta}\\) ab:\n\nlm1_coefs &lt;- lm1$coefficients\nlm1_coefs\n## (Intercept)           x \n##   0.2666667   0.9000000\n\nDie vorhergesagten Werte des Modells, \\(\\matr{\\hat{Y}}\\)\n\npredict(lm1)\n##        1        2        3 \n## 1.166667 2.066667 2.966667\n\nJetzt bauen wir das Modell mit Matrixmultiplikation nach.\nDabei müssen wir für den Intercept eine Spalte mit nur 1 ergänzen und erhalten die Matrix für die X-Werte (pro Beobachtung), \\(\\matr{X}\\):\n\nx_matrix &lt;- d |&gt; \n  select(b0, x) |&gt; \n  as.matrix() \n\nx_matrix\n##      b0 x\n## [1,]  1 1\n## [2,]  1 2\n## [3,]  1 3\n\nDann multiplizieren wir die Matrix mit den X-Werten mit der Matrix (Vektor) mit den Modellkoeffizienten. So erhalten wir die vorhergesagten Y-Werte, $:\n\ny_pred &lt;- x_matrix %*% lm1_coefs\ny_pred \n##          [,1]\n## [1,] 1.166667\n## [2,] 2.066667\n## [3,] 2.966667\n\nIn Mathe-Sprech sieht das so aus:\n\\(y = \\beta_0 \\cdot 1 + \\beta_1 \\cdot x_1\\).\nIn Matrixschreibweise sieht das dann so aus:\n\\(\\matr{\\hat{Y}} = \\matr{X} \\cdot \\matr{\\matr{\\beta}}\\)\nAusgeschrieben als Gleichungssystem:\n\n\n\n\n\n\n\n\ny_hat\n\n\n\n1.17\n\n\n2.07\n\n\n2.97\n\n\n\n\n\n\n\n\\(=\\)\n\n\n\n\n\n\n\nb0\nx\n\n\n\n1\n1\n\n\n1\n2\n\n\n1\n3\n\n\n\n\n\n\n\n\\(\\cdot\\)\n\n\n\n\n\n\n\nbeta\n\n\n\n0.27\n\n\n0.90",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#b1b",
    "href": "110-nn-theo1.html#b1b",
    "title": "\n15  Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.5 3b1b",
    "text": "15.5 3b1b\nIm YouTube-Kanal von Grant Sanderson 3blue1brown gibt es eine exzellente Einführung (bestehend aus 4 Videos zu je ca. 15 Min.) in die Theorie der neuronalen Netze.\n\n15.5.1 Video 1\n\n\n15.5.2 Video 2\n\n\n15.5.3 Video 3\n\n\n15.5.4 Video 4\nAnspruchsvoller; mathematische Grundlagen von Backpropagation (parzielle Ableitung)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#vertiefung",
    "href": "110-nn-theo1.html#vertiefung",
    "title": "\n15  Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.6 Vertiefung",
    "text": "15.6 Vertiefung\nFrancois Chollet hat eine nützliche, zugängliche und (zum Einstieg) umfassende Anleitung zum Thema neuronale Netze mit R bzw. mit Python geschrieben (Chollet, Kalinowski, und Allaire 2022; Chollet 2021).\nEs finden sich viele weitere Lehrbücher für Einsteiger und Fortgeschrittene, z.B. Kulkarni und Shivananda (2021), Gallatin und Albon (2023). Bekannt ist auch Géron (2023). Der Großteil der entsprechenden Werke nutzt Python, nicht R.\nEine einsteigerfreundliche Anleitung zur Matrixmultiplikation findet sich bei Kalid Azad, betterexplained.com. Auf Wikipedia finden sich einige einsteigerfreundliche Illustrationen.\nDie Videos von vcubingx zum Thema Neuronale Netze sind empfehlenswert.\nSehr einsteigerfreundlich sind auch die Videos im YouTube-Kanal StatQuest. Der Autor Josh Starmer bieten einen großen Umfang an Themen aus dem Bereich Maschinenlernen.\n\n\n\n\nChollet, François. 2021. Deep Learning with Python. Second edition. Shelter Island, NY: Manning.\n\n\nChollet, François, Tomasz Kalinowski, und J. J. Allaire. 2022. Deep Learning with R. Second edition. Shelter Island, NY: Manning Publications Co.\n\n\nGallatin, Kyle, und Chris Albon. 2023. Machine Learning with Python Cookbook: Practical Solutions from Preprocessing to Deep Learning. Beijing Boston Farnham Sebastopol Tokyo: O’Reilly Media.\n\n\nGéron, Aurélien. 2023. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras und TensorFlow: Konzepte, Tools und Techniken für intelligente Systeme. Übersetzt von Kristian Rother und Thomas Demmig. 3., aktualisierte und erweiterte Auflage. Heidelberg: O’Reilly.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An Introduction to Statistical Learning: With Applications in R. Second edition. Springer Texts in Statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nKulkarni, Akshay, und Adarsha Shivananda. 2021. Natural Language Processing Recipes: Unlocking Text Data with Machine Learning and Deep Learning Using Python. Second edition. New York: Apress.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#vorab",
    "href": "120-transformer.html#vorab",
    "title": "\n17  Transformer\n",
    "section": "\n17.1 Vorab",
    "text": "17.1 Vorab\n\n17.1.1 Lernziele\n\nSie können die grundlegende Architektur eines Transformer-Modells beschreiben.\nSie können Transformer-Modelle mit der API von Hugging-Face berechnen.\n\n17.1.2 Begleitliteratur\nDer Blogpost von Jay Alammar gibt einen illustrierten Überblick über Transformer.\n\n17.1.3 Benötigte Software\nWir benötigen Python, R sowei einige im Folgenden aufgeführte Python-Module.\n\nimport pandas as pd\nimport os\n\nFür den Schüleraustausch von R nach Python nutzen wir das R-Paket reticulate:\n\nlibrary(reticulate)\n\nAußerdem starte ich die “richtige” Python-Version, wo die benötigten Pakete (in der richtigen Version) installiert sind:\n\n#use_virtualenv(\"r-tensorflow\")\n\nCheck:\n\npy_available()\n## [1] TRUE\n\nWelche Python-Version nutzt reticulate gerade?\n\npy_config()\n## python:         /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/bin/python\n## libpython:      /Users/sebastiansaueruser/.pyenv/versions/3.8.16/lib/libpython3.8.dylib\n## pythonhome:     /Users/sebastiansaueruser/.virtualenvs/r-tensorflow:/Users/sebastiansaueruser/.virtualenvs/r-tensorflow\n## version:        3.8.16 (default, Sep 15 2023, 17:53:02)  [Clang 14.0.3 (clang-1403.0.22.14.1)]\n## numpy:          /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/lib/python3.8/site-packages/numpy\n## numpy_version:  1.24.3\n## \n## NOTE: Python version was forced by VIRTUAL_ENV",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#überblick",
    "href": "120-transformer.html#überblick",
    "title": "\n17  Transformer\n",
    "section": "\n17.2 Überblick",
    "text": "17.2 Überblick\nTransformer sind eine Architekturvariante neuronaler Netze. Sie stellen die Grundlage vieler aktueller großer Sprachmodelle1; da sie einige Vorzüge gegenüber Vorgängermodellen aufweisen, haben sie einen zentralen Platz für verschiedenen Aufgaben des NLP eingenommen.\nIm Jahr 2017 erschien ein Paper auf Arxive mit dem Titel “Attention is all you need”, Vaswani u. a. (2023)2. Transformer basieren auf einer bestimmten Art von “Aufmerksamkeit”, genannt Selbst-Aufmerksamkeit (self-attention). Natürlich ist damit eine bestimmte Architektur im neuronalen Netzwerk gemeint, kein kognitivpsychologiches Konstruktr; allerdings lehnt sich die Methode an Konzepte der Kognitionspsychologie vage an.\nSelf-Attention weist zwei große Verteile auf: Erstens erlaubt es parallele Verarbeitung, was viele Vorgängermodelle nicht erlaubten. Zweitens kann es den Kontext eines Tokens, also den Text um ein bestimmtes Wort herum, deutlich besser “im Blick” (oder in der Aufmerksamkeit) behalten als viele Vorgängermodelle.\nGerade für Daten mit sequenziellem Charakter, wie Text oder Sprache, sind Transformer-Modelle gut geeignet3.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#grundkonzepte",
    "href": "120-transformer.html#grundkonzepte",
    "title": "\n17  Transformer\n",
    "section": "\n17.3 Grundkonzepte",
    "text": "17.3 Grundkonzepte",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#einführung-in-hugging-face",
    "href": "120-transformer.html#einführung-in-hugging-face",
    "title": "\n17  Transformer\n",
    "section": "\n17.4 Einführung in Hugging Face 🤗",
    "text": "17.4 Einführung in Hugging Face 🤗\nDieser Abschnitt orientiert sich an Tunstall u. a. (2022). Die Syntax zu allen Kapiteln des Buchs findet sich praktischerweise in diesem Github-Repo.\nBei 🤗 liegt der Schwerpunkt klar bei Python, nicht bei R. Allerdings erlaubt RStudio ein einfaches Wechseln zwischen R und Python: Funktionen und Daten aus Python können einfach mit dem $-Operator angesprochen werden. In diesem Post wirds das demonstriert.\nSchauen wir uns das einführende Beispiel aus Tunstall u. a. (2022). an.\n\n17.4.1 Hugging Face mit R\nHier ein ein Text-Schnipsel, dessen Sentiment wir detektieren wollen:\n\ntext &lt;- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\nUnd hier in der Python-Version:\n\ntext_py = r.text\n\nDann importieren wir die nötigen Module:\n\n\nPython\nR\n\n\n\n\n#import tensorflow\nfrom transformers import pipeline\n\nNatürlich müssen Python-Module installiert sein, bevor man sie nutzen kann, genau so wie R-Pakete.\n\n\nMan kann die die Python-Module auch über R starten:\n\ntransformers &lt;- reticulate::import(\"transformers\")\n\n\n\n\n\n17.4.2 Einfache Pipeline\n{.panel-tabset}\n\n17.4.3 Python\nWir bereiten das Modell vor; im Default wird distilbert-base-uncased-finetuned-sst-2-english verwendet.\n\nclassifier = pipeline(\"text-classification\")\n## No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n## Using a pipeline without specifying a model name and revision in production is not recommended.\n## All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n## \n## All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#germeval-out-of-the-box-mit-hugging-face",
    "href": "120-transformer.html#germeval-out-of-the-box-mit-hugging-face",
    "title": "\n17  Transformer\n",
    "section": "\n17.5 Germeval Out-of-the-Box mit Hugging Face",
    "text": "17.5 Germeval Out-of-the-Box mit Hugging Face\nZuert importieren wir die Daten.\n\n\nR\nPython\n\n\n\n\ndata(germeval_train, package = \"pradadata\")\ntext &lt;- germeval_train$text[1:2]\ntext[1:2]\n## [1] \"@corinnamilborn Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar?\"                                 \n## [2] \"@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.\"\n\n\n\n\ngermeval_train_py = r.text\n\n\n\n\n\n17.5.1 Standard-Pipeline\n\nclassifier = pipeline(\"text-classification\")\n## No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n## Using a pipeline without specifying a model name and revision in production is not recommended.\n## All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n## \n## All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\noutputs2 = classifier(germeval_train_py)\noutputs2\n## [{'label': 'NEGATIVE', 'score': 0.9950070381164551}, {'label': 'NEGATIVE', 'score': 0.9954568147659302}]\n\nTja, vielleicht sollten wir ein Modell verwenden, das die deutsche Sprache versteht?\n\n17.5.2 Man spricht Deutsh\nAuf Hugging Face gibt es eine Menge von Modellen. Welches nehm ich nur? DISTILBERT oder BERT-Varianten dürfte kein schlechter Start sein.\n\n#classifier = pipeline(\"text-classification\", model=\"distilbert-base-german-cased\")\n\n\nclassifier = pipeline(\n  \"text-classification\", model=\"oliverguhr/german-sentiment-bert\")\n## All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n## \n## All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n\n\noutputs3 = classifier(germeval_train_py)\ndf = pd.DataFrame(outputs3)    \ndf.head()\n##       label     score\n## 0   neutral  0.987253\n## 1  negative  0.918047\n\n\ndf_r &lt;- py$pd\nhead(df_r)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#openai-api",
    "href": "120-transformer.html#openai-api",
    "title": "\n17  Transformer\n",
    "section": "\n17.6 OpenAI-API",
    "text": "17.6 OpenAI-API\n\n\n\n\n\n\nWichtig\n\n\n\nDer API-Aufruf von ChatGPT kostet Geld 💸. \\(\\square\\)\n\n\n\n17.6.1 Authentifizierung\nWir müssen uns bei der API anmelden:\n\n\nR\nPython\n\n\n\n\nopenai_key_r &lt;- Sys.getenv(\"OPENAI_API_KEY\")\n\n\n\n\nopenai_key_py = os.environ.get(\"OPENAI_API_KEY\")\n\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nSpeichern Sie keine sensiblen Daten in geteilten Ordner/Repos. Achten Sie auf Log-Dateien wir .Rhistory, in der u.U. Ihre sensiblen Daten enthalten sein können. \\(\\square\\)\n\n\nEine sichere Variante als das unverschlüsselte Speichenr von Passwörtern ist es, sensible Daten mit einem Passwort zu schützen. Dazu kann man z.B. in R das Paket keyring nutzen.\n\nlibrary(keyring)\nopenai_key_r &lt;- key_get(\"OPENAI_API_KEY\")\n\n\n17.6.2 Setup\n\nsentiment_scores = []\nsentiment_analysis = []\ntext = '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.'\n\n\n17.6.3 Anfrage an die API\n\nprompt = f\"Analysiere das Sentiment des folgenden Texts: \\n{text}\"\n\nresponse = openai.Completion.create(\n        prompt=prompt,\n        engine=\"davinci\",\n        max_tokens=100,\n        temperature=0.5,\n    )",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#vertiefung",
    "href": "120-transformer.html#vertiefung",
    "title": "\n17  Transformer\n",
    "section": "\n17.7 Vertiefung",
    "text": "17.7 Vertiefung\nDer Originalartikel von Vaswani u. a. (2023) gibt einen guten Einblick in die Konzepte; der Anspruch ist auf mittlerem Niveau. Von den Hugging-Face-Machern gibt es ein Buch, das - ebenfalls auf mittlerem Niveau - einen Einblick in Transformer-Modelle im Hugging-Face-Ökosystem gewährt (Tunstall u. a. 2022). Rothman (2022) scheint gute Freunde bei Google zu haben, wenn man sein Buch über Transformer liest, jedenfalls sind die Modelle jener Firma in dem Buch gut gefeatured. Géron (2023a) Standardwerk zu Scikit-Learn bietet auch einen Einblick in Attention-Konzepte (Kap. 16). Übrigens ist das Buch (3. Auflage) jetzt auch in deutscher Sprache erhältlich (Géron 2023b).\n\n\n\n\nGéron, Aurélien. 2023a. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Third edition. Beijing Boston Farnham Sebastopol Tokyo: O’Reilly.\n\n\n———. 2023b. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras und TensorFlow: Konzepte, Tools und Techniken für intelligente Systeme. Übersetzt von Kristian Rother und Thomas Demmig. 3., aktualisierte und erweiterte Auflage. Heidelberg: O’Reilly.\n\n\nRothman, Denis. 2022. Transformers for Natural Language Processing: Build, Train, and Fine-Tune Deep Neural Network Architectures for NLP with Python, Hugging Face, and OpenAI´s GPT3, ChatGPT, and GPT-4. Second edition. Expert Insight. Birmingham Mumbai: Packt.\n\n\nTunstall, Lewis, Leandro von Werra, Thomas Wolf, und Aurélien Géron. 2022. Natural Language Processing with Transformers: Building Language Applications with Hugging Face. Revised edition. Sebastopol: O’Reilly.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, und Illia Polosukhin. 2023. „Attention Is All You Need“. 1. August 2023. https://doi.org/10.48550/arXiv.1706.03762.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#vorab",
    "href": "130-chatgpt.html#vorab",
    "title": "\n18  ChatGPT-API\n",
    "section": "\n18.1 Vorab",
    "text": "18.1 Vorab\n\n18.1.1 Lernziele\n\nSie können gängige Anfragen an die OpenAI-ChatGPT-API senden.\n\n18.1.2 Benötigte Software\n\nlibrary(stringr)\nlibrary(httr)  # Wrapper um curl\n\n\n18.1.3 Spielzeug-Daten\n\ntweets &lt;- c(\n'@corinnamilborn Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar?', '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.')",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#grundlagen",
    "href": "130-chatgpt.html#grundlagen",
    "title": "\n18  ChatGPT-API\n",
    "section": "\n18.2 Grundlagen",
    "text": "18.2 Grundlagen\n\n18.2.1 ChatGPT ist auch ein Transformer\n\n👨‍🏫 Bist du ein Transformer?\n\n\n🤖 Ja, ich bin ein Modell, das auf der GPT-3.5-Architektur von OpenAI basiert, und diese Architektur wird als “Transformer” bezeichnet. Der Begriff “Transformer” bezieht sich auf die spezifische Architektur des neuronalen Netzwerks, die von Vaswani et al. in ihrem Paper “Attention is All You Need” vorgestellt wurde. Die Transformer-Architektur hat sich als äußerst leistungsfähig für natürliche Sprachverarbeitungsaufgaben erwiesen und bildet die Grundlage für Modelle wie GPT (Generative Pre-trained Transformer), einschließlich GPT-3.5, auf dem meine Fähigkeiten basieren.\n\n[Quelle: ChatGPT-3.5, 2023-11-23]\n\n18.2.2 Alles ist API\nDie Python- (oder R-)Pakete zum Zugriff zur ChatGPT-API sind letztlich nur Wrapper um den “direkten” Zugriff auf die API.\n\nDefinition 18.1 (API (Application Programming Interface)) Eine API stellt genormte Befehle zur Verfügung, um von einem Dienst (über eine Webseite) Daten abzufragen oder einzustellen. \\(\\square\\)\n\n\n18.2.3 curl\n\ncurl ist eine gängige Methode (auf der Kommondozeile), um Daten von einer Webseite abzufragen (oder einzustellen).\nLaut Dokumentation der API lautet der CURL-Befehl wie folgt (Pseudocode):\n\n```{zsh}\n#| eval: false\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n  \"model\": \"gpt-3.5-turbo\",\n  \"messages\": [{\"role\": \"user\", \"content\": \"Was ist die Frage zur Antwort '42'?\"}] ,\n  \"temperature\": 0,\n  \"max_tokens\": 256\n}'\n```\n\nEntscheidend ist der “Endpunkt” der URL: completions.\n\n\n\n\n\n\nHinweis\n\n\n\nOpenAi stellt eine Reihe von spezialisierten Diensten zur Verfügung, z.B. zur Sentimentanalyse von Tweets oder, natürlich, Textgeneration, und vieles mehr. \\(\\square\\)\n\n\nObige Syntax übersetzt sich so nach Python:\n\n# This code is for v1 of the openai package: pypi.org/project/openai\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[],\n  temperature=0,\n  max_tokens=256\n)\n\n\n18.2.4 Prompting\nAls Prompt kann man z.B. übergeben (bezeichnet als “System”):\n\n🧑‍🦰 You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative. USER\n\nDann kommt der zu klassifizierende Textschnipsel (bezeichent als “user”):\n\n📄 I loved the new Batman movie!\n\nUnd schließlich antwortet der Bot:\n\n🤖 positive\n\nEs ist günstig, dem Bot zu sagen, in welcher Sprache der Tweet ist. Außerdem ist es nützlich, den Prompt (die Anweisung) bereits in der Zielsprache zu formulieren.\n\nprompt_stem &lt;- \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: \"\n\n\nprompts &lt;- \n  str_c(prompt_stem, tweets)\n\nprompts\n## [1] \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @corinnamilborn Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar?\"                                 \n## [2] \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.\"\n\n\n18.2.5 Anmelden an der API\nDie API erlaubt nur Zugriffe angemeldeter Nutzer.\n\nOPENAI_API_KEY &lt;- Sys.getenv(\"OPENAI_API_KEY\")\n\nDamit eine Environment-Variable OPENAI_API_KEY ausgelesen werden kann, muss sie in .Rprofile definiert sein. Alternativ kann man aber die Variable auch auf anderen Wegen definieren, etwa aus einer Textdatei einlesen.\n\n\n\n\n\n\nWichtig\n\n\n\nLassen Sie sensible Daten, wie API-Keys, niemals auf öffentlichen Ordnern oder Repos (etwa auf Github) herumliegen. Stellen Sie sich vor, Sie haben bei dem Dienst ihre Kreditkarte hinterlege und ein übelwollender Dritter nutzt kostenpflichtige Dienste mit sehr hohem Budget. 🤯 \\(\\square\\)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#wrapper-um-curl",
    "href": "130-chatgpt.html#wrapper-um-curl",
    "title": "\n18  ChatGPT-API\n",
    "section": "\n18.3 Wrapper um curl",
    "text": "18.3 Wrapper um curl\nDieser Abschnitt basiert auf einem Blogpost bei R-Bloggers von Rasmus Bååth.\n\nresponse &lt;- POST(\n  # curl https://api.openai.com/v1/chat/completions \n  url = \"https://api.openai.com/v1/chat/completions\", \n  # -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  add_headers(Authorization = \n                paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\"))),\n  # -H \"Content-Type: application/json\"\n  content_type_json(),\n  # -d '{\n  #   \"model\": \"gpt-3.5-turbo\",\n  #   \"messages\": [{\"role\": \"user\", \"content\": \"What is a banana?\"}] \n  # }'\n  encode = \"json\",\n  body = list(\n    model = \"gpt-3.5-turbo\",\n    messages = list(list(role = \"user\", content = prompts[1]))\n  ))\n\n\ncontent(response)\n\n$object\n[1] \"chat.completion\"\n\n$created\n[1] 1700753610\n\n$model\n[1] \"gpt-3.5-turbo-0613\"\n\n$choices\n$choices[[1]]\n$choices[[1]]$index\n[1] 0\n\n$choices[[1]]$message\n$choices[[1]]$message$role\n[1] \"assistant\"\n\n$choices[[1]]$message$content\n[1] \"Das Sentiment dieses Tweets ist positiv. \"\n\n$choices[[1]]$finish_reason\n[1] \"stop\"\n\n$usage\n$usage$prompt_tokens\n[1] 76\n\n$usage$completion_tokens\n[1] 10\n\n$usage$total_tokens\n[1] 86\nDer für uns entscheidende Punkt ist:\n\nstr_trim(content(response)$choices[[1]]$message$content)\n\nDas Sentiment dieses Tweets ist positiv. \n\n18.3.1 Curl-Wrapper in eine Funktion gebracht\n\nask_chatgpt &lt;- function(prompt) {\nresponse &lt;- POST(\n  # curl https://api.openai.com/v1/chat/completions \n  url = \"https://api.openai.com/v1/chat/completions\", \n  # -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  add_headers(Authorization = \n                paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\"))),\n  # -H \"Content-Type: application/json\"\n  content_type_json(),\n  # -d '{\n  #   \"model\": \"gpt-3.5-turbo\",\n  #   \"messages\": [{\"role\": \"user\", \"content\": \"What is a banana?\"}] \n  # }'\n  encode = \"json\",\n  body = list(\n    model = \"gpt-3.5-turbo\",\n    messages = list(list(role = \"user\", content = prompt))\n  ))\n  str_trim(content(response)$choices[[1]]$message$content)\n}\n\n\n18.3.2 Schleife\n\nprompts |&gt; \n  sapply(ask_chatgpt)\n\nNach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @corinnamilborn Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar? \n\n\"positiv\" \n \nNach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir. \n\n \"neutral\"",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#vertiefung",
    "href": "130-chatgpt.html#vertiefung",
    "title": "\n18  ChatGPT-API\n",
    "section": "\n18.4 Vertiefung",
    "text": "18.4 Vertiefung\nMit etwas Zusatzaufwand kann man den Kontext bzw. den Verlauf der Konversation mit dem Bot berücksichtigen, wie dieser Post zeigt.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#aufgaben",
    "href": "130-chatgpt.html#aufgaben",
    "title": "\n18  ChatGPT-API\n",
    "section": "\n18.5 Aufgaben",
    "text": "18.5 Aufgaben\nSchauen Sie sich die Aufgaben mit dem Tag ‘Transformer’ auf dem Datenwerk an.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#pipeline-management",
    "href": "200-projektmgt.html#pipeline-management",
    "title": "\n19  Projektmanagement\n",
    "section": "\n19.1 Pipeline-Management",
    "text": "19.1 Pipeline-Management\n\n19.1.1 Am Anfang\nSie haben Großes vor! Naja, zumindest planen Sie ein neues Data-Science-Projekt.\nUnd, schlau wie Sie sind, stürzen Sie nicht sofort an die Tastatur, um sich einige Modelle berechnen zu lassen. Nein! Sie denken erst einmal nach. Zum Beispiel, wie die einzelnen Analyseschritte aussehen, worin sie bestehen, und in welcher Abfolge sie zu berechnen sind, s. Abbildung 19.1.\n\n\n\n\n\nAbbildung 19.1: So könnte Ihr Projektplan am Anfang aussehen, man spricht auch von einer Pipeline\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDen Graph der einzelnen Analyseschritte in ihrer Abhängigkeit bezeichnet man als *Pipeline.\n\n\n\n19.1.2 Sie träumen von einem Werkzeug\nNach einiger Zeit überlegen Sie sich, dass Sie ein System bräuchten, das Ihre Skizze umsetzt in tatsächliche Berechnungen. Und zwar suchen Sie ein Projektmanagement-System das folgendes Desiderata erfüllt:\n\nEs führt die einzelnen Schritte Ihres Projekt, die “Pipeline” in der richtigen Reihenfolge\nEs aktualisiert veraltete Objekte, aber es berechnet nicht Modelle neu, die unverändert sind\nEs ist gut zu debuggen\n\nJa, von so einem Werkzeug träumen Sie.\nUnd tatsächlich, Ihr Traum geht in Erfüllung. Dieses System existiert. Genau genommen gibt es viele Systeme, die sich anschicken, Ihre Wünsche zu erfüllen. Wir schauen uns eines näher an, das speziell für R gemacht ist. Das R-Paket targets.\n\n19.1.3 Targets\nEs lohnt sich, an dieser Stelle den “Walkthrough” aus dem Benutzerhandbuch von Targets durchzuarbeiten.\nFür ein Projekt ähnlich zu den, die wir in diesem Buch bearbeiten, ist folgende _targets.R-Datei ein guter Start.\n\nlibrary(targets)\n\n\n# Funktionen einlesen:\n#purrr::walk(list.files(path = \"funs\", pattern = \".R\", full.names = TRUE), source)\nsource(\"funs/def-recipe.R\")\nsource(\"funs/read-train-data.R\")\nsource(\"funs/read-test-data.R\")\n\n# Optionen, z.B. allgemein verfügbare Pakete in den Targets:tar_option_set(packages = c(\"readr\", \n                            \"dplyr\", \n                            \"ggplot2\", \n                            \"purrr\", \n                            \"easystats\", \n                            \"tidymodels\", \n                            \"textrecipes\"))\n\n# Definition der Pipeline:\nlist(\n  tar_target(data_train, read_train_data()),\n  tar_target(data_test, read_test_data()),\n  tar_target(recipe1, def_recipe(data_train)\n  ),\n  tar_target(model1,\n             logistic_reg(penalty = tune(), mixture = 1) %&gt;%\n               set_mode(\"classification\") %&gt;%\n               set_engine(\"glmnet\")\n             ),\n  tar_target(workflow1,\n             workflow() %&gt;% add_recipe(recipe1) %&gt;% add_model(model1)\n             ),\n  tar_target(grid1,\n             grid_regular(penalty(), levels = 3)\n             ),\n  tar_target(grid_fitted,\n             tune_grid(workflow1, \n                       resamples = vfold_cv(data_train, v = 2),\n                       grid = grid1)\n  ),\n  tar_target(best_hyperparams,\n             select_by_one_std_err(grid_fitted, metric = \"roc_auc\", penalty)\n             ),\n  tar_target(fit1,\n             workflow1 %&gt;% finalize_workflow(best_hyperparams) %&gt;% fit(data_train)),\n  tar_target(preds,\n             fit1 %&gt;% \n               predict(data_test) %&gt;% \n               bind_cols(data_test) %&gt;% \n               mutate(c1 = factor(c1))),\n  tar_target(metrics1,\n             preds %&gt;% metrics(truth = c1, .pred_class))\n)\n\nDann kann man auf den Play-Button drücken und die ganze Pipeline wird berechnet:\n\ntar_make()\n\nWenn die Pipeline aktuell ist, und nichts berechnet werden muss (und daher auch schon fehlerfrei durchgelaufen ist), sieht die Ausgabe so aus:\n✔ skip target grid1\n✔ skip target model1\n✔ skip target data_train\n✔ skip target data_test\n✔ skip target recipe1\n✔ skip target workflow1\n✔ skip target grid_fitted\n✔ skip target best_hyperparams\n✔ skip target fit1\n✔ skip target preds\n✔ skip target metrics1\n✔ skip pipeline [0.121 seconds]\nDie Pipeline kann man sich als DAG bzw. als Abhängigkeitsgraph visualisieren lassen:\n\ntar_visnetwork()\n\n\n\nAbhängigkeitsgraph der Pipeline\n\nEinzelne Objekte kann man sich komfortabel anschauen mit tar_load(objekt), z.B. tar_load(fit1) usw.\n\n19.1.4 Eine Pipeline als Spielwiese\nDieses Github-Repo stellt Ihnen eine “Spielwiese” zur Verfügung, wo Sie sich mit Pipleines à la Targets vertraut machen können.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#zeit-sparen",
    "href": "200-projektmgt.html#zeit-sparen",
    "title": "\n19  Projektmanagement\n",
    "section": "\n19.2 Zeit sparen",
    "text": "19.2 Zeit sparen\nEiner Maschine etwas beizubringen kann dauern … Ein einfaches Rechenbeispiel dazu:\n\nSie haben eine Kreuzvalidierung mit 10 Faltungen\nund 3 Wiederholungen\nund 3 Tuningparameter\nmit je 10 Werten\n\nDas sind 1033*10=900 Wiederholungen.\nLeider haben Sie noch in den ersten 10 Versuchen jeweils einen Bug, so dass sich die Rechenzeit noch einmal um den Faktor 10 erhöht…\nDie Rechenzeit kann also schnell ins astronomische steigen. Es braucht also Methoden, um Rechenzeit zu sparen.1 Einige Methoden zum Rechenzeit sparen sind:\n\n\nCloud: Cloud-Dienste in Anspruch nehmen (faktisch mietet man damit schnelle Rechner)\n\nParallelisierung: Mehrere Kerne des eigenen Computers nutzen\n\nUpgrade: Kaufen Sie sich einen schnelleren Rechner…\n\nCleveres Grid-Search: Methoden wie ANOVA Racing können die Rechenzeit - was das Tuning - betrifft - deutlich verringern.\n\nDieser Post gibt einen Überblick zu Rechenzeiten bei verschiedenen Tuningparameter-Optionen mit Tidymodels.\nNatürlich ist die (mit Abstand) beste Methode: guten Code schreiben. Denn “guter Code” verringert die Wahrscheinlichkeit von Bugs, und damit die Gefahr, dass die ganze schöne Rechenzeit für die Katz war.\n“Guter Code” ist vielleicht primär von zwei Dingen abhängig: erstens einen guten Plan zu haben bevor man das Programmieren anfängt und zweitens gute Methoden des Projektmanagements. Hunt und Thomas (2000) präsentieren eine weithin anerkannte Umsetzung, was “guter” Code bedeuten könnte.\n\n\nQuelle: imgflip.com",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#publizieren",
    "href": "200-projektmgt.html#publizieren",
    "title": "\n19  Projektmanagement\n",
    "section": "\n19.3 Publizieren",
    "text": "19.3 Publizieren\nSie haben eine super Analyse geschrieben, eine schicke Pipeline, und jetzt soll die Welt davon erfahren? Es gibt einige komfortable Möglichkeiten, Ihre Arbeit zu publizieren, z.B. als Blog mit Quarto.\nDieses Video zeigt Ihnen wie man einen Quarto-Blog in RStudio erstellt und ihn bei Netlify publiziert.\n\nDas Hosten bzw. Deployen bei Netlify ist kostenlos (in der Basis-Variante).\nSie können alternativ Github Pages als Hosting-Dienst verwenden. Dieses Video gibt dazu eine Anleitung.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#komplexitätsmanagement",
    "href": "200-projektmgt.html#komplexitätsmanagement",
    "title": "\n19  Projektmanagement\n",
    "section": "\n19.4 Komplexitätsmanagement",
    "text": "19.4 Komplexitätsmanagement\nProgrammieren ist faszinierend. Vor allem, wenn das Programm funktioniert. Genau genommen ist es eigentlich nur dann faszinierend, ansonsten wird es anstrengend? aufregend? süchtig? faszinierend? nervig? Wie auch immer: Bugs treten auf und mit steigender Komplexität Ihrer Software steigen die Bugs nicht linear, sondern eher quadratisch oder gar exponentiell an.\nEs gibt viele Ansätze, sich gegen die Komplexität zu “wehren”. Der beste ist vielleicht: Die Software so einfach wie möglich zu halten - und nur so komplex wie nötig. Sozusagen: Das beste Feature ist das, das Sie nicht implementieren.\n\n19.4.1 Geben Sie gute Namen\nDaraus leitet sich ab, dass die zentralen Methoden, um der Fehler Herr zu werden im Komplexitätsmanagement liegen. Den Variablen (Objekten) “gute”, “sprechende”, aber prägnante Namen zu geben, ist in diesem Lichte auch als Komplexitätsmanagement (Reduktion) zu verstehen.\nEin typischer Fehler, der mir immer mal wieder passiert, ist: Ich ändere den Namen eines Objekts, aber vergesse, an allen Stellen im Code den Namen anzupassen. Glücklicherweise gibt es hier eine einfache Abhilfe: Replace-All.\nDer zwar einfache Weg, mehrere ähnliche Objekte durchzunummerieren (workflow2a, recipe1, …). ist zwar einfach, aber insgesamt nicht zu empfehlen: Es ist nicht leicht, immer genau zu wissen, was der Inhalt hinter der Nummer 2a etc. ist. Ändert man außerdem die Reihenfolge (oder schiebt ein Objekt dazwischen ein), macht die Nummerierung keinen Sinn mehr (oder man muss mühselig die Nummern ändern, was fehleranfällig und nervig ist).\n\n19.4.2 Portionieren\nEine andere, zentrale Maßnahme ist es, den Code in handlichen “Häppchen” zu verpacken. Statt einer Skriptdatei mit zich Tausend Zeilen, wünschen Sie sich doch sicher ein Skript der Art:\nmache_1()\nmache_2()\nmache_3()\ngratuliere_fertig()\nSchaut man dann in mache_1() rein, sieht man wiederum übersichtlichen Code.\nFunktionales Programmieren ist eine Umsetzung davon: Jedes Häppchen, jeder Schritt ist eine Funktion. Eine Funktion hat Input und Output; der Output ist dann der Input für die Funktion des nächsten Schrittes. targets ist eine Umsetzung dieser Idee.\n\n19.4.3 Debugging mit einem Logger\nWenn das Kind in dem Brunnen gefallen ist, hilft nur Heulen und Wehklagen Das Problem finden und lösen. Mit einem Logger kann man sich das Entwanzen, das Finden der Fehler, erleichtern. Ein Logger schreibt Zwischenschritte in eine Log-Datei.\nHier ist ein Beispiel mit dem futile Logger:. Mein Problem war, dass ich eine dynamische Aufgabe für eine Statistik-Klausur programmiert hatte, aber leider gab es einen Bug, den ich nicht gefunden habe2.\nDie Lösung brachte ein Logger, mit dem ich den Wert zentraler Variablen im Verlauf des Durchlaufens des Codes - bis eben der Laufzeitfehler aufkam3.\nHier ist ein Ausschnitt der Syntax. Zuerst initialisiert man den Logger mit einer Datei, hier exams.log. Neue Logging-Inhalte sollen an die bestehenden Logs angehängt werden (appender).\n\nlibrary(futile.logger)\nflog.appender(appender.file(\"/Users/sebastiansaueruser/github-repos/rexams-exams/exams.log\"))\n\nDann gebe ich eine Loggings vom Typ “Info” zum Protokoll:\n\nflog.info(paste0(\"Ex: post-uncertainty1\"))\nflog.info(msg = paste0(\"Data set: \", d_name))\nflog.info(paste0(\"Preds chosen: \", stringr::str_c(preds_chosen, collapse = \", \")))\nflog.info(paste0(\"Output var: \", av))\n\nDie Ergebnisse kann man dann in der Logging-Datei anschauen:\nNFO [2023-01-05 11:27:51] Rhats: 1.004503053029\nINFO [2023-01-05 11:27:51] Sol: 0.18\nINFO [2023-01-05 11:27:51] Sol typeof: double\nINFO [2023-01-05 11:27:52] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:52] Data set: tips\nINFO [2023-01-05 11:27:52] Preds chosen: size, total_bill\nINFO [2023-01-05 11:27:52] Output var: tip\nINFO [2023-01-05 11:27:53] Rhats: 0.999004883794722\nINFO [2023-01-05 11:27:53] Rhats: 1.00021605674421\nINFO [2023-01-05 11:27:53] Rhats: 1.00091357638756\nINFO [2023-01-05 11:27:53] Sol: 0.32\nINFO [2023-01-05 11:27:53] Sol typeof: double\nINFO [2023-01-05 11:27:54] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:54] Data set: TeachingRatings\nINFO [2023-01-05 11:27:54] Preds chosen: prof, beauty\nINFO [2023-01-05 11:27:54] Output var: eval\nINFO [2023-01-05 11:27:55] Rhats: 0.999060308710712\nINFO [2023-01-05 11:27:55] Rhats: 0.999032305267221\nINFO [2023-01-05 11:27:55] Rhats: 0.999229003550072\nINFO [2023-01-05 11:27:55] Sol: 0\nINFO [2023-01-05 11:27:55] Sol typeof: double\nINFO [2023-01-05 11:27:56] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:56] Data set: gtcars\nINFO [2023-01-05 11:27:56] Preds chosen: mpg_c, year\nINFO [2023-01-05 11:27:56] Output var: msrp\nINFO [2023-01-05 11:28:00] Rhats: 0.99913061005524\nINFO [2023-01-05 11:28:00] Rhats: 0.998999786100339\nINFO [2023-01-05 11:28:00] Rhats: 0.999130286784586\nINFO [2023-01-05 11:28:01] Sol: 21959.35\nINFO [2023-01-05 11:28:01] Sol typeof: double\nJa, das sieht nicht schön aus. Aber es brachte mir die Lösung: Mir fiel auf, dass der Fehler nur auftrat, wenn sol einen großen Wert hatte (1000 oder mehr). Danke, Logger!\n\n\n\n\nHunt, Andrew, und David Thomas. 2000. The Pragmatic Programmer from Journeyman to Master. Reading, Mass.: Addison-Wesley.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "300-fallstudien.html#quellen-für-textdaten",
    "href": "300-fallstudien.html#quellen-für-textdaten",
    "title": "20  Fallstudien",
    "section": "20.1 Quellen für Textdaten",
    "text": "20.1 Quellen für Textdaten\nDer MonkeyLearn Blog liefert eine Reihe von Quellen zu API, die Textdaten bereitstellen.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Fallstudien</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alkomah, Fatimah, and Xiaogang Ma. 2022. “A Literature\nReview of Textual Hate Speech Detection Methods and\nDatasets.” Information 13 (6, 6): 273. https://doi.org/10.3390/info13060273.\n\n\nAlmeida, Felipe, and Geraldo Xexéo. 2019. “Word\nEmbeddings: A Survey.” ArXiv,\nJanuary. https://www.semanticscholar.org/paper/Word-Embeddings%3A-A-Survey-Almeida-Xex%C3%A9o/e28e81a8cb6655aebb72357538f7b7a360366a29.\n\n\nBarry, Paul. 2017. Python von Kopf bis Fuß. Translated by\nJørgen W. Lang. Zweite Auflage. Von Kopf bis Fuß. Beijing Boston\nFarnham Sebastopol Tokyo: O’Reilly.\n\n\nCamacho-Collados, Jose, and Mohammad Taher Pilehvar. 2020.\n“Embeddings in Natural Language Processing.”\nIn Proceedings of the 28th International Conference on\nComputational Linguistics: Tutorial\nAbstracts, 10–15. Barcelona, Spain (Online):\nInternational Committee for Computational Linguistics. https://doi.org/10.18653/v1/2020.coling-tutorials.2.\n\n\nCastaño-Pulgarín, Sergio Andrés, Natalia Suárez-Betancur, Luz Magnolia\nTilano Vega, and Harvey Mauricio Herrera López. 2021. “Internet,\nSocial Media and Online Hate Speech. Systematic\nReview.” Aggression and Violent Behavior 58 (May):\n101608. https://doi.org/10.1016/j.avb.2021.101608.\n\n\nChollet, François. 2021. Deep Learning with\nPython. Second edition. Shelter Island,\nNY: Manning.\n\n\nChollet, François, Tomasz Kalinowski, and J. J. Allaire. 2022a. Deep\nLearning with R. Second edition. Shelter Island,\nNY: Manning.\n\n\n———. 2022b. Deep Learning with R. Second edition.\nShelter Island, NY: Manning Publications Co.\n\n\nDowney, Allen B. 2021. Think Python: systematisch programmieren\nlernen mit Python. Translated by Peter Klicman. 1. Auflage.\nHeidelberg: O’Reilly.\n\n\nGallatin, Kyle, and Chris Albon. 2023. Machine Learning with\nPython Cookbook: Practical Solutions from Preprocessing to\nDeep Learning. Beijing Boston Farnham Sebastopol\nTokyo: O’Reilly Media.\n\n\nGeorge, Alexandra. 2022. Python Text Mining: Perform Text\nProcessing, Word Embedding, Text Classification and Machine\nTranslation. Delhi: BPB Publications.\n\n\nGéron, Aurélien. 2023a. Hands-on Machine Learning with\nScikit-Learn, Keras, and\nTensorFlow: Concepts, Tools, and Techniques to Build\nIntelligent Systems. Third edition. Beijing Boston Farnham\nSebastopol Tokyo: O’Reilly.\n\n\n———. 2023b. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras\nund TensorFlow: Konzepte, Tools und Techniken für intelligente\nSysteme. Translated by Kristian Rother and Thomas Demmig. 3.,\naktualisierte und erweiterte Auflage. Heidelberg:\nO’Reilly.\n\n\n———. 2023c. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras\nund TensorFlow: Konzepte, Tools und Techniken für intelligente\nSysteme. Translated by Kristian Rother and Thomas Demmig. 3.,\naktualisierte und erweiterte Auflage. Heidelberg:\nO’Reilly.\n\n\nHunt, Andrew, and David Thomas. 2000. The Pragmatic Programmer from\nJourneyman to Master. Reading, Mass.:\nAddison-Wesley.\n\n\nHvitfeldt, Emil, and Julia Silge. 2021. Supervised Machine\nLearning for Text Analysis in R.\n1st ed. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nInden, Michael. 2023. Python lernen: kurz & gut. 1.\nAuflage. O’Reillys Taschenbibliothek. Heidelberg:\nO’Reilly.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2021. An Introduction to Statistical Learning: With Applications in\nR. Second edition. Springer Texts in Statistics.\nNew York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nKönig, Tim, Wolf J. Schünemann, Alexander Brand, Julian Freyberg, and\nMichael Gertz. 2022. “The EPINetz Twitter Politicians\nDataset 2021. A New Resource for the Study of the German\nTwittersphere and Its Application for the 2021 Federal\nElections.” Politische Vierteljahresschrift 63 (3):\n529–47. https://doi.org/10.1007/s11615-022-00405-7.\n\n\nKulkarni, Akshay, and Adarsha Shivananda. 2021. Natural Language\nProcessing Recipes: Unlocking Text Data with Machine Learning and Deep\nLearning Using Python. Second edition. New\nYork: Apress.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLex, Alexander, Nils Gehlenborg, Hendrik Strobelt, Romain Vuillemot, and\nHanspeter Pfister. 2014. “UpSet:\nVisualization of Intersecting Sets.” IEEE\nTransactions on Visualization and Computer Graphics 20 (12):\n1983–92. https://doi.org/10.1109/TVCG.2014.2346248.\n\n\nLiu, Zhiyuan, Yankai Lin, and Maosong Sun, eds. 2023. Representation\nLearning for Natural Language Processing.\nSingapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-1600-9.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013.\n“Efficient Estimation of Word\nRepresentations in Vector Space.” September\n6, 2013. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014.\n“GloVe: Global Vectors for Word\nRepresentation.” In Proceedings of the 2014 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), 1532–43. Doha, Qatar:\nAssociation for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.\n\n\nPilehvar, Mohammad Taher, and Jose Camacho-Collados. 2021.\nEmbeddings in Natural Language Processing:\nTheory and Advances in Vector\nRepresentations of Meaning. Synthesis\nLectures on Human Language Technologies.\nCham: Springer International Publishing. https://doi.org/10.1007/978-3-031-02177-0.\n\n\nRemus, Robert, Uwe Quasthoff, and Gerhard Heyer. 2010.\n“SentiWS - a Publicly Available German-Language\nResource for Sentiment Analysis.” Proceedings of the 7th\nInternational Language Ressources and Evaluation (LREC’10),\n1168–71.\n\n\nRhys, Hefin. 2020. Machine Learning with\nR, the Tidyverse, and Mlr. Shelter Island,\nNY: Manning publications.\n\n\nRisch, Julian, Anke Stoll, Lena Wilms, and Michael Wiegand. 2021.\n“Overview of the GermEval 2021 Shared Task on the\nIdentification of Toxic, Engaging, and Fact-Claiming Comments.”\nIn Proceedings of the GermEval 2021 Shared Task on the\nIdentification of Toxic, Engaging, and Fact-Claiming Comments,\n1–12. Duesseldorf, Germany: Association for\nComputational Linguistics. https://aclanthology.org/2021.germeval-1.1.\n\n\nRothman, Denis. 2022. Transformers for Natural Language Processing:\nBuild, Train, and Fine-Tune Deep Neural Network Architectures for\nNLP with Python, Hugging Face,\nand OpenAI´s GPT3, ChatGPT, and\nGPT-4. Second edition. Expert Insight.\nBirmingham Mumbai: Packt.\n\n\nShannon, C. E. 1948. “A Mathematical Theory of\nCommunication.” Bell System Technical Journal 27 (3):\n379–423. https://doi.org/10.1002/j.1538-7305.1948.tb01338.x.\n\n\nSiegel, Melanie, and Melpomeni Alexa. 2020. Sentiment-Analyse\ndeutschsprachiger Meinungsäußerungen: Grundlagen, Methoden und\npraktische Umsetzung. Wiesbaden: Springer\nFachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-29699-5.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with\nR: A Tidy Approach. First edition. Beijing ;\nBoston: O’Reilly. https://www.tidytextmining.com/.\n\n\nStone, James V. 2019. “Information Theory: A\nTutorial Introduction.” June 13, 2019. http://arxiv.org/abs/1802.05968.\n\n\nTunstall, Lewis, Leandro von Werra, Thomas Wolf, and Aurélien Géron.\n2022. Natural Language Processing with Transformers: Building\nLanguage Applications with Hugging Face. Revised edition.\nSebastopol: O’Reilly.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2023.\n“Attention Is All You Need.” August 1, 2023.\nhttps://doi.org/10.48550/arXiv.1706.03762.\n\n\nWickham, Hadley, and Garrett Grolemund. 2016. R for Data\nScience: Visualize, Model,\nTransform, Tidy, and Import\nData. O’Reilly Media. https://r4ds.had.co.nz/index.html.\n\n\nWiegand, Michael. 2019a. “GermEval-2018 Corpus\n(DE).” heiDATA. https://doi.org/10.11588/data/0B5VML.\n\n\n———. 2019b. “GermEval-2018 Corpus\n(DE).” heiDATA. https://doi.org/10.11588/data/0B5VML.\n\n\n———. 2019c. “GermEval-2018-Data-master.” In\nGermEval-2018 Corpus (DE).\nheiDATA. https://doi.org/10.11588/data/0B5VML/XIUWJ7.\n\n\n“Word Embeddings in NLP: A Complete\nGuide.” 2023. Turing. 2023. https://www.turing.com/kb/guide-on-word-embeddings-in-nlp.\n\n\nYamada, Ikuya, and Hiroyuki Shindo. 2019. “Neural Attentive\nBag-of-Entities Model for Text Classification.” In\nProceedings of the 23th SIGNLL Conference on\nComputational Natural Language Learning, 563–73. Association\nfor Computational Linguistics.",
    "crumbs": [
      "Abschluss",
      "References"
    ]
  }
]