[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "datascience2: Prädiktive Modelle auf Basis von Textdaten",
    "section": "",
    "text": "falls Sie die Pakete schon installiert haben, könnten Sie mal in RStudio auf “update.packages” klicken↩︎"
  },
  {
    "objectID": "pruefung.html",
    "href": "pruefung.html",
    "title": "1  Prüfung",
    "section": "",
    "text": "Text als Datenbasis prädiktiver Modelle\nBild von mcmurryjulie auf Pixabay"
  },
  {
    "objectID": "pruefung.html#prüfungsform-datenanalyse-als-quarto-blog-post",
    "href": "pruefung.html#prüfungsform-datenanalyse-als-quarto-blog-post",
    "title": "1  Prüfung",
    "section": "1.1 Prüfungsform: Datenanalyse als Quarto-Blog-Post",
    "text": "1.1 Prüfungsform: Datenanalyse als Quarto-Blog-Post\nAls Prüfungsleistung ist ein Corpus an Twitter-Daten deutscher aktueller Politiker auf Hate Speech hin zu untersuchen.\n\nDer Bericht der Analyse ist als Quarto Blog-Posts zu formatieren.\nEinzureichen ist die URL des Posts.\nDer Post muss während des gesamten Prüfungszeitraums online sein, gehostet von einem beliebigen Provider (z.B. Netlify oder Github).\nNach Einreichen des Posts dürfen keine Änderungen mehr vorgenommen werden.\nZu Dokumentationszwecken soll ein PDF-Print des Posts in die Abgabe mit hochgeladen werden. Das PDF-Print des Posts muss identisch (exakt gleich) sein zum Post, der über die URL verfügbar ist.\nDer Quelltext des Posts soll bei Github vorliegen.\n\n\nAlle folgenden Hinweise gelten nur insoweit Ihre Lehrkraft Ihnen keine anders lautenden Hinweise gegeben hat (schriftlich)."
  },
  {
    "objectID": "pruefung.html#allgemeines",
    "href": "pruefung.html#allgemeines",
    "title": "1  Prüfung",
    "section": "1.2 Allgemeines",
    "text": "1.2 Allgemeines\n\nGegenstand dieser Prüfungsform ist die Analyse eines Datensatzes nach einer Forschungsfrage und die Dokumentation dieser Analyse.\nSchreiben Sie Ihre Datenanalyse in Form eines Berichts, der sich an den Gliederungspunkten wie unten dargestellt orientiert.\nWenden Sie die passenden, im Unterricht eingeführten, statistischen Verfahren an. Es steht Ihnen frei, andere (nicht im Unterricht behandelte) Verfahren zur Analyse der Daten anzuwenden, nach Maßgabe der fachlichen Angemessenheit.\nWerten Sie die Daten mit R aus.\nDie R-Syntax soll im Hauptteil des Berichts dokumentiert werden. R-Output darf ggf. gekürzt wiedergegeben werden.\nFügen Sie keine Erklärungen oder Definitionen von statistischen Verfahren an.\nBeschreiben und interpretieren Sie jede Analyse bzw. jeden R-Code bzw. jedes Ergebnis (jede R-Ausgabe).\nVon hoher Bedeutung ist die Korrektheit der Beschreibung und Interpretation der statistischen Modellierung (z.B. mit der Regressionsanalyse).\nEs hat keinen Einfluss auf Ihre Note, ob sich ein (erwarteter) Effekt zeigt und wie stark dieser Effekt ggf. ist."
  },
  {
    "objectID": "pruefung.html#formatierung-des-berichts",
    "href": "pruefung.html#formatierung-des-berichts",
    "title": "1  Prüfung",
    "section": "1.3 Formatierung des Berichts",
    "text": "1.3 Formatierung des Berichts\n\nDer Bericht ist nur elektronisch, nicht ausgedruckt einzureichen.\nDer Bericht kann als paginiertes Dokument oder als nicht-paginiertes Dokument (d.h. als HTML-Dokument) eingereicht werden.\nPaginierte Formate sind als PDF-Datei einzureichen. HTML-Formate sind entweder in HTML-Form oder (nur bei Bedarf) als PDF-Druck eines HTML-Dokuments einzureichen.\nDie Wahl eines bestimmten Stylesheets ist nicht von Bedeutung. Lesbarkeit und Übersichtlichkeit in der Formatierung sind unabhängig davon anzustreben.\nIm Kopfbereich (oder auf einem Deckblatt) sind die relevanten Metadatan anzugeben wie Name (Nachname, Vorname) der Autorin/des Autors, Abgabedatum, Titel der Arbeit, Modul."
  },
  {
    "objectID": "pruefung.html#formalia",
    "href": "pruefung.html#formalia",
    "title": "1  Prüfung",
    "section": "1.4 Formalia",
    "text": "1.4 Formalia\n\nRichtlinien einer Wortzahl gibt es nicht. Entscheidend ist, dass relevante Analysen durchgeführt und beschrieben wurden.\nDer Anspruch richtet sich nach dem Inhalt und Niveau der auf dieses Modul vorbereitenden Module. Oft sind das Module in quantitativer Datenanalyse (und wissenschaftliches Arbeiten). Deren Inhalte sollen im Rahmen dieser Prüfungsleistung als selbständig und flüssig verfügbare Kompetenz von den Studentis demonstriert werden.\nDie Gliederung der Arbeit kann sich an den PPDAC-Zyklus und am Data Science Model von Wickham und Grolemund orientieren."
  },
  {
    "objectID": "pruefung.html#beurteilungskriterien",
    "href": "pruefung.html#beurteilungskriterien",
    "title": "1  Prüfung",
    "section": "1.5 Beurteilungskriterien",
    "text": "1.5 Beurteilungskriterien\nDie Arbeit wird im Hinblick auf drei Kriterien bewertet:\n\nFormalia (z. B. Vollständigkeit der Abarbeitung, Angemessenheit der äußeren Gestaltung, Fokus auf Wesentliches)\nMethodik (z. B. Richtige Auswahl und Anwendung der Verfahren)\nInhalt (z. B. Verständlichkeit, Breite und Tiefe der Problemlösung, Korrektheit der Interpretation)\n\nSie erhalten für jedes der drei Kriterien eine Teilnote sowie eine Gesamtnote. Außerdem erhalten Sie ggf. für die Kriterien noch ausformulierte Hinweise.\nDie Gesamtnote muss sich nicht als Mittelwert der Teilnoten ergeben.\nInsbesondere kann eine Fünf in einem der Kriterien zum Durchfallen führen, auch wenn die anderen beiden Kriterien gut oder sehr gut beurteilt wurden."
  },
  {
    "objectID": "pruefung.html#beispiele-für-aspekte-der-beurteilungskriterien",
    "href": "pruefung.html#beispiele-für-aspekte-der-beurteilungskriterien",
    "title": "1  Prüfung",
    "section": "1.6 Beispiele für Aspekte der Beurteilungskriterien",
    "text": "1.6 Beispiele für Aspekte der Beurteilungskriterien\n\nWurden deskriptive Statistiken (an angemessenen Ort) berichtet?\nWurden Diagramme und Tabellen angemessen eingesetzt?\nWurde Inferenzstatistik (angemessen) eingesetzt?\nWurden Effektstärkemaße (idealerweise mit Konfidenzintervallen dazu) berichtet?\nWurden alle relevanten Informationen für ein statistisches Verfahren angegeben (z.B. zum gewählten Prior)?\nWurde die Aussagekraft von Modellergebnissen richtig eingeschätzt?\nWaren die Schlussfolgerungen, die aus den statistischen Ergebnissen gezogen wurden, angemessen (z. B. wurde erkannt, dass ein Nicht-Verwerfeen einer Hypothese nicht automatisch ein Bestätigen derselben bedeutet)?\nWurde angemessen gerundet (inkl. konsistente Anzahl von Nachkommastellen)?\nPassen die statistischen Verfahren zu den Hypothesen?\nWurden die Voraussetzungen der statistischen Verfahren geprüft?\nSind die Ergebnisse reproduzierbar (Daten und Syntax eingereicht)?"
  },
  {
    "objectID": "pruefung.html#beispiele-für-fehler",
    "href": "pruefung.html#beispiele-für-fehler",
    "title": "1  Prüfung",
    "section": "1.7 Beispiele für Fehler",
    "text": "1.7 Beispiele für Fehler\nSchwere Fehler, die zum Durchfallen oder deutlichem Abwerten der Note führen können, sind z.B.:\n\nfehlende Inferenzstatistik (oder adäquatem Ersatz)\nfalsche Interpretation von Posteriori-Verteilungen oder p-Werten\nkeine Angabe von Konfidenzintervallen\nfalsche Interpretation von Konfidenzintervallen\nWahl des falschen Intervalls (Vorhersageintervall vs. Perzentilintervall vs. HDI)\nfalsche Entscheidung zum Hypothesentest auf Basis entsprechender Kennwerte (wie ROPE-Wahrscheinlichkeit oder p-Wert)\nfalsche Wahl des statistischen Verfahrens\nfehlende Deskriptivstatistik\n\nHäufige kleinere Mängel sind z. B.\n\npixelige Abbildungen\nR-Ausgaben oder R-Syntax als Screenshot\nfehlende Seitenzahlen (nur bei paginierten Formaten, nicht bei HTML)\nunübersichtliche Diagramme\nkein (verlinktes) Inhaltsverzeichnis ︎\nfehlende oder unverständliche Achsenbeschriftung bei Diagrammen\nfehlende oder falsche Beschreibung der/des Skalenniveau(s) der untersuchten Variablen"
  },
  {
    "objectID": "twittermining.html",
    "href": "twittermining.html",
    "title": "2  Twitter Mining",
    "section": "",
    "text": "Text als Datenbasis prädiktiver Modelle\nBild von mcmurryjulie auf Pixabay"
  },
  {
    "objectID": "twittermining.html#vorab",
    "href": "twittermining.html#vorab",
    "title": "2  Twitter Mining",
    "section": "2.1 Vorab",
    "text": "2.1 Vorab\n\n2.1.1 Lernziele\n\nTwitterdaten via API von Twitter auslesen\n\n\n\n2.1.2 Vorbereitung\n\nLesen Sie in Hvitfeldt und Silge (2022) Kap. 1.\nLegen Sie sich ein Konto bei Github an.\nLegen Sie sich ein Konto bei Twitter an.\nLesen Sie diesen Artikel zur Anmeldung bei der Twitter API1\n\n\n\n2.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(rtweet)\n\n\n\n\nR-Paket {rtweet}\n\n\nEinen Überblick über die Funktionen des Pakets (function reference) findet sich hier."
  },
  {
    "objectID": "twittermining.html#anmelden-bei-twitter",
    "href": "twittermining.html#anmelden-bei-twitter",
    "title": "2  Twitter Mining",
    "section": "2.2 Anmelden bei Twitter",
    "text": "2.2 Anmelden bei Twitter\n\n2.2.1 Welche Accounts interessieren uns?\nHier ist eine (subjektive) Auswahl von deutschen Politikern, die einen Startpunkt gibt zur Analyse von Art und Ausmaß von Hate Speech gerichtet an deutsche Politiker:innen.\n\nd_path <- \"data/twitter-german-politicians.csv\"\n\nd <- read_csv(d_path)\nd\n\n\n\n\n\n\n\n\n\n\n\nname\nparty\nscreenname\ncomment\n\n\n\n\nKarl Lauterbach\nSPD\nKarl_Lauterbach\nNA\n\n\nOlaf Scholz\nSPD\nOlafScholz\nNA\n\n\nAnnalena Baerback\nGruene\nABaerbock\nNA\n\n\nBundesministerium für Wirtschaft und Klimaschutz\nGruene\nBMWK\nRobert Habeck ist der Minister im BMWK\n\n\nFriedrich Merz\nCDU\n_FriedrichMerz\nCDU-Chef\n\n\nMarkus Söder\nCSU\nMarkus_Soeder\nCSU-Chef\n\n\nCem Özdemir\nGruene\ncem_oezdemir\nBMEL\n\n\nJanine Wissler\nLinke\nJanine_Wissler\nLinke-Chefin\n\n\nMartin Schirdewan\nLinke\nschirdewan\nLinke-Chef\n\n\nChristian Lindner\nFDP\nc_lindner\nFDP-Chef\n\n\nMarie-Agnes Strack-Zimmermann\nFDP\nMAStrackZi\nVorsitzende Verteidigungsausschuss\n\n\nTino Chrupalla\nAFD\nTino_Chrupalla\nAFD-Bundessprecher\n\n\nAlice Weidel\nAFD\nAlice_Weidel\nAFD-Bundessprecherin\n\n\n\n\n\n\n\n\n2.2.2 Twitter App erstellen\nTutorial\n\n\n2.2.3 Intro\nDie Seite von rtweet gibt eine gute Starthilfe in die Benutzung des Pakets.\n\n\n2.2.4 Zugangsdaten\nZugangsdaten sollte man geschützt speichern, also z.B. nicht in einem geteilten Ordner.\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nAnmelden:\n\n#auth_setup_default() \n\nauth <- rtweet_bot(api_key = api_key,\n                   api_secret = api_secret,\n                   access_token = access_token,\n                   access_secret = access_secret)"
  },
  {
    "objectID": "twittermining.html#tweets-einlesen",
    "href": "twittermining.html#tweets-einlesen",
    "title": "2  Twitter Mining",
    "section": "2.3 Tweets einlesen",
    "text": "2.3 Tweets einlesen\nZu beachten ist, dass es Limits gibt, wie viele Informationen (pro Zeiteinheit) man über die Twitter-API auslesen darf. Informationen dazu findet man z.B. hier oder auch mit rate_limit().\nEin gängiges Limit der Twitter-API sind 900 Anfragen (z.B. Tweets auslesen) pro 15 Minuten.\n\n2.3.1 Timeline einlesen einzelner Accounts\nMal ein paar Tweets zur Probe:\n\nsesa_test <- get_timeline(user = \"sauer_sebastian\", n = 3) %>% \n  select(full_text)\n\n\n\nRT @pia_lamberty: Ein Ansatz, der sich beim Debunking wissenschaftlich als erfolgreich herausgestellt hat, ist das sog. Faktensandwich: htt…\nRT @ianbremmer: sure, it’s the hottest summer europe has ever had in history \n\nbut look at the upside\n\nit’s one of the coolest summers euro…\nRT @twisteddoodles: Balanced news reporting https://t.co/O1iiItEQrs\n\n\n\ntweets <- get_timeline(user = d$screenname)\nsaveRDS(tweets, file = \"tweets/tweets01.rds\")\n\nMichael Kearney rät uns:\n\nPRO TIP #4: (for developer accounts only) Use bearer_token() to increase rate limit to 45,000 per fifteen minutes.\n\n\n\n2.3.2 Retweets einlesen\n\noptions(rtweet.retryonratelimit = TRUE)\n\n\ntweets01_retweets <- \n  tweets$id_str %>% \n  head(3) %>% \n  map_dfr( ~ get_retweets(status_id = .x, retryonratelimit = TRUE))\n\nDa die meisten Retweets aber nix sagen, sondern nur auf das einen Tweet wiederholen, ist das Sammeln der Retweets ziemlich langweilig.\n\n\n2.3.3 EPINetz Twitter Politicians 2021\nKönig u. a. (2022) Volltext hier haben einen Datensatz mit knapp 2500 Twitter Accounts deutscher Politiker zusammengestellt, zum Stand 2021.\nDer Datensatz kann über Gesis bezogen werden.\nAuf der gleichen Seite findet sich auch eine Dokumentation des Vorgehens.\nNachdem wir den Datensatz heruntergeladen haben, können wir ihn einlesen:\n\npoliticians_path <- \"data/EPINetz_TwitterPoliticians_2021.RDs\"\npoliticians_twitter <- read_rds(politicians_path)\n\nhead(politicians_twitter)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID\nofficial_name\nparty\nregion\ninstitution\noffice\nuser_id\ntwitter_name\ntwitter_handle\nfrom\nuntil\nyear_of_birth\nabgeordnetenwatch_id\ngender\nwikidata_id\n\n\n\n\n535\nManja Schüle\nSPD\nBrandenburg\nState Parliament\nParliamentarian\n827090742162100224\nManja Schüle\nManjaSchuele\n2019-09-25\nNA\n1976\n146790\nfemale\nQ40974942\n\n\n962\nPetra Pau\nDIE LINKE\nFederal\nFederal Parliament\nParliamentarian\n1683845126\nTeam PetraPau\nTeamPetraPau\n2017-10-24\nNA\n1963\n79091\nfemale\nQ77195\n\n\n864\nDagmar Schmidt\nSPD\nFederal\nFederal Parliament\nParliamentarian\n1377117206\nTeam #dieschmidt\nTeamDieSchmidt\n2017-10-24\nNA\n1973\n79036\nfemale\nQ15433815\n\n\n2517\nBernd Buchholz\nFDP\nSchleswig-Holstein\nState Parliament\nParliamentarian\n1073605033\nBernd Buchholz\nBerndBuchholz\n2017-06-06\nNA\n1961\n121092\nmale\nQ823715\n\n\n1378\nIngrid Remmers\nDIE LINKE\nFederal\nFederal Parliament\nParliamentarian\n551802475\nIngrid Remmers MdB\ningrid_remmers\n2017-10-24\nNA\n1965\n120775\nfemale\nQ1652660\n\n\n1116\nReinhard Brandl\nCSU\nFederal\nFederal Parliament\nParliamentarian\n262730721\nReinhard Brandl\nreinhardbrandl\n2017-10-24\nNA\n1977\n79427\nmale\nQ111160\n\n\n\n\n\n\nDann lesen wir die Timelines (die Tweets) dieser Konten aus; in diesem Beispiel nur 10 Tweets pro Account:\n\nepi_tweets <- get_timeline(user = head(politicians_twitter$twitter_name), n = 10)\nhead(epi_tweets)\n\nNatürlich könnte man auch mehr als 10 Tweets pro Konto einsammeln, braucht nur seine Zeit.\n\n\n2.3.4 Followers suchen\n\nfollowers01 <-\n  d$screenname %>% \n map_dfr( ~ get_followers(user = .x, retryonratelimit = TRUE))\n\nsaveRDS(followers01, file = \"tweets/followers01.rds\")\n\nDamit haben wir eine Liste an Followers, deren Tweets wir einlesen und analysieren können, z.B. nach Hate Speech.\nIm Gegensatz zu Followers heißen bei Twitter die Accounts, denen ei Nutzi folgt “Friends”.\n\n\n2.3.5 Follower Tweets einlesen\n\nfollowers_tweets <- get_timeline(user = head(followers01$from_id), n = 10)"
  },
  {
    "objectID": "twittermining.html#cron-jobs",
    "href": "twittermining.html#cron-jobs",
    "title": "2  Twitter Mining",
    "section": "2.4 Cron Jobs",
    "text": "2.4 Cron Jobs\n\n2.4.1 Was ist ein Cron Job?\nCron ist ein Programm auf Unix-artigen Betriebssystemen, das Skripte zu eingestellten Zeiten (wiederholt) ausführt, das sind dann “Cron Jobs”. Auf Windows gibt es aber analoge Funktionen. Cron Jobs sind praktisch, da man nicht jedes Mal selber z.B. Tweets, die heute zu einem Thema getweetet wurden, herunterladen muss. Das wird dann vom Cron Job übernommen.\nIn R gibt es eine API zum Programm Cron mit dem Paket {cronR}, s. Anleitung hier.\nDas analoge R-Paket für Windows heißt {taskscheduleR}.\n\n\n2.4.2 Beispiel für einen Cron Job\n\nlibrary(cronR)\n\nscrape_script <- cron_rscript(\"scrape_tweets.R\")\n\n# Cron Job hinzufügen:\ncron_add(command = scrape_script, \n         frequency = 'daily', \n         at = \"10AM\",\n         id = 'Hate Speech')  # Name des Cron Jobs\n\ncron_clear(ask = FALSE)  # Alle Cron Jobs löschen\ncron_ls()  # Liste aller Cron Jobs\n\nIm obigen Beispiel wird das R-Skript scrape_tweets.R täglich um 10h ausgeführt.\nDer Inhalt von scrape_tweets.R könnte dann, in Grundzügen, so aussehen:\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(rtweet)\nfollowers_lauterbach <-\n  followers01 %>% \n  filter(to_id == \"Karl_Lauterbach\")\n\nfollowers_lauterbach_tweets <- \n  get_timeline(user = followers_lauterbach$from_id[1:10], n = 10, retryonratelimit = TRUE, verbose = FALSE)\n\n\npath_output <- \"/Users/sebastiansaueruser/Google Drive/RRRing/Scrape-Tweets/tweets/\"\n\nwrite_csv(x = followers_lauterbach_tweets,\n          file = paste0(path_output, \"followers_lauterbach_tweets.csv\"),\n          append = TRUE)\n\nWir schreiben nicht jedes Mal (jeden Tag) eine neue CSV-Datei, sondern wir hängen hier die neu ausgelesenen Daten an die Datei an.\nLeider ist es mit rtweet nicht möglich, ein Datum anzugeben, ab dem man Tweets auslesen möchte2"
  },
  {
    "objectID": "twittermining.html#workshop-zu-rtweet",
    "href": "twittermining.html#workshop-zu-rtweet",
    "title": "2  Twitter Mining",
    "section": "2.5 Workshop zu rtweet",
    "text": "2.5 Workshop zu rtweet\nErarbeiten Sie die Folien zu diesem rtweet-Workshop. Eine Menge guter Tipps!"
  },
  {
    "objectID": "twittermining.html#aufgaben",
    "href": "twittermining.html#aufgaben",
    "title": "2  Twitter Mining",
    "section": "2.6 Aufgaben",
    "text": "2.6 Aufgaben\n\nÜberlegen Sie, wie Sie das Ausmaß an Hate Speech, dem deutsche Politikerinnen und Politiker konfrontiert sind, messen können.\nArgumentieren Sie die Vorteile und Nachteile Ihres Ansatzes. Außerdem, auf welches Ergebnis dieser Analyse sie gespannt sind bzw. wären.\nÜberlegen Sie Korrelate, oder besser noch: (mögliche) Ursachen, des Hasses in den Tweets, gerichtet auf Polikter:innen. Sie können auch Gruppen von Ursachen bilden, etwas personengebundene Variablen der Politiker:innen (z.B. Alter? Geschlecht? Migrationshintergrund?).\nErstellen Sie sich eine Liste an Personen, deren Tweets sich lohnen (könnten), auf Hate Speech hin analysiert zu werden. Laden Sie deren Tweets (ggf. in Auszügen) herunter.\nDas Skript zu scrape_tweets.R könnte man noch verbessern, in dem man jeden Tag nur die neuesten Tweets herunterlädt. Dazu kann man bei get_timeline() mit dem Argument since_id eine Untergrenze der ID festlegen, so dass nur neuere Tweets (d.h. mit größerem Wert bei ID) ausgelesen werden. Ändern Sie das Skript entsprechend, so dass nur neuerer Tweets gelesen werden.\n\n\n\n\n\nHvitfeldt, Emil, und Julia Silge. 2022. Supervised Machine Learning for Text Analysis in R. 1. Aufl. Boca Raton: Chapman; Hall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nKönig, Tim, Wolf J. Schünemann, Alexander Brand, Julian Freyberg, und Michael Gertz. 2022. „The EPINetz Twitter Politicians Dataset 2021. A New Resource for the Study of the German Twittersphere and Its Application for the 2021 Federal Elections“. Politische Vierteljahresschrift 63 (3): 529–47. https://doi.org/10.1007/s11615-022-00405-7."
  },
  {
    "objectID": "textmining1.html",
    "href": "textmining1.html",
    "title": "3  Grundlagen des Textmining",
    "section": "",
    "text": "Bild von mcmurryjulie auf Pixabay"
  },
  {
    "objectID": "textmining1.html#vorab",
    "href": "textmining1.html#vorab",
    "title": "3  Grundlagen des Textmining",
    "section": "3.1 Vorab",
    "text": "3.1 Vorab\n\n3.1.1 Lernziele\n\nDie vorgestellten Techniken des Textminings mit R anwenden können\n\n\n\n3.1.2 Vorbereitung\n\nLesen Sie in Hvitfeldt und Silge (2022) Kap. 2.\n\n\n\n3.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(tokenizers)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(hcandersenr)\nlibrary(SnowballC)  # Stemming\nlibrary(lsa)  # Stopwörter\nlibrary(easystats)  # Komfort für deskriptive Statistiken, wie `describe_distribution`"
  },
  {
    "objectID": "textmining1.html#einfache-methoden-des-textminings",
    "href": "textmining1.html#einfache-methoden-des-textminings",
    "title": "3  Grundlagen des Textmining",
    "section": "3.2 Einfache Methoden des Textminings",
    "text": "3.2 Einfache Methoden des Textminings\nArbeiten Sie die folgenden grundlegenden Methoden des Textminigs durch.\n\n3.2.1 Tokenisierung\nErarbeiten Sie dieses Kapitel: Hvitfeldt und Silge (2022), Kap. 2\nWie viele Zeilen hat das Märchen “The Fir tree” (in der englischen Fassung?)\n\nhcandersen_en %>% \n  filter(book == \"The fir tree\") %>% \n  nrow()\n\n[1] 253\n\n\n\n\n3.2.2 Stopwörter entfernen\nErarbeiten Sie dieses Kapitel: s. Hvitfeldt und Silge (2022), Kap. 3\n\n\n3.2.3 Stemming (Wortstamm finden)\nErarbeiten Sie dieses Kapitel: Hvitfeldt und Silge (2022), Kap. 4\nVertiefende Hinweise zum UpSet plot finden Sie hier, Lex u. a. (2014).\nFür welche Sprachen gibt es Stemming im Paket SnowballC?\n\nlibrary(SnowballC)\ngetStemLanguages()\n\n [1] \"arabic\"     \"basque\"     \"catalan\"    \"danish\"     \"dutch\"     \n [6] \"english\"    \"finnish\"    \"french\"     \"german\"     \"greek\"     \n[11] \"hindi\"      \"hungarian\"  \"indonesian\" \"irish\"      \"italian\"   \n[16] \"lithuanian\" \"nepali\"     \"norwegian\"  \"porter\"     \"portuguese\"\n[21] \"romanian\"   \"russian\"    \"spanish\"    \"swedish\"    \"tamil\"     \n[26] \"turkish\"   \n\n\nEinfacher Test: Suchen wir den Wordstamm für das Wort “wissensdurstigen”, wie in “die wissensdurstigen Studentis löcherten dis armis Professi”1.\n\nwordStem(\"wissensdurstigen\", language = \"german\")\n\n[1] \"wissensdurst\"\n\n\nWerfen Sie mal einen Blick in das Handbuch von SnowballC.\n\n\n3.2.4 Fallstudie AfD-Parteiprogramm\nDaten einlesen:\n\nd_link <- \"https://raw.githubusercontent.com/sebastiansauer/pradadata/master/data-raw/afd_2022.csv\"\nafd <- read_csv(d_link, show_col_types = FALSE)\n\nAus breit mach lang, oder: wir tokenisieren (nach Wörtern):\n\nafd %>% \n  unnest_tokens(output = token, input = text) %>% \n  filter(str_detect(token, \"[a-z]\")) -> afd_long\n\nStopwörter entfernen:\n\ndata(stopwords_de, package = \"lsa\")\n\nstopwords_de <- tibble(word = stopwords_de)\n\n# Für das Joinen werden gleiche Spaltennamen benötigt:\nstopwords_de <- stopwords_de %>% \n  rename(token = word)  \n\nafd_long %>% \n  anti_join(stopwords_de) -> afd_no_stop\n\nJoining, by = \"token\"\n\n\nWörter zählen:\n\nafd_no_stop %>% \n  count(token, sort = TRUE) -> afd_count\n\nhead(afd_count)\n\n\n\n\n\ntoken\nn\n\n\n\n\nafd\n174\n\n\ndeutschland\n113\n\n\nwollen\n66\n\n\neuro\n60\n\n\nbürger\n57\n\n\neu\n54\n\n\n\n\n\n\nWörter trunkieren:\n\nafd_no_stop %>% \n  mutate(token_stem = wordStem(.$token, language = \"de\")) %>% \n  count(token_stem, sort = TRUE) -> afd_count_stemmed\n\nhead(afd_no_stop)\n\n\n\n\n\npage\ntoken\n\n\n\n\n1\nprogramm\n\n\n1\ndeutschland\n\n\n1\ngrundsatzprogramm\n\n\n1\nalternative\n\n\n1\ndeutschland\n\n\n2\ninhaltsverzeichnis\n\n\n\n\n\n\n\n\n3.2.5 Stringverarbeitung\nErarbeiten Sie dieses Kapitel: Wickham und Grolemund (2018), Kap. 14\n\n3.2.5.1 Regulärausdrücke\nDas \"[a-z]\" in der Syntax oben steht für “alle Buchstaben von a-z”. D iese flexible Art von “String-Verarbeitung mit Jokern” nennt man Regulärausdrücke (regular expressions; regex). Es gibt eine ganze Reihe von diesen Regulärausdrücken, die die Verarbeitung von Texten erleichert. Mit dem Paket stringr geht das - mit etwas Übung - gut von der Hand. Nehmen wir als Beispiel den Text eines Tweets:\n\nstring <- \"Correlation of unemployment and #AfD votes at #btw17: ***r = 0.18***\\n\\nhttps://t.co/YHyqTguVWx\"  \n\nMöchte man Ziffern identifizieren, so hilft der Reulärausdruck [:digit:]:\n“Gibt es mindestens eine Ziffer in dem String?”\n\nstr_detect(string, \"[:digit:]\")\n\n[1] TRUE\n\n\n“Finde die Position der ersten Ziffer! Welche Ziffer ist es?”\n\nstr_locate(string, \"[:digit:]\")\n\n     start end\n[1,]    51  51\n\nstr_extract(string, \"[:digit:]\")\n\n[1] \"1\"\n\n\n“Finde alle Ziffern!”\n\nstr_extract_all(string, \"[:digit:]\")\n\n[[1]]\n[1] \"1\" \"7\" \"0\" \"1\" \"8\"\n\n\n“Finde alle Stellen an denen genau 2 Ziffern hintereinander folgen!”\n\nstr_extract_all(string, \"[:digit:]{2}\")\n\n[[1]]\n[1] \"17\" \"18\"\n\n\nDer Quantitätsoperator {n} findet alle Stellen, in der der der gesuchte Ausdruck genau \\(n\\) mal auftaucht.\n“Zeig die Hashtags!”\n\nstr_extract_all(string, \"#[:alnum:]+\")\n\n[[1]]\n[1] \"#AfD\"   \"#btw17\"\n\n\nDer Operator [:alnum:] steht für “alphanumerischer Charakter” - also eine Ziffer oder ein Buchstabe; synonym hätte man auch \\\\w schreiben können (w wie word). Warum werden zwei Backslashes gebraucht? Mit \\\\w wird signalisiert, dass nicht der Buchstabe w, sondern etwas Besonderes, eben der Regex-Operator \\w gesucht wird.\n“Zeig die URLs!”\n\nstr_extract_all(string, \"https?://[:graph:]+\")\n\n[[1]]\n[1] \"https://t.co/YHyqTguVWx\"\n\n\nDas Fragezeichen ? ist eine Quantitätsoperator, der einen Treffer liefert, wenn das vorherige Zeichen (hier s) null oder einmal gefunden wird. [:graph:] ist die Summe von [:alpha:] (Buchstaben, groß und klein), [:digit:] (Ziffern) und [:punct:] (Satzzeichen u.ä.).\n“Zähle die Wörter im String!”\n\nstr_count(string, boundary(\"word\"))\n\n[1] 13\n\n\n“Liefere nur Buchstabenfolgen zurück, lösche alles übrige”\n\nstr_extract_all(string, \"[:alpha:]+\")\n\n[[1]]\n [1] \"Correlation\"  \"of\"           \"unemployment\" \"and\"          \"AfD\"         \n [6] \"votes\"        \"at\"           \"btw\"          \"r\"            \"https\"       \n[11] \"t\"            \"co\"           \"YHyqTguVWx\"  \n\n\nDer Quantitätsoperator + liefert alle Stellen zurück, in denen der gesuchte Ausdruck einmal oder häufiger vorkommt. Die Ergebnisse werden als Vektor von Wörtern zurückgegeben. Ein anderer Quantitätsoperator ist *, der für 0 oder mehr Treffer steht. Möchte man einen Vektor, der aus Stringen-Elementen besteht zu einem Strring zusammenfüngen, hilft paste(string) oder str_c(string, collapse = \" \").\n\nstr_replace_all(string, \"[^[:alpha:]+]\", \"\")\n\n[1] \"CorrelationofunemploymentandAfDvotesatbtwrhttpstcoYHyqTguVWx\"\n\n\nMit dem Negationsoperator [^x] wird der Regulärausrck x negiert; die Syntax oben heißt also “ersetze in string alles außer Buchstaben durch Nichts”. Mit “Nichts” sind hier Strings der Länge Null gemeint; ersetzt man einen belieibgen String durch einen String der Länge Null, so hat man den String gelöscht.\nDas Cheatsheet zur Strings bzw zu stringr von RStudio gibt einen guten Überblick über Regex; im Internet finden sich viele Beispiele.\n\n\n\n3.2.6 Sentimentanalyse\n\n3.2.6.1 Einführung\nEine weitere interessante Analyse ist, die “Stimmung” oder “Emotionen” (Sentiments) eines Textes auszulesen. Die Anführungszeichen deuten an, dass hier ein Maß an Verständnis suggeriert wird, welches nicht (unbedingt) von der Analyse eingehalten wird. Jedenfalls ist das Prinzip der Sentiment-Analyse im einfachsten Fall so:\n\nSchau dir jeden Token aus dem Text an.\n\nPrüfe, ob sich das Wort im Lexikon der Sentiments wiederfindet.\n\nWenn ja, dann addiere den Sentimentswert dieses Tokens zum bestehenden Sentiments-Wert.\n\nWenn nein, dann gehe weiter zum nächsten Wort.\n\nLiefere zum Schluss die Summenwerte pro Sentiment zurück.\n\nEs gibt Sentiment-Lexika, die lediglich einen Punkt für “positive Konnotation” bzw. “negative Konnotation” geben; andere Lexiko weisen differenzierte Gefühlskonnotationen auf. Wir nutzen hier das Sentimentlexikon sentiws (Remus, Quasthoff, und Heyer 2010). Sie können das Lexikon als CSV hier herunterladen:\n\nsentiws <- read_csv(\"https://osf.io/x89wq/?action=download\")\n\nDen Volltext zum Paper finden Sie z.B. hier.\nAlternativ können Sie die Daten aus dem Paket pradadata laden. Allerdings müssen Sie dieses Paket von Github installieren:\n\ninstall.packages(\"devtools\", dep = TRUE)\ndevtools::install_github(\"sebastiansauer/pradadata\")\n\n\ndata(sentiws, package = \"pradadata\")\n\nTabelle (tab-afdcount?) zeigt einen Ausschnitt aus dem Sentiment-Lexikon SentiWS.\n\n\n\n\nAuszug aus SentiWS \n\n\nneg_pos\nword\nvalue\ninflections\n\n\n\n\nneg\nAbbau\n-0.0580\nAbbaus,Abbaues,Abbauen,Abbaue\n\n\nneg\nAbbruch\n-0.0048\nAbbruches,Abbrüche,Abbruchs,Abbrüchen\n\n\nneg\nAbdankung\n-0.0048\nAbdankungen\n\n\nneg\nAbdämpfung\n-0.0048\nAbdämpfungen\n\n\nneg\nAbfall\n-0.0048\nAbfalles,Abfälle,Abfalls,Abfällen\n\n\nneg\nAbfuhr\n-0.3367\nAbfuhren\n\n\n\n\n\n\n\n\n3.2.6.2 Ungewichtete Sentiment-Analyse\nNun können wir jedes Token des Textes mit dem Sentiment-Lexikon abgleichen; dabei zählen wir die Treffer für positive bzw. negative Terme. Zuvor müssen wir aber noch die Daten (afd_long) mit dem Sentimentlexikon zusammenführen (joinen). Das geht nach bewährter Manier mit inner_join; “inner” sorgt dabei dafür, dass nur Zeilen behalten werden, die in beiden Dataframes vorkommen. Tabelle (tab-afd-senti-tab?) zeigt Summe, Anzahl und Anteil der Emotionswerte.\nWir nutzen die Tabelle afd_long, die wir oben definiert haben.\n\nafd_long %>% \n  inner_join(sentiws, by = c(\"token\" = \"word\")) %>% \n  select(-inflections) -> afd_senti  # die Spalte brauchen wir nicht\n\nafd_senti %>% \n  group_by(neg_pos) %>% \n  summarise(polarity_sum = sum(value),\n            polarity_count = n()) %>% \n  mutate(polarity_prop = (polarity_count / sum(polarity_count)) %>% round(2)) ->\n  afd_senti_tab\n\n\n\n\n\ntab-afd-senti-tab \n\n\nneg_pos\npolarity_sum\npolarity_count\npolarity_prop\n\n\n\n\nneg\n-48.5307\n210\n0.27\n\n\npos\n30.6595\n578\n0.73\n\n\n\n\n\n\nDie Analyse zeigt, dass die emotionale Bauart des Textes durchaus interessant ist: Es gibt viel mehr positiv getönte Wörter als negativ getönte. Allerdings sind die negativen Wörter offenbar deutlich stärker emotional aufgeladen, denn die Summe an Emotionswert der negativen Wörter ist (überraschenderweise?) deutlich größer als die der positiven.\nBetrachten wir also die intensivsten negativ und positive konnotierten Wörter näher.\n\nafd_senti %>% \n  distinct(token, .keep_all = TRUE) %>% \n  mutate(value_abs = abs(value)) %>% \n  top_n(20, value_abs) %>% \n  pull(token)\n\n [1] \"ungerecht\"    \"besonders\"    \"gefährlich\"   \"überflüssig\"  \"behindern\"   \n [6] \"gelungen\"     \"brechen\"      \"unzureichend\" \"gemein\"       \"verletzt\"    \n[11] \"zerstören\"    \"trennen\"      \"falsch\"       \"vermeiden\"    \"zerstört\"    \n[16] \"schwach\"      \"belasten\"     \"schädlich\"    \"töten\"        \"verbieten\"   \n\n\nDiese “Hitliste” wird zumeist (19/20) von negativ polarisierten Begriffen aufgefüllt, wobei “besonders” ein Intensivierwort ist, welches das Bezugswort verstärt (“besonders gefährlich”). Das Argument keep_all = TRUE sorgt dafür, dass alle Spalten zurückgegeben werden, nicht nur die durchsuchte Spalte token. Mit pull haben wir aus dem Dataframe, der von den dplyr-Verben übergeben wird, die Spalte pull “herausgezogen”; hier nur um Platz zu sparen bzw. der Übersichtlichkeit halber.\nNun könnte man noch den erzielten “Netto-Sentimentswert” des Corpus ins Verhältnis setzen Sentimentswert des Lexikons: Wenn es insgesamt im Sentiment-Lexikon sehr negativ zuginge, wäre ein negativer Sentimentwer in einem beliebigen Corpus nicht überraschend. describe_distribution aus {easystats} gibt uns einen Überblick der üblichen deskriptiven Statistiken.\n\nsentiws %>% \n  select(value, neg_pos) %>% \n  #group_by(neg_pos) %>% \n  describe_distribution()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nMean\nSD\nIQR\nMin\nMax\nSkewness\nKurtosis\nn\nn_Missing\n\n\n\n\nvalue\n-0.0539057\n0.2040508\n0.0474\n-1\n1\n-0.6843984\n2.364438\n3468\n0\n\n\n\n\n\n\nInsgesamt ist das Lexikon ziemlich ausgewogen; negative Werte sind leicht in der Überzahl im Lexikon. Unser Corpus hat eine ähnliche mittlere emotionale Konnotation wie das Lexikon:\n\nafd_senti %>% \n  summarise(senti_sum = mean(value) %>% round(2))\n\n\n\n\n\nsenti_sum\n\n\n\n\n-0.02"
  },
  {
    "objectID": "textmining1.html#aufgaben",
    "href": "textmining1.html#aufgaben",
    "title": "3  Grundlagen des Textmining",
    "section": "3.3 Aufgaben",
    "text": "3.3 Aufgaben\n\npurrr-map01\npurrr-map02\npurrr-map03\npurrr-map04"
  },
  {
    "objectID": "textmining1.html#fallstudie-hate-speech",
    "href": "textmining1.html#fallstudie-hate-speech",
    "title": "3  Grundlagen des Textmining",
    "section": "3.4 Fallstudie Hate-Speech",
    "text": "3.4 Fallstudie Hate-Speech\n\n3.4.1 Daten\nEs finden sich mehrere Datensätze zum Thema Hate-Speech im öffentlichen Internet, eine Quelle ist Hate Speech Data, ein Repositorium, das mehrere Datensätze beinhaltet.\n\nKaggle Hate Speech and Offensive Language Dataset\nBretschneider and Peters Prejudice on Facebook Dataset\nDaten zum Fachartikel”Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior”\n\nTwitterdaten dürfen nur in “dehydrierter” Form weitergegeben werden, so dass kein Rückschluss von ID zum Inhalt des Tweets möglich ist. Daher werden öffentlich nur die IDs der Tweets, als einzige Information zum Tweet, a lso ohne den eigentlichen Inhalt des Tweets, bereitgestellt.\nÜber die Twitter-API kann man sich, wie oben dargestellt, dann die Tweets wieder “rehydrieren”, also wieder mit dem zugehörigen Tweet-Text (und sonstigen Infos des Tweets) zu versehen.\n\n\n3.4.2 Grundlegendes Text Mining\nWenden Sie die oben aufgeführten Techniken des grundlegenden Textminings auf einen der oben dargestellten Hate-Speech-Datensätze an. Erstellen Sie ein (HTML-Dokument) mit Ihren Ergebnissen. Stellen Sie die Ergebnisse auf dem Github-Repo dieses Kurses ein. Vergleichen Sie Ihre Lösung mit den Lösungen der anderen Kursmitglieder.\nWir nutzen noch nicht eigene Daten, die wir von Twitter ausgelesen haben, das heben wir uns für später auf.\n\n\n\n\nHvitfeldt, Emil, und Julia Silge. 2022. Supervised Machine Learning for Text Analysis in R. 1. Aufl. Boca Raton: Chapman; Hall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nLex, Alexander, Nils Gehlenborg, Hendrik Strobelt, Romain Vuillemot, und Hanspeter Pfister. 2014. „UpSet: Visualization of Intersecting Sets“. IEEE Transactions on Visualization and Computer Graphics 20 (12): 1983–92. https://doi.org/10.1109/TVCG.2014.2346248.\n\n\nRemus, Robert, Uwe Quasthoff, und Gerhard Heyer. 2010. „SentiWS - a Publicly Available German-language Resource for Sentiment Analysis“. Proceedings of the 7th International Language Ressources and Evaluation (LREC’10), 1168–71.\n\n\nWickham, Hadley, und Garrett Grolemund. 2018. R für Data Science: Daten importieren, bereinigen, umformen, modellieren und visualisieren. Übersetzt von Frank Langenau. 1. Auflage. Heidelberg: O’Reilly. https://r4ds.had.co.nz/index.html."
  },
  {
    "objectID": "populismus.html",
    "href": "populismus.html",
    "title": "4  Fallstudie Populismus",
    "section": "",
    "text": "Bild von mcmurryjulie auf Pixabay"
  },
  {
    "objectID": "populismus.html#wie-populistisch-tweeten-unsere-politikerinnen",
    "href": "populismus.html#wie-populistisch-tweeten-unsere-politikerinnen",
    "title": "4  Fallstudie Populismus",
    "section": "4.1 Wie populistisch tweeten unsere Politiker:innen?",
    "text": "4.1 Wie populistisch tweeten unsere Politiker:innen?\nVerschaffen Sie sich einen Überblick über dieses Projekt! Im Rahmen dieses Projekts vergleicht der Autor den Populismus von deutschen Politiker:innen, so wie er sich in den Tweets dieser Personen niederschlägt. Auf dieser Basis wird ein Populismuswert, bestehend aus mehreren Teilwerten, berechnet und auf Parteiebenen (als Mittel der zugehörigen Politiker:innen) berechnet. Natürlich fragt man sich, wie Populismus definiert ist und wie diese Definition in den Berechnungen umgesetzt wurde. Finden Sie es selber heraus: Im Github-Repo sind alle Details dokumentiert.\nZum Einstieg hilft ein Überblick über die Ergebnisse der Analyse, die in diesem Vortrag zusammengefasst sind.\nDieser Post stellt die Ergebnisse mit etwas Kontext dar."
  },
  {
    "objectID": "word-embedding.html",
    "href": "word-embedding.html",
    "title": "5  Word Embedding",
    "section": "",
    "text": "Arbeiten Sie Hvitfeldt und Silge (2022), Kap. 5 durch.\n\n\n\n\nHvitfeldt, Emil, und Julia Silge. 2022. Supervised Machine Learning for Text Analysis in R. 1. Aufl. Boca Raton: Chapman; Hall/CRC. https://doi.org/10.1201/9781003093459."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Hvitfeldt, Emil, and Julia Silge. 2022. Supervised Machine Learning\nfor Text Analysis in r. 1st ed. Boca Raton: Chapman;\nHall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nKönig, Tim, Wolf J. Schünemann, Alexander Brand, Julian Freyberg, and\nMichael Gertz. 2022. “The EPINetz Twitter Politicians\nDataset 2021. A New Resource for the Study of the German Twittersphere\nand Its Application for the 2021 Federal Elections.”\nPolitische Vierteljahresschrift 63 (3): 529–47. https://doi.org/10.1007/s11615-022-00405-7.\n\n\nLex, Alexander, Nils Gehlenborg, Hendrik Strobelt, Romain Vuillemot, and\nHanspeter Pfister. 2014. “UpSet: Visualization of\nIntersecting Sets.” IEEE Transactions on\nVisualization and Computer Graphics 20 (12): 1983–92. https://doi.org/10.1109/TVCG.2014.2346248.\n\n\nRemus, Robert, Uwe Quasthoff, and Gerhard Heyer. 2010.\n“SentiWS - a Publicly Available German-Language\nResource for Sentiment Analysis.” Proceedings of the 7th\nInternational Language Ressources and Evaluation\n(LREC’10), 1168–71.\n\n\nWickham, Hadley, and Garrett Grolemund. 2018. R Für Data Science:\nDaten Importieren, Bereinigen, Umformen, Modellieren Und\nVisualisieren. Translated by Frank Langenau. 1. Auflage.\nHeidelberg: O’Reilly. https://r4ds.had.co.nz/index.html."
  }
]