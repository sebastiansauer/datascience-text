[
  {
    "objectID": "125-fallstudie-keras1.html#lernsteuerung",
    "href": "125-fallstudie-keras1.html#lernsteuerung",
    "title": "\n16¬† Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.1 Lernsteuerung",
    "text": "16.1 Lernsteuerung\n\n16.1.1 Lernziele\nNach Abschluss dieses Kapitels ‚Ä¶\n\nein einfaches neuronales Netzwerk mit Keras erstellen zur Klassifikation von Hate-Speech.\n\n16.1.2 √úberblick\nIn diesem Kapitel nutzen wir grundlegende Methoden neuronaler Netze, um Hate-Speech vorherzusagen. Dabei findet der Datensatz GermEval Verwendung. Zun√§chst verwenden wir den schon aufbereiteten Datensatz, das macht es uns einfacher. Dieser aufbereitete Datensatz ist schon ‚Äúnumerisiert‚Äù1. Der Text der Tweets ist schon in numerische Pr√§diktoren umgewandelt. Dabei fanden einfache (deutschsprachige) Wordvektoren (wikipedia2vec) Verwendung. In diesem Kapitel arbeiten wir mit ausschlie√ülich mit Python.\n\n16.1.3 Ben√∂tigte R-Pakete\n\n# keines :-)\n\n\n16.1.4 Python-Check\n\nreticulate::py_available()\n## [1] FALSE\nreticulate::py_config()\n## python:         /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/bin/python\n## libpython:      /Users/sebastiansaueruser/.pyenv/versions/3.8.16/lib/libpython3.8.dylib\n## pythonhome:     /Users/sebastiansaueruser/.virtualenvs/r-tensorflow:/Users/sebastiansaueruser/.virtualenvs/r-tensorflow\n## version:        3.8.16 (default, Sep 15 2023, 17:53:02)  [Clang 14.0.3 (clang-1403.0.22.14.1)]\n## numpy:          /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/lib/python3.8/site-packages/numpy\n## numpy_version:  1.24.3\n## \n## NOTE: Python version was forced by VIRTUAL_ENV\n\n\n16.1.5 Ben√∂tigte Python-Module\n\nimport keras\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import accuracy_score",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "125-fallstudie-keras1.html#pipeline-mit-1-hidden-layer",
    "href": "125-fallstudie-keras1.html#pipeline-mit-1-hidden-layer",
    "title": "\n16¬† Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.2 Pipeline mit 1 Hidden Layer",
    "text": "16.2 Pipeline mit 1 Hidden Layer\n\n16.2.1 Daten\n\nd_train_baked = pd.read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_train_recipe_wordvec_senti.csv\")\n\nd_train_num = d_train_baked.select_dtypes(include='number')\n\nd_train2 = d_train_baked.loc[:, \"emo_count\":\"wordembed_text_V101\"]\n\nX_train = d_train2.values\n\nd_train_baked[\"y\"] = d_train_baked[\"c1\"].map({\"OTHER\" : 0, \"OFFENSE\" : 1})\n\ny_train = d_train_baked.loc[:, \"y\"].values\n\nHead von y_train:\n\nprint(y_train[:6])\n## [0 0 0 0 1 0]\n\nInfo zum Objekt:\n\nd_train2.info()\n## &lt;class 'pandas.core.frame.DataFrame'&gt;\n## RangeIndex: 5009 entries, 0 to 5008\n## Columns: 119 entries, emo_count to wordembed_text_V101\n## dtypes: float64(119)\n## memory usage: 4.5 MB\n\nHead von y_train2:\n\nprint(d_train2.head())\n##    emo_count  schimpf_count  ...  wordembed_text_V100  wordembed_text_V101\n## 0   0.574594      -0.450067  ...            -0.449265            -0.277801\n## 1  -1.111107      -0.450067  ...             0.974438             0.223422\n## 2   0.186402      -0.450067  ...             0.407285             0.470835\n## 3   0.201551      -0.450067  ...            -0.681155             0.351565\n## 4   0.168223      -0.450067  ...            -0.674108             0.543312\n## \n## [5 rows x 119 columns]\n\n\nd_test_baked = pd.read_csv(\"https://raw.githubusercontent.com/sebastiansauer/Datenwerk2/main/data/germeval/germeval_test_recipe_wordvec_senti.csv\")\n\nd_test_num = d_test_baked.select_dtypes(include='number')\n\nd_test2 = d_test_baked.loc[:, \"emo_count\":\"wordembed_text_V101\"]\n\nX_test = d_test2.values\n\n\nd_test_baked[\"y\"] = d_test_baked[\"c1\"].map({\"OTHER\" : 0, \"OFFENSE\" : 1})\n\ny_test = d_test_baked.loc[:, \"y\"].values\n\n\nprint(y_test[:5])\n## [0 0 0 0 1]\n\n\n16.2.2 Modeldefinition\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n\n16.2.3 Fit\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n## Epoch 1/10\n## \n 1/79 [..............................] - ETA: 57s - loss: 0.9031 - accuracy: 0.4688\n32/79 [===========&gt;..................] - ETA: 0s - loss: 0.7415 - accuracy: 0.5435 \n66/79 [========================&gt;.....] - ETA: 0s - loss: 0.6537 - accuracy: 0.6264\n79/79 [==============================] - 1s 5ms/step - loss: 0.6366 - accuracy: 0.6396 - val_loss: 0.5578 - val_accuracy: 0.7166\n## Epoch 2/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.5155 - accuracy: 0.7969\n36/79 [============&gt;.................] - ETA: 0s - loss: 0.5192 - accuracy: 0.7374\n70/79 [=========================&gt;....] - ETA: 0s - loss: 0.5059 - accuracy: 0.7473\n79/79 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7479 - val_loss: 0.5491 - val_accuracy: 0.7262\n## Epoch 3/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.5058 - accuracy: 0.7344\n36/79 [============&gt;.................] - ETA: 0s - loss: 0.4703 - accuracy: 0.7726\n71/79 [=========================&gt;....] - ETA: 0s - loss: 0.4771 - accuracy: 0.7658\n79/79 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7678 - val_loss: 0.5540 - val_accuracy: 0.7273\n## Epoch 4/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.4064 - accuracy: 0.7969\n36/79 [============&gt;.................] - ETA: 0s - loss: 0.4464 - accuracy: 0.7860\n73/79 [==========================&gt;...] - ETA: 0s - loss: 0.4523 - accuracy: 0.7815\n79/79 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7820 - val_loss: 0.5623 - val_accuracy: 0.7240\n## Epoch 5/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.3533 - accuracy: 0.8438\n35/79 [============&gt;.................] - ETA: 0s - loss: 0.4413 - accuracy: 0.7915\n71/79 [=========================&gt;....] - ETA: 0s - loss: 0.4400 - accuracy: 0.7931\n79/79 [==============================] - 0s 3ms/step - loss: 0.4380 - accuracy: 0.7944 - val_loss: 0.5607 - val_accuracy: 0.7248\n## Epoch 6/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.3845 - accuracy: 0.8281\n34/79 [===========&gt;..................] - ETA: 0s - loss: 0.4141 - accuracy: 0.8051\n70/79 [=========================&gt;....] - ETA: 0s - loss: 0.4201 - accuracy: 0.7998\n79/79 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.7978 - val_loss: 0.5656 - val_accuracy: 0.7251\n## Epoch 7/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.4457 - accuracy: 0.7812\n24/79 [========&gt;.....................] - ETA: 0s - loss: 0.4157 - accuracy: 0.8027\n57/79 [====================&gt;.........] - ETA: 0s - loss: 0.4115 - accuracy: 0.8062\n79/79 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8065 - val_loss: 0.5689 - val_accuracy: 0.7282\n## Epoch 8/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.3460 - accuracy: 0.8906\n32/79 [===========&gt;..................] - ETA: 0s - loss: 0.3959 - accuracy: 0.8184\n67/79 [========================&gt;.....] - ETA: 0s - loss: 0.3945 - accuracy: 0.8190\n79/79 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.8169 - val_loss: 0.5731 - val_accuracy: 0.7268\n## Epoch 9/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.4085 - accuracy: 0.7969\n21/79 [======&gt;.......................] - ETA: 0s - loss: 0.3617 - accuracy: 0.8549\n49/79 [=================&gt;............] - ETA: 0s - loss: 0.3765 - accuracy: 0.8339\n76/79 [===========================&gt;..] - ETA: 0s - loss: 0.3832 - accuracy: 0.8283\n79/79 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8271 - val_loss: 0.5836 - val_accuracy: 0.7268\n## Epoch 10/10\n## \n 1/79 [..............................] - ETA: 0s - loss: 0.2995 - accuracy: 0.8906\n26/79 [========&gt;.....................] - ETA: 0s - loss: 0.3683 - accuracy: 0.8335\n52/79 [==================&gt;...........] - ETA: 0s - loss: 0.3717 - accuracy: 0.8287\n78/79 [============================&gt;.] - ETA: 0s - loss: 0.3725 - accuracy: 0.8305\n79/79 [==============================] - 0s 3ms/step - loss: 0.3726 - accuracy: 0.8305 - val_loss: 0.5840 - val_accuracy: 0.7265\n## &lt;keras.src.callbacks.History object at 0x137a43ac0&gt;\n\n\n16.2.4 Fazit\nSchon mit diesem einfachen Netzwerk, das sich schnell berechnen l√§sst, √ºbertreffen wir auf Anhieb die Modellg√ºte (Gesamtgenauigkeit) der Shallow-Learners aus fr√ºheren Kapiteln.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "125-fallstudie-keras1.html#pipeline-mit-2-hidden-layers",
    "href": "125-fallstudie-keras1.html#pipeline-mit-2-hidden-layers",
    "title": "\n16¬† Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.3 Pipeline mit 2 Hidden Layers",
    "text": "16.3 Pipeline mit 2 Hidden Layers\nWir verwenden die gleichen Daten wie oben.\nWir f√ºgen eine zweite Hidden Layer hinzu. Au√üerdem ver√§ndern wir die Batch-Size.\n\n16.3.1 Modeldefinition\n\nmodel = Sequential()\nmodel.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\nmodel.add(Dense(units=32, activation='relu'))  # Second hidden layer\nmodel.add(Dense(1, activation='sigmoid'))\n\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n\n16.3.2 Fit\n\nmodel.fit(X_train, y_train, epochs=10, batch_size=8, validation_data=(X_test, y_test))\n## Epoch 1/10\n## \n  1/627 [..............................] - ETA: 8:54 - loss: 0.6587 - accuracy: 0.5000\n 28/627 [&gt;.............................] - ETA: 1s - loss: 0.6542 - accuracy: 0.6384  \n 56/627 [=&gt;............................] - ETA: 1s - loss: 0.6259 - accuracy: 0.6562\n 86/627 [===&gt;..........................] - ETA: 0s - loss: 0.6204 - accuracy: 0.6570\n119/627 [====&gt;.........................] - ETA: 0s - loss: 0.6080 - accuracy: 0.6691\n153/627 [======&gt;.......................] - ETA: 0s - loss: 0.6012 - accuracy: 0.6748\n189/627 [========&gt;.....................] - ETA: 0s - loss: 0.5924 - accuracy: 0.6779\n224/627 [=========&gt;....................] - ETA: 0s - loss: 0.5813 - accuracy: 0.6864\n255/627 [===========&gt;..................] - ETA: 0s - loss: 0.5744 - accuracy: 0.6926\n291/627 [============&gt;.................] - ETA: 0s - loss: 0.5744 - accuracy: 0.6942\n327/627 [==============&gt;...............] - ETA: 0s - loss: 0.5726 - accuracy: 0.6957\n332/627 [==============&gt;...............] - ETA: 0s - loss: 0.5713 - accuracy: 0.6969\n366/627 [================&gt;.............] - ETA: 0s - loss: 0.5658 - accuracy: 0.7018\n401/627 [==================&gt;...........] - ETA: 0s - loss: 0.5634 - accuracy: 0.7042\n438/627 [===================&gt;..........] - ETA: 0s - loss: 0.5616 - accuracy: 0.7072\n473/627 [=====================&gt;........] - ETA: 0s - loss: 0.5554 - accuracy: 0.7106\n509/627 [=======================&gt;......] - ETA: 0s - loss: 0.5552 - accuracy: 0.7110\n545/627 [=========================&gt;....] - ETA: 0s - loss: 0.5522 - accuracy: 0.7149\n582/627 [==========================&gt;...] - ETA: 0s - loss: 0.5497 - accuracy: 0.7174\n617/627 [============================&gt;.] - ETA: 0s - loss: 0.5499 - accuracy: 0.7180\n627/627 [==============================] - 3s 3ms/step - loss: 0.5477 - accuracy: 0.7181 - val_loss: 0.5593 - val_accuracy: 0.7214\n## Epoch 2/10\n## \n  1/627 [..............................] - ETA: 0s - loss: 0.1919 - accuracy: 1.0000\n 36/627 [&gt;.............................] - ETA: 0s - loss: 0.4186 - accuracy: 0.8194\n 71/627 [==&gt;...........................] - ETA: 0s - loss: 0.4415 - accuracy: 0.8046\n105/627 [====&gt;.........................] - ETA: 0s - loss: 0.4356 - accuracy: 0.8036\n141/627 [=====&gt;........................] - ETA: 0s - loss: 0.4379 - accuracy: 0.7979\n175/627 [=======&gt;......................] - ETA: 0s - loss: 0.4489 - accuracy: 0.7893\n211/627 [=========&gt;....................] - ETA: 0s - loss: 0.4469 - accuracy: 0.7885\n246/627 [==========&gt;...................] - ETA: 0s - loss: 0.4488 - accuracy: 0.7881\n282/627 [============&gt;.................] - ETA: 0s - loss: 0.4509 - accuracy: 0.7877\n317/627 [==============&gt;...............] - ETA: 0s - loss: 0.4441 - accuracy: 0.7898\n354/627 [===============&gt;..............] - ETA: 0s - loss: 0.4508 - accuracy: 0.7871\n389/627 [=================&gt;............] - ETA: 0s - loss: 0.4538 - accuracy: 0.7831\n425/627 [===================&gt;..........] - ETA: 0s - loss: 0.4540 - accuracy: 0.7815\n460/627 [=====================&gt;........] - ETA: 0s - loss: 0.4549 - accuracy: 0.7793\n491/627 [======================&gt;.......] - ETA: 0s - loss: 0.4589 - accuracy: 0.7777\n525/627 [========================&gt;.....] - ETA: 0s - loss: 0.4598 - accuracy: 0.7769\n561/627 [=========================&gt;....] - ETA: 0s - loss: 0.4598 - accuracy: 0.7790\n593/627 [===========================&gt;..] - ETA: 0s - loss: 0.4589 - accuracy: 0.7789\n623/627 [============================&gt;.] - ETA: 0s - loss: 0.4577 - accuracy: 0.7791\n627/627 [==============================] - 2s 3ms/step - loss: 0.4568 - accuracy: 0.7796 - val_loss: 0.5706 - val_accuracy: 0.7285\n## Epoch 3/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.4661 - accuracy: 0.5000\n 36/627 [&gt;.............................] - ETA: 0s - loss: 0.4126 - accuracy: 0.7847\n 70/627 [==&gt;...........................] - ETA: 0s - loss: 0.4173 - accuracy: 0.7929\n100/627 [===&gt;..........................] - ETA: 0s - loss: 0.4206 - accuracy: 0.8025\n132/627 [=====&gt;........................] - ETA: 0s - loss: 0.4117 - accuracy: 0.8078\n167/627 [======&gt;.......................] - ETA: 0s - loss: 0.4155 - accuracy: 0.8046\n202/627 [========&gt;.....................] - ETA: 0s - loss: 0.4129 - accuracy: 0.8069\n233/627 [==========&gt;...................] - ETA: 0s - loss: 0.4146 - accuracy: 0.8063\n267/627 [===========&gt;..................] - ETA: 0s - loss: 0.4173 - accuracy: 0.8034\n298/627 [=============&gt;................] - ETA: 0s - loss: 0.4177 - accuracy: 0.8054\n326/627 [==============&gt;...............] - ETA: 0s - loss: 0.4154 - accuracy: 0.8067\n357/627 [================&gt;.............] - ETA: 0s - loss: 0.4143 - accuracy: 0.8074\n380/627 [=================&gt;............] - ETA: 0s - loss: 0.4139 - accuracy: 0.8076\n407/627 [==================&gt;...........] - ETA: 0s - loss: 0.4154 - accuracy: 0.8050\n428/627 [===================&gt;..........] - ETA: 0s - loss: 0.4137 - accuracy: 0.8055\n458/627 [====================&gt;.........] - ETA: 0s - loss: 0.4140 - accuracy: 0.8051\n489/627 [======================&gt;.......] - ETA: 0s - loss: 0.4164 - accuracy: 0.8037\n517/627 [=======================&gt;......] - ETA: 0s - loss: 0.4159 - accuracy: 0.8044\n548/627 [=========================&gt;....] - ETA: 0s - loss: 0.4174 - accuracy: 0.8043\n574/627 [==========================&gt;...] - ETA: 0s - loss: 0.4170 - accuracy: 0.8051\n600/627 [===========================&gt;..] - ETA: 0s - loss: 0.4162 - accuracy: 0.8067\n626/627 [============================&gt;.] - ETA: 0s - loss: 0.4140 - accuracy: 0.8075\n627/627 [==============================] - 2s 3ms/step - loss: 0.4140 - accuracy: 0.8075 - val_loss: 0.6027 - val_accuracy: 0.7248\n## Epoch 4/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.3053 - accuracy: 0.7500\n 32/627 [&gt;.............................] - ETA: 0s - loss: 0.3231 - accuracy: 0.8672\n 62/627 [=&gt;............................] - ETA: 0s - loss: 0.3515 - accuracy: 0.8407\n 93/627 [===&gt;..........................] - ETA: 0s - loss: 0.3484 - accuracy: 0.8562\n120/627 [====&gt;.........................] - ETA: 0s - loss: 0.3372 - accuracy: 0.8583\n153/627 [======&gt;.......................] - ETA: 0s - loss: 0.3312 - accuracy: 0.8603\n183/627 [=======&gt;......................] - ETA: 0s - loss: 0.3439 - accuracy: 0.8518\n212/627 [=========&gt;....................] - ETA: 0s - loss: 0.3443 - accuracy: 0.8532\n226/627 [=========&gt;....................] - ETA: 0s - loss: 0.3461 - accuracy: 0.8507\n245/627 [==========&gt;...................] - ETA: 0s - loss: 0.3511 - accuracy: 0.8495\n269/627 [===========&gt;..................] - ETA: 0s - loss: 0.3523 - accuracy: 0.8494\n288/627 [============&gt;.................] - ETA: 0s - loss: 0.3567 - accuracy: 0.8455\n317/627 [==============&gt;...............] - ETA: 0s - loss: 0.3589 - accuracy: 0.8442\n346/627 [===============&gt;..............] - ETA: 0s - loss: 0.3659 - accuracy: 0.8396\n376/627 [================&gt;.............] - ETA: 0s - loss: 0.3672 - accuracy: 0.8371\n397/627 [=================&gt;............] - ETA: 0s - loss: 0.3673 - accuracy: 0.8369\n425/627 [===================&gt;..........] - ETA: 0s - loss: 0.3697 - accuracy: 0.8350\n447/627 [====================&gt;.........] - ETA: 0s - loss: 0.3711 - accuracy: 0.8353\n467/627 [=====================&gt;........] - ETA: 0s - loss: 0.3726 - accuracy: 0.8362\n492/627 [======================&gt;.......] - ETA: 0s - loss: 0.3726 - accuracy: 0.8364\n511/627 [=======================&gt;......] - ETA: 0s - loss: 0.3726 - accuracy: 0.8371\n537/627 [========================&gt;.....] - ETA: 0s - loss: 0.3756 - accuracy: 0.8350\n568/627 [==========================&gt;...] - ETA: 0s - loss: 0.3755 - accuracy: 0.8343\n595/627 [===========================&gt;..] - ETA: 0s - loss: 0.3756 - accuracy: 0.8334\n622/627 [============================&gt;.] - ETA: 0s - loss: 0.3751 - accuracy: 0.8336\n627/627 [==============================] - 2s 3ms/step - loss: 0.3753 - accuracy: 0.8333 - val_loss: 0.6474 - val_accuracy: 0.7101\n## Epoch 5/10\n## \n  1/627 [..............................] - ETA: 0s - loss: 0.4109 - accuracy: 0.7500\n 37/627 [&gt;.............................] - ETA: 0s - loss: 0.3228 - accuracy: 0.8818\n 70/627 [==&gt;...........................] - ETA: 0s - loss: 0.3331 - accuracy: 0.8643\n106/627 [====&gt;.........................] - ETA: 0s - loss: 0.3080 - accuracy: 0.8774\n144/627 [=====&gt;........................] - ETA: 0s - loss: 0.3092 - accuracy: 0.8724\n180/627 [=======&gt;......................] - ETA: 0s - loss: 0.3196 - accuracy: 0.8611\n216/627 [=========&gt;....................] - ETA: 0s - loss: 0.3272 - accuracy: 0.8559\n247/627 [==========&gt;...................] - ETA: 0s - loss: 0.3281 - accuracy: 0.8548\n274/627 [============&gt;.................] - ETA: 0s - loss: 0.3275 - accuracy: 0.8540\n295/627 [=============&gt;................] - ETA: 0s - loss: 0.3305 - accuracy: 0.8504\n314/627 [==============&gt;...............] - ETA: 0s - loss: 0.3297 - accuracy: 0.8527\n335/627 [===============&gt;..............] - ETA: 0s - loss: 0.3285 - accuracy: 0.8537\n365/627 [================&gt;.............] - ETA: 0s - loss: 0.3286 - accuracy: 0.8565\n393/627 [=================&gt;............] - ETA: 0s - loss: 0.3289 - accuracy: 0.8569\n423/627 [===================&gt;..........] - ETA: 0s - loss: 0.3304 - accuracy: 0.8561\n453/627 [====================&gt;.........] - ETA: 0s - loss: 0.3323 - accuracy: 0.8551\n482/627 [======================&gt;.......] - ETA: 0s - loss: 0.3368 - accuracy: 0.8527\n512/627 [=======================&gt;......] - ETA: 0s - loss: 0.3374 - accuracy: 0.8525\n547/627 [=========================&gt;....] - ETA: 0s - loss: 0.3359 - accuracy: 0.8544\n581/627 [==========================&gt;...] - ETA: 0s - loss: 0.3340 - accuracy: 0.8552\n617/627 [============================&gt;.] - ETA: 0s - loss: 0.3361 - accuracy: 0.8539\n627/627 [==============================] - 2s 2ms/step - loss: 0.3359 - accuracy: 0.8537 - val_loss: 0.6784 - val_accuracy: 0.7129\n## Epoch 6/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.1333 - accuracy: 1.0000\n 37/627 [&gt;.............................] - ETA: 0s - loss: 0.2734 - accuracy: 0.8784\n 74/627 [==&gt;...........................] - ETA: 0s - loss: 0.2664 - accuracy: 0.8953\n108/627 [====&gt;.........................] - ETA: 0s - loss: 0.2676 - accuracy: 0.8831\n145/627 [=====&gt;........................] - ETA: 0s - loss: 0.2765 - accuracy: 0.8767\n182/627 [=======&gt;......................] - ETA: 0s - loss: 0.2808 - accuracy: 0.8805\n213/627 [=========&gt;....................] - ETA: 0s - loss: 0.2856 - accuracy: 0.8762\n248/627 [==========&gt;...................] - ETA: 0s - loss: 0.2890 - accuracy: 0.8755\n279/627 [============&gt;.................] - ETA: 0s - loss: 0.2914 - accuracy: 0.8768\n309/627 [=============&gt;................] - ETA: 0s - loss: 0.2889 - accuracy: 0.8786\n329/627 [==============&gt;...............] - ETA: 0s - loss: 0.2903 - accuracy: 0.8784\n347/627 [===============&gt;..............] - ETA: 0s - loss: 0.2896 - accuracy: 0.8779\n367/627 [================&gt;.............] - ETA: 0s - loss: 0.2911 - accuracy: 0.8764\n392/627 [=================&gt;............] - ETA: 0s - loss: 0.2906 - accuracy: 0.8753\n418/627 [===================&gt;..........] - ETA: 0s - loss: 0.2951 - accuracy: 0.8747\n447/627 [====================&gt;.........] - ETA: 0s - loss: 0.2958 - accuracy: 0.8753\n470/627 [=====================&gt;........] - ETA: 0s - loss: 0.2948 - accuracy: 0.8771\n501/627 [======================&gt;.......] - ETA: 0s - loss: 0.2992 - accuracy: 0.8743\n533/627 [========================&gt;.....] - ETA: 0s - loss: 0.2989 - accuracy: 0.8748\n570/627 [==========================&gt;...] - ETA: 0s - loss: 0.2995 - accuracy: 0.8750\n606/627 [===========================&gt;..] - ETA: 0s - loss: 0.2992 - accuracy: 0.8744\n627/627 [==============================] - 2s 3ms/step - loss: 0.2980 - accuracy: 0.8746 - val_loss: 0.6883 - val_accuracy: 0.7189\n## Epoch 7/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.2289 - accuracy: 1.0000\n 30/627 [&gt;.............................] - ETA: 1s - loss: 0.1825 - accuracy: 0.9583\n 57/627 [=&gt;............................] - ETA: 1s - loss: 0.1969 - accuracy: 0.9364\n 76/627 [==&gt;...........................] - ETA: 1s - loss: 0.1903 - accuracy: 0.9391\n101/627 [===&gt;..........................] - ETA: 1s - loss: 0.2084 - accuracy: 0.9295\n133/627 [=====&gt;........................] - ETA: 0s - loss: 0.2183 - accuracy: 0.9295\n158/627 [======&gt;.......................] - ETA: 0s - loss: 0.2289 - accuracy: 0.9217\n186/627 [=======&gt;......................] - ETA: 0s - loss: 0.2223 - accuracy: 0.9267\n213/627 [=========&gt;....................] - ETA: 0s - loss: 0.2283 - accuracy: 0.9255\n239/627 [==========&gt;...................] - ETA: 0s - loss: 0.2371 - accuracy: 0.9179\n270/627 [===========&gt;..................] - ETA: 0s - loss: 0.2388 - accuracy: 0.9171\n301/627 [=============&gt;................] - ETA: 0s - loss: 0.2454 - accuracy: 0.9128\n333/627 [==============&gt;...............] - ETA: 0s - loss: 0.2507 - accuracy: 0.9088\n365/627 [================&gt;.............] - ETA: 0s - loss: 0.2482 - accuracy: 0.9106\n396/627 [=================&gt;............] - ETA: 0s - loss: 0.2515 - accuracy: 0.9056\n426/627 [===================&gt;..........] - ETA: 0s - loss: 0.2526 - accuracy: 0.9040\n459/627 [====================&gt;.........] - ETA: 0s - loss: 0.2537 - accuracy: 0.9022\n490/627 [======================&gt;.......] - ETA: 0s - loss: 0.2545 - accuracy: 0.9003\n522/627 [=======================&gt;......] - ETA: 0s - loss: 0.2552 - accuracy: 0.8997\n553/627 [=========================&gt;....] - ETA: 0s - loss: 0.2553 - accuracy: 0.8996\n586/627 [===========================&gt;..] - ETA: 0s - loss: 0.2591 - accuracy: 0.8974\n620/627 [============================&gt;.] - ETA: 0s - loss: 0.2612 - accuracy: 0.8964\n627/627 [==============================] - 2s 2ms/step - loss: 0.2609 - accuracy: 0.8962 - val_loss: 0.7289 - val_accuracy: 0.7152\n## Epoch 8/10\n## \n  1/627 [..............................] - ETA: 0s - loss: 0.2016 - accuracy: 0.8750\n 39/627 [&gt;.............................] - ETA: 0s - loss: 0.1916 - accuracy: 0.9519\n 75/627 [==&gt;...........................] - ETA: 0s - loss: 0.2067 - accuracy: 0.9317\n109/627 [====&gt;.........................] - ETA: 0s - loss: 0.2097 - accuracy: 0.9255\n125/627 [====&gt;.........................] - ETA: 0s - loss: 0.2040 - accuracy: 0.9290\n142/627 [=====&gt;........................] - ETA: 0s - loss: 0.2028 - accuracy: 0.9278\n165/627 [======&gt;.......................] - ETA: 0s - loss: 0.2021 - accuracy: 0.9258\n190/627 [========&gt;.....................] - ETA: 0s - loss: 0.2058 - accuracy: 0.9257\n211/627 [=========&gt;....................] - ETA: 0s - loss: 0.2065 - accuracy: 0.9259\n234/627 [==========&gt;...................] - ETA: 0s - loss: 0.2115 - accuracy: 0.9252\n259/627 [===========&gt;..................] - ETA: 0s - loss: 0.2183 - accuracy: 0.9213\n283/627 [============&gt;.................] - ETA: 0s - loss: 0.2159 - accuracy: 0.9231\n308/627 [=============&gt;................] - ETA: 0s - loss: 0.2170 - accuracy: 0.9225\n331/627 [==============&gt;...............] - ETA: 0s - loss: 0.2183 - accuracy: 0.9226\n358/627 [================&gt;.............] - ETA: 0s - loss: 0.2184 - accuracy: 0.9214\n388/627 [=================&gt;............] - ETA: 0s - loss: 0.2218 - accuracy: 0.9188\n421/627 [===================&gt;..........] - ETA: 0s - loss: 0.2238 - accuracy: 0.9175\n455/627 [====================&gt;.........] - ETA: 0s - loss: 0.2256 - accuracy: 0.9170\n485/627 [======================&gt;.......] - ETA: 0s - loss: 0.2263 - accuracy: 0.9160\n512/627 [=======================&gt;......] - ETA: 0s - loss: 0.2263 - accuracy: 0.9155\n533/627 [========================&gt;.....] - ETA: 0s - loss: 0.2239 - accuracy: 0.9172\n557/627 [=========================&gt;....] - ETA: 0s - loss: 0.2243 - accuracy: 0.9165\n581/627 [==========================&gt;...] - ETA: 0s - loss: 0.2242 - accuracy: 0.9163\n610/627 [============================&gt;.] - ETA: 0s - loss: 0.2253 - accuracy: 0.9152\n627/627 [==============================] - 2s 3ms/step - loss: 0.2258 - accuracy: 0.9152 - val_loss: 0.8327 - val_accuracy: 0.6937\n## Epoch 9/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.1488 - accuracy: 1.0000\n 34/627 [&gt;.............................] - ETA: 0s - loss: 0.1648 - accuracy: 0.9706\n 59/627 [=&gt;............................] - ETA: 1s - loss: 0.1746 - accuracy: 0.9513\n 90/627 [===&gt;..........................] - ETA: 0s - loss: 0.1658 - accuracy: 0.9528\n110/627 [====&gt;.........................] - ETA: 0s - loss: 0.1710 - accuracy: 0.9477\n135/627 [=====&gt;........................] - ETA: 0s - loss: 0.1700 - accuracy: 0.9463\n170/627 [=======&gt;......................] - ETA: 0s - loss: 0.1739 - accuracy: 0.9426\n204/627 [========&gt;.....................] - ETA: 0s - loss: 0.1777 - accuracy: 0.9400\n240/627 [==========&gt;...................] - ETA: 0s - loss: 0.1774 - accuracy: 0.9406\n271/627 [===========&gt;..................] - ETA: 0s - loss: 0.1780 - accuracy: 0.9414\n304/627 [=============&gt;................] - ETA: 0s - loss: 0.1796 - accuracy: 0.9404\n335/627 [===============&gt;..............] - ETA: 0s - loss: 0.1770 - accuracy: 0.9410\n367/627 [================&gt;.............] - ETA: 0s - loss: 0.1786 - accuracy: 0.9390\n402/627 [==================&gt;...........] - ETA: 0s - loss: 0.1780 - accuracy: 0.9384\n434/627 [===================&gt;..........] - ETA: 0s - loss: 0.1828 - accuracy: 0.9335\n469/627 [=====================&gt;........] - ETA: 0s - loss: 0.1851 - accuracy: 0.9315\n500/627 [======================&gt;.......] - ETA: 0s - loss: 0.1865 - accuracy: 0.9310\n535/627 [========================&gt;.....] - ETA: 0s - loss: 0.1868 - accuracy: 0.9301\n568/627 [==========================&gt;...] - ETA: 0s - loss: 0.1894 - accuracy: 0.9294\n604/627 [===========================&gt;..] - ETA: 0s - loss: 0.1912 - accuracy: 0.9280\n627/627 [==============================] - 2s 3ms/step - loss: 0.1926 - accuracy: 0.9275 - val_loss: 0.8951 - val_accuracy: 0.7143\n## Epoch 10/10\n## \n  1/627 [..............................] - ETA: 1s - loss: 0.4191 - accuracy: 0.7500\n 35/627 [&gt;.............................] - ETA: 0s - loss: 0.1559 - accuracy: 0.9536\n 63/627 [==&gt;...........................] - ETA: 0s - loss: 0.1439 - accuracy: 0.9643\n 99/627 [===&gt;..........................] - ETA: 0s - loss: 0.1418 - accuracy: 0.9646\n129/627 [=====&gt;........................] - ETA: 0s - loss: 0.1377 - accuracy: 0.9632\n164/627 [======&gt;.......................] - ETA: 0s - loss: 0.1360 - accuracy: 0.9604\n198/627 [========&gt;.....................] - ETA: 0s - loss: 0.1369 - accuracy: 0.9621\n231/627 [==========&gt;...................] - ETA: 0s - loss: 0.1409 - accuracy: 0.9605\n266/627 [===========&gt;..................] - ETA: 0s - loss: 0.1423 - accuracy: 0.9586\n303/627 [=============&gt;................] - ETA: 0s - loss: 0.1435 - accuracy: 0.9571\n340/627 [===============&gt;..............] - ETA: 0s - loss: 0.1466 - accuracy: 0.9555\n377/627 [=================&gt;............] - ETA: 0s - loss: 0.1508 - accuracy: 0.9532\n408/627 [==================&gt;...........] - ETA: 0s - loss: 0.1513 - accuracy: 0.9522\n444/627 [====================&gt;.........] - ETA: 0s - loss: 0.1544 - accuracy: 0.9507\n482/627 [======================&gt;.......] - ETA: 0s - loss: 0.1568 - accuracy: 0.9502\n516/627 [=======================&gt;......] - ETA: 0s - loss: 0.1575 - accuracy: 0.9494\n554/627 [=========================&gt;....] - ETA: 0s - loss: 0.1601 - accuracy: 0.9483\n590/627 [===========================&gt;..] - ETA: 0s - loss: 0.1594 - accuracy: 0.9481\n622/627 [============================&gt;.] - ETA: 0s - loss: 0.1589 - accuracy: 0.9488\n627/627 [==============================] - 1s 2ms/step - loss: 0.1596 - accuracy: 0.9483 - val_loss: 1.0364 - val_accuracy: 0.7044\n## &lt;keras.src.callbacks.History object at 0x13828df40&gt;\n\n\n16.3.3 Modellg√ºte\n\ny_pred = (model.predict(X_test) &gt; 0.5).astype(\"int32\")\n## \n  1/111 [..............................] - ETA: 10s\n 50/111 [============&gt;.................] - ETA: 0s \n107/111 [===========================&gt;..] - ETA: 0s\n111/111 [==============================] - 0s 951us/step\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test Accuracy: {accuracy}\")\n## Test Accuracy: 0.7044167610419027\n\n\n16.3.4 Fazit\nDie Modellg√ºte der 2. Pipeline ist etwas geringer als in der ersten. Die zweite Hidden-Layer muss also nicht zur Modellg√ºte positiv beitragen. √Ñhnliches gilt f√ºr die Batch-Size; wobei eigentlich kleine Batch-Sizes f√ºr diesen eher kleinen Datensatz sinnvoll sein sollten ‚Ä¶",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "125-fallstudie-keras1.html#pipeline-mit-word-embedding",
    "href": "125-fallstudie-keras1.html#pipeline-mit-word-embedding",
    "title": "\n16¬† Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.4 Pipeline mit Word Embedding",
    "text": "16.4 Pipeline mit Word Embedding\nDiese Pipeline orientiert sich an diesem Beispiel von Tensorflow.\n\n16.4.1 Daten\n\nimport pandas as pd\n\ntrain_file_path = \"https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_train.csv\"\n\nd_train = pd.read_csv(train_file_path)\n\ntest_file_path = \"https://github.com/sebastiansauer/pradadata/raw/master/data-raw/germeval_test.csv\"\n\nd_test = pd.read_csv(test_file_path)\n\nPr√§diktor-Dataframes als Arrays:\n\nX_train = d_train[\"text\"].values\n\nX_test = d_test[\"text\"].values\n\n\n16.4.2 Module\ntensorflow-hub ist √ºbrigens NICHT mehr n√∂tig. Das Paket ist jetzt Teil von tensorflow.\n\nimport os\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow_hub as hub",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "125-fallstudie-keras1.html#gpu",
    "href": "125-fallstudie-keras1.html#gpu",
    "title": "\n16¬† Fallstudie GermEval-Keras-Simple\n",
    "section": "\n16.5 GPU",
    "text": "16.5 GPU\nTesten, ob eine GPU verf√ºgbar ist:\n\ntf.config.list_physical_devices('GPU') \n## []\n\n\nprint(\"TF Version: \", tf.__version__)\n## TF Version:  2.13.1\nprint(\"Eager mode: \", tf.executing_eagerly())\n## Eager mode:  True\nprint(\"Hub version: \", hub.__version__)\n## Hub version:  0.14.0\nprint(\"GPU is\", \"available\" if tf.config.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")\n## GPU is NOT AVAILABLE\n\nTja, leider nein.\n\n16.5.1 Wort-Einbettungen\n\nembedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\nhub_layer = hub.KerasLayer(embedding, input_shape=[], \n                           dtype=tf.string, trainable=True)\n\n\n16.5.2 Modell\n\nmodel = tf.keras.Sequential()\nmodel.add(hub_layer)\nmodel.add(tf.keras.layers.Dense(16, activation='relu'))\nmodel.add(tf.keras.layers.Dense(1))\n\nmodel.summary()\n## Model: \"sequential_2\"\n## _________________________________________________________________\n##  Layer (type)                Output Shape              Param #   \n## =================================================================\n##  keras_layer (KerasLayer)    (None, 50)                48190600  \n##                                                                  \n##  dense_5 (Dense)             (None, 16)                816       \n##                                                                  \n##  dense_6 (Dense)             (None, 1)                 17        \n##                                                                  \n## =================================================================\n## Total params: 48191433 (183.84 MB)\n## Trainable params: 48191433 (183.84 MB)\n## Non-trainable params: 0 (0.00 Byte)\n## _________________________________________________________________\n\n\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n\n\n16.5.3 Trainieren\n\nmodel.fit(X_train, y_train, \nepochs=10, \nbatch_size=8, \nvalidation_data=(X_test, y_test),\nverbose = 1)\n\nEpoch 1/10\n627/627 [==============================] - 490s 781ms/step - loss: 0.6232 - accuracy: 0.6638 - val_loss: 0.6093 - val_accuracy: 0.6628\nEpoch 2/10\n627/627 [==============================] - 477s 760ms/step - loss: 0.4541 - accuracy: 0.7686 - val_loss: 0.6536 - val_accuracy: 0.6761\nEpoch 3/10\n627/627 [==============================] - 482s 769ms/step - loss: 0.2762 - accuracy: 0.8794 - val_loss: 0.8118 - val_accuracy: 0.6526\nEpoch 4/10\n627/627 [==============================] - 521s 831ms/step - loss: 0.1671 - accuracy: 0.9367 - val_loss: 1.0416 - val_accuracy: 0.6467\nEpoch 5/10\n627/627 [==============================] - 456s 727ms/step - loss: 0.0936 - accuracy: 0.9689 - val_loss: 1.2981 - val_accuracy: 0.6486\nEpoch 6/10\n627/627 [==============================] - 455s 726ms/step - loss: 0.0478 - accuracy: 0.9872 - val_loss: 1.5631 - val_accuracy: 0.6297\nEpoch 7/10\n627/627 [==============================] - 456s 727ms/step - loss: 0.0240 - accuracy: 0.9954 - val_loss: 1.8281 - val_accuracy: 0.6285\nEpoch 8/10\n627/627 [==============================] - 455s 726ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 2.0636 - val_accuracy: 0.6334\nEpoch 9/10\n627/627 [==============================] - 459s 732ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 2.2470 - val_accuracy: 0.6291\nEpoch 10/10\n627/627 [==============================] - 455s 727ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 2.3786 - val_accuracy: 0.6277\n&lt;keras.src.callbacks.History object at 0x148309730&gt;\n```\n\n\n### Modellg√ºte\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny_pred = (model.predict(X_test) &gt; 0.5).astype(\"int32\")\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Test Accuracy: {accuracy}\")\n```\n:::\n\n111/111 [==============================] - 17s 151ms/step Test Accuracy: 0.6276896942242356 ````\n\n16.5.4 Fazit\nNaja, daf√ºr dass es englische Wortvektoren waren, gar nicht so schlecht ü§£",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>16</span>¬† <span class='chapter-title'>Fallstudie GermEval-Keras-Simple</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#lernsteuerung",
    "href": "110-nn-theo1.html#lernsteuerung",
    "title": "\n15¬† Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.1 Lernsteuerung",
    "text": "15.1 Lernsteuerung\n\n15.1.1 Lernziele\nNach Abschluss dieses Kapitels ‚Ä¶\n\nk√∂nnen Sie die theoretischen Grundlagen eines einfachen neuronalen Netzwerks erkl√§ren.\n\n15.1.2 √úberblick\nDieses Kapitel f√ºhrt in die Grundlagen (einfacher) neuronaler Netze ein. Die Darstellung orientiert sich an James u.¬†a. (2021). Viele der gezeigten Abbildungen stammen aus James u.¬†a. (2021).1\n\n15.1.3 Ben√∂tigte R-Pakete\n\nlibrary(dplyr)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#netzwerke-mit-einer-einzelnen-zwischenschicht",
    "href": "110-nn-theo1.html#netzwerke-mit-einer-einzelnen-zwischenschicht",
    "title": "\n15¬† Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.2 Netzwerke mit einer einzelnen Zwischenschicht",
    "text": "15.2 Netzwerke mit einer einzelnen Zwischenschicht\nEin neuronales Netzwerk besteht auf\n\neinem Input-Vektor mit \\(p\\) Variablen \\(X=(X_1, X_2, \\ldots, X_p)\\)\n\neiner nicht-linearen Funktion \\(f(X)\\)\n\nsagt einen Output-Vektor \\(Y\\) vorher.\n\nAbbildung¬†15.1 zeigt ein einfaches sog. Feed-Forward-Neuronales-Netzwerk, um eine quantitative Output-Variable \\(Y\\) vorherzusagen anhand von 4 Pr√§diktoren. Das Netzwerk besteht aus drei ‚ÄúSchichten‚Äù, der Eingabeschicht (Input Layer), der Zwischenschicht (Hidden Layer) und der Ausgabeschicht (Output Layer). Jeder Kreis symbolisiert ein ‚ÄúNeuron‚Äù. In der Zwischenschicht in Abbildung¬†15.1 gibt es \\(K=5\\) Neuronen in der Zwischenschicht.\n\n\n\n\n\n\nK√ºnstliche Neurone\n\n\n\nDie Idee der ‚ÄúNeurone‚Äù war namensgebend f√ºr Neuronale Netze. Ein biologisches Neuron gibt die Erregung (‚Äúfeuert‚Äù) nur dann, wenn es √ºber eine Schwelle erregt (aktiviert) wird. Analog sind ‚Äúk√ºnstliche Neurone‚Äù in einem Neuronalen Netzwerk konzipiert. Sicherlich tun wir der gewaltigen Komplexit√§t biologischer Neurone Unrecht, wenn wir die gedanklichen bescheidenen Einheiten k√ºnstlicher Neuronalen Netze auch als Neurone bezeichnen. Die (urspr√ºngliche ausschlie√ülich vernendete) Logistische Funktion (mit sigmoiden Verlauf) setzt den ‚ÄúAn-Aus-Mechanismen‚Äù biologischer Neurone um: Diese feuern nur oberhalb einer gewissen Aktivierung (und dann mit konstanter St√§rke unabh√§ngig von der Aktivierung).\\(\\square\\)\n\n\n\n\n\n\n\nAbbildung¬†15.1: Ein neuronales Netzwerk mit einer Zwischenschicht\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nEinfach gesprochen besteht ein neuronales Netzwerk aus einem System linearen Gleichungen, die aber jedes Mal noch durch eine einfache nicht-lineare Funktion gejagt werden. \\(\\square\\)\n\n\nEine h√§ufige Wahl f√ºr \\(g\\) ist die ReLU-Funktion (rectified linear unit), die √§hnlich zum sigmoiden Verlauf des logististischen Funktion ist, s. Abbildung¬†15.2.\n\n\n\n\n\nAbbildung¬†15.2: ReLU und sigmoide Funktion\n\n\nDieses Netzwerk (als Ganzes) hat folgende Struktur, s. Gleichung¬†15.1.\n\\[\\begin{align}\nf(X) &= \\beta_0 + \\sum_{k=1}^K \\beta_k h_k(X) \\\\\n     &= \\beta_0 + \\sum_{k=1}^K \\beta_k g(w_{k0} + \\sum_{j=1}^p w_{kj} X_j)\n\\end{align} \\tag{15.1}\\]\nJedes Neuron der Zwischenschicht erf√§hrt eine Aktivierung (##eq-nn1-akt):\n\\[A_k = h_k(X) = g(w_{k0} + \\sum_{j=1}^p w_{kj} X_j) \\tag{15.2}\\]\nDie Aktivierung eines Neurons √§hnelt einer multiplen Regression, nur dass ‚Äúzum Schluss‚Äù noch die nicht-lineare Sahnehaube drauf kommt.\nWichtig ist, dass \\(g\\) eine nicht-lineare Funktion ist, denn sonst w√ºrde das ganze Netzwerk ‚Äúnur‚Äù ein lineares Gleichungssystem sein. Die nicht-lineare Funktion erlaubt aber ein viel flexibleres Verhalten, als es einer linearen Funktion m√∂glich w√§re.\n‚ÄúFitten‚Äù eines neuronalen Netzwerk bedeutet, genau wie bei allen anderen Methoden des Maschinenlernens, die Parameter zu sch√§tzen (berechnen). Wie bei jeder Methode des (√ºberwachten) Maschinenlernen braucht es eine Fehlerfunktion, die minimiert wird. F√ºr quantitative Y-Variablen wird zumeist die quadratische Fehlerfunktion verwendet, s. Gleichung¬†15.3.\n\\[\\sum_{i=1}^n(y_i - f(x_i)) \\tag{15.3}\\]",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#multilayer-netzwerke",
    "href": "110-nn-theo1.html#multilayer-netzwerke",
    "title": "\n15¬† Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.3 Multilayer-Netzwerke",
    "text": "15.3 Multilayer-Netzwerke\nNetzwerke mit mehreren Zwischenschichten bezeichnet man als Multi-Layer-Netzwerke. Theoretisch k√∂nnte ein Netzwerk mit nur einer Zwischenschicht, aber einer gro√üen Zahl an Neuronen, fast alle denkbaren (oder zumindest sehr viele) Funktionen simulieren. Aber in der Praxis ist es einfacher, mehrere Schichten mit mittlerer Neuronen-Anzahl zu implementieren.\nAbbildung¬†15.3 zeigt ein Multilayer-Netzwerk, um die MNIST-Ziffern vorherzusagen. Im Gegensatz zu Abbildung¬†15.1 ‚Ä¶\n\nbesitzt es zwei Zwischenschichten, \\(L_1\\) (256 Neurone) und \\(L_2\\) (128 Neurone).\nhat es 10 Ausgabe-Neurone in der Output-Layer, die den 10 Ziffern (0-9) entsprechen sollen.\n\n\n\n\n\n\nAbbildung¬†15.3: Multilayer-Netzwerk, um die MNIST-Ziffern vorherzusagen\n\n\nDie Aktivierung \\(A\\) der \\(k^{(1)}\\) Neurone in der ersten Zwischenschicht gleicht dem einfachen Netzwerk oben (vgl. Gleichung¬†15.1 und Gleichung¬†15.2), s. Gleichung¬†15.4:\n\\[\\begin{align}\nA_k^{(1)} &= h_k^{(1)}(X)\\\\\n          &= g(w_{k0}^{(1)} + \\sum_{j=1}^p w_{kj}^{(1)} X_j)\n\\end{align} \\tag{15.4}\\]\nf√ºr alle \\(k_1, k_2, \\ldots, K_1\\) Neurone der ersten Zwischenschicht. F√ºr die zweite Zwischenschicht, \\(L_2\\) gilt das analog: Die Aktivierung der Neurone der vorherigen Schicht werden als Input verwendet und auf dieser Basis wird die Aktivierung des jeweiligen Neurons der aktuellen Schicht berechnet, s. Gleichung¬†15.5:\n\\[\\begin{align}\nA_l^{(2)} &= h_l^{(2)}(X)\\\\\n          &= g(w_{l0}^{(2)} + \\sum_{j=2}^p w_{lj}^{(1)} X_j)\n\\end{align} \\tag{15.5}\\]\nf√ºr alle \\(l = 1, 2, \\ldots, K2\\) Neurone der zweiten Zwischenschicht.\nDa sammeln sich schnell eine gro√üe Zahl an Parametern.\n\\(\\newcommand{\\matr}[1]{#1}\\)\n\\(\\matr{W_1}\\) in Abbildung¬†15.3 repr√§sentiert die Matrix mit allen (‚ÄúRegressions‚Äù-)Gewichten (und ‚ÄúIntercepts‚Äù) on der Input-Layer zur ersten Zwischenschicht. Diese Matrix umfasst \\(785\\times256=200\\,960\\) Koeffizienten (785=784 ‚ÄúRegressions-‚ÄùGewichte plus 1 Intercept-Term, auch ‚ÄúBias‚Äù genannt).\nEntsprechend weist jedes Neuron der zweiten Zwischenschicht ein Gewicht zu jedem Neuron der ersten Zwischenschicht auf. Daher hat \\(\\matr{W_2}\\) die Dimensionen \\(257 \\times 128 = 32\\,896\\).\nJetzt gelangen wir zur Output-Layer; dort gibt es 10 Ausgabe-Neuronen. Hier sind zwei Schritte n√∂tig. Schritt 1 besteht darin f√ºr jedes der 10 Neurone ein lineares Modell zu berechnen, basierend auf den Gewichten der vorherigen Zwischenschicht:\n\\[\\begin{aligned}\nZ_m &= \\beta_{m0} +   \\sum_{l=1}^{K_2} \\beta_{ml} h_l^{(2)}(X) \\\\\n&= \\beta_{m0} +   \\sum_{l=1}^{K_2} \\beta_{ml} A_l^{(2)}\n\\end{aligned} \\tag{15.6}\\]\nmit \\(m = 0,1, \\ldots, 9\\). Diese \\(129 \\times 10 = 1290\\) Koeffizienten sind in der Matrix \\(\\matr{B}\\) gespeichert.\nSchritt 2 fehlt noch. Wir m√∂chten ja, dass die Ausgabe f√ºr jede Ziffer in einer Wahrscheinlichkeit besteht, das kann man mit der Softmax-Aktivierung erreichen (Gleichung¬†15.7):\n\\[f_m(X) = Pr(Y=m|X) = \\frac{e^{Z_m}}{\\sum_{l=0}^9 e^{Z_l}}, \\tag{15.7}\\]\nmit \\(m=0,1, \\ldots, 9\\).\nDie zu minimierende Funktion (‚ÄúLoss Function‚Äù) ist im Falle qualitativer Variablen keine metrische Quadratfunktion, sondern man miniert die Kreuzentropie, vgl. Gleichung¬†6.2.\nDas Netzwerk hat insgesamt √ºber 200k Parameter! Und das bei gerade mal 60k Bildern. Wenn da das Modell keine Overfitting-Party macht, wei√ü ich auch nicht.\nGegenma√ünahmen zum Overfitting sind also dringend n√∂tig, besonders bei neuronalen Netzwerken.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#mathematik-neuronaler-netzwerke",
    "href": "110-nn-theo1.html#mathematik-neuronaler-netzwerke",
    "title": "\n15¬† Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.4 Mathematik neuronaler Netzwerke",
    "text": "15.4 Mathematik neuronaler Netzwerke\nNeuronale Netzwerke basierend auf zwei Konzepte: Lineare Algebra und Ableiten (Infinitesimalrechnung).\n\n15.4.1 Punktprodukt\nIm YouTube-Kanal von 3b1b gibt es eine exzellente Einf√ºhrung in die lineare Algebra.\nDie zentrale Operation ist das Dot Product (Skalar- oder Punktprodukt), s. Abbildung¬†15.5.\nIm einfachen Fall (der euklidischen Ebene) gilt:\n\\(\\vec a \\cdot \\vec b = \\begin{pmatrix} a_1 \\\\ a_2 \\end{pmatrix} \\cdot \\begin{pmatrix} b_1 \\\\ b_2 \\end{pmatrix} = a_1 b_1 + a_2 b_2.\\)\n\nBeispiel 15.1 (Einfaches Punktprodukt) Gegeben seien zwei Vektoren \\(\\vec x=(1,2,3)\\) und \\(\\vec y=(1,2,3)\\). Das Punktprodukt von \\(x\\) und \\(y\\) ist die Summe der Produkte der jeweilige Paare, s. Abbildung¬†15.4 (a).\n\\(\\vec x \\cdot \\vec y = 1\\cdot1 + 2\\cdot 2 + 3 \\cdot 3 = 1 +3+ 9 = 13. \\qquad \\square\\)\n\n\n\n\n\n\n\n\n\n\n(a) Schema des Punktprodukts\n\n\n\n\n\n\n\n\n\n(b) Mehrfaches Punktprodukt: Matrixmultiplikation\n\n\n\n\n\n\nAbbildung¬†15.4\n\n\nGeometrisch gesprochen entspricht das Punktprodukt dem Ausma√ü, in dem zwei Vektoren in die gleiche Richtung zeigen:\n\n\n\n\nDie Vektoren zeigen in die gleiche Richtung: Maximales Punktprodukt (gleich dem Produkt der Vektorl√§ngen)\n\n\n\n\nMinimales Punktprodukt (Null), da die Vektoren orthogonal zueinander stehen\n\n\n\n\nMittleres Punktprodukt, proportional zur Gr√∂√üe des Winkels \\(\\phi\\) und dem Produkt der Vektorl√§ngen\n\n\n\nBildquelle: Martin Thoma, Wikipedia, CC-BY 3.0\n\n\n\n\n\n\nHinweis\n\n\n\nEine (etwas ausf√ºhrlichere) geometrische Erkl√§rung findet sich z.B. bei Math is Fun. F√ºr Einsteiger interessant ist auch die Erkl√§rung von Kalid Azad. Eine 3D-Darstellung von Vektoren findet sich hier. \\(\\square\\)\n\n\nIn R kann man das Punktprodukt mit dem %*%-Operator berechnen\n\nx &lt;- c(1,2,3)\ny &lt;- c(1,2,3)\n\ndot_xy &lt;- x %*% y\ndot_xy\n##      [,1]\n## [1,]   14\n\nIm Paket geometry gibt es alternativ eine entsprechende Funktion, dot:\n\ngeometry::dot(x, y)\n## [1] 14\n\n\nDefinition 15.1 (Punktprodukt) Das Produkt zweier Vektoren \\(\\mathbf{a}\\) und \\(\\mathbf{b}\\) ist so definiert, Gleichung¬†15.8. \\[{\\displaystyle \\mathbf {a} \\cdot \\mathbf {b} =\\sum _{i=1}^{n}a_{i}b_{i}=a_{1}b_{1}+a_{2}b_{2}+\\cdots +a_{n}b_{n}} \\qquad \\square \\tag{15.8}\\]\n\n\n15.4.2 Matrixmultiplikation\nMultiplizert man zwei Matrizen, so kann man das als mehrfaches Punktprodukt auffassen, s. Abbildung¬†15.5.\n\n\n\n\n\nAbbildung¬†15.5: Berechnung des Punktprodukts\n\n\n\n\n\n\n\n\nTipp\n\n\n\nProbieren Sie diesen Matrizenrechner aus zur Berechnung des Punktprodukts bzw. der Matrizenmultiplikation. \\(\\square\\)\n\n\n\n15.4.3 Regression als Matrixmultiplikation\nDie (einfache oder multiple) Regression kann man als Matrixmultiplikation auffassen. Schauen wir uns dazu ein einfaches Beispiel an.\nDer Datensatz d besteht auf einer Outcome-Variable, y sowie einem Pr√§diktor, x; drei Beobachtungen umfasst die Tabelle, s. Tabelle¬†15.1. Eine Regression mit einem Pr√§diktor hat zwei Koeffizienten, \\(\\beta_0, \\beta_1\\).\n\n\n\nd &lt;-\n  data.frame(\n    x = c(1, 2, 3),\n    y = c(1.1, 2.2, 2.9),\n    b0 = c(1,1,1)\n  )\n\nlm1 &lt;- lm(y ~ x, data = d)\n\n\n\n\n\nTabelle¬†15.1: Datensatz d\n\n\n\n\n\n\nx\ny\nb0\n\n\n\n1\n1.1\n1\n\n\n2\n2.2\n1\n\n\n3\n2.9\n1\n\n\n\n\n\n\n\n\n\n\n\nSpeichern wir uns die Modellkoeffizienten, \\(\\beta_0, \\beta_1\\) in einem Objekt \\(\\mathbf{\\beta}\\) ab:\n\nlm1_coefs &lt;- lm1$coefficients\nlm1_coefs\n## (Intercept)           x \n##   0.2666667   0.9000000\n\nDie vorhergesagten Werte des Modells, \\(\\matr{\\hat{Y}}\\)\n\npredict(lm1)\n##        1        2        3 \n## 1.166667 2.066667 2.966667\n\nJetzt bauen wir das Modell mit Matrixmultiplikation nach.\nDabei m√ºssen wir f√ºr den Intercept eine Spalte mit nur 1 erg√§nzen und erhalten die Matrix f√ºr die X-Werte (pro Beobachtung), \\(\\matr{X}\\):\n\nx_matrix &lt;- d |&gt; \n  select(b0, x) |&gt; \n  as.matrix() \n\nx_matrix\n##      b0 x\n## [1,]  1 1\n## [2,]  1 2\n## [3,]  1 3\n\nDann multiplizieren wir die Matrix mit den X-Werten mit der Matrix (Vektor) mit den Modellkoeffizienten. So erhalten wir die vorhergesagten Y-Werte, $:\n\ny_pred &lt;- x_matrix %*% lm1_coefs\ny_pred \n##          [,1]\n## [1,] 1.166667\n## [2,] 2.066667\n## [3,] 2.966667\n\nIn Mathe-Sprech sieht das so aus:\n\\(y = \\beta_0 \\cdot 1 + \\beta_1 \\cdot x_1\\).\nIn Matrixschreibweise sieht das dann so aus:\n\\(\\matr{\\hat{Y}} = \\matr{X} \\cdot \\matr{\\matr{\\beta}}\\)\nAusgeschrieben als Gleichungssystem:\n\n\n\n\n\n\n\n\ny_hat\n\n\n\n1.17\n\n\n2.07\n\n\n2.97\n\n\n\n\n\n\n\n\\(=\\)\n\n\n\n\n\n\n\nb0\nx\n\n\n\n1\n1\n\n\n1\n2\n\n\n1\n3\n\n\n\n\n\n\n\n\\(\\cdot\\)\n\n\n\n\n\n\n\nbeta\n\n\n\n0.27\n\n\n0.90",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#b1b",
    "href": "110-nn-theo1.html#b1b",
    "title": "\n15¬† Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.5 3b1b",
    "text": "15.5 3b1b\nIm YouTube-Kanal von Grant Sanderson 3blue1brown gibt es eine exzellente Einf√ºhrung (bestehend aus 4 Videos zu je ca. 15 Min.) in die Theorie der neuronalen Netze.\n\n15.5.1 Video 1\n\n\n15.5.2 Video 2\n\n\n15.5.3 Video 3\n\n\n15.5.4 Video 4\nAnspruchsvoller; mathematische Grundlagen von Backpropagation (parzielle Ableitung)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "110-nn-theo1.html#vertiefung",
    "href": "110-nn-theo1.html#vertiefung",
    "title": "\n15¬† Theoretische Grundlagen neuronaler Netze\n",
    "section": "\n15.6 Vertiefung",
    "text": "15.6 Vertiefung\nFrancois Chollet hat eine n√ºtzliche, zug√§ngliche und (zum Einstieg) umfassende Anleitung zum Thema neuronale Netze mit R bzw. mit Python geschrieben (Chollet, Kalinowski, und Allaire 2022; Chollet 2021).\nEs finden sich viele weitere Lehrb√ºcher f√ºr Einsteiger und Fortgeschrittene, z.B. Kulkarni und Shivananda (2021), Gallatin und Albon (2023). Bekannt ist auch G√©ron (2023). Der Gro√üteil der entsprechenden Werke nutzt Python, nicht R.\nEine einsteigerfreundliche Anleitung zur Matrixmultiplikation findet sich bei Kalid Azad, betterexplained.com. Auf Wikipedia finden sich einige einsteigerfreundliche Illustrationen.\nDie Videos von vcubingx zum Thema Neuronale Netze sind empfehlenswert.\nSehr einsteigerfreundlich sind auch die Videos im YouTube-Kanal StatQuest. Der Autor Josh Starmer bieten einen gro√üen Umfang an Themen aus dem Bereich Maschinenlernen.\n\n\n\n\nChollet, Fran√ßois. 2021. Deep Learning with Python. Second edition. Shelter Island, NY: Manning.\n\n\nChollet, Fran√ßois, Tomasz Kalinowski, und J. J. Allaire. 2022. Deep Learning with R. Second edition. Shelter Island, NY: Manning Publications Co.\n\n\nGallatin, Kyle, und Chris Albon. 2023. Machine Learning with Python Cookbook: Practical Solutions from Preprocessing to Deep Learning. Beijing Boston Farnham Sebastopol Tokyo: O‚ÄôReilly Media.\n\n\nG√©ron, Aur√©lien. 2023. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras und TensorFlow: Konzepte, Tools und Techniken f√ºr intelligente Systeme. √úbersetzt von Kristian Rother und Thomas Demmig. 3., aktualisierte und erweiterte Auflage. Heidelberg: O‚ÄôReilly.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, und Robert Tibshirani. 2021. An Introduction to Statistical Learning: With Applications in R. Second edition. Springer Texts in Statistics. New York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nKulkarni, Akshay, und Adarsha Shivananda. 2021. Natural Language Processing Recipes: Unlocking Text Data with Machine Learning and Deep Learning Using Python. Second edition. New York: Apress.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>15</span>¬† <span class='chapter-title'>Theoretische Grundlagen neuronaler Netze</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#vorab",
    "href": "120-transformer.html#vorab",
    "title": "\n17¬† Transformer\n",
    "section": "\n17.1 Vorab",
    "text": "17.1 Vorab\n\n17.1.1 Lernziele\n\nSie k√∂nnen die grundlegende Architektur eines Transformer-Modells beschreiben.\nSie k√∂nnen Transformer-Modelle mit der API von Hugging-Face berechnen.\n\n17.1.2 Begleitliteratur\nDer Blogpost von Jay Alammar gibt einen illustrierten √úberblick √ºber Transformer.\n\n17.1.3 Ben√∂tigte Software\nWir ben√∂tigen Python, R sowei einige im Folgenden aufgef√ºhrte Python-Module.\n\nimport pandas as pd\nimport os\n\nF√ºr den Sch√ºleraustausch von R nach Python nutzen wir das R-Paket reticulate:\n\nlibrary(reticulate)\n\nAu√üerdem starte ich die ‚Äúrichtige‚Äù Python-Version, wo die ben√∂tigten Pakete (in der richtigen Version) installiert sind:\n\n#use_virtualenv(\"r-tensorflow\")\n\nCheck:\n\npy_available()\n## [1] TRUE\n\nWelche Python-Version nutzt reticulate gerade?\n\npy_config()\n## python:         /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/bin/python\n## libpython:      /Users/sebastiansaueruser/.pyenv/versions/3.8.16/lib/libpython3.8.dylib\n## pythonhome:     /Users/sebastiansaueruser/.virtualenvs/r-tensorflow:/Users/sebastiansaueruser/.virtualenvs/r-tensorflow\n## version:        3.8.16 (default, Sep 15 2023, 17:53:02)  [Clang 14.0.3 (clang-1403.0.22.14.1)]\n## numpy:          /Users/sebastiansaueruser/.virtualenvs/r-tensorflow/lib/python3.8/site-packages/numpy\n## numpy_version:  1.24.3\n## \n## NOTE: Python version was forced by VIRTUAL_ENV",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#√ºberblick",
    "href": "120-transformer.html#√ºberblick",
    "title": "\n17¬† Transformer\n",
    "section": "\n17.2 √úberblick",
    "text": "17.2 √úberblick\nTransformer sind eine Architekturvariante neuronaler Netze. Sie stellen die Grundlage vieler aktueller gro√üer Sprachmodelle1; da sie einige Vorz√ºge gegen√ºber Vorg√§ngermodellen aufweisen, haben sie einen zentralen Platz f√ºr verschiedenen Aufgaben des NLP eingenommen.\nIm Jahr 2017 erschien ein Paper auf Arxive mit dem Titel ‚ÄúAttention is all you need‚Äù, Vaswani u.¬†a. (2023)2. Transformer basieren auf einer bestimmten Art von ‚ÄúAufmerksamkeit‚Äù, genannt Selbst-Aufmerksamkeit (self-attention). Nat√ºrlich ist damit eine bestimmte Architektur im neuronalen Netzwerk gemeint, kein kognitivpsychologiches Konstruktr; allerdings lehnt sich die Methode an Konzepte der Kognitionspsychologie vage an.\nSelf-Attention weist zwei gro√üe Verteile auf: Erstens erlaubt es parallele Verarbeitung, was viele Vorg√§ngermodelle nicht erlaubten. Zweitens kann es den Kontext eines Tokens, also den Text um ein bestimmtes Wort herum, deutlich besser ‚Äúim Blick‚Äù (oder in der Aufmerksamkeit) behalten als viele Vorg√§ngermodelle.\nGerade f√ºr Daten mit sequenziellem Charakter, wie Text oder Sprache, sind Transformer-Modelle gut geeignet3.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#grundkonzepte",
    "href": "120-transformer.html#grundkonzepte",
    "title": "\n17¬† Transformer\n",
    "section": "\n17.3 Grundkonzepte",
    "text": "17.3 Grundkonzepte",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#einf√ºhrung-in-hugging-face",
    "href": "120-transformer.html#einf√ºhrung-in-hugging-face",
    "title": "\n17¬† Transformer\n",
    "section": "\n17.4 Einf√ºhrung in Hugging Face ü§ó",
    "text": "17.4 Einf√ºhrung in Hugging Face ü§ó\nDieser Abschnitt orientiert sich an Tunstall u.¬†a. (2022). Die Syntax zu allen Kapiteln des Buchs findet sich praktischerweise in diesem Github-Repo.\nBei ü§ó liegt der Schwerpunkt klar bei Python, nicht bei R. Allerdings erlaubt RStudio ein einfaches Wechseln zwischen R und Python: Funktionen und Daten aus Python k√∂nnen einfach mit dem $-Operator angesprochen werden. In diesem Post wirds das demonstriert.\nSchauen wir uns das einf√ºhrende Beispiel aus Tunstall u.¬†a. (2022). an.\n\n17.4.1 Hugging Face mit R\nHier ein ein Text-Schnipsel, dessen Sentiment wir detektieren wollen:\n\ntext &lt;- (\"Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\")\n\nUnd hier in der Python-Version:\n\ntext_py = r.text\n\nDann importieren wir die n√∂tigen Module:\n\n\nPython\nR\n\n\n\n\n#import tensorflow\nfrom transformers import pipeline\n\nNat√ºrlich m√ºssen Python-Module installiert sein, bevor man sie nutzen kann, genau so wie R-Pakete.\n\n\nMan kann die die Python-Module auch √ºber R starten:\n\ntransformers &lt;- reticulate::import(\"transformers\")\n\n\n\n\n\n17.4.2 Einfache Pipeline\n{.panel-tabset}\n\n17.4.3 Python\nWir bereiten das Modell vor; im Default wird distilbert-base-uncased-finetuned-sst-2-english verwendet.\n\nclassifier = pipeline(\"text-classification\")\n## No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n## Using a pipeline without specifying a model name and revision in production is not recommended.\n## All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n## \n## All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#germeval-out-of-the-box-mit-hugging-face",
    "href": "120-transformer.html#germeval-out-of-the-box-mit-hugging-face",
    "title": "\n17¬† Transformer\n",
    "section": "\n17.5 Germeval Out-of-the-Box mit Hugging Face",
    "text": "17.5 Germeval Out-of-the-Box mit Hugging Face\nZuert importieren wir die Daten.\n\n\nR\nPython\n\n\n\n\ndata(germeval_train, package = \"pradadata\")\ntext &lt;- germeval_train$text[1:2]\ntext[1:2]\n## [1] \"@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\"                                 \n## [2] \"@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\"\n\n\n\n\ngermeval_train_py = r.text\n\n\n\n\n\n17.5.1 Standard-Pipeline\n\nclassifier = pipeline(\"text-classification\")\n## No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n## Using a pipeline without specifying a model name and revision in production is not recommended.\n## All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n## \n## All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\noutputs2 = classifier(germeval_train_py)\noutputs2\n## [{'label': 'NEGATIVE', 'score': 0.9950070381164551}, {'label': 'NEGATIVE', 'score': 0.9954568147659302}]\n\nTja, vielleicht sollten wir ein Modell verwenden, das die deutsche Sprache versteht?\n\n17.5.2 Man spricht Deutsh\nAuf Hugging Face gibt es eine Menge von Modellen. Welches nehm ich nur? DISTILBERT oder BERT-Varianten d√ºrfte kein schlechter Start sein.\n\n#classifier = pipeline(\"text-classification\", model=\"distilbert-base-german-cased\")\n\n\nclassifier = pipeline(\n  \"text-classification\", model=\"oliverguhr/german-sentiment-bert\")\n## All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n## \n## All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n## If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n\n\noutputs3 = classifier(germeval_train_py)\ndf = pd.DataFrame(outputs3)    \ndf.head()\n##       label     score\n## 0   neutral  0.987253\n## 1  negative  0.918047\n\n\ndf_r &lt;- py$pd\nhead(df_r)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#openai-api",
    "href": "120-transformer.html#openai-api",
    "title": "\n17¬† Transformer\n",
    "section": "\n17.6 OpenAI-API",
    "text": "17.6 OpenAI-API\n\n\n\n\n\n\nWichtig\n\n\n\nDer API-Aufruf von ChatGPT kostet Geld üí∏. \\(\\square\\)\n\n\n\n17.6.1 Authentifizierung\nWir m√ºssen uns bei der API anmelden:\n\n\nR\nPython\n\n\n\n\nopenai_key_r &lt;- Sys.getenv(\"OPENAI_API_KEY\")\n\n\n\n\nopenai_key_py = os.environ.get(\"OPENAI_API_KEY\")\n\n\n\n\n\n\n\n\n\n\nVorsicht\n\n\n\nSpeichern Sie keine sensiblen Daten in geteilten Ordner/Repos. Achten Sie auf Log-Dateien wir .Rhistory, in der u.U. Ihre sensiblen Daten enthalten sein k√∂nnen. \\(\\square\\)\n\n\nEine sichere Variante als das unverschl√ºsselte Speichenr von Passw√∂rtern ist es, sensible Daten mit einem Passwort zu sch√ºtzen. Dazu kann man z.B. in R das Paket keyring nutzen.\n\nlibrary(keyring)\nopenai_key_r &lt;- key_get(\"OPENAI_API_KEY\")\n\n\n17.6.2 Setup\n\nsentiment_scores = []\nsentiment_analysis = []\ntext = '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.'\n\n\n17.6.3 Anfrage an die API\n\nprompt = f\"Analysiere das Sentiment des folgenden Texts: \\n{text}\"\n\nresponse = openai.Completion.create(\n        prompt=prompt,\n        engine=\"davinci\",\n        max_tokens=100,\n        temperature=0.5,\n    )",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "120-transformer.html#vertiefung",
    "href": "120-transformer.html#vertiefung",
    "title": "\n17¬† Transformer\n",
    "section": "\n17.7 Vertiefung",
    "text": "17.7 Vertiefung\nDer Originalartikel von Vaswani u.¬†a. (2023) gibt einen guten Einblick in die Konzepte; der Anspruch ist auf mittlerem Niveau. Von den Hugging-Face-Machern gibt es ein Buch, das - ebenfalls auf mittlerem Niveau - einen Einblick in Transformer-Modelle im Hugging-Face-√ñkosystem gew√§hrt (Tunstall u.¬†a. 2022). Rothman (2022) scheint gute Freunde bei Google zu haben, wenn man sein Buch √ºber Transformer liest, jedenfalls sind die Modelle jener Firma in dem Buch gut gefeatured. G√©ron (2023a) Standardwerk zu Scikit-Learn bietet auch einen Einblick in Attention-Konzepte (Kap. 16). √úbrigens ist das Buch (3. Auflage) jetzt auch in deutscher Sprache erh√§ltlich (G√©ron 2023b).\n\n\n\n\nG√©ron, Aur√©lien. 2023a. Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. Third edition. Beijing Boston Farnham Sebastopol Tokyo: O‚ÄôReilly.\n\n\n‚Äî‚Äî‚Äî. 2023b. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras und TensorFlow: Konzepte, Tools und Techniken f√ºr intelligente Systeme. √úbersetzt von Kristian Rother und Thomas Demmig. 3., aktualisierte und erweiterte Auflage. Heidelberg: O‚ÄôReilly.\n\n\nRothman, Denis. 2022. Transformers for Natural Language Processing: Build, Train, and Fine-Tune Deep Neural Network Architectures for NLP with Python, Hugging Face, and OpenAI¬¥s GPT3, ChatGPT, and GPT-4. Second edition. Expert Insight. Birmingham Mumbai: Packt.\n\n\nTunstall, Lewis, Leandro von Werra, Thomas Wolf, und Aur√©lien G√©ron. 2022. Natural Language Processing with Transformers: Building Language Applications with Hugging Face. Revised edition. Sebastopol: O‚ÄôReilly.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, und Illia Polosukhin. 2023. ‚ÄûAttention Is All You Need‚Äú. 1. August 2023. https://doi.org/10.48550/arXiv.1706.03762.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>17</span>¬† <span class='chapter-title'>Transformer</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#vorab",
    "href": "130-chatgpt.html#vorab",
    "title": "\n18¬† ChatGPT-API\n",
    "section": "\n18.1 Vorab",
    "text": "18.1 Vorab\n\n18.1.1 Lernziele\n\nSie k√∂nnen g√§ngige Anfragen an die OpenAI-ChatGPT-API senden.\n\n18.1.2 Ben√∂tigte Software\n\nlibrary(stringr)\nlibrary(httr)  # Wrapper um curl\n\n\n18.1.3 Spielzeug-Daten\n\ntweets &lt;- c(\n'@corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?', '@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.')",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#grundlagen",
    "href": "130-chatgpt.html#grundlagen",
    "title": "\n18¬† ChatGPT-API\n",
    "section": "\n18.2 Grundlagen",
    "text": "18.2 Grundlagen\n\n18.2.1 ChatGPT ist auch ein Transformer\n\nüë®‚Äçüè´ Bist du ein Transformer?\n\n\nü§ñ Ja, ich bin ein Modell, das auf der GPT-3.5-Architektur von OpenAI basiert, und diese Architektur wird als ‚ÄúTransformer‚Äù bezeichnet. Der Begriff ‚ÄúTransformer‚Äù bezieht sich auf die spezifische Architektur des neuronalen Netzwerks, die von Vaswani et al.¬†in ihrem Paper ‚ÄúAttention is All You Need‚Äù vorgestellt wurde. Die Transformer-Architektur hat sich als √§u√üerst leistungsf√§hig f√ºr nat√ºrliche Sprachverarbeitungsaufgaben erwiesen und bildet die Grundlage f√ºr Modelle wie GPT (Generative Pre-trained Transformer), einschlie√ülich GPT-3.5, auf dem meine F√§higkeiten basieren.\n\n[Quelle: ChatGPT-3.5, 2023-11-23]\n\n18.2.2 Alles ist API\nDie Python- (oder R-)Pakete zum Zugriff zur ChatGPT-API sind letztlich nur Wrapper um den ‚Äúdirekten‚Äù Zugriff auf die API.\n\nDefinition 18.1 (API (Application Programming Interface)) Eine API stellt genormte Befehle zur Verf√ºgung, um von einem Dienst (√ºber eine Webseite) Daten abzufragen oder einzustellen. \\(\\square\\)\n\n\n18.2.3 curl\n\ncurl ist eine g√§ngige Methode (auf der Kommondozeile), um Daten von einer Webseite abzufragen (oder einzustellen).\nLaut Dokumentation der API lautet der CURL-Befehl wie folgt (Pseudocode):\n\n```{zsh}\n#| eval: false\ncurl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n  \"model\": \"gpt-3.5-turbo\",\n  \"messages\": [{\"role\": \"user\", \"content\": \"Was ist die Frage zur Antwort '42'?\"}] ,\n  \"temperature\": 0,\n  \"max_tokens\": 256\n}'\n```\n\nEntscheidend ist der ‚ÄúEndpunkt‚Äù der URL: completions.\n\n\n\n\n\n\nHinweis\n\n\n\nOpenAi stellt eine Reihe von spezialisierten Diensten zur Verf√ºgung, z.B. zur Sentimentanalyse von Tweets oder, nat√ºrlich, Textgeneration, und vieles mehr. \\(\\square\\)\n\n\nObige Syntax √ºbersetzt sich so nach Python:\n\n# This code is for v1 of the openai package: pypi.org/project/openai\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[],\n  temperature=0,\n  max_tokens=256\n)\n\n\n18.2.4 Prompting\nAls Prompt kann man z.B. √ºbergeben (bezeichnet als ‚ÄúSystem‚Äù):\n\nüßë‚Äçü¶∞ You will be provided with a tweet, and your task is to classify its sentiment as positive, neutral, or negative. USER\n\nDann kommt der zu klassifizierende Textschnipsel (bezeichent als ‚Äúuser‚Äù):\n\nüìÑ I loved the new Batman movie!\n\nUnd schlie√ülich antwortet der Bot:\n\nü§ñ positive\n\nEs ist g√ºnstig, dem Bot zu sagen, in welcher Sprache der Tweet ist. Au√üerdem ist es n√ºtzlich, den Prompt (die Anweisung) bereits in der Zielsprache zu formulieren.\n\nprompt_stem &lt;- \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: \"\n\n\nprompts &lt;- \n  str_c(prompt_stem, tweets)\n\nprompts\n## [1] \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\"                                 \n## [2] \"Nach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\"\n\n\n18.2.5 Anmelden an der API\nDie API erlaubt nur Zugriffe angemeldeter Nutzer.\n\nOPENAI_API_KEY &lt;- Sys.getenv(\"OPENAI_API_KEY\")\n\nDamit eine Environment-Variable OPENAI_API_KEY ausgelesen werden kann, muss sie in .Rprofile definiert sein. Alternativ kann man aber die Variable auch auf anderen Wegen definieren, etwa aus einer Textdatei einlesen.\n\n\n\n\n\n\nWichtig\n\n\n\nLassen Sie sensible Daten, wie API-Keys, niemals auf √∂ffentlichen Ordnern oder Repos (etwa auf Github) herumliegen. Stellen Sie sich vor, Sie haben bei dem Dienst ihre Kreditkarte hinterlege und ein √ºbelwollender Dritter nutzt kostenpflichtige Dienste mit sehr hohem Budget. ü§Ø \\(\\square\\)",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#wrapper-um-curl",
    "href": "130-chatgpt.html#wrapper-um-curl",
    "title": "\n18¬† ChatGPT-API\n",
    "section": "\n18.3 Wrapper um curl",
    "text": "18.3 Wrapper um curl\nDieser Abschnitt basiert auf einem Blogpost bei R-Bloggers von Rasmus B√•√•th.\n\nresponse &lt;- POST(\n  # curl https://api.openai.com/v1/chat/completions \n  url = \"https://api.openai.com/v1/chat/completions\", \n  # -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  add_headers(Authorization = \n                paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\"))),\n  # -H \"Content-Type: application/json\"\n  content_type_json(),\n  # -d '{\n  #   \"model\": \"gpt-3.5-turbo\",\n  #   \"messages\": [{\"role\": \"user\", \"content\": \"What is a banana?\"}] \n  # }'\n  encode = \"json\",\n  body = list(\n    model = \"gpt-3.5-turbo\",\n    messages = list(list(role = \"user\", content = prompts[1]))\n  ))\n\n\ncontent(response)\n\n$object\n[1] \"chat.completion\"\n\n$created\n[1] 1700753610\n\n$model\n[1] \"gpt-3.5-turbo-0613\"\n\n$choices\n$choices[[1]]\n$choices[[1]]$index\n[1] 0\n\n$choices[[1]]$message\n$choices[[1]]$message$role\n[1] \"assistant\"\n\n$choices[[1]]$message$content\n[1] \"Das Sentiment dieses Tweets ist positiv. \"\n\n$choices[[1]]$finish_reason\n[1] \"stop\"\n\n$usage\n$usage$prompt_tokens\n[1] 76\n\n$usage$completion_tokens\n[1] 10\n\n$usage$total_tokens\n[1] 86\nDer f√ºr uns entscheidende Punkt ist:\n\nstr_trim(content(response)$choices[[1]]$message$content)\n\nDas Sentiment dieses Tweets ist positiv. \n\n18.3.1 Curl-Wrapper in eine Funktion gebracht\n\nask_chatgpt &lt;- function(prompt) {\nresponse &lt;- POST(\n  # curl https://api.openai.com/v1/chat/completions \n  url = \"https://api.openai.com/v1/chat/completions\", \n  # -H \"Authorization: Bearer $OPENAI_API_KEY\"\n  add_headers(Authorization = \n                paste(\"Bearer\", Sys.getenv(\"OPENAI_API_KEY\"))),\n  # -H \"Content-Type: application/json\"\n  content_type_json(),\n  # -d '{\n  #   \"model\": \"gpt-3.5-turbo\",\n  #   \"messages\": [{\"role\": \"user\", \"content\": \"What is a banana?\"}] \n  # }'\n  encode = \"json\",\n  body = list(\n    model = \"gpt-3.5-turbo\",\n    messages = list(list(role = \"user\", content = prompt))\n  ))\n  str_trim(content(response)$choices[[1]]$message$content)\n}\n\n\n18.3.2 Schleife\n\nprompts |&gt; \n  sapply(ask_chatgpt)\n\nNach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @corinnamilborn Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar? \n\n\"positiv\" \n \nNach dem Doppelpunkt folgt ein Tweet in deutscher Sprache. Klassifizieren Sie das Sentiment dieses Tweets als positiv, neutral oder negativ. Antworten Sie nur mit einem Wort. Hier ist der Tweet: @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir. \n\n \"neutral\"",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#vertiefung",
    "href": "130-chatgpt.html#vertiefung",
    "title": "\n18¬† ChatGPT-API\n",
    "section": "\n18.4 Vertiefung",
    "text": "18.4 Vertiefung\nMit etwas Zusatzaufwand kann man den Kontext bzw. den Verlauf der Konversation mit dem Bot ber√ºcksichtigen, wie dieser Post zeigt.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "130-chatgpt.html#aufgaben",
    "href": "130-chatgpt.html#aufgaben",
    "title": "\n18¬† ChatGPT-API\n",
    "section": "\n18.5 Aufgaben",
    "text": "18.5 Aufgaben\nSchauen Sie sich die Aufgaben mit dem Tag ‚ÄòTransformer‚Äô auf dem Datenwerk an.",
    "crumbs": [
      "Deep Learning",
      "<span class='chapter-number'>18</span>¬† <span class='chapter-title'>ChatGPT-API</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#pipeline-management",
    "href": "200-projektmgt.html#pipeline-management",
    "title": "\n19¬† Projektmanagement\n",
    "section": "\n19.1 Pipeline-Management",
    "text": "19.1 Pipeline-Management\n\n19.1.1 Am Anfang\nSie haben Gro√ües vor! Naja, zumindest planen Sie ein neues Data-Science-Projekt.\nUnd, schlau wie Sie sind, st√ºrzen Sie nicht sofort an die Tastatur, um sich einige Modelle berechnen zu lassen. Nein! Sie denken erst einmal nach. Zum Beispiel, wie die einzelnen Analyseschritte aussehen, worin sie bestehen, und in welcher Abfolge sie zu berechnen sind, s. Abbildung¬†19.1.\n\n\n\n\n\nAbbildung¬†19.1: So k√∂nnte Ihr Projektplan am Anfang aussehen, man spricht auch von einer Pipeline\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDen Graph der einzelnen Analyseschritte in ihrer Abh√§ngigkeit bezeichnet man als *Pipeline.\n\n\n\n19.1.2 Sie tr√§umen von einem Werkzeug\nNach einiger Zeit √ºberlegen Sie sich, dass Sie ein System br√§uchten, das Ihre Skizze umsetzt in tats√§chliche Berechnungen. Und zwar suchen Sie ein Projektmanagement-System das folgendes Desiderata erf√ºllt:\n\nEs f√ºhrt die einzelnen Schritte Ihres Projekt, die ‚ÄúPipeline‚Äù in der richtigen Reihenfolge\nEs aktualisiert veraltete Objekte, aber es berechnet nicht Modelle neu, die unver√§ndert sind\nEs ist gut zu debuggen\n\nJa, von so einem Werkzeug tr√§umen Sie.\nUnd tats√§chlich, Ihr Traum geht in Erf√ºllung. Dieses System existiert. Genau genommen gibt es viele Systeme, die sich anschicken, Ihre W√ºnsche zu erf√ºllen. Wir schauen uns eines n√§her an, das speziell f√ºr R gemacht ist. Das R-Paket targets.\n\n19.1.3 Targets\nEs lohnt sich, an dieser Stelle den ‚ÄúWalkthrough‚Äù aus dem Benutzerhandbuch von Targets durchzuarbeiten.\nF√ºr ein Projekt √§hnlich zu den, die wir in diesem Buch bearbeiten, ist folgende _targets.R-Datei ein guter Start.\n\nlibrary(targets)\n\n\n# Funktionen einlesen:\n#purrr::walk(list.files(path = \"funs\", pattern = \".R\", full.names = TRUE), source)\nsource(\"funs/def-recipe.R\")\nsource(\"funs/read-train-data.R\")\nsource(\"funs/read-test-data.R\")\n\n# Optionen, z.B. allgemein verf√ºgbare Pakete in den Targets:tar_option_set(packages = c(\"readr\", \n                            \"dplyr\", \n                            \"ggplot2\", \n                            \"purrr\", \n                            \"easystats\", \n                            \"tidymodels\", \n                            \"textrecipes\"))\n\n# Definition der Pipeline:\nlist(\n  tar_target(data_train, read_train_data()),\n  tar_target(data_test, read_test_data()),\n  tar_target(recipe1, def_recipe(data_train)\n  ),\n  tar_target(model1,\n             logistic_reg(penalty = tune(), mixture = 1) %&gt;%\n               set_mode(\"classification\") %&gt;%\n               set_engine(\"glmnet\")\n             ),\n  tar_target(workflow1,\n             workflow() %&gt;% add_recipe(recipe1) %&gt;% add_model(model1)\n             ),\n  tar_target(grid1,\n             grid_regular(penalty(), levels = 3)\n             ),\n  tar_target(grid_fitted,\n             tune_grid(workflow1, \n                       resamples = vfold_cv(data_train, v = 2),\n                       grid = grid1)\n  ),\n  tar_target(best_hyperparams,\n             select_by_one_std_err(grid_fitted, metric = \"roc_auc\", penalty)\n             ),\n  tar_target(fit1,\n             workflow1 %&gt;% finalize_workflow(best_hyperparams) %&gt;% fit(data_train)),\n  tar_target(preds,\n             fit1 %&gt;% \n               predict(data_test) %&gt;% \n               bind_cols(data_test) %&gt;% \n               mutate(c1 = factor(c1))),\n  tar_target(metrics1,\n             preds %&gt;% metrics(truth = c1, .pred_class))\n)\n\nDann kann man auf den Play-Button dr√ºcken und die ganze Pipeline wird berechnet:\n\ntar_make()\n\nWenn die Pipeline aktuell ist, und nichts berechnet werden muss (und daher auch schon fehlerfrei durchgelaufen ist), sieht die Ausgabe so aus:\n‚úî skip target grid1\n‚úî skip target model1\n‚úî skip target data_train\n‚úî skip target data_test\n‚úî skip target recipe1\n‚úî skip target workflow1\n‚úî skip target grid_fitted\n‚úî skip target best_hyperparams\n‚úî skip target fit1\n‚úî skip target preds\n‚úî skip target metrics1\n‚úî skip pipeline [0.121 seconds]\nDie Pipeline kann man sich als DAG bzw. als Abh√§ngigkeitsgraph visualisieren lassen:\n\ntar_visnetwork()\n\n\n\nAbh√§ngigkeitsgraph der Pipeline\n\nEinzelne Objekte kann man sich komfortabel anschauen mit tar_load(objekt), z.B. tar_load(fit1) usw.\n\n19.1.4 Eine Pipeline als Spielwiese\nDieses Github-Repo stellt Ihnen eine ‚ÄúSpielwiese‚Äù zur Verf√ºgung, wo Sie sich mit Pipleines √† la Targets vertraut machen k√∂nnen.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#zeit-sparen",
    "href": "200-projektmgt.html#zeit-sparen",
    "title": "\n19¬† Projektmanagement\n",
    "section": "\n19.2 Zeit sparen",
    "text": "19.2 Zeit sparen\nEiner Maschine etwas beizubringen kann dauern ‚Ä¶ Ein einfaches Rechenbeispiel dazu:\n\nSie haben eine Kreuzvalidierung mit 10 Faltungen\nund 3 Wiederholungen\nund 3 Tuningparameter\nmit je 10 Werten\n\nDas sind 1033*10=900 Wiederholungen.\nLeider haben Sie noch in den ersten 10 Versuchen jeweils einen Bug, so dass sich die Rechenzeit noch einmal um den Faktor 10 erh√∂ht‚Ä¶\nDie Rechenzeit kann also schnell ins astronomische steigen. Es braucht also Methoden, um Rechenzeit zu sparen.1 Einige Methoden zum Rechenzeit sparen sind:\n\n\nCloud: Cloud-Dienste in Anspruch nehmen (faktisch mietet man damit schnelle Rechner)\n\nParallelisierung: Mehrere Kerne des eigenen Computers nutzen\n\nUpgrade: Kaufen Sie sich einen schnelleren Rechner‚Ä¶\n\nCleveres Grid-Search: Methoden wie ANOVA Racing k√∂nnen die Rechenzeit - was das Tuning - betrifft - deutlich verringern.\n\nDieser Post gibt einen √úberblick zu Rechenzeiten bei verschiedenen Tuningparameter-Optionen mit Tidymodels.\nNat√ºrlich ist die (mit Abstand) beste Methode: guten Code schreiben. Denn ‚Äúguter Code‚Äù verringert die Wahrscheinlichkeit von Bugs, und damit die Gefahr, dass die ganze sch√∂ne Rechenzeit f√ºr die Katz war.\n‚ÄúGuter Code‚Äù ist vielleicht prim√§r von zwei Dingen abh√§ngig: erstens einen guten Plan zu haben bevor man das Programmieren anf√§ngt und zweitens gute Methoden des Projektmanagements. Hunt und Thomas (2000) pr√§sentieren eine weithin anerkannte Umsetzung, was ‚Äúguter‚Äù Code bedeuten k√∂nnte.\n\n\nQuelle: imgflip.com",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#publizieren",
    "href": "200-projektmgt.html#publizieren",
    "title": "\n19¬† Projektmanagement\n",
    "section": "\n19.3 Publizieren",
    "text": "19.3 Publizieren\nSie haben eine super Analyse geschrieben, eine schicke Pipeline, und jetzt soll die Welt davon erfahren? Es gibt einige komfortable M√∂glichkeiten, Ihre Arbeit zu publizieren, z.B. als Blog mit Quarto.\nDieses Video zeigt Ihnen wie man einen Quarto-Blog in RStudio erstellt und ihn bei Netlify publiziert.\n\nDas Hosten bzw. Deployen bei Netlify ist kostenlos (in der Basis-Variante).\nSie k√∂nnen alternativ Github Pages als Hosting-Dienst verwenden. Dieses Video gibt dazu eine Anleitung.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "200-projektmgt.html#komplexit√§tsmanagement",
    "href": "200-projektmgt.html#komplexit√§tsmanagement",
    "title": "\n19¬† Projektmanagement\n",
    "section": "\n19.4 Komplexit√§tsmanagement",
    "text": "19.4 Komplexit√§tsmanagement\nProgrammieren ist faszinierend. Vor allem, wenn das Programm funktioniert. Genau genommen ist es eigentlich nur dann faszinierend, ansonsten wird es anstrengend? aufregend? s√ºchtig? faszinierend? nervig? Wie auch immer: Bugs treten auf und mit steigender Komplexit√§t Ihrer Software steigen die Bugs nicht linear, sondern eher quadratisch oder gar exponentiell an.\nEs gibt viele Ans√§tze, sich gegen die Komplexit√§t zu ‚Äúwehren‚Äù. Der beste ist vielleicht: Die Software so einfach wie m√∂glich zu halten - und nur so komplex wie n√∂tig. Sozusagen: Das beste Feature ist das, das Sie nicht implementieren.\n\n19.4.1 Geben Sie gute Namen\nDaraus leitet sich ab, dass die zentralen Methoden, um der Fehler Herr zu werden im Komplexit√§tsmanagement liegen. Den Variablen (Objekten) ‚Äúgute‚Äù, ‚Äúsprechende‚Äù, aber pr√§gnante Namen zu geben, ist in diesem Lichte auch als Komplexit√§tsmanagement (Reduktion) zu verstehen.\nEin typischer Fehler, der mir immer mal wieder passiert, ist: Ich √§ndere den Namen eines Objekts, aber vergesse, an allen Stellen im Code den Namen anzupassen. Gl√ºcklicherweise gibt es hier eine einfache Abhilfe: Replace-All.\nDer zwar einfache Weg, mehrere √§hnliche Objekte durchzunummerieren (workflow2a, recipe1, ‚Ä¶). ist zwar einfach, aber insgesamt nicht zu empfehlen: Es ist nicht leicht, immer genau zu wissen, was der Inhalt hinter der Nummer 2a etc. ist. √Ñndert man au√üerdem die Reihenfolge (oder schiebt ein Objekt dazwischen ein), macht die Nummerierung keinen Sinn mehr (oder man muss m√ºhselig die Nummern √§ndern, was fehleranf√§llig und nervig ist).\n\n19.4.2 Portionieren\nEine andere, zentrale Ma√ünahme ist es, den Code in handlichen ‚ÄúH√§ppchen‚Äù zu verpacken. Statt einer Skriptdatei mit zich Tausend Zeilen, w√ºnschen Sie sich doch sicher ein Skript der Art:\nmache_1()\nmache_2()\nmache_3()\ngratuliere_fertig()\nSchaut man dann in mache_1() rein, sieht man wiederum √ºbersichtlichen Code.\nFunktionales Programmieren ist eine Umsetzung davon: Jedes H√§ppchen, jeder Schritt ist eine Funktion. Eine Funktion hat Input und Output; der Output ist dann der Input f√ºr die Funktion des n√§chsten Schrittes. targets ist eine Umsetzung dieser Idee.\n\n19.4.3 Debugging mit einem Logger\nWenn das Kind in dem Brunnen gefallen ist, hilft nur Heulen und Wehklagen Das Problem finden und l√∂sen. Mit einem Logger kann man sich das Entwanzen, das Finden der Fehler, erleichtern. Ein Logger schreibt Zwischenschritte in eine Log-Datei.\nHier ist ein Beispiel mit dem futile Logger:. Mein Problem war, dass ich eine dynamische Aufgabe f√ºr eine Statistik-Klausur programmiert hatte, aber leider gab es einen Bug, den ich nicht gefunden habe2.\nDie L√∂sung brachte ein Logger, mit dem ich den Wert zentraler Variablen im Verlauf des Durchlaufens des Codes - bis eben der Laufzeitfehler aufkam3.\nHier ist ein Ausschnitt der Syntax. Zuerst initialisiert man den Logger mit einer Datei, hier exams.log. Neue Logging-Inhalte sollen an die bestehenden Logs angeh√§ngt werden (appender).\n\nlibrary(futile.logger)\nflog.appender(appender.file(\"/Users/sebastiansaueruser/github-repos/rexams-exams/exams.log\"))\n\nDann gebe ich eine Loggings vom Typ ‚ÄúInfo‚Äù zum Protokoll:\n\nflog.info(paste0(\"Ex: post-uncertainty1\"))\nflog.info(msg = paste0(\"Data set: \", d_name))\nflog.info(paste0(\"Preds chosen: \", stringr::str_c(preds_chosen, collapse = \", \")))\nflog.info(paste0(\"Output var: \", av))\n\nDie Ergebnisse kann man dann in der Logging-Datei anschauen:\nNFO [2023-01-05 11:27:51] Rhats: 1.004503053029\nINFO [2023-01-05 11:27:51] Sol: 0.18\nINFO [2023-01-05 11:27:51] Sol typeof: double\nINFO [2023-01-05 11:27:52] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:52] Data set: tips\nINFO [2023-01-05 11:27:52] Preds chosen: size, total_bill\nINFO [2023-01-05 11:27:52] Output var: tip\nINFO [2023-01-05 11:27:53] Rhats: 0.999004883794722\nINFO [2023-01-05 11:27:53] Rhats: 1.00021605674421\nINFO [2023-01-05 11:27:53] Rhats: 1.00091357638756\nINFO [2023-01-05 11:27:53] Sol: 0.32\nINFO [2023-01-05 11:27:53] Sol typeof: double\nINFO [2023-01-05 11:27:54] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:54] Data set: TeachingRatings\nINFO [2023-01-05 11:27:54] Preds chosen: prof, beauty\nINFO [2023-01-05 11:27:54] Output var: eval\nINFO [2023-01-05 11:27:55] Rhats: 0.999060308710712\nINFO [2023-01-05 11:27:55] Rhats: 0.999032305267221\nINFO [2023-01-05 11:27:55] Rhats: 0.999229003550072\nINFO [2023-01-05 11:27:55] Sol: 0\nINFO [2023-01-05 11:27:55] Sol typeof: double\nINFO [2023-01-05 11:27:56] Ex: post-uncertainty1\nINFO [2023-01-05 11:27:56] Data set: gtcars\nINFO [2023-01-05 11:27:56] Preds chosen: mpg_c, year\nINFO [2023-01-05 11:27:56] Output var: msrp\nINFO [2023-01-05 11:28:00] Rhats: 0.99913061005524\nINFO [2023-01-05 11:28:00] Rhats: 0.998999786100339\nINFO [2023-01-05 11:28:00] Rhats: 0.999130286784586\nINFO [2023-01-05 11:28:01] Sol: 21959.35\nINFO [2023-01-05 11:28:01] Sol typeof: double\nJa, das sieht nicht sch√∂n aus. Aber es brachte mir die L√∂sung: Mir fiel auf, dass der Fehler nur auftrat, wenn sol einen gro√üen Wert hatte (1000 oder mehr). Danke, Logger!\n\n\n\n\nHunt, Andrew, und David Thomas. 2000. The Pragmatic Programmer from Journeyman to Master. Reading, Mass.: Addison-Wesley.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>19</span>¬† <span class='chapter-title'>Projektmanagement</span>"
    ]
  },
  {
    "objectID": "300-fallstudien.html#quellen-f√ºr-textdaten",
    "href": "300-fallstudien.html#quellen-f√ºr-textdaten",
    "title": "20¬† Fallstudien",
    "section": "20.1 Quellen f√ºr Textdaten",
    "text": "20.1 Quellen f√ºr Textdaten\nDer MonkeyLearn Blog liefert eine Reihe von Quellen zu API, die Textdaten bereitstellen.",
    "crumbs": [
      "Anwendung",
      "<span class='chapter-number'>20</span>¬† <span class='chapter-title'>Fallstudien</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Alkomah, Fatimah, and Xiaogang Ma. 2022. ‚ÄúA Literature\nReview of Textual Hate Speech Detection Methods and\nDatasets.‚Äù Information 13 (6, 6): 273. https://doi.org/10.3390/info13060273.\n\n\nAlmeida, Felipe, and Geraldo Xex√©o. 2019. ‚ÄúWord\nEmbeddings: A Survey.‚Äù ArXiv,\nJanuary. https://www.semanticscholar.org/paper/Word-Embeddings%3A-A-Survey-Almeida-Xex%C3%A9o/e28e81a8cb6655aebb72357538f7b7a360366a29.\n\n\nBarry, Paul. 2017. Python von Kopf bis Fu√ü. Translated by\nJ√∏rgen W. Lang. Zweite Auflage. Von Kopf bis Fu√ü. Beijing Boston\nFarnham Sebastopol Tokyo: O‚ÄôReilly.\n\n\nCamacho-Collados, Jose, and Mohammad Taher Pilehvar. 2020.\n‚ÄúEmbeddings in Natural Language Processing.‚Äù\nIn Proceedings of the 28th International Conference on\nComputational Linguistics: Tutorial\nAbstracts, 10‚Äì15. Barcelona, Spain (Online):\nInternational Committee for Computational Linguistics. https://doi.org/10.18653/v1/2020.coling-tutorials.2.\n\n\nCasta√±o-Pulgar√≠n, Sergio Andr√©s, Natalia Su√°rez-Betancur, Luz Magnolia\nTilano Vega, and Harvey Mauricio Herrera L√≥pez. 2021. ‚ÄúInternet,\nSocial Media and Online Hate Speech. Systematic\nReview.‚Äù Aggression and Violent Behavior 58 (May):\n101608. https://doi.org/10.1016/j.avb.2021.101608.\n\n\nChollet, Fran√ßois. 2021. Deep Learning with\nPython. Second edition. Shelter Island,\nNY: Manning.\n\n\nChollet, Fran√ßois, Tomasz Kalinowski, and J. J. Allaire. 2022a. Deep\nLearning with R. Second edition. Shelter Island,\nNY: Manning.\n\n\n‚Äî‚Äî‚Äî. 2022b. Deep Learning with R. Second edition.\nShelter Island, NY: Manning Publications Co.\n\n\nDowney, Allen B. 2021. Think Python: systematisch programmieren\nlernen mit Python. Translated by Peter Klicman. 1. Auflage.\nHeidelberg: O‚ÄôReilly.\n\n\nGallatin, Kyle, and Chris Albon. 2023. Machine Learning with\nPython Cookbook: Practical Solutions from Preprocessing to\nDeep Learning. Beijing Boston Farnham Sebastopol\nTokyo: O‚ÄôReilly Media.\n\n\nGeorge, Alexandra. 2022. Python Text Mining: Perform Text\nProcessing, Word Embedding, Text Classification and Machine\nTranslation. Delhi: BPB Publications.\n\n\nG√©ron, Aur√©lien. 2023a. Hands-on Machine Learning with\nScikit-Learn, Keras, and\nTensorFlow: Concepts, Tools, and Techniques to Build\nIntelligent Systems. Third edition. Beijing Boston Farnham\nSebastopol Tokyo: O‚ÄôReilly.\n\n\n‚Äî‚Äî‚Äî. 2023b. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras\nund TensorFlow: Konzepte, Tools und Techniken f√ºr intelligente\nSysteme. Translated by Kristian Rother and Thomas Demmig. 3.,\naktualisierte und erweiterte Auflage. Heidelberg:\nO‚ÄôReilly.\n\n\n‚Äî‚Äî‚Äî. 2023c. Praxiseinstieg Machine Learning mit Scikit-Learn, Keras\nund TensorFlow: Konzepte, Tools und Techniken f√ºr intelligente\nSysteme. Translated by Kristian Rother and Thomas Demmig. 3.,\naktualisierte und erweiterte Auflage. Heidelberg:\nO‚ÄôReilly.\n\n\nHunt, Andrew, and David Thomas. 2000. The Pragmatic Programmer from\nJourneyman to Master. Reading, Mass.:\nAddison-Wesley.\n\n\nHvitfeldt, Emil, and Julia Silge. 2021. Supervised Machine\nLearning for Text Analysis in R.\n1st ed. Boca Raton: Chapman and Hall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nInden, Michael. 2023. Python lernen: kurz & gut. 1.\nAuflage. O‚ÄôReillys Taschenbibliothek. Heidelberg:\nO‚ÄôReilly.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2021. An Introduction to Statistical Learning: With Applications in\nR. Second edition. Springer Texts in Statistics.\nNew York: Springer. https://link.springer.com/book/10.1007/978-1-0716-1418-1.\n\n\nK√∂nig, Tim, Wolf J. Sch√ºnemann, Alexander Brand, Julian Freyberg, and\nMichael Gertz. 2022. ‚ÄúThe EPINetz Twitter Politicians\nDataset 2021. A New Resource for the Study of the German\nTwittersphere and Its Application for the 2021 Federal\nElections.‚Äù Politische Vierteljahresschrift 63 (3):\n529‚Äì47. https://doi.org/10.1007/s11615-022-00405-7.\n\n\nKulkarni, Akshay, and Adarsha Shivananda. 2021. Natural Language\nProcessing Recipes: Unlocking Text Data with Machine Learning and Deep\nLearning Using Python. Second edition. New\nYork: Apress.\n\n\nKurz, A. Solomon. 2021. Statistical Rethinking with Brms, Ggplot2,\nand the Tidyverse: Second Edition. https://bookdown.org/content/4857/.\n\n\nLex, Alexander, Nils Gehlenborg, Hendrik Strobelt, Romain Vuillemot, and\nHanspeter Pfister. 2014. ‚ÄúUpSet:\nVisualization of Intersecting Sets.‚Äù IEEE\nTransactions on Visualization and Computer Graphics 20 (12):\n1983‚Äì92. https://doi.org/10.1109/TVCG.2014.2346248.\n\n\nLiu, Zhiyuan, Yankai Lin, and Maosong Sun, eds. 2023. Representation\nLearning for Natural Language Processing.\nSingapore: Springer Nature Singapore. https://doi.org/10.1007/978-981-99-1600-9.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A\nBayesian Course with Examples in R and\nStan. 2nd ed. CRC Texts in Statistical\nScience. Boca Raton: Taylor and Francis, CRC\nPress.\n\n\nMikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013.\n‚ÄúEfficient Estimation of Word\nRepresentations in Vector Space.‚Äù September\n6, 2013. https://doi.org/10.48550/arXiv.1301.3781.\n\n\nPennington, Jeffrey, Richard Socher, and Christopher Manning. 2014.\n‚ÄúGloVe: Global Vectors for Word\nRepresentation.‚Äù In Proceedings of the 2014 Conference on\nEmpirical Methods in Natural Language Processing\n(EMNLP), 1532‚Äì43. Doha, Qatar:\nAssociation for Computational Linguistics. https://doi.org/10.3115/v1/D14-1162.\n\n\nPilehvar, Mohammad Taher, and Jose Camacho-Collados. 2021.\nEmbeddings in Natural Language Processing:\nTheory and Advances in Vector\nRepresentations of Meaning. Synthesis\nLectures on Human Language Technologies.\nCham: Springer International Publishing. https://doi.org/10.1007/978-3-031-02177-0.\n\n\nRemus, Robert, Uwe Quasthoff, and Gerhard Heyer. 2010.\n‚ÄúSentiWS - a Publicly Available German-Language\nResource for Sentiment Analysis.‚Äù Proceedings of the 7th\nInternational Language Ressources and Evaluation (LREC‚Äô10),\n1168‚Äì71.\n\n\nRhys, Hefin. 2020. Machine Learning with\nR, the Tidyverse, and Mlr. Shelter Island,\nNY: Manning publications.\n\n\nRisch, Julian, Anke Stoll, Lena Wilms, and Michael Wiegand. 2021.\n‚ÄúOverview of the GermEval 2021 Shared Task on the\nIdentification of Toxic, Engaging, and Fact-Claiming Comments.‚Äù\nIn Proceedings of the GermEval 2021 Shared Task on the\nIdentification of Toxic, Engaging, and Fact-Claiming Comments,\n1‚Äì12. Duesseldorf, Germany: Association for\nComputational Linguistics. https://aclanthology.org/2021.germeval-1.1.\n\n\nRothman, Denis. 2022. Transformers for Natural Language Processing:\nBuild, Train, and Fine-Tune Deep Neural Network Architectures for\nNLP with Python, Hugging Face,\nand OpenAI¬¥s GPT3, ChatGPT, and\nGPT-4. Second edition. Expert Insight.\nBirmingham Mumbai: Packt.\n\n\nShannon, C. E. 1948. ‚ÄúA Mathematical Theory of\nCommunication.‚Äù Bell System Technical Journal 27 (3):\n379‚Äì423. https://doi.org/10.1002/j.1538-7305.1948.tb01338.x.\n\n\nSiegel, Melanie, and Melpomeni Alexa. 2020. Sentiment-Analyse\ndeutschsprachiger Meinungs√§u√üerungen: Grundlagen, Methoden und\npraktische Umsetzung. Wiesbaden: Springer\nFachmedien Wiesbaden. https://doi.org/10.1007/978-3-658-29699-5.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with\nR: A Tidy Approach. First edition. Beijing ;\nBoston: O‚ÄôReilly. https://www.tidytextmining.com/.\n\n\nStone, James V. 2019. ‚ÄúInformation Theory: A\nTutorial Introduction.‚Äù June 13, 2019. http://arxiv.org/abs/1802.05968.\n\n\nTunstall, Lewis, Leandro von Werra, Thomas Wolf, and Aur√©lien G√©ron.\n2022. Natural Language Processing with Transformers: Building\nLanguage Applications with Hugging Face. Revised edition.\nSebastopol: O‚ÄôReilly.\n\n\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\nJones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2023.\n‚ÄúAttention Is All You Need.‚Äù August 1, 2023.\nhttps://doi.org/10.48550/arXiv.1706.03762.\n\n\nWickham, Hadley, and Garrett Grolemund. 2016. R for Data\nScience: Visualize, Model,\nTransform, Tidy, and Import\nData. O‚ÄôReilly Media. https://r4ds.had.co.nz/index.html.\n\n\nWiegand, Michael. 2019a. ‚ÄúGermEval-2018 Corpus\n(DE).‚Äù heiDATA. https://doi.org/10.11588/data/0B5VML.\n\n\n‚Äî‚Äî‚Äî. 2019b. ‚ÄúGermEval-2018 Corpus\n(DE).‚Äù heiDATA. https://doi.org/10.11588/data/0B5VML.\n\n\n‚Äî‚Äî‚Äî. 2019c. ‚ÄúGermEval-2018-Data-master.‚Äù In\nGermEval-2018 Corpus (DE).\nheiDATA. https://doi.org/10.11588/data/0B5VML/XIUWJ7.\n\n\n‚ÄúWord Embeddings in NLP: A Complete\nGuide.‚Äù 2023. Turing. 2023. https://www.turing.com/kb/guide-on-word-embeddings-in-nlp.\n\n\nYamada, Ikuya, and Hiroyuki Shindo. 2019. ‚ÄúNeural Attentive\nBag-of-Entities Model for Text Classification.‚Äù In\nProceedings of the 23th SIGNLL Conference on\nComputational Natural Language Learning, 563‚Äì73. Association\nfor Computational Linguistics.",
    "crumbs": [
      "Abschluss",
      "References"
    ]
  }
]