[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science 2: Textdaten als Grundlage prädiktiver Modelle",
    "section": "",
    "text": "falls Sie die Pakete schon installiert haben, könnten Sie mal in RStudio auf “update.packages” klicken↩︎"
  },
  {
    "objectID": "klassifikation.html",
    "href": "klassifikation.html",
    "title": "1  Klassifikation von Hatespeech",
    "section": "",
    "text": "Sie können grundlegende Verfahren zur Klassifikation von Hatespeech einsetzen und erklären\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(tidymodels)\nlibrary(tidytext)\nlibrary(textrecipes)\nlibrary(lsa)  # stopwords\nlibrary(discrim)  # naive bayes classification\nlibrary(naivebayes)\nlibrary(tictoc)  # Zeitmessung\nlibrary(fastrtext)  # Worteinbettungen\nlibrary(remoji)  # Emojis\nlibrary(tokenizers)  # Vektoren tokenisieren"
  },
  {
    "objectID": "klassifikation.html#daten",
    "href": "klassifikation.html#daten",
    "title": "1  Klassifikation von Hatespeech",
    "section": "1.2 Daten",
    "text": "1.2 Daten\nFür Maschinenlernen brauchen wir Trainingsdaten, Daten also, bei denen wir pro Beobachtung der Wert der Zielvariablen kennen. Man spricht auch von “gelabelten” Daten.\nWir nutzen die Daten von Wiegand (2019a) bzw. Wiegand (2019b). Die Daten sind unter CC-By-4.0 Int. lizensiert.\n\nd_raw <- \n  import(\"data/germeval2018.training.txt\",\n         header = FALSE)\n\nWarning in (function (input = \"\", file = NULL, text = NULL, cmd = NULL, : Found\nand resolved improper quoting out-of-sample. First healed line 111: <<\"Edel sei\nder Mensch, hilfreich und gut\" - Nicht eine dieser Charaktereigenschaften kann\nMerkel für sich beanspruchen. OTHER OTHER>>. If the fields are not quoted (e.g.\nfield separator does not appear within any field), try quote=\"\" to avoid this\nwarning.\n\n\nDa die Daten keine Spaltenköpfe haben, informieren wir die Funktion dazu mit header = FALSE.\nBenennen wir die die Spalten um:\n\nnames(d_raw) <- c(\"text\", \"c1\", \"c2\")\n\nDabei soll c1 und c2 für die 1. bzw. 2. Klassifikation stehen.\nIn c1 finden sich diese Werte:\n\nd_raw %>% \n  count(c1)\n\n\n\n\n\nc1\nn\n\n\n\n\nOFFENSE\n1688\n\n\nOTHER\n3321\n\n\n\n\n\n\nHier wurde klassifiziert, ob beleidigende Sprache (offensive language) vorlag oder nicht (isch-etal-2021-overview?):\n\nTask 1 was to decide whether a tweet includes some form of offensive language or not. The tweets had to be classiﬁed into the two classes OFFENSE and OTHER. The OFFENSE category covered abusive language, insults, as well as merely profane statements.\n\nUnd in c2 finden sich folgende Ausprägungen:\n\nd_raw %>% \n  count(c2)\n\n\n\n\n\nc2\nn\n\n\n\n\nABUSE\n1022\n\n\nINSULT\n595\n\n\nOTHER\n3321\n\n\nPROFANITY\n71\n\n\n\n\n\n\nIn c2 ging es um eine feinere Klassifikation beleidigender Sprache (isch-etal-2021-overview?):\n\nThe second task involved four categories, a nonoffensive OTHER class and three sub-categories of what is OFFENSE in Task 1. In the case of PROFANITY, profane words are used, however, the tweet does not want to insult anyone. This typically concerns the usage of swearwords (Scheiße, Fuck etc.) and cursing (Zur Hölle! Verdammt! etc.). This can be often found in youth language. Swearwords and cursing may, but need not, co-occur with insults or abusive speech. Profane language may in fact be used in tweets with positive sentiment to express emphasis. Whenever profane words are not directed towards a speciﬁc person or group of persons and there are no separate cues of INSULT or ABUSE, then tweets are labeled as simple cases of PROFANITY.\n\nSind Texte, die als OFFENSE klassifiziert sind, auch (fast) immer als ABUSE, INSULT oder PROFANITY klassifiziert?\n\nd_raw %>% \n  filter(c1 == \"OTHER\", c2 == \"OTHER\") %>% \n  nrow() / nrow(d_raw)\n\n[1] 0.6630066\n\n\nIn ca. 2/3 der Fälle wurden in beiden Klassifikation OTHER klassifiziert.\n\nd_raw %>% \n  filter(c1 != \"OTHER\", c2 != \"OTHER\") %>% \n  nrow() / nrow(d_raw)\n\n[1] 0.3369934\n\n\nEntsprechend in ca. 1/3 der Fälle wurde jeweils nicht mit OTHER klassifiziert.\nWir begnügen uns hier mit der ersten, gröberen Klassifikation."
  },
  {
    "objectID": "klassifikation.html#feature-engineering",
    "href": "klassifikation.html#feature-engineering",
    "title": "1  Klassifikation von Hatespeech",
    "section": "1.3 Feature Engineering",
    "text": "1.3 Feature Engineering\nReichern wir die Daten mit weiteren Features an, in der Hoffnung, damit eine bessere Klassifikation erzielen zu können.\n\n1.3.1 Textlänge\n\nd2 <-\n  d_raw %>% \n  mutate(text_length = str_length(text)) %>% \n  mutate(id = 1:nrow(.))\n\nhead(d2)\n\n\n\n\n\n\n\n\n\n\n\n\ntext\nc1\nc2\ntext_length\nid\n\n\n\n\n(corinnamilborn?) Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar?\nOTHER\nOTHER\n109\n1\n\n\n(Martin28a?) Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.\nOTHER\nOTHER\n142\n2\n\n\n(ahrens_theo?) fröhlicher gruß aus der schönsten stadt der welt theo ⚓️\nOTHER\nOTHER\n69\n3\n\n\n(dushanwegner?) Amis hätten alles und jeden gewählt…nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\nOTHER\nOTHER\n140\n4\n\n\n(spdde?) kein verläßlicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgesprächen - schickt diese Stümper #SPD in die Versenkung.\nOFFENSE\nINSULT\n136\n5\n\n\n(Dirki_M?) Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Geschützte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bemüht - übrigens leicht rückläufig gewesen.\nOTHER\nOTHER\n284\n6\n\n\n\n\n\n\n\n\n1.3.2 Sentimentanalyse\nWir nutzen dazu SentiWS (Remus, Quasthoff, und Heyer 2010).\n\nsentiws <- read_csv(\"https://osf.io/x89wq/?action=download\")\n\nRows: 3468 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): neg_pos, word, inflections\ndbl (1): value\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nd2_long <-\n  d2 %>% \n  unnest_tokens(input = text, output = token)\n\nhead(d2_long)\n\n\n\n\n\nc1\nc2\ntext_length\nid\ntoken\n\n\n\n\nOTHER\nOTHER\n109\n1\ncorinnamilborn\n\n\nOTHER\nOTHER\n109\n1\nliebe\n\n\nOTHER\nOTHER\n109\n1\ncorinna\n\n\nOTHER\nOTHER\n109\n1\nwir\n\n\nOTHER\nOTHER\n109\n1\nwürden\n\n\nOTHER\nOTHER\n109\n1\ndich\n\n\n\n\n\n\nJetzt filtern wir unsere Textdaten so, dass nur Wörter mit Sentimentwert übrig bleiben:\n\nd2_long_senti <- \n  d2_long %>%  \n  inner_join(sentiws %>% select(-inflections), by = c(\"token\" = \"word\"))\n\nhead(d2_long)\n\n\n\n\n\nc1\nc2\ntext_length\nid\ntoken\n\n\n\n\nOTHER\nOTHER\n109\n1\ncorinnamilborn\n\n\nOTHER\nOTHER\n109\n1\nliebe\n\n\nOTHER\nOTHER\n109\n1\ncorinna\n\n\nOTHER\nOTHER\n109\n1\nwir\n\n\nOTHER\nOTHER\n109\n1\nwürden\n\n\nOTHER\nOTHER\n109\n1\ndich\n\n\n\n\n\n\nSchließlich berechnen wir die Sentimentwert pro Polarität und pro Tweet:\n\nd2_sentis <-\n  d2_long_senti %>% \n  group_by(id, neg_pos) %>% \n  summarise(senti_avg = mean(value))\n\n`summarise()` has grouped output by 'id'. You can override using the `.groups`\nargument.\n\nhead(d2_sentis)\n\n\n\n\n\nid\nneg_pos\nsenti_avg\n\n\n\n\n1\npos\n0.0040\n\n\n2\nneg\n-0.3466\n\n\n6\nneg\n-0.2042\n\n\n6\npos\n0.0040\n\n\n8\nneg\n-0.5023\n\n\n9\npos\n0.5161\n\n\n\n\n\n\nDiese Tabelle bringen wir wieder eine breitere Form, um sie dann wieder mit den Hauptdaten zu vereinigen.\n\nd2_sentis_wide <-\n  d2_sentis %>% \n  pivot_wider(names_from = \"neg_pos\", values_from = \"senti_avg\")\n\nd2_sentis_wide %>% head()\n\n\n\n\n\nid\npos\nneg\n\n\n\n\n1\n0.0040\nNA\n\n\n2\nNA\n-0.3466\n\n\n6\n0.0040\n-0.2042\n\n\n8\nNA\n-0.5023\n\n\n9\n0.5161\nNA\n\n\n11\n0.0040\nNA\n\n\n\n\n\n\n\nd3 <-\n  d2 %>% \n  full_join(d2_sentis_wide)\n\nJoining, by = \"id\"\n\nhead(d3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntext\nc1\nc2\ntext_length\nid\npos\nneg\n\n\n\n\n(corinnamilborn?) Liebe Corinna, wir würden dich gerne als Moderatorin für uns gewinnen! Wärst du begeisterbar?\nOTHER\nOTHER\n109\n1\n0.004\nNA\n\n\n(Martin28a?) Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt, kritisieren wir.\nOTHER\nOTHER\n142\n2\nNA\n-0.3466\n\n\n(ahrens_theo?) fröhlicher gruß aus der schönsten stadt der welt theo ⚓️\nOTHER\nOTHER\n69\n3\nNA\nNA\n\n\n(dushanwegner?) Amis hätten alles und jeden gewählt…nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\nOTHER\nOTHER\n140\n4\nNA\nNA\n\n\n(spdde?) kein verläßlicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgesprächen - schickt diese Stümper #SPD in die Versenkung.\nOFFENSE\nINSULT\n136\n5\nNA\nNA\n\n\n(Dirki_M?) Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Geschützte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bemüht - übrigens leicht rückläufig gewesen.\nOTHER\nOTHER\n284\n6\n0.004\n-0.2042\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDie Sentimentanalyse hier vernachlässigt Flexionen der Wörter. Der Autor fühlt den Drang zu schreiben: “Left as an exercise for the reader” :-)\n\n\n\n\n1.3.3 Schimpfwörter\nZählen wir die Schimpfwörter pro Text. Dazu nutzen wir die Daten von LDNOOBW, lizensiert nach CC-BY-4.0-Int.\n\nschimpf1 <- import(\"https://raw.githubusercontent.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/master/de\", format = \",\", header = FALSE)\n\nLänger aber noch ist die Liste aus dem InsultWiki, lizensiert CC0.\n\nschimpf2 <- \n  import(\"data/insult-de.txt\", header = FALSE) %>% \n  mutate_all(str_to_lower)\n\nBinden wir die Listen zusammen:\n\nschimpf <-\n  schimpf1 %>% \n  bind_rows(schimpf2) %>% \n  distinct() %>% \n  rename(word = \"V1\")\n\nnrow(schimpf)\n\n[1] 6208\n\n\nUm die Lesis vor (unnötiger?) Kopfverschmutzung zu bewahren, sind diese Schimpfwörter hier nicht abgedruckt.\nJetzt zählen wir, ob unsere Tweets/Texte solcherlei Wörter enthalten.\n\nd_schimpf <- \nd2_long %>% \n  select(id, token) %>% \n  mutate(schimpf = token %in% schimpf$word)\n  \nd_schimpf %>% \n  filter(schimpf)\n\n\n\n\n\nid\ntoken\nschimpf\n\n\n\n\n5\nstümper\nTRUE\n\n\n7\narsch\nTRUE\n\n\n15\nschamlos\nTRUE\n\n\n31\nschwätzer\nTRUE\n\n\n45\nhelfershelfer\nTRUE\n\n\n58\nheuchler\nTRUE\n\n\n60\nwaschlappen\nTRUE\n\n\n65\nbürger\nTRUE\n\n\n65\nmiststück\nTRUE\n\n\n69\nhause\nTRUE\n\n\n73\nhaut\nTRUE\n\n\n77\nnichts\nTRUE\n\n\n78\nnichts\nTRUE\n\n\n81\npack\nTRUE\n\n\n82\nschnecke\nTRUE\n\n\n92\nnichts\nTRUE\n\n\n95\nkleber\nTRUE\n\n\n104\npilz\nTRUE\n\n\n113\nhaut\nTRUE\n\n\n114\nweihnachtsmann\nTRUE\n\n\n117\ntyp\nTRUE\n\n\n118\ngesicht\nTRUE\n\n\n118\nfratze\nTRUE\n\n\n119\nnichts\nTRUE\n\n\n126\ndreck\nTRUE\n\n\n135\nhaut\nTRUE\n\n\n135\nkacke\nTRUE\n\n\n135\nbravo\nTRUE\n\n\n140\nnichts\nTRUE\n\n\n140\nlangsam\nTRUE\n\n\n143\nfreier\nTRUE\n\n\n152\npack\nTRUE\n\n\n155\ntroll\nTRUE\n\n\n156\nhause\nTRUE\n\n\n170\nhause\nTRUE\n\n\n174\nkammerjäger\nTRUE\n\n\n178\nnichts\nTRUE\n\n\n192\nnichts\nTRUE\n\n\n196\npest\nTRUE\n\n\n197\nnichts\nTRUE\n\n\n199\nbild\nTRUE\n\n\n203\nlauch\nTRUE\n\n\n203\nscheisser\nTRUE\n\n\n203\ntroll\nTRUE\n\n\n212\ntrolle\nTRUE\n\n\n213\narsch\nTRUE\n\n\n213\nhitler\nTRUE\n\n\n221\nding\nTRUE\n\n\n221\ngeist\nTRUE\n\n\n222\nhund\nTRUE\n\n\n227\nschauspieler\nTRUE\n\n\n229\nbürger\nTRUE\n\n\n231\nopfer\nTRUE\n\n\n246\nhitler\nTRUE\n\n\n246\nantichrist\nTRUE\n\n\n247\nidiot\nTRUE\n\n\n260\nnichts\nTRUE\n\n\n262\nschmock\nTRUE\n\n\n263\npack\nTRUE\n\n\n266\nopfer\nTRUE\n\n\n277\nsozialschmarotzer\nTRUE\n\n\n279\ndreck\nTRUE\n\n\n280\nluder\nTRUE\n\n\n283\nmarionette\nTRUE\n\n\n295\ngesicht\nTRUE\n\n\n298\nbild\nTRUE\n\n\n305\nopfer\nTRUE\n\n\n308\nart\nTRUE\n\n\n312\ntor\nTRUE\n\n\n315\nzwitter\nTRUE\n\n\n316\nseele\nTRUE\n\n\n323\nbild\nTRUE\n\n\n325\npack\nTRUE\n\n\n338\nnichts\nTRUE\n\n\n339\nart\nTRUE\n\n\n348\nhecke\nTRUE\n\n\n348\npissen\nTRUE\n\n\n358\ndreck\nTRUE\n\n\n360\nnichts\nTRUE\n\n\n368\nbild\nTRUE\n\n\n369\ntyp\nTRUE\n\n\n369\ntyp\nTRUE\n\n\n372\nhund\nTRUE\n\n\n373\nschlepper\nTRUE\n\n\n393\nwicht\nTRUE\n\n\n397\nnichts\nTRUE\n\n\n399\nhause\nTRUE\n\n\n400\nabschaum\nTRUE\n\n\n403\nniemand\nTRUE\n\n\n406\nopfer\nTRUE\n\n\n408\nniemand\nTRUE\n\n\n412\nnichts\nTRUE\n\n\n427\nnichts\nTRUE\n\n\n427\nschmarotzer\nTRUE\n\n\n428\nstück\nTRUE\n\n\n435\ndackel\nTRUE\n\n\n442\nwitzfigur\nTRUE\n\n\n444\nspinner\nTRUE\n\n\n452\nhexe\nTRUE\n\n\n453\nhitler\nTRUE\n\n\n456\nnichts\nTRUE\n\n\n457\npack\nTRUE\n\n\n457\nteufel\nTRUE\n\n\n459\nnichts\nTRUE\n\n\n461\nporno\nTRUE\n\n\n467\nfresse\nTRUE\n\n\n467\nkacke\nTRUE\n\n\n468\nmaul\nTRUE\n\n\n469\nlangsam\nTRUE\n\n\n474\nniemand\nTRUE\n\n\n481\nratte\nTRUE\n\n\n484\ndumpfbacke\nTRUE\n\n\n488\nhund\nTRUE\n\n\n488\ngurgel\nTRUE\n\n\n495\nvolksverräter\nTRUE\n\n\n513\nhaufen\nTRUE\n\n\n518\nstück\nTRUE\n\n\n518\nnichts\nTRUE\n\n\n533\nschwätzer\nTRUE\n\n\n538\npack\nTRUE\n\n\n538\nschlampe\nTRUE\n\n\n547\nabschaum\nTRUE\n\n\n547\nscheiße\nTRUE\n\n\n548\nrenner\nTRUE\n\n\n549\nschmierfinke\nTRUE\n\n\n551\ntor\nTRUE\n\n\n555\nkuh\nTRUE\n\n\n558\nhause\nTRUE\n\n\n561\nbürger\nTRUE\n\n\n565\ndieb\nTRUE\n\n\n565\ndieb\nTRUE\n\n\n574\nbild\nTRUE\n\n\n582\nnichts\nTRUE\n\n\n584\nsesselfurzer\nTRUE\n\n\n598\nnichts\nTRUE\n\n\n600\nbürger\nTRUE\n\n\n608\nschnösel\nTRUE\n\n\n611\nbild\nTRUE\n\n\n617\nhurensohn\nTRUE\n\n\n628\nausreißer\nTRUE\n\n\n629\nverbrecher\nTRUE\n\n\n630\nbürger\nTRUE\n\n\n637\nmaul\nTRUE\n\n\n638\nniemand\nTRUE\n\n\n652\nbild\nTRUE\n\n\n653\nbürger\nTRUE\n\n\n664\nflüchtling\nTRUE\n\n\n668\nneandertaler\nTRUE\n\n\n668\nprolle\nTRUE\n\n\n670\nzwitter\nTRUE\n\n\n670\nzwitter\nTRUE\n\n\n671\ngesicht\nTRUE\n\n\n678\nbild\nTRUE\n\n\n681\narsch\nTRUE\n\n\n699\nspinner\nTRUE\n\n\n700\narsch\nTRUE\n\n\n703\nbild\nTRUE\n\n\n706\nlächerlich\nTRUE\n\n\n707\ntyp\nTRUE\n\n\n707\nnichts\nTRUE\n\n\n711\nbaby\nTRUE\n\n\n718\nniemand\nTRUE\n\n\n718\nfeind\nTRUE\n\n\n728\nkuh\nTRUE\n\n\n728\nhund\nTRUE\n\n\n749\nmörder\nTRUE\n\n\n749\nvergewaltiger\nTRUE\n\n\n751\nspeichellecker\nTRUE\n\n\n757\nfreier\nTRUE\n\n\n761\nversager\nTRUE\n\n\n761\nnichts\nTRUE\n\n\n764\nvaterlandsverräter\nTRUE\n\n\n767\nniemand\nTRUE\n\n\n771\nlangsam\nTRUE\n\n\n771\nsack\nTRUE\n\n\n772\nbild\nTRUE\n\n\n774\nniemand\nTRUE\n\n\n782\nlangsam\nTRUE\n\n\n785\nzweifler\nTRUE\n\n\n791\nfeigling\nTRUE\n\n\n796\nverlierer\nTRUE\n\n\n809\nniemand\nTRUE\n\n\n811\nschimmel\nTRUE\n\n\n815\nverbrecher\nTRUE\n\n\n817\nfettsack\nTRUE\n\n\n817\npack\nTRUE\n\n\n829\narschloch\nTRUE\n\n\n834\nnichts\nTRUE\n\n\n835\nnichts\nTRUE\n\n\n837\nnull\nTRUE\n\n\n860\nniemand\nTRUE\n\n\n862\nnichts\nTRUE\n\n\n871\nhetzer\nTRUE\n\n\n872\nhartzer\nTRUE\n\n\n888\nlächerlich\nTRUE\n\n\n891\nratte\nTRUE\n\n\n893\nniemand\nTRUE\n\n\n900\nfeigling\nTRUE\n\n\n905\narsch\nTRUE\n\n\n908\npirat\nTRUE\n\n\n908\nflasche\nTRUE\n\n\n922\nmaul\nTRUE\n\n\n923\nbürger\nTRUE\n\n\n923\nbürger\nTRUE\n\n\n926\nstorch\nTRUE\n\n\n930\nknüppel\nTRUE\n\n\n932\nnichts\nTRUE\n\n\n942\ndreck\nTRUE\n\n\n943\npack\nTRUE\n\n\n950\nhecht\nTRUE\n\n\n951\npudel\nTRUE\n\n\n959\nschüssel\nTRUE\n\n\n961\nschwein\nTRUE\n\n\n965\nteufel\nTRUE\n\n\n965\nblödmann\nTRUE\n\n\n965\nidiot\nTRUE\n\n\n967\nnichts\nTRUE\n\n\n968\ntrulla\nTRUE\n\n\n976\nwaschlappen\nTRUE\n\n\n996\nopfer\nTRUE\n\n\n996\nlügner\nTRUE\n\n\n997\ndreck\nTRUE\n\n\n998\narsch\nTRUE\n\n\n1004\nbürger\nTRUE\n\n\n1012\nbürger\nTRUE\n\n\n1024\nnichts\nTRUE\n\n\n1027\nbild\nTRUE\n\n\n1030\ncurrywurst\nTRUE\n\n\n1039\nnichts\nTRUE\n\n\n1042\ntroll\nTRUE\n\n\n1046\nduckmäuser\nTRUE\n\n\n1050\nverräter\nTRUE\n\n\n1055\nziege\nTRUE\n\n\n1065\ngesicht\nTRUE\n\n\n1065\ngesicht\nTRUE\n\n\n1073\nbild\nTRUE\n\n\n1075\ngutmensch\nTRUE\n\n\n1078\nhitler\nTRUE\n\n\n1081\nhaut\nTRUE\n\n\n1081\npfeife\nTRUE\n\n\n1085\npack\nTRUE\n\n\n1092\nbürger\nTRUE\n\n\n1104\nbild\nTRUE\n\n\n1104\nschlampe\nTRUE\n\n\n1115\nspinner\nTRUE\n\n\n1116\ndreck\nTRUE\n\n\n1123\nnichts\nTRUE\n\n\n1133\ngesindel\nTRUE\n\n\n1133\nart\nTRUE\n\n\n1140\npack\nTRUE\n\n\n1140\nhitler\nTRUE\n\n\n1140\nschläger\nTRUE\n\n\n1144\nniemand\nTRUE\n\n\n1148\nmaul\nTRUE\n\n\n1150\nbesenbinder\nTRUE\n\n\n1166\nvollpfosten\nTRUE\n\n\n1170\nidiot\nTRUE\n\n\n1173\nanarchist\nTRUE\n\n\n1193\nbürger\nTRUE\n\n\n1195\nart\nTRUE\n\n\n1200\ngutmensch\nTRUE\n\n\n1203\npest\nTRUE\n\n\n1210\nkotzbrocken\nTRUE\n\n\n1216\ngesicht\nTRUE\n\n\n1227\nstück\nTRUE\n\n\n1230\nflüchtling\nTRUE\n\n\n1235\ndreck\nTRUE\n\n\n1242\nding\nTRUE\n\n\n1255\nfrauenbild\nTRUE\n\n\n1256\ngesindel\nTRUE\n\n\n1262\nwitzbold\nTRUE\n\n\n1266\neitel\nTRUE\n\n\n1266\nart\nTRUE\n\n\n1269\nbild\nTRUE\n\n\n1270\narsch\nTRUE\n\n\n1270\nlecker\nTRUE\n\n\n1272\nnichts\nTRUE\n\n\n1274\nnichts\nTRUE\n\n\n1274\nheuchler\nTRUE\n\n\n1283\nnichts\nTRUE\n\n\n1290\nmist\nTRUE\n\n\n1295\nteufel\nTRUE\n\n\n1297\ntor\nTRUE\n\n\n1316\nknecht\nTRUE\n\n\n1323\nverbrecher\nTRUE\n\n\n1328\npfeife\nTRUE\n\n\n1331\nnichts\nTRUE\n\n\n1332\nbild\nTRUE\n\n\n1344\nprügel\nTRUE\n\n\n1352\nböser\nTRUE\n\n\n1362\nmörder\nTRUE\n\n\n1377\narsch\nTRUE\n\n\n1379\nfresse\nTRUE\n\n\n1391\nnichts\nTRUE\n\n\n1393\nbürger\nTRUE\n\n\n1394\nfisch\nTRUE\n\n\n1396\nscheiße\nTRUE\n\n\n1401\nkinderschänder\nTRUE\n\n\n1402\ndummerchen\nTRUE\n\n\n1408\nziegenbart\nTRUE\n\n\n1408\ntoller\nTRUE\n\n\n1409\nverbrecher\nTRUE\n\n\n1418\nart\nTRUE\n\n\n1434\ntraumtänzer\nTRUE\n\n\n1438\nbürger\nTRUE\n\n\n1441\nnull\nTRUE\n\n\n1447\nasozialer\nTRUE\n\n\n1447\npenner\nTRUE\n\n\n1457\nverräter\nTRUE\n\n\n1460\nlangsam\nTRUE\n\n\n1465\nkasten\nTRUE\n\n\n1472\nnichts\nTRUE\n\n\n1476\neimer\nTRUE\n\n\n1483\nlauch\nTRUE\n\n\n1484\nnichts\nTRUE\n\n\n1487\nhitler\nTRUE\n\n\n1489\nstrick\nTRUE\n\n\n1491\nkacke\nTRUE\n\n\n1493\nstreiter\nTRUE\n\n\n1494\ntonne\nTRUE\n\n\n1495\nopfer\nTRUE\n\n\n1495\nopfer\nTRUE\n\n\n1499\nnichts\nTRUE\n\n\n1504\nschlaumeier\nTRUE\n\n\n1504\nbild\nTRUE\n\n\n1511\nbild\nTRUE\n\n\n1518\nnase\nTRUE\n\n\n1524\ncurrywurst\nTRUE\n\n\n1524\ndreck\nTRUE\n\n\n1527\nmatschbirne\nTRUE\n\n\n1527\nlangsam\nTRUE\n\n\n1528\nungeziefer\nTRUE\n\n\n1534\ngeisterfahrer\nTRUE\n\n\n1537\nfeind\nTRUE\n\n\n1539\nniemand\nTRUE\n\n\n1544\nnichts\nTRUE\n\n\n1550\ntrolle\nTRUE\n\n\n1558\nbild\nTRUE\n\n\n1559\nversager\nTRUE\n\n\n1560\npfeife\nTRUE\n\n\n1570\nauswurf\nTRUE\n\n\n1571\nversager\nTRUE\n\n\n1574\npack\nTRUE\n\n\n1579\nniemand\nTRUE\n\n\n1583\nnerd\nTRUE\n\n\n1588\narsch\nTRUE\n\n\n1590\nsau\nTRUE\n\n\n1593\nnichts\nTRUE\n\n\n1593\nbösewicht\nTRUE\n\n\n1594\nnichts\nTRUE\n\n\n1594\nopfer\nTRUE\n\n\n1600\ngeist\nTRUE\n\n\n1604\nversager\nTRUE\n\n\n1610\nschnüffler\nTRUE\n\n\n1615\nratte\nTRUE\n\n\n1618\nfell\nTRUE\n\n\n1627\nstock\nTRUE\n\n\n1627\nfettarsch\nTRUE\n\n\n1630\nziege\nTRUE\n\n\n1638\nkratzer\nTRUE\n\n\n1639\nnull\nTRUE\n\n\n1642\nbild\nTRUE\n\n\n1648\nart\nTRUE\n\n\n1656\nnichts\nTRUE\n\n\n1659\nfrosch\nTRUE\n\n\n1660\nnichts\nTRUE\n\n\n1662\nscheisser\nTRUE\n\n\n1669\nraffzahn\nTRUE\n\n\n1672\nflüchtling\nTRUE\n\n\n1673\naussätziger\nTRUE\n\n\n1678\nschmierfinke\nTRUE\n\n\n1680\nnichts\nTRUE\n\n\n1687\ntrulla\nTRUE\n\n\n1699\ntrampel\nTRUE\n\n\n1710\nschwuchtel\nTRUE\n\n\n1712\nopfer\nTRUE\n\n\n1718\narschloch\nTRUE\n\n\n1733\nmörder\nTRUE\n\n\n1752\nmönch\nTRUE\n\n\n1755\nnichts\nTRUE\n\n\n1757\npfeife\nTRUE\n\n\n1762\nnichts\nTRUE\n\n\n1762\nhungrig\nTRUE\n\n\n1762\nhungrig\nTRUE\n\n\n1767\nspinne\nTRUE\n\n\n1772\nhause\nTRUE\n\n\n1774\nlächerlich\nTRUE\n\n\n1783\nwespe\nTRUE\n\n\n1788\nhelfershelfer\nTRUE\n\n\n1813\nbild\nTRUE\n\n\n1813\nbild\nTRUE\n\n\n1820\nschwein\nTRUE\n\n\n1827\ngegner\nTRUE\n\n\n1838\nweib\nTRUE\n\n\n1841\nnichts\nTRUE\n\n\n1856\nschlampe\nTRUE\n\n\n1857\narsch\nTRUE\n\n\n1868\nunkraut\nTRUE\n\n\n1873\nzunge\nTRUE\n\n\n1873\nnase\nTRUE\n\n\n1877\nnichts\nTRUE\n\n\n1882\nscheinheiliger\nTRUE\n\n\n1885\nbaby\nTRUE\n\n\n1886\nbild\nTRUE\n\n\n1886\nbild\nTRUE\n\n\n1893\nbande\nTRUE\n\n\n1894\ntrottel\nTRUE\n\n\n1895\nlachnummer\nTRUE\n\n\n1908\nbazille\nTRUE\n\n\n1914\nmade\nTRUE\n\n\n1919\nbürger\nTRUE\n\n\n1928\nnichts\nTRUE\n\n\n1930\nniemand\nTRUE\n\n\n1931\ntrolle\nTRUE\n\n\n1931\nvollpfosten\nTRUE\n\n\n1934\npapagei\nTRUE\n\n\n1934\nnichts\nTRUE\n\n\n1935\nnichts\nTRUE\n\n\n1940\ngeist\nTRUE\n\n\n1945\nhetzer\nTRUE\n\n\n1948\nhurensohn\nTRUE\n\n\n1958\nnichts\nTRUE\n\n\n1959\nteufel\nTRUE\n\n\n1962\nfresse\nTRUE\n\n\n1972\nbürger\nTRUE\n\n\n1984\ngegner\nTRUE\n\n\n1992\narschloch\nTRUE\n\n\n1999\nwichtigtuer\nTRUE\n\n\n2000\nnichts\nTRUE\n\n\n2005\nnull\nTRUE\n\n\n2006\nschweinepriester\nTRUE\n\n\n2015\ndreck\nTRUE\n\n\n2027\npack\nTRUE\n\n\n2033\nkuh\nTRUE\n\n\n2039\nbild\nTRUE\n\n\n2045\nlappen\nTRUE\n\n\n2052\nduckmäuser\nTRUE\n\n\n2052\nfanatiker\nTRUE\n\n\n2054\nbild\nTRUE\n\n\n2054\nbild\nTRUE\n\n\n2060\nnichts\nTRUE\n\n\n2069\nbrut\nTRUE\n\n\n2069\nstinker\nTRUE\n\n\n2081\npisser\nTRUE\n\n\n2082\npack\nTRUE\n\n\n2084\nbrandstifter\nTRUE\n\n\n2085\nstinkstiefel\nTRUE\n\n\n2090\nhasser\nTRUE\n\n\n2097\nhaufen\nTRUE\n\n\n2097\nböser\nTRUE\n\n\n2102\nkuh\nTRUE\n\n\n2104\nmichel\nTRUE\n\n\n2106\nwicht\nTRUE\n\n\n2119\nhaufen\nTRUE\n\n\n2126\nschmarotzer\nTRUE\n\n\n2134\nblender\nTRUE\n\n\n2137\nbild\nTRUE\n\n\n2155\npack\nTRUE\n\n\n2155\nfresse\nTRUE\n\n\n2160\nsau\nTRUE\n\n\n2163\npack\nTRUE\n\n\n2174\nscheisser\nTRUE\n\n\n2176\nschmierfinke\nTRUE\n\n\n2184\nschwanz\nTRUE\n\n\n2185\nart\nTRUE\n\n\n2190\ntrüffelschwein\nTRUE\n\n\n2199\nlangsam\nTRUE\n\n\n2204\nlangsam\nTRUE\n\n\n2204\nnichts\nTRUE\n\n\n2205\nheuchler\nTRUE\n\n\n2226\ngesindel\nTRUE\n\n\n2226\nnigger\nTRUE\n\n\n2227\nversager\nTRUE\n\n\n2229\nhelfershelfer\nTRUE\n\n\n2231\narsch\nTRUE\n\n\n2241\nhagel\nTRUE\n\n\n2245\nschabracke\nTRUE\n\n\n2246\nbild\nTRUE\n\n\n2248\nbürger\nTRUE\n\n\n2253\ntropf\nTRUE\n\n\n2265\narschloch\nTRUE\n\n\n2269\nnichts\nTRUE\n\n\n2271\nnichts\nTRUE\n\n\n2271\nnichts\nTRUE\n\n\n2275\nbild\nTRUE\n\n\n2286\nstumm\nTRUE\n\n\n2288\nding\nTRUE\n\n\n2289\npack\nTRUE\n\n\n2289\narsch\nTRUE\n\n\n2299\nverbrecher\nTRUE\n\n\n2303\nkröte\nTRUE\n\n\n2308\nnichts\nTRUE\n\n\n2311\ndummkopf\nTRUE\n\n\n2312\nsack\nTRUE\n\n\n2318\ntor\nTRUE\n\n\n2324\nnichts\nTRUE\n\n\n2327\nbild\nTRUE\n\n\n2331\nschreiber\nTRUE\n\n\n2331\nschreiber\nTRUE\n\n\n2332\nnichts\nTRUE\n\n\n2333\nbürger\nTRUE\n\n\n2335\ndreck\nTRUE\n\n\n2338\nbürger\nTRUE\n\n\n2339\nonanieren\nTRUE\n\n\n2341\nkreuzritter\nTRUE\n\n\n2349\nnichts\nTRUE\n\n\n2354\nfreier\nTRUE\n\n\n2356\nfresse\nTRUE\n\n\n2360\nding\nTRUE\n\n\n2363\nnichts\nTRUE\n\n\n2371\nnichts\nTRUE\n\n\n2382\nmaul\nTRUE\n\n\n2382\nnichts\nTRUE\n\n\n2384\nbürger\nTRUE\n\n\n2387\nfleisch\nTRUE\n\n\n2389\nversager\nTRUE\n\n\n2396\ntor\nTRUE\n\n\n2406\nmörder\nTRUE\n\n\n2410\nfeind\nTRUE\n\n\n2415\nschlepper\nTRUE\n\n\n2416\nverbrecher\nTRUE\n\n\n2418\npest\nTRUE\n\n\n2430\ndreck\nTRUE\n\n\n2432\nzeug\nTRUE\n\n\n2434\nhitler\nTRUE\n\n\n2440\nneger\nTRUE\n\n\n2440\npack\nTRUE\n\n\n2442\ntroll\nTRUE\n\n\n2443\nterrorist\nTRUE\n\n\n2444\ngesicht\nTRUE\n\n\n2457\nbengel\nTRUE\n\n\n2457\nnichts\nTRUE\n\n\n2457\nschädel\nTRUE\n\n\n2460\npack\nTRUE\n\n\n2462\nbild\nTRUE\n\n\n2474\nnichts\nTRUE\n\n\n2475\nficken\nTRUE\n\n\n2475\nschandmaul\nTRUE\n\n\n2477\nteufel\nTRUE\n\n\n2481\nnichts\nTRUE\n\n\n2492\nscheißdreck\nTRUE\n\n\n2504\nlangsam\nTRUE\n\n\n2505\nbesen\nTRUE\n\n\n2507\nhitler\nTRUE\n\n\n2510\nbande\nTRUE\n\n\n2512\nkasten\nTRUE\n\n\n2513\nnase\nTRUE\n\n\n2523\nbürger\nTRUE\n\n\n2536\nfeind\nTRUE\n\n\n2537\nabschaum\nTRUE\n\n\n2537\nnichts\nTRUE\n\n\n2543\nhasser\nTRUE\n\n\n2545\nverlierer\nTRUE\n\n\n2550\nkoffer\nTRUE\n\n\n2551\nseehund\nTRUE\n\n\n2559\nmuschi\nTRUE\n\n\n2560\nlangsam\nTRUE\n\n\n2565\nkaputter\nTRUE\n\n\n2565\nhetzer\nTRUE\n\n\n2565\nhetzer\nTRUE\n\n\n2573\nblock\nTRUE\n\n\n2575\nnase\nTRUE\n\n\n2577\nbild\nTRUE\n\n\n2578\nwitzfigur\nTRUE\n\n\n2599\ngesicht\nTRUE\n\n\n2600\nfigur\nTRUE\n\n\n2608\nfreier\nTRUE\n\n\n2620\nmaul\nTRUE\n\n\n2625\nstorch\nTRUE\n\n\n2628\nhause\nTRUE\n\n\n2631\nbürger\nTRUE\n\n\n2631\nidiot\nTRUE\n\n\n2633\nnichts\nTRUE\n\n\n2635\nschmarotzer\nTRUE\n\n\n2639\nniemand\nTRUE\n\n\n2641\nvolltrottel\nTRUE\n\n\n2644\nschäferhund\nTRUE\n\n\n2646\nbürger\nTRUE\n\n\n2657\nvergewaltiger\nTRUE\n\n\n2665\nlecker\nTRUE\n\n\n2669\nbürger\nTRUE\n\n\n2672\nnichts\nTRUE\n\n\n2673\nniemand\nTRUE\n\n\n2676\nart\nTRUE\n\n\n2676\nart\nTRUE\n\n\n2678\nfresse\nTRUE\n\n\n2682\nfresse\nTRUE\n\n\n2686\nhause\nTRUE\n\n\n2690\nheuchler\nTRUE\n\n\n2698\nidiot\nTRUE\n\n\n2704\nart\nTRUE\n\n\n2705\nfell\nTRUE\n\n\n2709\nhause\nTRUE\n\n\n2723\nbild\nTRUE\n\n\n2723\narsch\nTRUE\n\n\n2725\nkinderschänder\nTRUE\n\n\n2727\nopfer\nTRUE\n\n\n2732\nneidhammel\nTRUE\n\n\n2734\nvollpfosten\nTRUE\n\n\n2737\ntoller\nTRUE\n\n\n2738\nbild\nTRUE\n\n\n2740\nweihnachtsmann\nTRUE\n\n\n2741\nmaul\nTRUE\n\n\n2744\nnackt\nTRUE\n\n\n2761\ngesicht\nTRUE\n\n\n2764\nnichts\nTRUE\n\n\n2780\ngerät\nTRUE\n\n\n2785\nhitler\nTRUE\n\n\n2785\npest\nTRUE\n\n\n2785\nhitler\nTRUE\n\n\n2790\narschloch\nTRUE\n\n\n2795\nschwein\nTRUE\n\n\n2797\nschädel\nTRUE\n\n\n2806\nnichts\nTRUE\n\n\n2807\nbild\nTRUE\n\n\n2807\nschlampe\nTRUE\n\n\n2813\nbild\nTRUE\n\n\n2831\nklugscheißer\nTRUE\n\n\n2832\ntierquäler\nTRUE\n\n\n2834\nhetzer\nTRUE\n\n\n2841\nbürger\nTRUE\n\n\n2844\nmiststück\nTRUE\n\n\n2845\nbild\nTRUE\n\n\n2848\nkuh\nTRUE\n\n\n2851\nhorde\nTRUE\n\n\n2852\npack\nTRUE\n\n\n2855\nwesen\nTRUE\n\n\n2871\nniemand\nTRUE\n\n\n2871\nniemand\nTRUE\n\n\n2884\nnichts\nTRUE\n\n\n2885\nnichts\nTRUE\n\n\n2885\nopfer\nTRUE\n\n\n2897\nkratzer\nTRUE\n\n\n2897\nhund\nTRUE\n\n\n2900\nschlange\nTRUE\n\n\n2901\ngerät\nTRUE\n\n\n2904\nhurensohn\nTRUE\n\n\n2912\nnichts\nTRUE\n\n\n2920\nmist\nTRUE\n\n\n2921\nhause\nTRUE\n\n\n2925\narsch\nTRUE\n\n\n2930\ngesindel\nTRUE\n\n\n2935\nart\nTRUE\n\n\n2940\nterrorist\nTRUE\n\n\n2947\neselstreiber\nTRUE\n\n\n2951\nabschaum\nTRUE\n\n\n2957\nnichts\nTRUE\n\n\n2959\nnull\nTRUE\n\n\n2965\ntaugenichts\nTRUE\n\n\n2973\npack\nTRUE\n\n\n2974\nhenker\nTRUE\n\n\n2975\nvolksverräter\nTRUE\n\n\n2981\nheuchler\nTRUE\n\n\n2983\nteufel\nTRUE\n\n\n2988\nnichts\nTRUE\n\n\n2991\nbild\nTRUE\n\n\n2992\nniemand\nTRUE\n\n\n2997\nverbrecher\nTRUE\n\n\n2997\nopfer\nTRUE\n\n\n3001\nnichts\nTRUE\n\n\n3007\nbild\nTRUE\n\n\n3014\nseele\nTRUE\n\n\n3014\ngeist\nTRUE\n\n\n3019\nstumm\nTRUE\n\n\n3022\nhure\nTRUE\n\n\n3048\nbild\nTRUE\n\n\n3050\nlahm\nTRUE\n\n\n3050\ngegner\nTRUE\n\n\n3055\ntrolle\nTRUE\n\n\n3064\nnichts\nTRUE\n\n\n3066\nphönix\nTRUE\n\n\n3076\nlangsam\nTRUE\n\n\n3079\nbild\nTRUE\n\n\n3087\nmade\nTRUE\n\n\n3089\nbürger\nTRUE\n\n\n3100\nnichts\nTRUE\n\n\n3101\nnichts\nTRUE\n\n\n3102\nnase\nTRUE\n\n\n3108\nbild\nTRUE\n\n\n3108\npack\nTRUE\n\n\n3113\nheuchler\nTRUE\n\n\n3115\nnichts\nTRUE\n\n\n3115\nschwachsinniger\nTRUE\n\n\n3119\ngesicht\nTRUE\n\n\n3120\nstiefmutter\nTRUE\n\n\n3124\nniemand\nTRUE\n\n\n3128\nniemand\nTRUE\n\n\n3133\nschwanz\nTRUE\n\n\n3142\nmaul\nTRUE\n\n\n3143\nfeind\nTRUE\n\n\n3145\nnase\nTRUE\n\n\n3145\nhetzer\nTRUE\n\n\n3145\nnichts\nTRUE\n\n\n3152\nbild\nTRUE\n\n\n3154\neingeschränkt\nTRUE\n\n\n3166\nwildschwein\nTRUE\n\n\n3168\nbild\nTRUE\n\n\n3170\nschmarotzer\nTRUE\n\n\n3177\nhitler\nTRUE\n\n\n3183\nlächerlich\nTRUE\n\n\n3184\nfresse\nTRUE\n\n\n3187\nnichts\nTRUE\n\n\n3200\npenner\nTRUE\n\n\n3207\nnichts\nTRUE\n\n\n3207\nverlierer\nTRUE\n\n\n3210\nhetzer\nTRUE\n\n\n3211\narschkriecher\nTRUE\n\n\n3212\ndreist\nTRUE\n\n\n3218\nlächerlich\nTRUE\n\n\n3222\nmonster\nTRUE\n\n\n3225\nvollpfosten\nTRUE\n\n\n3227\nhetzer\nTRUE\n\n\n3230\nhurensohn\nTRUE\n\n\n3246\npfeife\nTRUE\n\n\n3247\nopfer\nTRUE\n\n\n3258\nopfer\nTRUE\n\n\n3261\ntrulla\nTRUE\n\n\n3268\ngerät\nTRUE\n\n\n3270\nhetzer\nTRUE\n\n\n3276\nkamel\nTRUE\n\n\n3277\nverbrecher\nTRUE\n\n\n3286\nnichts\nTRUE\n\n\n3304\nnichts\nTRUE\n\n\n3318\nfanatiker\nTRUE\n\n\n3321\ngutmensch\nTRUE\n\n\n3321\nkinderfeind\nTRUE\n\n\n3324\nneger\nTRUE\n\n\n3331\nbürger\nTRUE\n\n\n3334\nbürger\nTRUE\n\n\n3342\nhammer\nTRUE\n\n\n3353\nbild\nTRUE\n\n\n3353\nmade\nTRUE\n\n\n3354\nhetzer\nTRUE\n\n\n3354\ngutmensch\nTRUE\n\n\n3354\nlatte\nTRUE\n\n\n3360\nhause\nTRUE\n\n\n3364\nabfall\nTRUE\n\n\n3369\nnichts\nTRUE\n\n\n3371\nniemand\nTRUE\n\n\n3389\nnull\nTRUE\n\n\n3389\nmelkkuh\nTRUE\n\n\n3398\nfleisch\nTRUE\n\n\n3405\nnichts\nTRUE\n\n\n3410\nlecker\nTRUE\n\n\n3414\nlächerlich\nTRUE\n\n\n3416\nspieler\nTRUE\n\n\n3425\nbild\nTRUE\n\n\n3437\nfeind\nTRUE\n\n\n3437\nfeind\nTRUE\n\n\n3443\nfreier\nTRUE\n\n\n3453\nlacher\nTRUE\n\n\n3456\nnichts\nTRUE\n\n\n3470\nnichts\nTRUE\n\n\n3481\ndepp\nTRUE\n\n\n3486\nspinner\nTRUE\n\n\n3491\narsch\nTRUE\n\n\n3495\nnichts\nTRUE\n\n\n3498\nabschaum\nTRUE\n\n\n3502\nhaut\nTRUE\n\n\n3504\nvollpfosten\nTRUE\n\n\n3505\nbild\nTRUE\n\n\n3510\ntor\nTRUE\n\n\n3511\nart\nTRUE\n\n\n3511\nflüchtling\nTRUE\n\n\n3517\nnichts\nTRUE\n\n\n3519\nbild\nTRUE\n\n\n3527\nflüchtling\nTRUE\n\n\n3535\nbild\nTRUE\n\n\n3542\ntrolle\nTRUE\n\n\n3546\nbild\nTRUE\n\n\n3548\nnase\nTRUE\n\n\n3552\ngesocks\nTRUE\n\n\n3559\nhause\nTRUE\n\n\n3564\nbürger\nTRUE\n\n\n3565\nniemand\nTRUE\n\n\n3569\nunkraut\nTRUE\n\n\n3572\nverbrecher\nTRUE\n\n\n3572\nfanatiker\nTRUE\n\n\n3573\nopfer\nTRUE\n\n\n3573\ngesicht\nTRUE\n\n\n3574\nhause\nTRUE\n\n\n3581\ntropf\nTRUE\n\n\n3591\ndreck\nTRUE\n\n\n3601\nfresse\nTRUE\n\n\n3601\nkacke\nTRUE\n\n\n3607\nnichts\nTRUE\n\n\n3614\nfaschist\nTRUE\n\n\n3615\narsch\nTRUE\n\n\n3623\nnudel\nTRUE\n\n\n3625\nnichts\nTRUE\n\n\n3628\nbrut\nTRUE\n\n\n3628\nhause\nTRUE\n\n\n3637\nbürger\nTRUE\n\n\n3640\nseele\nTRUE\n\n\n3640\nsatan\nTRUE\n\n\n3643\nkuh\nTRUE\n\n\n3643\nschmierfinke\nTRUE\n\n\n3653\nlöwe\nTRUE\n\n\n3653\nesel\nTRUE\n\n\n3653\npest\nTRUE\n\n\n3653\nratte\nTRUE\n\n\n3656\nmassenmörder\nTRUE\n\n\n3665\nmaul\nTRUE\n\n\n3666\nnichts\nTRUE\n\n\n3669\ndummbrot\nTRUE\n\n\n3670\nschmarotzer\nTRUE\n\n\n3670\nhaut\nTRUE\n\n\n3675\nnichts\nTRUE\n\n\n3690\nvergewaltiger\nTRUE\n\n\n3697\ntor\nTRUE\n\n\n3698\nunkraut\nTRUE\n\n\n3702\nnichts\nTRUE\n\n\n3702\nopfer\nTRUE\n\n\n3717\nzwitter\nTRUE\n\n\n3717\ntunte\nTRUE\n\n\n3720\nabschaum\nTRUE\n\n\n3723\nignorant\nTRUE\n\n\n3725\nschmierfinke\nTRUE\n\n\n3727\nbild\nTRUE\n\n\n3731\nabschaum\nTRUE\n\n\n3732\nvergewaltiger\nTRUE\n\n\n3732\nmörder\nTRUE\n\n\n3750\nschlampe\nTRUE\n\n\n3766\nnichts\nTRUE\n\n\n3767\nhammer\nTRUE\n\n\n3775\naffe\nTRUE\n\n\n3777\nflasche\nTRUE\n\n\n3785\nbild\nTRUE\n\n\n3785\nneger\nTRUE\n\n\n3790\nhahn\nTRUE\n\n\n3793\nniemand\nTRUE\n\n\n3803\ntusse\nTRUE\n\n\n3805\nbastard\nTRUE\n\n\n3807\nopfer\nTRUE\n\n\n3807\ngeist\nTRUE\n\n\n3808\nsau\nTRUE\n\n\n3815\nmörder\nTRUE\n\n\n3816\nniemand\nTRUE\n\n\n3818\ntyp\nTRUE\n\n\n3819\nfisch\nTRUE\n\n\n3820\nbrut\nTRUE\n\n\n3824\nmist\nTRUE\n\n\n3833\nniemand\nTRUE\n\n\n3833\nspinner\nTRUE\n\n\n3836\nart\nTRUE\n\n\n3841\ntoller\nTRUE\n\n\n3843\nverlierer\nTRUE\n\n\n3844\nniemand\nTRUE\n\n\n3845\nkacke\nTRUE\n\n\n3847\nbluthund\nTRUE\n\n\n3847\nverräter\nTRUE\n\n\n3849\nbazille\nTRUE\n\n\n3850\ngeier\nTRUE\n\n\n3862\nsack\nTRUE\n\n\n3862\nknüppel\nTRUE\n\n\n3863\nbürger\nTRUE\n\n\n3863\nbürger\nTRUE\n\n\n3863\nhaut\nTRUE\n\n\n3864\nnichts\nTRUE\n\n\n3864\nnichts\nTRUE\n\n\n3865\nbild\nTRUE\n\n\n3880\nbild\nTRUE\n\n\n3882\nstück\nTRUE\n\n\n3888\nlumpenpack\nTRUE\n\n\n3900\nbastard\nTRUE\n\n\n3915\nding\nTRUE\n\n\n3930\nopfer\nTRUE\n\n\n3930\nopfer\nTRUE\n\n\n3939\nmist\nTRUE\n\n\n3956\nhurensohn\nTRUE\n\n\n3975\nkröte\nTRUE\n\n\n3980\ndichter\nTRUE\n\n\n3980\nduckmäuser\nTRUE\n\n\n3982\nheulsuse\nTRUE\n\n\n3992\nspeichellecker\nTRUE\n\n\n3994\nopfer\nTRUE\n\n\n4004\ntor\nTRUE\n\n\n4004\nniemand\nTRUE\n\n\n4005\nbumsen\nTRUE\n\n\n4008\nweib\nTRUE\n\n\n4010\nfresse\nTRUE\n\n\n4016\nnichts\nTRUE\n\n\n4016\nnichts\nTRUE\n\n\n4017\nnichts\nTRUE\n\n\n4024\nbild\nTRUE\n\n\n4024\npinkeln\nTRUE\n\n\n4032\npack\nTRUE\n\n\n4036\nnichts\nTRUE\n\n\n4042\nbürger\nTRUE\n\n\n4047\nlangsam\nTRUE\n\n\n4055\nnase\nTRUE\n\n\n4055\nzeug\nTRUE\n\n\n4061\nbild\nTRUE\n\n\n4063\nzeug\nTRUE\n\n\n4067\nopfer\nTRUE\n\n\n4071\nnichts\nTRUE\n\n\n4072\nverlierer\nTRUE\n\n\n4087\nschnüffler\nTRUE\n\n\n4092\nhenker\nTRUE\n\n\n4092\nart\nTRUE\n\n\n4094\nhamster\nTRUE\n\n\n4094\nhamster\nTRUE\n\n\n4103\nabschaum\nTRUE\n\n\n4104\nmist\nTRUE\n\n\n4108\nopfer\nTRUE\n\n\n4120\nvaterlandsverräter\nTRUE\n\n\n4128\ngegner\nTRUE\n\n\n4133\nnudel\nTRUE\n\n\n4138\nflüchtling\nTRUE\n\n\n4140\ndreck\nTRUE\n\n\n4144\nbild\nTRUE\n\n\n4146\nnichts\nTRUE\n\n\n4151\narsch\nTRUE\n\n\n4153\nausbeuter\nTRUE\n\n\n4154\narsch\nTRUE\n\n\n4173\nnichts\nTRUE\n\n\n4175\nnichts\nTRUE\n\n\n4178\nhaufen\nTRUE\n\n\n4181\narsch\nTRUE\n\n\n4187\npuppe\nTRUE\n\n\n4189\ntrittbrettfahrer\nTRUE\n\n\n4191\nding\nTRUE\n\n\n4199\ndichter\nTRUE\n\n\n4209\nlangsam\nTRUE\n\n\n4215\nscheiße\nTRUE\n\n\n4226\nhitler\nTRUE\n\n\n4233\nart\nTRUE\n\n\n4233\npinkeln\nTRUE\n\n\n4233\nnichts\nTRUE\n\n\n4234\nrattenfänger\nTRUE\n\n\n4234\nhitler\nTRUE\n\n\n4237\nnichts\nTRUE\n\n\n4247\nniemand\nTRUE\n\n\n4250\nbürger\nTRUE\n\n\n4250\nnichts\nTRUE\n\n\n4259\nnichts\nTRUE\n\n\n4264\nnichts\nTRUE\n\n\n4280\nbürger\nTRUE\n\n\n4288\nart\nTRUE\n\n\n4291\nzeug\nTRUE\n\n\n4301\nhitler\nTRUE\n\n\n4303\nfettsack\nTRUE\n\n\n4306\nmassenmörder\nTRUE\n\n\n4306\nterrorist\nTRUE\n\n\n4308\npöbel\nTRUE\n\n\n4310\nmörder\nTRUE\n\n\n4310\nverbrecher\nTRUE\n\n\n4325\nopfer\nTRUE\n\n\n4325\nkreatur\nTRUE\n\n\n4330\nkatze\nTRUE\n\n\n4331\ntor\nTRUE\n\n\n4335\nbürger\nTRUE\n\n\n4341\nart\nTRUE\n\n\n4342\ngiraffe\nTRUE\n\n\n4343\nnichts\nTRUE\n\n\n4347\nhause\nTRUE\n\n\n4351\nabschaum\nTRUE\n\n\n4353\nbild\nTRUE\n\n\n4354\nbande\nTRUE\n\n\n4359\ntrüffelschwein\nTRUE\n\n\n4360\narsch\nTRUE\n\n\n4361\nfanatiker\nTRUE\n\n\n4366\nhonk\nTRUE\n\n\n4371\nnichts\nTRUE\n\n\n4385\nniemand\nTRUE\n\n\n4385\nniemand\nTRUE\n\n\n4389\narsch\nTRUE\n\n\n4390\nnichts\nTRUE\n\n\n4390\ndreck\nTRUE\n\n\n4394\nflüchtling\nTRUE\n\n\n4395\ntoller\nTRUE\n\n\n4410\ndreck\nTRUE\n\n\n4413\nschwuchtel\nTRUE\n\n\n4419\nscherge\nTRUE\n\n\n4421\npfeife\nTRUE\n\n\n4424\nabschaum\nTRUE\n\n\n4432\nbürger\nTRUE\n\n\n4441\nnichts\nTRUE\n\n\n4454\ntrulla\nTRUE\n\n\n4456\nscheiße\nTRUE\n\n\n4456\nbürger\nTRUE\n\n\n4458\nkratzer\nTRUE\n\n\n4461\nfeigling\nTRUE\n\n\n4473\neselficker\nTRUE\n\n\n4479\nabschaum\nTRUE\n\n\n4481\nlump\nTRUE\n\n\n4481\nflasche\nTRUE\n\n\n4482\ngroßmaul\nTRUE\n\n\n4482\nmaul\nTRUE\n\n\n4492\nnichts\nTRUE\n\n\n4493\nmuschi\nTRUE\n\n\n4493\nkatze\nTRUE\n\n\n4493\nschwanz\nTRUE\n\n\n4493\nschweif\nTRUE\n\n\n4493\nstück\nTRUE\n\n\n4493\nhund\nTRUE\n\n\n4495\nbild\nTRUE\n\n\n4496\nverbrecher\nTRUE\n\n\n4510\nmaul\nTRUE\n\n\n4520\nniemand\nTRUE\n\n\n4527\nschamlos\nTRUE\n\n\n4536\nhetzer\nTRUE\n\n\n4536\nhetzer\nTRUE\n\n\n4541\nkerl\nTRUE\n\n\n4543\nart\nTRUE\n\n\n4548\nkratzer\nTRUE\n\n\n4548\nopfer\nTRUE\n\n\n4552\nbild\nTRUE\n\n\n4554\ngeist\nTRUE\n\n\n4554\ngeist\nTRUE\n\n\n4555\nniemand\nTRUE\n\n\n4563\ndreck\nTRUE\n\n\n4564\nstock\nTRUE\n\n\n4572\nfresse\nTRUE\n\n\n4578\nesel\nTRUE\n\n\n4580\nfresse\nTRUE\n\n\n4588\nscheiße\nTRUE\n\n\n4588\npack\nTRUE\n\n\n4590\nnichts\nTRUE\n\n\n4592\nfeind\nTRUE\n\n\n4610\nvogel\nTRUE\n\n\n4610\ngesicht\nTRUE\n\n\n4610\nbulle\nTRUE\n\n\n4613\nverlierer\nTRUE\n\n\n4615\nbock\nTRUE\n\n\n4617\nding\nTRUE\n\n\n4618\npest\nTRUE\n\n\n4624\nhause\nTRUE\n\n\n4626\nzerstörer\nTRUE\n\n\n4626\nhitler\nTRUE\n\n\n4632\nschwein\nTRUE\n\n\n4634\nnichts\nTRUE\n\n\n4638\nnichts\nTRUE\n\n\n4638\nnichts\nTRUE\n\n\n4638\nversager\nTRUE\n\n\n4647\nkoffer\nTRUE\n\n\n4649\nmist\nTRUE\n\n\n4651\nmörder\nTRUE\n\n\n4651\nvergewaltiger\nTRUE\n\n\n4651\nmist\nTRUE\n\n\n4654\nwichtigtuer\nTRUE\n\n\n4654\nversager\nTRUE\n\n\n4664\nhurensohn\nTRUE\n\n\n4672\nbild\nTRUE\n\n\n4672\nesel\nTRUE\n\n\n4675\nphilosoph\nTRUE\n\n\n4682\nfreier\nTRUE\n\n\n4690\nnichts\nTRUE\n\n\n4694\nsack\nTRUE\n\n\n4714\nnichts\nTRUE\n\n\n4717\nlecker\nTRUE\n\n\n4721\nfeind\nTRUE\n\n\n4730\nteufel\nTRUE\n\n\n4738\nbild\nTRUE\n\n\n4738\nbock\nTRUE\n\n\n4738\nmarionette\nTRUE\n\n\n4745\nbande\nTRUE\n\n\n4748\nnichts\nTRUE\n\n\n4754\nscheiße\nTRUE\n\n\n4759\nzicke\nTRUE\n\n\n4762\nlump\nTRUE\n\n\n4770\nschatten\nTRUE\n\n\n4775\nnichts\nTRUE\n\n\n4781\nschwein\nTRUE\n\n\n4783\nopfer\nTRUE\n\n\n4785\nrassel\nTRUE\n\n\n4788\nfleisch\nTRUE\n\n\n4789\nnichts\nTRUE\n\n\n4796\nlümmel\nTRUE\n\n\n4805\nleidenschaftlich\nTRUE\n\n\n4806\nniemand\nTRUE\n\n\n4808\noberpfeife\nTRUE\n\n\n4809\nhurensohn\nTRUE\n\n\n4815\nmichel\nTRUE\n\n\n4815\nnichts\nTRUE\n\n\n4816\nkreatur\nTRUE\n\n\n4820\nhäkchen\nTRUE\n\n\n4821\nspeichellecker\nTRUE\n\n\n4821\nnull\nTRUE\n\n\n4825\nlarve\nTRUE\n\n\n4825\nlarve\nTRUE\n\n\n4827\nbild\nTRUE\n\n\n4840\nbürger\nTRUE\n\n\n4840\nnull\nTRUE\n\n\n4847\njunker\nTRUE\n\n\n4847\nniemand\nTRUE\n\n\n4853\nhitler\nTRUE\n\n\n4854\ntyp\nTRUE\n\n\n4856\nbild\nTRUE\n\n\n4858\nbild\nTRUE\n\n\n4859\narsch\nTRUE\n\n\n4867\nbild\nTRUE\n\n\n4870\nkuh\nTRUE\n\n\n4870\nfleischfresser\nTRUE\n\n\n4880\nbild\nTRUE\n\n\n4880\ntrolle\nTRUE\n\n\n4881\narsch\nTRUE\n\n\n4881\nvollidiot\nTRUE\n\n\n4883\nhering\nTRUE\n\n\n4886\nbild\nTRUE\n\n\n4891\nnichts\nTRUE\n\n\n4892\nkerl\nTRUE\n\n\n4897\nbild\nTRUE\n\n\n4897\ntoller\nTRUE\n\n\n4898\nlöwe\nTRUE\n\n\n4898\nhamster\nTRUE\n\n\n4898\nhamster\nTRUE\n\n\n4901\ndreck\nTRUE\n\n\n4909\nbild\nTRUE\n\n\n4916\nkerl\nTRUE\n\n\n4922\nvolltrottel\nTRUE\n\n\n4922\ntrottel\nTRUE\n\n\n4923\nsimpel\nTRUE\n\n\n4925\ntor\nTRUE\n\n\n4926\nnichts\nTRUE\n\n\n4927\nbürger\nTRUE\n\n\n4930\nmöse\nTRUE\n\n\n4931\nkröte\nTRUE\n\n\n4931\nnichts\nTRUE\n\n\n4936\nkatze\nTRUE\n\n\n4938\nhungrig\nTRUE\n\n\n4941\narsch\nTRUE\n\n\n4942\nanus\nTRUE\n\n\n4943\nschauspieler\nTRUE\n\n\n4957\nhetzer\nTRUE\n\n\n4957\npack\nTRUE\n\n\n4959\narsch\nTRUE\n\n\n4960\nbürger\nTRUE\n\n\n4960\narsch\nTRUE\n\n\n4964\nvollpfosten\nTRUE\n\n\n4965\nfeind\nTRUE\n\n\n4966\nnichts\nTRUE\n\n\n4975\nnichts\nTRUE\n\n\n4976\nniemand\nTRUE\n\n\n4989\nverbrecher\nTRUE\n\n\n5004\nstück\nTRUE\n\n\n\n\n\n\nWie viele Schimpfwörter haben wir gefunden?\n\nd_schimpf %>% \n  count(schimpf)\n\n\n\n\n\nschimpf\nn\n\n\n\n\nFALSE\n99081\n\n\nTRUE\n1136\n\n\n\n\n\n\nEtwa ein Prozent der Wörter sind Schimpfwörter in unserem Corpus.\n\nd_schimpf2 <-\n  d_schimpf %>% \n  group_by(id) %>% \n  summarise(schimpf_n = sum(schimpf))\n\nhead(d_schimpf2)\n\n\n\n\n\nid\nschimpf_n\n\n\n\n\n1\n0\n\n\n2\n0\n\n\n3\n0\n\n\n4\n0\n\n\n5\n1\n\n\n6\n0\n\n\n\n\n\n\n\nd_main <-\n  d3 %>% \n  full_join(d_schimpf2)\n\nJoining, by = \"id\"\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nNamen wie final, main oder result sind gefährlich, da es unter Garantie ein “final-final geben wird, oder der”Haupt-Datensat” plötzlich nicht mehr so wichtig erscheint und so weiter.\n\n\n\n\n1.3.4 Emojis\n\nemj <- emoji(list_emoji(), pad = FALSE)\n\nhead(emj)\n\n[1] \"😄\" \"😃\" \"😀\" \"😊\" \"☺️\"  \"😉\"\n\n\nDiese Liste umfasst knapp 900 Emojis, das sind allerdings noch nicht alle, die es gibt. Diese Liste umfasst mit gut 1800 Emojis gut das Doppelte.\nSelbstkuratierte Liste an “wilden” Emoji; diese Liste ist inspiriert von emojicombos.com.\n\nwild_emojis <- \n  c(\n    emoji(find_emoji(\"gun\")),\n    emoji(find_emoji(\"bomb\")),\n    emoji(find_emoji(\"fist\")),\n    emoji(find_emoji(\"knife\"))[1],\n     emoji(find_emoji(\"ambulance\")),\n    \"😠\",\n    \"👹\",\n    \"💩\",\n    \"☠\",\n    \"🖕\",\n    emoji(find_emoji(\"middle finger\")),\n    \"😡\",\n    \"🤢\",\n    \"🤮\",\n    \"😖\",\n    \"😣\",\n    \"😩\",\n    \"😨\",\n    \"😝\",\n    \"😳\",\n    \"😬\",\n    \"😱\",\n    \"😵\",\n    \"😤\",\n    \"🤦‍♀️\",\n    \"🤦‍♂️\"\n  )\n\nAuf dieser Basis können wir einen Prädiktor erstellen, der zählt, ob ein Tweet einen oder mehrere der “wilden” Emojis enthält."
  },
  {
    "objectID": "klassifikation.html#workflow-1-rezept-1-naive-bayes",
    "href": "klassifikation.html#workflow-1-rezept-1-naive-bayes",
    "title": "1  Klassifikation von Hatespeech",
    "section": "1.4 Workflow 1: Rezept 1 + Naive-Bayes",
    "text": "1.4 Workflow 1: Rezept 1 + Naive-Bayes\n\n1.4.1 Dummy-Rezept\nHier ist ein einfaches Beispiel, um die Textvorbereitung mit {textrecipes} zu verdeutlichen.\nWir erstellen uns einen Dummy-Text:\n\ndummy <- \n  tibble(text = c(\"Ich gehe heim und der die das nicht in ein and the\"))\n\nDann tokenisieren wir den Text:\n\nrec_dummy <-\n  recipe(text ~ 1, data = dummy) %>% \n  step_tokenize(text)\n  \nrec_dummy\n\nRecipe\n\nInputs:\n\n    role #variables\n outcome          1\n\nOperations:\n\nTokenization for text\n\n\nDie Tokens kann man sich so zeigen lassen:\n\nshow_tokens(rec_dummy, text)\n\n[[1]]\n [1] \"ich\"   \"gehe\"  \"heim\"  \"und\"   \"der\"   \"die\"   \"das\"   \"nicht\" \"in\"   \n[10] \"ein\"   \"and\"   \"the\"  \n\n\nJetzt entfernen wir die Stopwörter deutscher Sprache; dafür nutzen wir die Stopwort-Quelle snowball:\n\nrec_dummy <-\n  recipe(text ~ 1, data = dummy) %>% \n  step_tokenize(text) %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\")\n\nrec_dummy\n\nRecipe\n\nInputs:\n\n    role #variables\n outcome          1\n\nOperations:\n\nTokenization for text\nStop word removal for text\n\n\nPrüfen wir die Tokens; sind die Stopwörter wirklich entfernt?\n\nshow_tokens(rec_dummy, text)\n\n[[1]]\n[1] \"gehe\" \"heim\" \"and\"  \"the\" \n\n\nJa, die deutschen Stopwörter sind entfernt. Die englischen nicht; das macht Sinn!\n\n\n1.4.2 Datenaufteilung\n\nd_split <- initial_split(d_main, strata = c1)\n\nd_train <- training(d_split)\nd_test <- testing(d_split)\n\n\n\n1.4.3 Rezept 1\nRezept definieren:\n\nrec1 <- \n  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% \n  update_role(id, new_role = \"id\") %>% \n  step_tokenize(text) %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>% \n  step_stem(text) %>% \n  step_tokenfilter(text, max_tokens = 1e2) %>% \n  step_tfidf(text) %>% \n  step_normalize(all_numeric_predictors())\n\nrec1\n\nRecipe\n\nInputs:\n\n      role #variables\n        id          1\n   outcome          1\n predictor          1\n\nOperations:\n\nTokenization for text\nStop word removal for text\nStemming for text\nText filtering for text\nTerm frequency-inverse document frequency with text\nCentering and scaling for all_numeric_predictors()\n\n\nPreppen:\n\nrec1_prepped <- prep(rec1)\n\nUnd backen:\n\nd_rec1 <- bake(rec1_prepped, new_data = NULL)\n\nhead(d_rec1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nc1\ntfidf_text__macmik\ntfidf_text_2\ntfidf_text_ab\ntfidf_text_afd\ntfidf_text_amp\ntfidf_text_anna_iina\ntfidf_text_antisemitismu\ntfidf_text_athinamala\ntfidf_text_besser\ntfidf_text_bild\ntfidf_text_cdu\ntfidf_text_charlie_silv\ntfidf_text_csu\ntfidf_text_d\ntfidf_text_dafür\ntfidf_text_dank\ntfidf_text_dass\ntfidf_text_deutsch\ntfidf_text_deutschen\ntfidf_text_deutschland\ntfidf_text_dumm\ntfidf_text_einfach\ntfidf_text_ellibisathid\ntfidf_text_endlich\ntfidf_text_ennof_\ntfidf_text_erst\ntfidf_text_eu\ntfidf_text_europa\ntfidf_text_fdp\ntfidf_text_feldenfrizz\ntfidf_text_focusonlin\ntfidf_text_frage\ntfidf_text_frau\ntfidf_text_ganz\ntfidf_text_geht\ntfidf_text_gerad\ntfidf_text_gibt\ntfidf_text_grünen\ntfidf_text_gt\ntfidf_text_gut\ntfidf_text_hätte\ntfidf_text_heut\ntfidf_text_immer\ntfidf_text_info2099\ntfidf_text_islam\ntfidf_text_israel\ntfidf_text_ja\ntfidf_text_jahr\ntfidf_text_juden\ntfidf_text_kommt\ntfidf_text_krippmari\ntfidf_text_land\ntfidf_text_lassen\ntfidf_text_lbr\ntfidf_text_lifetrend\ntfidf_text_link\ntfidf_text_macht\ntfidf_text_machtjanix23\ntfidf_text_mal\ntfidf_text_md_franz\ntfidf_text_mehr\ntfidf_text_menschen\ntfidf_text_merkel\ntfidf_text_miriamozen\ntfidf_text_moslem\ntfidf_text_müssen\ntfidf_text_nancypeggymandi\ntfidf_text_nasanas\ntfidf_text_noherrman\ntfidf_text_norbinator2403\ntfidf_text_partei\ntfidf_text_petpanther0\ntfidf_text_politik\ntfidf_text_recht\ntfidf_text_richtig\ntfidf_text_sagt\ntfidf_text_schmiddiemaik\ntfidf_text_schon\ntfidf_text_schulz\ntfidf_text_seit\ntfidf_text_sicher\ntfidf_text_spd\ntfidf_text_tagesschau\ntfidf_text_thomasgbau\ntfidf_text_troll_putin\ntfidf_text_trump\ntfidf_text_tun\ntfidf_text_türken\ntfidf_text_u\ntfidf_text_unser\ntfidf_text_viel\ntfidf_text_volk\ntfidf_text_wäre\ntfidf_text_warum\ntfidf_text_welt\ntfidf_text_wer\ntfidf_text_willjrosenblatt\ntfidf_text_wohl\ntfidf_text_wurd\ntfidf_text_zeit\n\n\n\n\n9\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n6.1558148\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n9.5543591\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n12\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n3.6921593\n-0.0804698\n-0.1036414\n-0.0836286\n3.385033\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n1.2297516\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n17\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n3.7258962\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n4.1966394\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n4.4285094\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n33\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n3.6445592\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n3.1601002\n-0.1167916\n-0.2184447\n-0.0966546\n5.4434700\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n42\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n6.6612452\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n1.2297516\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n5.9134349\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n44\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n17.7948786\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n\n\n\n\n\n\n1.4.4 Modellspezifikation 1\nWir definiere einen Naive-Bayes-Algorithmus:\n\nnb_spec <- naive_Bayes() %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"naivebayes\")\n\nnb_spec\n\nNaive Bayes Model Specification (classification)\n\nComputational engine: naivebayes \n\n\nUnd setzen auf die klassische zehnfache Kreuzvalidierung.\n\nset.seed(42)\nfolds1 <- vfold_cv(d_train)\n\n\n\n1.4.5 Workflow 1\n\nwf1 <-\n  workflow() %>% \n  add_recipe(rec1) %>% \n  add_model(nb_spec)\n\nwf1\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: naive_Bayes()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_tokenize()\n• step_stopwords()\n• step_stem()\n• step_tokenfilter()\n• step_tfidf()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nNaive Bayes Model Specification (classification)\n\nComputational engine: naivebayes \n\n\n\n\n1.4.6 Fitting 1\n\nfit1 <-\n  fit_resamples(\n    wf1,\n    folds1,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nDie Vorhersagen speichern wir ab, um die Performanz in den Faltungen des Hold-out-Samples zu berechnen.\nMöchte man sich die Zeit sparen, die Syntax wieder durchlaufen zu lassen, kann man das Objekt speichern. Aber Vorsicht: Dabei kann es passieren, dass man mit veralteten Objekten arbeitet.\n\nwrite_rds(fit1, \"objects/chap_classific_fit1.rds\")\n\n\n\n\n\n\n1.4.7 Performanz 1\n\nwf1_performance <-\n  collect_metrics(fit1)\n\nwf1_performance\n\n\n\n\n\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\naccuracy\nbinary\n0.6637270\n10\n0.0057716\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.5893296\n10\n0.0081290\nPreprocessor1_Model1\n\n\n\n\n\n\n\nwf_preds <-\n  collect_predictions(fit1)\n\nwf_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\nconf_mat_resampled(fit1, tidy = FALSE) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "klassifikation.html#nullmodell",
    "href": "klassifikation.html#nullmodell",
    "title": "1  Klassifikation von Hatespeech",
    "section": "1.5 Nullmodell",
    "text": "1.5 Nullmodell\n\nnull_classification <- \n  parsnip::null_model() %>%\n  set_engine(\"parsnip\") %>%\n  set_mode(\"classification\")\n\nnull_rs <- workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(null_classification) %>%\n  fit_resamples(\n    folds1\n  )\n\n\n\n\n\n\n\nHier ist die Performanz des Nullmodells.\n\nnull_rs %>%\n  collect_metrics()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model01\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model01\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model02\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model02\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model03\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model03\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model04\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model04\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model05\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model05\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model06\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model06\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model07\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model07\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model08\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model08\n\n\n0.0000001\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model09\n\n\n0.0000001\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model09\n\n\n0.0000001\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model10\n\n\n0.0000001\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model10\n\n\n0.0000003\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model11\n\n\n0.0000003\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model11\n\n\n0.0000006\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model12\n\n\n0.0000006\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model12\n\n\n0.0000014\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model13\n\n\n0.0000014\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model13\n\n\n0.0000030\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model14\n\n\n0.0000030\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model14\n\n\n0.0000067\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model15\n\n\n0.0000067\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model15\n\n\n0.0000149\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model16\n\n\n0.0000149\nroc_auc\nbinary\n0.8095845\n10\n0.0096008\nPreprocessor1_Model16\n\n\n0.0000329\naccuracy\nbinary\n0.7667645\n10\n0.0061340\nPreprocessor1_Model17\n\n\n0.0000329\nroc_auc\nbinary\n0.8095282\n10\n0.0095826\nPreprocessor1_Model17\n\n\n0.0000728\naccuracy\nbinary\n0.7667645\n10\n0.0061340\nPreprocessor1_Model18\n\n\n0.0000728\nroc_auc\nbinary\n0.8095638\n10\n0.0095511\nPreprocessor1_Model18\n\n\n0.0001610\naccuracy\nbinary\n0.7662333\n10\n0.0057794\nPreprocessor1_Model19\n\n\n0.0001610\nroc_auc\nbinary\n0.8099159\n10\n0.0094448\nPreprocessor1_Model19\n\n\n0.0003562\naccuracy\nbinary\n0.7654348\n10\n0.0063700\nPreprocessor1_Model20\n\n\n0.0003562\nroc_auc\nbinary\n0.8103737\n10\n0.0092381\nPreprocessor1_Model20\n\n\n0.0007880\naccuracy\nbinary\n0.7664993\n10\n0.0062776\nPreprocessor1_Model21\n\n\n0.0007880\nroc_auc\nbinary\n0.8111630\n10\n0.0089414\nPreprocessor1_Model21\n\n\n0.0017433\naccuracy\nbinary\n0.7670333\n10\n0.0066734\nPreprocessor1_Model22\n\n\n0.0017433\nroc_auc\nbinary\n0.8116297\n10\n0.0087106\nPreprocessor1_Model22\n\n\n0.0038566\naccuracy\nbinary\n0.7646319\n10\n0.0069158\nPreprocessor1_Model23\n\n\n0.0038566\nroc_auc\nbinary\n0.8093719\n10\n0.0079992\nPreprocessor1_Model23\n\n\n0.0085317\naccuracy\nbinary\n0.7553156\n10\n0.0061916\nPreprocessor1_Model24\n\n\n0.0085317\nroc_auc\nbinary\n0.8032327\n10\n0.0073114\nPreprocessor1_Model24\n\n\n0.0188739\naccuracy\nbinary\n0.7308227\n10\n0.0069456\nPreprocessor1_Model25\n\n\n0.0188739\nroc_auc\nbinary\n0.7830419\n10\n0.0087585\nPreprocessor1_Model25\n\n\n0.0417532\naccuracy\nbinary\n0.6996695\n10\n0.0085704\nPreprocessor1_Model26\n\n\n0.0417532\nroc_auc\nbinary\n0.7537161\n10\n0.0090227\nPreprocessor1_Model26\n\n\n0.0923671\naccuracy\nbinary\n0.6629305\n10\n0.0054329\nPreprocessor1_Model27\n\n\n0.0923671\nroc_auc\nbinary\n0.6848928\n10\n0.0102870\nPreprocessor1_Model27\n\n\n0.2043360\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model28\n\n\n0.2043360\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model28\n\n\n0.4520354\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model29\n\n\n0.4520354\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model29\n\n\n1.0000000\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model30\n\n\n1.0000000\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model30"
  },
  {
    "objectID": "klassifikation.html#workflow-2-rezept-1-lasso",
    "href": "klassifikation.html#workflow-2-rezept-1-lasso",
    "title": "1  Klassifikation von Hatespeech",
    "section": "1.6 Workflow 2: Rezept 1 + Lasso",
    "text": "1.6 Workflow 2: Rezept 1 + Lasso\n\nlasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"glmnet\")\n\nlasso_spec\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\nWir definieren die Ausprägungen von penalty, die wir ausprobieren wollen:\n\nlambda_grid <- grid_regular(penalty(), levels = 30)\n\n\nwf2 <-\n  workflow() %>% \n  add_recipe(rec1) %>% \n  add_model(lasso_spec)\n\nwf2\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_tokenize()\n• step_stopwords()\n• step_stem()\n• step_tokenfilter()\n• step_tfidf()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\nTunen und Fitten:\n\nset.seed(42)\n\nfit2 <-\n  tune_grid(\n    wf2,\n    folds1,\n    grid = lambda_grid,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nfit2\n\nVorsicht beim Abspeichern.\n\nwrite_rds(fit2, \"objects/chap_classific_fit2.rds\")\n\n\n\n\nHier ist die Performanz:\n\ncollect_metrics(fit2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model01\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model01\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model02\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model02\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model03\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model03\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model04\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model04\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model05\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model05\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model06\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model06\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model07\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model07\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model08\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model08\n\n\n0.0000001\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model09\n\n\n0.0000001\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model09\n\n\n0.0000001\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model10\n\n\n0.0000001\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model10\n\n\n0.0000003\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model11\n\n\n0.0000003\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model11\n\n\n0.0000006\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model12\n\n\n0.0000006\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model12\n\n\n0.0000014\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model13\n\n\n0.0000014\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model13\n\n\n0.0000030\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model14\n\n\n0.0000030\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model14\n\n\n0.0000067\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model15\n\n\n0.0000067\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model15\n\n\n0.0000149\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model16\n\n\n0.0000149\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model16\n\n\n0.0000329\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model17\n\n\n0.0000329\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model17\n\n\n0.0000728\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model18\n\n\n0.0000728\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model18\n\n\n0.0001610\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model19\n\n\n0.0001610\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model19\n\n\n0.0003562\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model20\n\n\n0.0003562\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model20\n\n\n0.0007880\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model21\n\n\n0.0007880\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model21\n\n\n0.0017433\naccuracy\nbinary\n0.6727759\n10\n0.0063031\nPreprocessor1_Model22\n\n\n0.0017433\nroc_auc\nbinary\n0.5990815\n10\n0.0093387\nPreprocessor1_Model22\n\n\n0.0038566\naccuracy\nbinary\n0.6701156\n10\n0.0063769\nPreprocessor1_Model23\n\n\n0.0038566\nroc_auc\nbinary\n0.5965799\n10\n0.0089758\nPreprocessor1_Model23\n\n\n0.0085317\naccuracy\nbinary\n0.6703823\n10\n0.0062284\nPreprocessor1_Model24\n\n\n0.0085317\nroc_auc\nbinary\n0.5973047\n10\n0.0090449\nPreprocessor1_Model24\n\n\n0.0188739\naccuracy\nbinary\n0.6695844\n10\n0.0055210\nPreprocessor1_Model25\n\n\n0.0188739\nroc_auc\nbinary\n0.5891358\n10\n0.0089649\nPreprocessor1_Model25\n\n\n0.0417532\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model26\n\n\n0.0417532\nroc_auc\nbinary\n0.5802395\n10\n0.0071230\nPreprocessor1_Model26\n\n\n0.0923671\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model27\n\n\n0.0923671\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model27\n\n\n0.2043360\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model28\n\n\n0.2043360\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model28\n\n\n0.4520354\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model29\n\n\n0.4520354\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model29\n\n\n1.0000000\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model30\n\n\n1.0000000\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model30\n\n\n\n\n\n\n\nautoplot(fit2)\n\n\n\n\n\nfit2 %>% \n  show_best(\"roc_auc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model01\n\n\n0\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model02\n\n\n0\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model03\n\n\n0\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model04\n\n\n0\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model05\n\n\n\n\n\n\n\nchosen_auc <- \n  fit2 %>%\n  select_by_one_std_err(metric = \"roc_auc\", -penalty)\n\nFinalisieren:\n\nwf2_final <-\n  finalize_workflow(wf2, chosen_auc)\n\nwf2_final\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_tokenize()\n• step_stopwords()\n• step_stem()\n• step_tokenfilter()\n• step_tfidf()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.00853167852417281\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\nfit2_final_train <-\n  fit(wf2_final, d_train)\n\n\nfit2_final_train %>% \n  extract_fit_parsnip() %>% \n  tidy() %>% \n  arrange(-abs(estimate))\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-6\n\n\n\n\n\n\nterm\nestimate\npenalty\n\n\n\n\n(Intercept)\n0.6992837\n0.0085317\n\n\ntfidf_text_dumm\n-0.2201192\n0.0085317\n\n\ntfidf_text_merkel\n-0.2139564\n0.0085317\n\n\ntfidf_text_moslem\n-0.1772228\n0.0085317\n\n\ntfidf_text_lbr\n-0.1459591\n0.0085317\n\n\ntfidf_text_islam\n-0.1168911\n0.0085317\n\n\ntfidf_text_schulz\n-0.1125708\n0.0085317\n\n\ntfidf_text_anna_iina\n-0.1059814\n0.0085317\n\n\ntfidf_text_türken\n-0.0957637\n0.0085317\n\n\ntfidf_text_dank\n0.0929712\n0.0085317\n\n\ntfidf_text_gut\n0.0792327\n0.0085317\n\n\ntfidf_text_israel\n0.0705250\n0.0085317\n\n\ntfidf_text_tagesschau\n-0.0699302\n0.0085317\n\n\ntfidf_text_grünen\n-0.0668897\n0.0085317\n\n\ntfidf_text_link\n-0.0576155\n0.0085317\n\n\ntfidf_text_deutsch\n-0.0548113\n0.0085317\n\n\ntfidf_text_trump\n-0.0499617\n0.0085317\n\n\ntfidf_text_einfach\n-0.0498839\n0.0085317\n\n\ntfidf_text__macmik\n0.0469582\n0.0085317\n\n\ntfidf_text_dass\n0.0464695\n0.0085317\n\n\ntfidf_text_jahr\n0.0464606\n0.0085317\n\n\ntfidf_text_politik\n-0.0429593\n0.0085317\n\n\ntfidf_text_krippmari\n-0.0420569\n0.0085317\n\n\ntfidf_text_deutschen\n-0.0404395\n0.0085317\n\n\ntfidf_text_schon\n-0.0395614\n0.0085317\n\n\ntfidf_text_wäre\n-0.0390549\n0.0085317\n\n\ntfidf_text_antisemitismu\n0.0387323\n0.0085317\n\n\ntfidf_text_ab\n-0.0343773\n0.0085317\n\n\ntfidf_text_gt\n-0.0294070\n0.0085317\n\n\ntfidf_text_fdp\n0.0282413\n0.0085317\n\n\ntfidf_text_welt\n-0.0271037\n0.0085317\n\n\ntfidf_text_bild\n-0.0238585\n0.0085317\n\n\ntfidf_text_gibt\n-0.0226347\n0.0085317\n\n\ntfidf_text_eu\n0.0176105\n0.0085317\n\n\ntfidf_text_csu\n0.0154015\n0.0085317\n\n\ntfidf_text_lassen\n-0.0147725\n0.0085317\n\n\ntfidf_text_mal\n-0.0145759\n0.0085317\n\n\ntfidf_text_nasanas\n0.0120621\n0.0085317\n\n\ntfidf_text_wohl\n-0.0103838\n0.0085317\n\n\ntfidf_text_europa\n-0.0099091\n0.0085317\n\n\ntfidf_text_volk\n0.0088143\n0.0085317\n\n\ntfidf_text_frage\n0.0086949\n0.0085317\n\n\ntfidf_text_wer\n0.0061202\n0.0085317\n\n\ntfidf_text_heut\n0.0025037\n0.0085317\n\n\ntfidf_text_noherrman\n-0.0012571\n0.0085317\n\n\ntfidf_text_unser\n0.0004523\n0.0085317\n\n\ntfidf_text_deutschland\n-0.0003935\n0.0085317\n\n\ntfidf_text_feldenfrizz\n0.0000029\n0.0085317\n\n\ntfidf_text_2\n0.0000000\n0.0085317\n\n\ntfidf_text_afd\n0.0000000\n0.0085317\n\n\ntfidf_text_amp\n0.0000000\n0.0085317\n\n\ntfidf_text_athinamala\n0.0000000\n0.0085317\n\n\ntfidf_text_besser\n0.0000000\n0.0085317\n\n\ntfidf_text_cdu\n0.0000000\n0.0085317\n\n\ntfidf_text_charlie_silv\n0.0000000\n0.0085317\n\n\ntfidf_text_d\n0.0000000\n0.0085317\n\n\ntfidf_text_dafür\n0.0000000\n0.0085317\n\n\ntfidf_text_ellibisathid\n0.0000000\n0.0085317\n\n\ntfidf_text_endlich\n0.0000000\n0.0085317\n\n\ntfidf_text_ennof_\n0.0000000\n0.0085317\n\n\ntfidf_text_erst\n0.0000000\n0.0085317\n\n\ntfidf_text_focusonlin\n0.0000000\n0.0085317\n\n\ntfidf_text_frau\n0.0000000\n0.0085317\n\n\ntfidf_text_ganz\n0.0000000\n0.0085317\n\n\ntfidf_text_geht\n0.0000000\n0.0085317\n\n\ntfidf_text_gerad\n0.0000000\n0.0085317\n\n\ntfidf_text_hätte\n0.0000000\n0.0085317\n\n\ntfidf_text_immer\n0.0000000\n0.0085317\n\n\ntfidf_text_info2099\n0.0000000\n0.0085317\n\n\ntfidf_text_ja\n0.0000000\n0.0085317\n\n\ntfidf_text_juden\n0.0000000\n0.0085317\n\n\ntfidf_text_kommt\n0.0000000\n0.0085317\n\n\ntfidf_text_land\n0.0000000\n0.0085317\n\n\ntfidf_text_lifetrend\n0.0000000\n0.0085317\n\n\ntfidf_text_macht\n0.0000000\n0.0085317\n\n\ntfidf_text_machtjanix23\n0.0000000\n0.0085317\n\n\ntfidf_text_md_franz\n0.0000000\n0.0085317\n\n\ntfidf_text_mehr\n0.0000000\n0.0085317\n\n\ntfidf_text_menschen\n0.0000000\n0.0085317\n\n\ntfidf_text_miriamozen\n0.0000000\n0.0085317\n\n\ntfidf_text_müssen\n0.0000000\n0.0085317\n\n\ntfidf_text_nancypeggymandi\n0.0000000\n0.0085317\n\n\ntfidf_text_norbinator2403\n0.0000000\n0.0085317\n\n\ntfidf_text_partei\n0.0000000\n0.0085317\n\n\ntfidf_text_petpanther0\n0.0000000\n0.0085317\n\n\ntfidf_text_recht\n0.0000000\n0.0085317\n\n\ntfidf_text_richtig\n0.0000000\n0.0085317\n\n\ntfidf_text_sagt\n0.0000000\n0.0085317\n\n\ntfidf_text_schmiddiemaik\n0.0000000\n0.0085317\n\n\ntfidf_text_seit\n0.0000000\n0.0085317\n\n\ntfidf_text_sicher\n0.0000000\n0.0085317\n\n\ntfidf_text_spd\n0.0000000\n0.0085317\n\n\ntfidf_text_thomasgbau\n0.0000000\n0.0085317\n\n\ntfidf_text_troll_putin\n0.0000000\n0.0085317\n\n\ntfidf_text_tun\n0.0000000\n0.0085317\n\n\ntfidf_text_u\n0.0000000\n0.0085317\n\n\ntfidf_text_viel\n0.0000000\n0.0085317\n\n\ntfidf_text_warum\n0.0000000\n0.0085317\n\n\ntfidf_text_willjrosenblatt\n0.0000000\n0.0085317\n\n\ntfidf_text_wurd\n0.0000000\n0.0085317\n\n\ntfidf_text_zeit\n0.0000000\n0.0085317\n\n\n\n\n\n\n\nfit2_final_test <-\n  last_fit(wf2_final, d_split)\n\ncollect_metrics(fit2_final_test)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.6831604\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.6561186\nPreprocessor1_Model1\n\n\n\n\n\n\n\n1.6.1 Vorhersage\n\n\n1.6.2 Vohersagedaten\nPfad zu den Daten:\n\ntweet_data_path <- \"/Users/sebastiansaueruser/github-repos/hate-speech/data/\"\n\n\ntweet_data_files_names <- list.files(path = tweet_data_path,\n                                     pattern  = \"tweets-to-.*\\\\.rds$\")\nhead(tweet_data_files_names)\n\n[1] \"tweets-to-_FriedrichMerz_2021.rds\" \"tweets-to-_FriedrichMerz_2022.rds\"\n[3] \"tweets-to-ABaerbock_2021.rds\"      \"tweets-to-ABaerbock_2022.rds\"     \n[5] \"tweets-to-Alice_Weidel_2021.rds\"   \"tweets-to-Alice_Weidel_2022.rds\"  \n\n\nWie viele Dateien sind es?\n\nlength(tweet_data_files_names)\n\n[1] 26\n\n\nWir geben den Elementen des Vektors gängige Namen, das hilft uns gleich bei map:\n\nnames(tweet_data_files_names) <- str_remove(tweet_data_files_names, \"\\\\.rds\")\n\nOK, weiter: So können wir eine der Datendateien einlesen:\n\nd_raw <-\n  read_rds(file = paste0(tweet_data_path, tweet_data_files_names[1])) \n\nd <- \n  d_raw %>% \n  select(id, author_id, created_at, public_metrics) %>% \n  unnest_wider(public_metrics)\n\nhead(d)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nauthor_id\ncreated_at\nretweet_count\nreply_count\nlike_count\nquote_count\n\n\n\n\n1476992850944475136\n1270540287786565632\n2021-12-31T19:05:11.000Z\n0\n0\n0\n0\n\n\n1476982994556665862\n1471100575337140229\n2021-12-31T18:26:01.000Z\n0\n0\n0\n0\n\n\n1476958785977597958\n1438467230157602821\n2021-12-31T16:49:49.000Z\n0\n0\n0\n0\n\n\n1476637742884925447\n589112870\n2021-12-30T19:34:07.000Z\n0\n0\n0\n0\n\n\n1476587037046226949\n1041038433064562688\n2021-12-30T16:12:37.000Z\n0\n0\n0\n0\n\n\n1476534413802549249\n1425085042800406536\n2021-12-30T12:43:31.000Z\n10\n2\n44\n2\n\n\n\n\n\n\nUnd so lesen wir alle ein:\nZunächst erstellen wir uns eine Helper-Funktion:\n\nread_and_select <- function(file_name, path_to_tweet_data = tweet_data_path) {\n  \n  out <- \n    read_rds(file = paste0(path_to_tweet_data, file_name)) %>% \n    select(id, author_id, created_at, text, public_metrics) %>% \n    unnest_wider(public_metrics)\n  \n  cat(\"Data file was read.\\n\")\n  \n  return(out)\n}\n\nTesten:\n\nd1 <- read_and_select(tweet_data_files_names[1])\n\nhead(d1)\n\nDie Funktion read_and_select mappen wir auf alle Datendateien:\n\ntic()\nds <-\n  tweet_data_files_names %>% \n  map_dfr(read_and_select, .id = \"dataset\")\ntoc()\n\n214.531 sec elapsed\nDa wir den Elementen von tweet_data_files_names Namen gegeben haben, finden wir diese Namen praktischerweise wieder in ds:\n\n\n\n\n\n\n\nhead(ds)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndataset\nid\nauthor_id\ncreated_at\ntext\nretweet_count\nreply_count\nlike_count\nquote_count\n\n\n\n\ntweets-to-_FriedrichMerz_2021\n1476992850944475136\n1270540287786565632\n2021-12-31T19:05:11.000Z\n(_FriedrichMerz?) https://t.co/YR8HQh6TKT\n0\n0\n0\n0\n\n\ntweets-to-_FriedrichMerz_2021\n1476982994556665862\n1471100575337140229\n2021-12-31T18:26:01.000Z\n(_FriedrichMerz?) Ich freue mich auf eine neue, moderne und wiedererstarkte CDU unter Führung von Friedrich Merz. Bernd\n0\n0\n0\n0\n\n\ntweets-to-_FriedrichMerz_2021\n1476958785977597958\n1438467230157602821\n2021-12-31T16:49:49.000Z\n(_FriedrichMerz?)\n\n\n\n\n\n\n\n(Volker_Beck?) China is exploiting poor and neighboring countries either through aggression or debt trap. The expansion in the Chinese Navy is causing a psychological threat to these poor countries. #ChineseNavalExpansion #CCPGlobalThreat https://t.co/kHp5gu649x | 0| 0| 0| 0| |tweets-to-_FriedrichMerz_2021 |1476637742884925447 |589112870 |2021-12-30T19:34:07.000Z |(_FriedrichMerz?) Viele Mediziner werden den Sprung zum neuen Paradigma der menschlichen Gesundheit nie schaffen. Sie sind zu schwach und ängstlich und werden zurückbleiben, sich gegenseitig bekämpfen und sich selbst zerstören. So wie sie es jetzt tun. https://t.co/Jsecipn1m4 | 0| 0| 0| 0| |tweets-to-_FriedrichMerz_2021 |1476587037046226949 |1041038433064562688 |2021-12-30T16:12:37.000Z |(_FriedrichMerz?) hat vielleicht eine Antwort. (Alice_Weidel?) hat sicher eine. https://t.co/mTcPCKYDek | 0| 0| 0| 0| |tweets-to-_FriedrichMerz_2021 |1476534413802549249 |1425085042800406536 |2021-12-30T12:43:31.000Z |(_FriedrichMerz?) + (c_lindner?) - warum trauen sich die Parteien der #Mitte in #D nicht, die Position des dänischen Innenministers (KaareDypvad?) ebenso deutlich auszusprechen!? Warum überlassen wir #Migration #Ideologen statt dem vernünftigen dänischen Vorbild zu folgen? #Asyl (welt?) https://t.co/tA2ERbM1qf | 10| 2| 44| 2|\n\n\n\nVielleicht ist es zum Entwickeln besser, mit einem kleineren Datensatz einstweilen zu arbeiten:\n\nds_short <- slice_sample(ds, prop = .05)\n\n\n\n\n\n\n1.6.3 Vokabular erstellen\n\nds_long <-\n  ds %>% \n  select(text) %>% \n  unnest_tweets(input = text, output = word)\n\nPuh, das hat gedauert!\nSpeichern wir uns diese Daten daher auf die Festplatte:\n\nwrite_rds(ds_long, file = paste0(tweet_data_path, \"ds_long.rds\"))\n\nEntfernen wir daraus die Duplikate, um uns ein Vokabular zu erstellen:\n\nds_voc <-\n  ds_long %>% \n  #slice_head(n = 10) %>% \n  distinct(word)\n\nUnd das resultierende Objekt speichern wir wieder ab:\n\nwrite_rds(ds_voc, file = paste0(tweet_data_path, \"ds_voc.rds\"))"
  },
  {
    "objectID": "klassifikation.html#worteinbettungen-erstellen",
    "href": "klassifikation.html#worteinbettungen-erstellen",
    "title": "1  Klassifikation von Hatespeech",
    "section": "1.7 Worteinbettungen erstellen",
    "text": "1.7 Worteinbettungen erstellen\n\n1.7.1 FastText-Modell\nDefiniere die Konstanten für das fastText-Modell:\n\ntexts <- ds %>% pull(text)\ntexts <- tolower(texts)\n\n\nout_file_txt <- \"/Users/sebastiansaueruser/datasets/Twitter/twitter-polit-model.vec\"\nout_file_model <- \"/Users/sebastiansaueruser/datasets/Twitter/twitter-polit-model.bin\"\n\n\nwriteLines(text = texts, con = out_file_txt)\nexecute(commands = c(\"skipgram\", \"-input\", tmp_file_txt, \"-output\", out_file_model, \"-verbose\", 1))\n\nRead 22M words\nNumber of words:  130328\nNumber of labels: 0\nProgress: 100.0% words/sec/thread:   49218 lr:  0.000000 avg.loss:  1.720812 ETA:   0h 0m 0s\nJetzt laden wir das Modell von der Festplatte:\n\ntwitter_fasttext_model <- load_model(out_file_model)\ndict <- get_dictionary(twitter_fasttext_model)\n\nSchauen wir uns einige Begriffe aus dem Vokabular an:\n\nprint(head(dict, 10))\n\n [1] \"</s>\"            \"die\"             \"und\"             \"der\"            \n [5] \"sie\"             \"das\"             \"nicht\"           \"in\"             \n [9] \"ist\"             \"@_friedrichmerz\"\n\n\nHier sind die ersten paar Elemente des Vektors für menschen:\n\nget_word_vectors(twitter_fasttext_model, c(\"menschen\")) %>% `[`(1:10)\n\n [1]  0.14156282  0.44875699  0.23911817 -0.02580349  0.29811972  0.03870077\n [7]  0.06518744  0.22527063  0.28198120  0.39931887\nErstellen wir uns einen Tibble, der als erste Spalte das Vokabular und in den übrigen 100 Spalten die Dimensionen enthält:\n\nword_embedding_twitter <-\n  tibble(\n    word = dict\n  )\n\n\nwords_vecs_twitter <-\n  get_word_vectors(twitter_fasttext_model)\n\n\nword_embedding_twitter <-\n  word_embedding_twitter %>% \n  bind_cols(words_vecs_twitter)\n\nnames(word_embedding_twitter) <- c(\"word\", paste0(\"v\", sprintf(\"%03d\", 1:100)))  # Namen verschönern\n\nUnd als Worteinbettungs-Datei abspeichern:\n\nwrite_rds(word_embedding_twitter, file = paste0(tweet_data_path, \"word_embedding_twitter.rds\"))\n\n\n\n\n\n\n1.7.2 Aufbereiten\nAm besten nur die Spalten behalten, die wir zum Modellieren nutzen:\n\nds_short2 <-\n  ds_short %>% \n  select(text, id)\n\nDann backen wir die Daten mit dem vorhandenen Rezept:\n\nds_baked <- bake(rec1_prepped, new_data = ds_short2)\n\nhead(ds_baked)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntfidf_text__macmik\ntfidf_text_2\ntfidf_text_ab\ntfidf_text_afd\ntfidf_text_amp\ntfidf_text_anna_iina\ntfidf_text_antisemitismu\ntfidf_text_athinamala\ntfidf_text_besser\ntfidf_text_bild\ntfidf_text_cdu\ntfidf_text_charlie_silv\ntfidf_text_csu\ntfidf_text_d\ntfidf_text_dafür\ntfidf_text_dank\ntfidf_text_dass\ntfidf_text_deutsch\ntfidf_text_deutschen\ntfidf_text_deutschland\ntfidf_text_dumm\ntfidf_text_einfach\ntfidf_text_ellibisathid\ntfidf_text_endlich\ntfidf_text_ennof_\ntfidf_text_erst\ntfidf_text_eu\ntfidf_text_europa\ntfidf_text_fdp\ntfidf_text_feldenfrizz\ntfidf_text_focusonlin\ntfidf_text_frage\ntfidf_text_frau\ntfidf_text_ganz\ntfidf_text_geht\ntfidf_text_gerad\ntfidf_text_gibt\ntfidf_text_grünen\ntfidf_text_gt\ntfidf_text_gut\ntfidf_text_hätte\ntfidf_text_heut\ntfidf_text_immer\ntfidf_text_info2099\ntfidf_text_islam\ntfidf_text_israel\ntfidf_text_ja\ntfidf_text_jahr\ntfidf_text_juden\ntfidf_text_kommt\ntfidf_text_krippmari\ntfidf_text_land\ntfidf_text_lassen\ntfidf_text_lbr\ntfidf_text_lifetrend\ntfidf_text_link\ntfidf_text_macht\ntfidf_text_machtjanix23\ntfidf_text_mal\ntfidf_text_md_franz\ntfidf_text_mehr\ntfidf_text_menschen\ntfidf_text_merkel\ntfidf_text_miriamozen\ntfidf_text_moslem\ntfidf_text_müssen\ntfidf_text_nancypeggymandi\ntfidf_text_nasanas\ntfidf_text_noherrman\ntfidf_text_norbinator2403\ntfidf_text_partei\ntfidf_text_petpanther0\ntfidf_text_politik\ntfidf_text_recht\ntfidf_text_richtig\ntfidf_text_sagt\ntfidf_text_schmiddiemaik\ntfidf_text_schon\ntfidf_text_schulz\ntfidf_text_seit\ntfidf_text_sicher\ntfidf_text_spd\ntfidf_text_tagesschau\ntfidf_text_thomasgbau\ntfidf_text_troll_putin\ntfidf_text_trump\ntfidf_text_tun\ntfidf_text_türken\ntfidf_text_u\ntfidf_text_unser\ntfidf_text_viel\ntfidf_text_volk\ntfidf_text_wäre\ntfidf_text_warum\ntfidf_text_welt\ntfidf_text_wer\ntfidf_text_willjrosenblatt\ntfidf_text_wohl\ntfidf_text_wurd\ntfidf_text_zeit\n\n\n\n\n1586768624320135168\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n6.8580253\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n3.5879501\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n4.4080594\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n1583554257470357504\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n17.0144371\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n1583140717236391936\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n6.4682819\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n4.8888601\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n1418452119460454404\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n1585276821565759489\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n7.0164922\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n4.7406218\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n1441493674437664775\n-0.1472962\n-0.1025123\n-0.1045303\n6.1558148\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n6.8580253\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n\n\n\n\nIst das nicht komfortabel? Das Textrezept übernimmt die Arbeit für uns, mit den richtigen Features zu arbeiten, die tf-idfs für die richtigen Tokens zu berechnen.\nWer dem Frieden nicht traut, dem sei geraten, nachzuprüfen :-)"
  },
  {
    "objectID": "klassifikation.html#workflow-3-rezept-2-lasso",
    "href": "klassifikation.html#workflow-3-rezept-2-lasso",
    "title": "1  Klassifikation von Hatespeech",
    "section": "1.8 Workflow 3: Rezept 2 + Lasso",
    "text": "1.8 Workflow 3: Rezept 2 + Lasso\n\n1.8.1 Daten aufteilen\n\nd_split <- initial_split(d2, strata = c1)\n\nd_train <- training(d_split)\nd_test <- testing(d_split)\n\n\n\n1.8.2 Hilfsfunktionen\n\ndummy <- c(\"hallo\", \"baby\", \"fatal\")\n\n\ncount_profane <- function(text) {\n  sum((tokenize_tweets(text, simplify = TRUE) %>% simplify()) %in% schimpf$word)\n}\n\ncount_profane(dummy) \n\n[1] 1\n\n\n\ncount_emo_words <- function(text) {\n  sum((tokenize_tweets(text, simplify = TRUE) %>% simplify()) %in% sentiws$word)\n}\n\ncount_emo_words(dummy)\n\n[1] 1\n\n\n\ncount_emojis <- function(text){\n  sum((tokenize_tweets(text, simplify = TRUE) %>% simplify()) %in% trimws(emj))\n}\n\ndummy <- c(\"baby\", \"und\", \"🆗\", \"🖕\")\n\ncount_emojis(dummy)\n\n[1] 1\n\n\n\ncount_wild_emojis <- function(text){\n  sum((tokenize_tweets(text, simplify = TRUE) %>% simplify()) %in% wild_emojis)\n}\n\ncount_wild_emojis(dummy) \n\n[1] 1\n\n\n\n\n1.8.3 Rezept mit Worteinbettungen\n\nrec2 <- \n  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% \n  update_role(id, new_role = \"id\") %>% \n  step_text_normalization(text) %>% \n  step_mutate(text_copy = text,\n              profane_n = map_int(text, count_profane),\n              emo_words_n = map_int(text, count_emo_words),\n              emojis_n = map_int(text, count_emojis),\n              wild_emojis_n = map_int(text, count_wild_emojis)\n  ) %>% \n  step_textfeature(text_copy) %>% \n  step_tokenize(text, token = \"tweets\") %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>% \n  step_word_embeddings(text, embeddings = word_embedding_twitter)\n \nrec2\n\nRecipe\n\nInputs:\n\n      role #variables\n        id          1\n   outcome          1\n predictor          1\n\nOperations:\n\nText Normalization for text\nVariable mutation for text, map_int(text, count_profane), map_in...\nText feature extraction for text_copy\nTokenization for text\nStop word removal for text\nWord embeddings aggregated from text\n\n\n\nrec2_prepped <- prep(rec2)\nrec2_baked <- bake(rec2_prepped, new_data = NULL)\n\n\nrec2_baked %>% \n  select(1:15) %>% \n  glimpse()\n\nRows: 3,756\nColumns: 15\n$ id                                  <int> 5, 7, 9, 10, 17, 42, 44, 48, 53, 5…\n$ c1                                  <fct> OFFENSE, OFFENSE, OFFENSE, OFFENSE…\n$ profane_n                           <int> 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1…\n$ emo_words_n                         <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0…\n$ emojis_n                            <int> 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 2…\n$ wild_emojis_n                       <int> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0…\n$ textfeature_text_copy_n_words       <int> 16, 32, 12, 15, 19, 30, 31, 6, 24,…\n$ textfeature_text_copy_n_uq_words    <int> 16, 28, 12, 15, 17, 29, 29, 6, 23,…\n$ textfeature_text_copy_n_charS       <int> 121, 145, 66, 119, 112, 171, 170, …\n$ textfeature_text_copy_n_uq_charS    <int> 31, 29, 29, 30, 36, 42, 35, 23, 30…\n$ textfeature_text_copy_n_digits      <int> 0, 4, 0, 0, 4, 0, 1, 0, 2, 0, 2, 0…\n$ textfeature_text_copy_n_hashtags    <int> 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0…\n$ textfeature_text_copy_n_uq_hashtags <int> 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0…\n$ textfeature_text_copy_n_mentions    <int> 1, 1, 1, 0, 0, 5, 1, 0, 1, 1, 0, 2…\n$ textfeature_text_copy_n_uq_mentions <int> 1, 1, 1, 0, 0, 5, 1, 0, 1, 1, 0, 2…\n\n\n\n\n1.8.4 Fitting 3\n\nwf3 <-\n  workflow() %>% \n  add_recipe(rec2) %>% \n  add_model(lasso_spec)\n\nwf3\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_text_normalization()\n• step_mutate()\n• step_textfeature()\n• step_tokenize()\n• step_stopwords()\n• step_word_embeddings()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\nTunen und Fitten:\n\nset.seed(42)\n\ntic()\nfit3 <-\n  tune_grid(\n    wf3,\n    folds1,\n    grid = lambda_grid,\n    control = control_resamples(save_pred = TRUE)\n  )\n(toc)\nfit3\n\n\nwrite_rds(fit3, \"objects/chap_classific_fit3.rds\")\n\n\n\n\nHier ist die Performanz:\n\ncollect_metrics(fit3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model01\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model01\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model02\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model02\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model03\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model03\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model04\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model04\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model05\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model05\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model06\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model06\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model07\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model07\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model08\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model08\n\n\n0.0000001\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model09\n\n\n0.0000001\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model09\n\n\n0.0000001\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model10\n\n\n0.0000001\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model10\n\n\n0.0000003\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model11\n\n\n0.0000003\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model11\n\n\n0.0000006\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model12\n\n\n0.0000006\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model12\n\n\n0.0000014\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model13\n\n\n0.0000014\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model13\n\n\n0.0000030\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model14\n\n\n0.0000030\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model14\n\n\n0.0000067\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model15\n\n\n0.0000067\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model15\n\n\n0.0000149\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model16\n\n\n0.0000149\nroc_auc\nbinary\n0.8095845\n10\n0.0096008\nPreprocessor1_Model16\n\n\n0.0000329\naccuracy\nbinary\n0.7667645\n10\n0.0061340\nPreprocessor1_Model17\n\n\n0.0000329\nroc_auc\nbinary\n0.8095282\n10\n0.0095826\nPreprocessor1_Model17\n\n\n0.0000728\naccuracy\nbinary\n0.7667645\n10\n0.0061340\nPreprocessor1_Model18\n\n\n0.0000728\nroc_auc\nbinary\n0.8095638\n10\n0.0095511\nPreprocessor1_Model18\n\n\n0.0001610\naccuracy\nbinary\n0.7662333\n10\n0.0057794\nPreprocessor1_Model19\n\n\n0.0001610\nroc_auc\nbinary\n0.8099159\n10\n0.0094448\nPreprocessor1_Model19\n\n\n0.0003562\naccuracy\nbinary\n0.7654348\n10\n0.0063700\nPreprocessor1_Model20\n\n\n0.0003562\nroc_auc\nbinary\n0.8103737\n10\n0.0092381\nPreprocessor1_Model20\n\n\n0.0007880\naccuracy\nbinary\n0.7664993\n10\n0.0062776\nPreprocessor1_Model21\n\n\n0.0007880\nroc_auc\nbinary\n0.8111630\n10\n0.0089414\nPreprocessor1_Model21\n\n\n0.0017433\naccuracy\nbinary\n0.7670333\n10\n0.0066734\nPreprocessor1_Model22\n\n\n0.0017433\nroc_auc\nbinary\n0.8116297\n10\n0.0087106\nPreprocessor1_Model22\n\n\n0.0038566\naccuracy\nbinary\n0.7646319\n10\n0.0069158\nPreprocessor1_Model23\n\n\n0.0038566\nroc_auc\nbinary\n0.8093719\n10\n0.0079992\nPreprocessor1_Model23\n\n\n0.0085317\naccuracy\nbinary\n0.7553156\n10\n0.0061916\nPreprocessor1_Model24\n\n\n0.0085317\nroc_auc\nbinary\n0.8032327\n10\n0.0073114\nPreprocessor1_Model24\n\n\n0.0188739\naccuracy\nbinary\n0.7308227\n10\n0.0069456\nPreprocessor1_Model25\n\n\n0.0188739\nroc_auc\nbinary\n0.7830419\n10\n0.0087585\nPreprocessor1_Model25\n\n\n0.0417532\naccuracy\nbinary\n0.6996695\n10\n0.0085704\nPreprocessor1_Model26\n\n\n0.0417532\nroc_auc\nbinary\n0.7537161\n10\n0.0090227\nPreprocessor1_Model26\n\n\n0.0923671\naccuracy\nbinary\n0.6629305\n10\n0.0054329\nPreprocessor1_Model27\n\n\n0.0923671\nroc_auc\nbinary\n0.6848928\n10\n0.0102870\nPreprocessor1_Model27\n\n\n0.2043360\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model28\n\n\n0.2043360\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model28\n\n\n0.4520354\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model29\n\n\n0.4520354\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model29\n\n\n1.0000000\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model30\n\n\n1.0000000\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model30\n\n\n\n\n\n\n\nautoplot(fit3)\n\n\n\n\n\nfit3 %>% \n  show_best(\"roc_auc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0017433\nroc_auc\nbinary\n0.8116297\n10\n0.0087106\nPreprocessor1_Model22\n\n\n0.0007880\nroc_auc\nbinary\n0.8111630\n10\n0.0089414\nPreprocessor1_Model21\n\n\n0.0003562\nroc_auc\nbinary\n0.8103737\n10\n0.0092381\nPreprocessor1_Model20\n\n\n0.0001610\nroc_auc\nbinary\n0.8099159\n10\n0.0094448\nPreprocessor1_Model19\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model01\n\n\n\n\n\n\n\nchosen_auc_fit3 <- \n  fit3 %>%\n  select_by_one_std_err(metric = \"roc_auc\", -penalty)\n\nFinalisieren:\n\nwf3_final <-\n  finalize_workflow(wf3, chosen_auc_fit3)\n\nwf3_final\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n6 Recipe Steps\n\n• step_text_normalization()\n• step_mutate()\n• step_textfeature()\n• step_tokenize()\n• step_stopwords()\n• step_word_embeddings()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.00853167852417281\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\nfit3_final_train <-\n  fit(wf3_final, d_train)\n\n\nfit3_final_train %>% \n  extract_fit_parsnip() %>% \n  tidy() %>% \n  arrange(-abs(estimate)) %>% \n  head()\n\n\n\n\n\nterm\nestimate\npenalty\n\n\n\n\n(Intercept)\n1.2325023\n0.0085317\n\n\nprofane_n\n-0.5899329\n0.0085317\n\n\ntextfeature_text_copy_n_exclaims\n-0.1987554\n0.0085317\n\n\nwordembed_text_v055\n0.1799862\n0.0085317\n\n\nwordembed_text_v059\n-0.1465378\n0.0085317\n\n\nwordembed_text_v054\n0.1455451\n0.0085317\n\n\n\n\n\n\n\nfit3_final_test <-\n  last_fit(wf3_final, d_split)\n\ncollect_metrics(fit3_final_test)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.7533919\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.7871291\nPreprocessor1_Model1\n\n\n\n\n\n\nAm Ende so eines Arbeitsganges, bei dem man wieder (und wieder) die gleichen Funktionen kopiert, und nur aufpassen muss, aus fit2 an der richtigen Stelle fit3 zu machen: Da blickt man jedem Umbau dieses Codes zu einer Funktion freudig ins Gesicht.\nEin anderes Problem, für das hier keine elegante Lösung vorliegt, sind die langen Berechnungszeiten, die, wenn man Pecht hat, auch noch mehrfach wiederholt werden müssen.\nZu diesen Punkten später mehr.\n\n\n\n\nRemus, Robert, Uwe Quasthoff, und Gerhard Heyer. 2010. „SentiWS - a Publicly Available German-language Resource for Sentiment Analysis“. Proceedings of the 7th International Language Ressources and Evaluation (LREC’10), 1168–71.\n\n\nWiegand, Michael. 2019a. „GermEval-2018 Corpus (DE)“. heiDATA. https://doi.org/10.11588/DATA/0B5VML.\n\n\n———. 2019b. „GermEval-2018-Data-master“. In GermEval-2018 corpus (DE). heiDATA. https://doi.org/10.11588/data/0B5VML/XIUWJ7."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Hvitfeldt, Emil, and Julia Silge. 2022. Supervised Machine Learning\nfor Text Analysis in r. 1st ed. Boca Raton: Chapman;\nHall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nRemus, Robert, Uwe Quasthoff, and Gerhard Heyer. 2010.\n“SentiWS - a Publicly Available German-Language\nResource for Sentiment Analysis.” Proceedings of the 7th\nInternational Language Ressources and Evaluation\n(LREC’10), 1168–71.\n\n\nWiegand, Michael. 2019a. “GermEval-2018 Corpus\n(DE).” heiDATA. https://doi.org/10.11588/DATA/0B5VML.\n\n\n———. 2019b. “GermEval-2018-Data-Master.” In\nGermEval-2018 Corpus (DE).\nheiDATA. https://doi.org/10.11588/data/0B5VML/XIUWJ7."
  }
]