[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "datascience2: Prädiktive Modelle auf Basis von Textdaten",
    "section": "",
    "text": "falls Sie die Pakete schon installiert haben, könnten Sie mal in RStudio auf “update.packages” klicken↩︎"
  },
  {
    "objectID": "pruefung.html",
    "href": "pruefung.html",
    "title": "1  Prüfung",
    "section": "",
    "text": "Text als Datenbasis prädiktiver Modelle\nBild von mcmurryjulie auf Pixabay"
  },
  {
    "objectID": "pruefung.html#prüfungsform-datenanalyse-als-quarto-blog-post",
    "href": "pruefung.html#prüfungsform-datenanalyse-als-quarto-blog-post",
    "title": "1  Prüfung",
    "section": "1.1 Prüfungsform: Datenanalyse als Quarto-Blog-Post",
    "text": "1.1 Prüfungsform: Datenanalyse als Quarto-Blog-Post\nAls Prüfungsleistung ist ein Corpus an Twitter-Daten deutscher aktueller Politiker auf Hate Speech hin zu untersuchen.\n\nDer Bericht der Analyse ist als Quarto Blog-Posts zu formatieren.\nEinzureichen ist die URL des Posts.\nDer Post muss während des gesamten Prüfungszeitraums online sein, gehostet von einem beliebigen Provider (z.B. Netlify oder Github).\nNach Einreichen des Posts dürfen keine Änderungen mehr vorgenommen werden.\nZu Dokumentationszwecken soll ein PDF-Print des Posts in die Abgabe mit hochgeladen werden. Das PDF-Print des Posts muss identisch (exakt gleich) sein zum Post, der über die URL verfügbar ist.\nDer Quelltext des Posts soll bei Github vorliegen.\n\n\nAlle folgenden Hinweise gelten nur insoweit Ihre Lehrkraft Ihnen keine anders lautenden Hinweise gegeben hat (schriftlich)."
  },
  {
    "objectID": "pruefung.html#allgemeines",
    "href": "pruefung.html#allgemeines",
    "title": "1  Prüfung",
    "section": "1.2 Allgemeines",
    "text": "1.2 Allgemeines\n\nGegenstand dieser Prüfungsform ist die Analyse eines Datensatzes nach einer Forschungsfrage und die Dokumentation dieser Analyse.\nSchreiben Sie Ihre Datenanalyse in Form eines Berichts, der sich an den Gliederungspunkten wie unten dargestellt orientiert.\nWenden Sie die passenden, im Unterricht eingeführten, statistischen Verfahren an. Es steht Ihnen frei, andere (nicht im Unterricht behandelte) Verfahren zur Analyse der Daten anzuwenden, nach Maßgabe der fachlichen Angemessenheit.\nWerten Sie die Daten mit R aus.\nDie R-Syntax soll im Hauptteil des Berichts dokumentiert werden. R-Output darf ggf. gekürzt wiedergegeben werden.\nFügen Sie keine Erklärungen oder Definitionen von statistischen Verfahren an.\nBeschreiben und interpretieren Sie jede Analyse bzw. jeden R-Code bzw. jedes Ergebnis (jede R-Ausgabe).\nVon hoher Bedeutung ist die Korrektheit der Beschreibung und Interpretation der statistischen Modellierung (z.B. mit der Regressionsanalyse).\nEs hat keinen Einfluss auf Ihre Note, ob sich ein (erwarteter) Effekt zeigt und wie stark dieser Effekt ggf. ist."
  },
  {
    "objectID": "pruefung.html#formatierung-des-berichts",
    "href": "pruefung.html#formatierung-des-berichts",
    "title": "1  Prüfung",
    "section": "1.3 Formatierung des Berichts",
    "text": "1.3 Formatierung des Berichts\n\nDer Bericht ist nur elektronisch, nicht ausgedruckt einzureichen.\nDer Bericht kann als paginiertes Dokument oder als nicht-paginiertes Dokument (d.h. als HTML-Dokument) eingereicht werden.\nPaginierte Formate sind als PDF-Datei einzureichen. HTML-Formate sind entweder in HTML-Form oder (nur bei Bedarf) als PDF-Druck eines HTML-Dokuments einzureichen.\nDie Wahl eines bestimmten Stylesheets ist nicht von Bedeutung. Lesbarkeit und Übersichtlichkeit in der Formatierung sind unabhängig davon anzustreben.\nIm Kopfbereich (oder auf einem Deckblatt) sind die relevanten Metadatan anzugeben wie Name (Nachname, Vorname) der Autorin/des Autors, Abgabedatum, Titel der Arbeit, Modul."
  },
  {
    "objectID": "pruefung.html#formalia",
    "href": "pruefung.html#formalia",
    "title": "1  Prüfung",
    "section": "1.4 Formalia",
    "text": "1.4 Formalia\n\nRichtlinien einer Wortzahl gibt es nicht. Entscheidend ist, dass relevante Analysen durchgeführt und beschrieben wurden.\nDer Anspruch richtet sich nach dem Inhalt und Niveau der auf dieses Modul vorbereitenden Module. Oft sind das Module in quantitativer Datenanalyse (und wissenschaftliches Arbeiten). Deren Inhalte sollen im Rahmen dieser Prüfungsleistung als selbständig und flüssig verfügbare Kompetenz von den Studentis demonstriert werden.\nDie Gliederung der Arbeit kann sich an den PPDAC-Zyklus und am Data Science Model von Wickham und Grolemund orientieren."
  },
  {
    "objectID": "pruefung.html#beurteilungskriterien",
    "href": "pruefung.html#beurteilungskriterien",
    "title": "1  Prüfung",
    "section": "1.5 Beurteilungskriterien",
    "text": "1.5 Beurteilungskriterien\nDie Arbeit wird im Hinblick auf drei Kriterien bewertet:\n\nFormalia (z. B. Vollständigkeit der Abarbeitung, Angemessenheit der äußeren Gestaltung, Fokus auf Wesentliches)\nMethodik (z. B. Richtige Auswahl und Anwendung der Verfahren)\nInhalt (z. B. Verständlichkeit, Breite und Tiefe der Problemlösung, Korrektheit der Interpretation)\n\nSie erhalten für jedes der drei Kriterien eine Teilnote sowie eine Gesamtnote. Außerdem erhalten Sie ggf. für die Kriterien noch ausformulierte Hinweise.\nDie Gesamtnote muss sich nicht als Mittelwert der Teilnoten ergeben.\nInsbesondere kann eine Fünf in einem der Kriterien zum Durchfallen führen, auch wenn die anderen beiden Kriterien gut oder sehr gut beurteilt wurden."
  },
  {
    "objectID": "pruefung.html#beispiele-für-aspekte-der-beurteilungskriterien",
    "href": "pruefung.html#beispiele-für-aspekte-der-beurteilungskriterien",
    "title": "1  Prüfung",
    "section": "1.6 Beispiele für Aspekte der Beurteilungskriterien",
    "text": "1.6 Beispiele für Aspekte der Beurteilungskriterien\n\nWurden deskriptive Statistiken (an angemessenen Ort) berichtet?\nWurden Diagramme und Tabellen angemessen eingesetzt?\nWurde Inferenzstatistik (angemessen) eingesetzt?\nWurden Effektstärkemaße (idealerweise mit Konfidenzintervallen dazu) berichtet?\nWurden alle relevanten Informationen für ein statistisches Verfahren angegeben (z.B. zum gewählten Prior)?\nWurde die Aussagekraft von Modellergebnissen richtig eingeschätzt?\nWaren die Schlussfolgerungen, die aus den statistischen Ergebnissen gezogen wurden, angemessen (z. B. wurde erkannt, dass ein Nicht-Verwerfeen einer Hypothese nicht automatisch ein Bestätigen derselben bedeutet)?\nWurde angemessen gerundet (inkl. konsistente Anzahl von Nachkommastellen)?\nPassen die statistischen Verfahren zu den Hypothesen?\nWurden die Voraussetzungen der statistischen Verfahren geprüft?\nSind die Ergebnisse reproduzierbar (Daten und Syntax eingereicht)?"
  },
  {
    "objectID": "pruefung.html#beispiele-für-fehler",
    "href": "pruefung.html#beispiele-für-fehler",
    "title": "1  Prüfung",
    "section": "1.7 Beispiele für Fehler",
    "text": "1.7 Beispiele für Fehler\nSchwere Fehler, die zum Durchfallen oder deutlichem Abwerten der Note führen können, sind z.B.:\n\nfehlende Inferenzstatistik (oder adäquatem Ersatz)\nfalsche Interpretation von Posteriori-Verteilungen oder p-Werten\nkeine Angabe von Konfidenzintervallen\nfalsche Interpretation von Konfidenzintervallen\nWahl des falschen Intervalls (Vorhersageintervall vs. Perzentilintervall vs. HDI)\nfalsche Entscheidung zum Hypothesentest auf Basis entsprechender Kennwerte (wie ROPE-Wahrscheinlichkeit oder p-Wert)\nfalsche Wahl des statistischen Verfahrens\nfehlende Deskriptivstatistik\n\nHäufige kleinere Mängel sind z. B.\n\npixelige Abbildungen\nR-Ausgaben oder R-Syntax als Screenshot\nfehlende Seitenzahlen (nur bei paginierten Formaten, nicht bei HTML)\nunübersichtliche Diagramme\nkein (verlinktes) Inhaltsverzeichnis ︎\nfehlende oder unverständliche Achsenbeschriftung bei Diagrammen\nfehlende oder falsche Beschreibung der/des Skalenniveau(s) der untersuchten Variablen"
  },
  {
    "objectID": "twittermining.html",
    "href": "twittermining.html",
    "title": "2  Twitter Mining",
    "section": "",
    "text": "Text als Datenbasis prädiktiver Modelle\nBild von mcmurryjulie auf Pixabay"
  },
  {
    "objectID": "twittermining.html#vorab",
    "href": "twittermining.html#vorab",
    "title": "2  Twitter Mining",
    "section": "2.1 Vorab",
    "text": "2.1 Vorab\n\n2.1.1 Lernziele\n\nTwitterdaten via API von Twitter auslesen\n\n\n\n2.1.2 Vorbereitung\n\nLesen Sie in Hvitfeldt und Silge (2022) Kap. 1.\nLegen Sie sich ein Konto bei Github an.\nLegen Sie sich ein Konto bei Twitter an.\nLesen Sie diesen Artikel zur Anmeldung bei der Twitter API1\n\n\n\n2.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(rtweet)\n\n\n\n\nR-Paket {rtweet}\n\n\nEinen Überblick über die Funktionen des Pakets (function reference) findet sich hier."
  },
  {
    "objectID": "twittermining.html#anmelden-bei-twitter",
    "href": "twittermining.html#anmelden-bei-twitter",
    "title": "2  Twitter Mining",
    "section": "2.2 Anmelden bei Twitter",
    "text": "2.2 Anmelden bei Twitter\n\n2.2.1 Welche Accounts interessieren uns?\nHier ist eine (subjektive) Auswahl von deutschen Politikern, die einen Startpunkt gibt zur Analyse von Art und Ausmaß von Hate Speech gerichtet an deutsche Politiker:innen.\n\nd_path <- \"data/twitter-german-politicians.csv\"\n\nd <- read_csv(d_path)\nd\n\n\n\n\n\n\n\n\n\n\n\nname\nparty\nscreenname\ncomment\n\n\n\n\nKarl Lauterbach\nSPD\nKarl_Lauterbach\nNA\n\n\nOlaf Scholz\nSPD\nOlafScholz\nNA\n\n\nAnnalena Baerback\nGruene\nABaerbock\nNA\n\n\nBundesministerium für Wirtschaft und Klimaschutz\nGruene\nBMWK\nRobert Habeck ist der Minister im BMWK\n\n\nFriedrich Merz\nCDU\n_FriedrichMerz\nCDU-Chef\n\n\nMarkus Söder\nCSU\nMarkus_Soeder\nCSU-Chef\n\n\nCem Özdemir\nGruene\ncem_oezdemir\nBMEL\n\n\nJanine Wissler\nLinke\nJanine_Wissler\nLinke-Chefin\n\n\nMartin Schirdewan\nLinke\nschirdewan\nLinke-Chef\n\n\nChristian Lindner\nFDP\nc_lindner\nFDP-Chef\n\n\nMarie-Agnes Strack-Zimmermann\nFDP\nMAStrackZi\nVorsitzende Verteidigungsausschuss\n\n\nTino Chrupalla\nAFD\nTino_Chrupalla\nAFD-Bundessprecher\n\n\nAlice Weidel\nAFD\nAlice_Weidel\nAFD-Bundessprecherin\n\n\n\n\n\n\n\n\n2.2.2 Twitter App erstellen\nTutorial\n\n\n2.2.3 Intro\nDie Seite von rtweet gibt eine gute Starthilfe in die Benutzung des Pakets.\n\n\n2.2.4 Zugangsdaten\nZugangsdaten sollte man geschützt speichern, also z.B. nicht in einem geteilten Ordner.\n\nsource(\"/Users/sebastiansaueruser/credentials/hate-speech-analysis-v01-twitter.R\")\n\nAnmelden:\n\n#auth_setup_default() \n\nauth <- rtweet_bot(api_key = api_key,\n                   api_secret = api_secret,\n                   access_token = access_token,\n                   access_secret = access_secret)"
  },
  {
    "objectID": "twittermining.html#tweets-einlesen",
    "href": "twittermining.html#tweets-einlesen",
    "title": "2  Twitter Mining",
    "section": "2.3 Tweets einlesen",
    "text": "2.3 Tweets einlesen\nZu beachten ist, dass es Limits gibt, wie viele Informationen (pro Zeiteinheit) man über die Twitter-API auslesen darf. Informationen dazu findet man z.B. hier oder auch mit rate_limit().\nEin gängiges Limit der Twitter-API sind 900 Anfragen (z.B. Tweets auslesen) pro 15 Minuten.\n\n2.3.1 Timeline einlesen einzelner Accounts\nMal ein paar Tweets zur Probe:\n\nsesa_test <- get_timeline(user = \"sauer_sebastian\", n = 3) %>% \n  select(full_text)\n\n\n\nRT @pia_lamberty: Ein Ansatz, der sich beim Debunking wissenschaftlich als erfolgreich herausgestellt hat, ist das sog. Faktensandwich: htt…\nRT @ianbremmer: sure, it’s the hottest summer europe has ever had in history \n\nbut look at the upside\n\nit’s one of the coolest summers euro…\nRT @twisteddoodles: Balanced news reporting https://t.co/O1iiItEQrs\n\n\n\ntweets <- get_timeline(user = d$screenname)\nsaveRDS(tweets, file = \"tweets/tweets01.rds\")\n\nMichael Kearney rät uns:\n\nPRO TIP #4: (for developer accounts only) Use bearer_token() to increase rate limit to 45,000 per fifteen minutes.\n\n\n\n2.3.2 Retweets einlesen\n\noptions(rtweet.retryonratelimit = TRUE)\n\n\ntweets01_retweets <- \n  tweets$id_str %>% \n  head(3) %>% \n  map_dfr( ~ get_retweets(status_id = .x, retryonratelimit = TRUE))\n\nDa die meisten Retweets aber nix sagen, sondern nur auf das einen Tweet wiederholen, ist das Sammeln der Retweets ziemlich langweilig.\n\n\n2.3.3 EPINetz Twitter Politicians 2021\nKönig u. a. (2022) Volltext hier haben einen Datensatz mit knapp 2500 Twitter Accounts deutscher Politiker zusammengestellt, zum Stand 2021.\nDer Datensatz kann über Gesis bezogen werden.\nAuf der gleichen Seite findet sich auch eine Dokumentation des Vorgehens.\nNachdem wir den Datensatz heruntergeladen haben, können wir ihn einlesen:\n\npoliticians_path <- \"data/EPINetz_TwitterPoliticians_2021.RDs\"\npoliticians_twitter <- read_rds(politicians_path)\n\nhead(politicians_twitter)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nID\nofficial_name\nparty\nregion\ninstitution\noffice\nuser_id\ntwitter_name\ntwitter_handle\nfrom\nuntil\nyear_of_birth\nabgeordnetenwatch_id\ngender\nwikidata_id\n\n\n\n\n535\nManja Schüle\nSPD\nBrandenburg\nState Parliament\nParliamentarian\n827090742162100224\nManja Schüle\nManjaSchuele\n2019-09-25\nNA\n1976\n146790\nfemale\nQ40974942\n\n\n962\nPetra Pau\nDIE LINKE\nFederal\nFederal Parliament\nParliamentarian\n1683845126\nTeam PetraPau\nTeamPetraPau\n2017-10-24\nNA\n1963\n79091\nfemale\nQ77195\n\n\n864\nDagmar Schmidt\nSPD\nFederal\nFederal Parliament\nParliamentarian\n1377117206\nTeam #dieschmidt\nTeamDieSchmidt\n2017-10-24\nNA\n1973\n79036\nfemale\nQ15433815\n\n\n2517\nBernd Buchholz\nFDP\nSchleswig-Holstein\nState Parliament\nParliamentarian\n1073605033\nBernd Buchholz\nBerndBuchholz\n2017-06-06\nNA\n1961\n121092\nmale\nQ823715\n\n\n1378\nIngrid Remmers\nDIE LINKE\nFederal\nFederal Parliament\nParliamentarian\n551802475\nIngrid Remmers MdB\ningrid_remmers\n2017-10-24\nNA\n1965\n120775\nfemale\nQ1652660\n\n\n1116\nReinhard Brandl\nCSU\nFederal\nFederal Parliament\nParliamentarian\n262730721\nReinhard Brandl\nreinhardbrandl\n2017-10-24\nNA\n1977\n79427\nmale\nQ111160\n\n\n\n\n\n\nDann lesen wir die Timelines (die Tweets) dieser Konten aus; in diesem Beispiel nur 10 Tweets pro Account:\n\nepi_tweets <- get_timeline(user = head(politicians_twitter$twitter_name), n = 10)\nhead(epi_tweets)\n\nNatürlich könnte man auch mehr als 10 Tweets pro Konto einsammeln, braucht nur seine Zeit.\n\n\n2.3.4 Followers suchen\n\nfollowers01 <-\n  d$screenname %>% \n map_dfr( ~ get_followers(user = .x, retryonratelimit = TRUE))\n\nsaveRDS(followers01, file = \"tweets/followers01.rds\")\n\nDamit haben wir eine Liste an Followers, deren Tweets wir einlesen und analysieren können, z.B. nach Hate Speech.\nIm Gegensatz zu Followers heißen bei Twitter die Accounts, denen ei Nutzi folgt “Friends”.\n\n\n2.3.5 Follower Tweets einlesen\n\nfollowers_tweets <- get_timeline(user = head(followers01$from_id), n = 10)"
  },
  {
    "objectID": "twittermining.html#cron-jobs",
    "href": "twittermining.html#cron-jobs",
    "title": "2  Twitter Mining",
    "section": "2.4 Cron Jobs",
    "text": "2.4 Cron Jobs\n\n2.4.1 Was ist ein Cron Job?\nCron ist ein Programm auf Unix-artigen Betriebssystemen, das Skripte zu eingestellten Zeiten (wiederholt) ausführt, das sind dann “Cron Jobs”. Auf Windows gibt es aber analoge Funktionen. Cron Jobs sind praktisch, da man nicht jedes Mal selber z.B. Tweets, die heute zu einem Thema getweetet wurden, herunterladen muss. Das wird dann vom Cron Job übernommen.\nIn R gibt es eine API zum Programm Cron mit dem Paket {cronR}, s. Anleitung hier.\nDas analoge R-Paket für Windows heißt {taskscheduleR}.\n\n\n2.4.2 Beispiel für einen Cron Job\n\nlibrary(cronR)\n\nscrape_script <- cron_rscript(\"scrape_tweets.R\")\n\n# Cron Job hinzufügen:\ncron_add(command = scrape_script, \n         frequency = 'daily', \n         at = \"10AM\",\n         id = 'Hate Speech')  # Name des Cron Jobs\n\ncron_clear(ask = FALSE)  # Alle Cron Jobs löschen\ncron_ls()  # Liste aller Cron Jobs\n\nIm obigen Beispiel wird das R-Skript scrape_tweets.R täglich um 10h ausgeführt.\nDer Inhalt von scrape_tweets.R könnte dann, in Grundzügen, so aussehen:\n\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(rtweet)\nfollowers_lauterbach <-\n  followers01 %>% \n  filter(to_id == \"Karl_Lauterbach\")\n\nfollowers_lauterbach_tweets <- \n  get_timeline(user = followers_lauterbach$from_id[1:10], n = 10, retryonratelimit = TRUE, verbose = FALSE)\n\n\npath_output <- \"/Users/sebastiansaueruser/Google Drive/RRRing/Scrape-Tweets/tweets/\"\n\nwrite_csv(x = followers_lauterbach_tweets,\n          file = paste0(path_output, \"followers_lauterbach_tweets.csv\"),\n          append = TRUE)\n\nWir schreiben nicht jedes Mal (jeden Tag) eine neue CSV-Datei, sondern wir hängen hier die neu ausgelesenen Daten an die Datei an.\nLeider ist es mit rtweet nicht möglich, ein Datum anzugeben, ab dem man Tweets auslesen möchte2"
  },
  {
    "objectID": "twittermining.html#workshop-zu-rtweet",
    "href": "twittermining.html#workshop-zu-rtweet",
    "title": "2  Twitter Mining",
    "section": "2.5 Workshop zu rtweet",
    "text": "2.5 Workshop zu rtweet\nErarbeiten Sie die Folien zu diesem rtweet-Workshop. Eine Menge guter Tipps!"
  },
  {
    "objectID": "twittermining.html#aufgaben",
    "href": "twittermining.html#aufgaben",
    "title": "2  Twitter Mining",
    "section": "2.6 Aufgaben",
    "text": "2.6 Aufgaben\n\nÜberlegen Sie, wie Sie das Ausmaß an Hate Speech, dem deutsche Politikerinnen und Politiker konfrontiert sind, messen können.\nArgumentieren Sie die Vorteile und Nachteile Ihres Ansatzes. Außerdem, auf welches Ergebnis dieser Analyse sie gespannt sind bzw. wären.\nÜberlegen Sie Korrelate, oder besser noch: (mögliche) Ursachen, des Hasses in den Tweets, gerichtet auf Polikter:innen. Sie können auch Gruppen von Ursachen bilden, etwas personengebundene Variablen der Politiker:innen (z.B. Alter? Geschlecht? Migrationshintergrund?).\nErstellen Sie sich eine Liste an Personen, deren Tweets sich lohnen (könnten), auf Hate Speech hin analysiert zu werden. Laden Sie deren Tweets (ggf. in Auszügen) herunter.\nDas Skript zu scrape_tweets.R könnte man noch verbessern, in dem man jeden Tag nur die neuesten Tweets herunterlädt. Dazu kann man bei get_timeline() mit dem Argument since_id eine Untergrenze der ID festlegen, so dass nur neuere Tweets (d.h. mit größerem Wert bei ID) ausgelesen werden. Ändern Sie das Skript entsprechend, so dass nur neuerer Tweets gelesen werden.\n\n\n\n\n\nHvitfeldt, Emil, und Julia Silge. 2022. Supervised Machine Learning for Text Analysis in R. 1. Aufl. Boca Raton: Chapman; Hall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nKönig, Tim, Wolf J. Schünemann, Alexander Brand, Julian Freyberg, und Michael Gertz. 2022. „The EPINetz Twitter Politicians Dataset 2021. A New Resource for the Study of the German Twittersphere and Its Application for the 2021 Federal Elections“. Politische Vierteljahresschrift 63 (3): 529–47. https://doi.org/10.1007/s11615-022-00405-7."
  },
  {
    "objectID": "textmining1.html",
    "href": "textmining1.html",
    "title": "3  Grundlagen des Textmining",
    "section": "",
    "text": "Bild von mcmurryjulie auf Pixabay"
  },
  {
    "objectID": "textmining1.html#vorab",
    "href": "textmining1.html#vorab",
    "title": "3  Grundlagen des Textmining",
    "section": "3.1 Vorab",
    "text": "3.1 Vorab\n\n3.1.1 Lernziele\n\nDie vorgestellten Techniken des Textminings mit R anwenden können\n\n\n\n3.1.2 Vorbereitung\n\nLesen Sie in Hvitfeldt und Silge (2022) Kap. 2.\n\n\n\n3.1.3 Benötigte R-Pakete\n\nlibrary(tidyverse)\nlibrary(tokenizers)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(hcandersenr)\nlibrary(SnowballC)"
  },
  {
    "objectID": "textmining1.html#einfache-methoden-des-textminings",
    "href": "textmining1.html#einfache-methoden-des-textminings",
    "title": "3  Grundlagen des Textmining",
    "section": "3.2 Einfache Methoden des Textminings",
    "text": "3.2 Einfache Methoden des Textminings\nArbeiten Sie die folgenden grundlegenden Methoden des Textminigs durch.\n\n3.2.1 Tokenisierung\nErarbeiten Sie dieses Kapitel: Hvitfeldt und Silge (2022), Kap. 2\nWie viele Zeilen hat das Märchen “The Fir tree” (in der englischen Fassung?)\n\nhcandersen_en %>% \n  filter(book == \"The fir tree\") %>% \n  nrow()\n\n[1] 253\n\n\n\n\n3.2.2 Stopwörter entfernen\nErarbeiten Sie dieses Kapitel: s. Hvitfeldt und Silge (2022), Kap. 3\n\n\n3.2.3 Stemming (Wortstamm finden)\nErarbeiten Sie dieses Kapitel: Hvitfeldt und Silge (2022), Kap. 4\nVertiefende Hinweise zum UpSet plot finden Sie hier, Lex u. a. (2014).\nFür welche Sprachen gibt es Stemming im Paket SnowballC?\n\nlibrary(SnowballC)\ngetStemLanguages()\n\n [1] \"arabic\"     \"basque\"     \"catalan\"    \"danish\"     \"dutch\"     \n [6] \"english\"    \"finnish\"    \"french\"     \"german\"     \"greek\"     \n[11] \"hindi\"      \"hungarian\"  \"indonesian\" \"irish\"      \"italian\"   \n[16] \"lithuanian\" \"nepali\"     \"norwegian\"  \"porter\"     \"portuguese\"\n[21] \"romanian\"   \"russian\"    \"spanish\"    \"swedish\"    \"tamil\"     \n[26] \"turkish\"   \n\n\nEinfacher Test: Suchen wir den Wordstamm für das Wort “wissensdurstigen”, wie in “die wissensdurstigen Studentis löcherten dis armis Professi”1.\n\nwordStem(\"wissensdurstigen\", language = \"german\")\n\n[1] \"wissensdurst\"\n\n\nWerfen Sie mal einen Blick in das Handbuch von SnowballC.\n\n\n3.2.4 Stringverarbeitung\nErarbeiten Sie dieses Kapitel: Wickham und Grolemund (2018), Kap. 14"
  },
  {
    "objectID": "textmining1.html#fallstudie",
    "href": "textmining1.html#fallstudie",
    "title": "3  Grundlagen des Textmining",
    "section": "3.3 Fallstudie",
    "text": "3.3 Fallstudie\n\n3.3.1 Daten\nEs finden sich mehrere Datensätze zum Thema Hate-Speech im öffentlichen Internet, eine Quelle ist Hate Speech Data, ein Repositorium, das mehrere Datensätze beinhaltet.\n\nKaggle Hate Speech and Offensive Language Dataset\nBretschneider and Peters Prejudice on Facebook Dataset\nDaten zum Fachartikel”Large Scale Crowdsourcing and Characterization of Twitter Abusive Behavior”\n\nTwitterdaten dürfen nur in “dehydrierter” Form weitergegeben werden, so dass kein Rückschluss von ID zum Inhalt des Tweets möglich ist. Daher werden öffentlich nur die IDs der Tweets, als einzige Information zum Tweet, also ohne den eigentlichen Inhalt des Tweets, bereitgestellt.\nÜber die Twitter-API kann man sich, wie oben dargestellt, dann die Tweets wieder “rehydrieren”, also wieder mit dem zugehörigen Tweet-Text (und sonstigen Infos des Tweets) zu versehen.\n\n\n3.3.2 Grundlegendes Text Mining\nWenden Sie die oben aufgeführten Techniken des grundlegenden Textminings auf einen der oben dargestellten Hate-Speech-Datensätze an. Erstellen Sie ein (HTML-Dokument) mit Ihren Ergebnissen. Stellen Sie die Ergebnisse auf dem Github-Repo dieses Kurses ein. Vergleichen Sie Ihre Lösung mit den Lösungen der anderen Kursmitglieder.\nWir nutzen noch nicht eigene Daten, die wir von Twitter ausgelesen haben, das heben wir uns für später auf.\n\n\n\n\nHvitfeldt, Emil, und Julia Silge. 2022. Supervised Machine Learning for Text Analysis in R. 1. Aufl. Boca Raton: Chapman; Hall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nLex, Alexander, Nils Gehlenborg, Hendrik Strobelt, Romain Vuillemot, und Hanspeter Pfister. 2014. „UpSet: Visualization of Intersecting Sets“. IEEE Transactions on Visualization and Computer Graphics 20 (12): 1983–92. https://doi.org/10.1109/TVCG.2014.2346248.\n\n\nWickham, Hadley, und Garrett Grolemund. 2018. R für Data Science: Daten importieren, bereinigen, umformen, modellieren und visualisieren. Übersetzt von Frank Langenau. 1. Auflage. Heidelberg: O’Reilly. https://r4ds.had.co.nz/index.html."
  },
  {
    "objectID": "populismus.html",
    "href": "populismus.html",
    "title": "4  Fallstudie Populismus",
    "section": "",
    "text": "Bild von mcmurryjulie auf Pixabay"
  },
  {
    "objectID": "populismus.html#wie-populistisch-tweeten-unsere-politikerinnen",
    "href": "populismus.html#wie-populistisch-tweeten-unsere-politikerinnen",
    "title": "4  Fallstudie Populismus",
    "section": "4.1 Wie populistisch tweeten unsere Politiker:innen?",
    "text": "4.1 Wie populistisch tweeten unsere Politiker:innen?\nVerschaffen Sie sich einen Überblick über dieses Projekt! Im Rahmen dieses Projekts vergleicht der Autor den Populismus von deutschen Politiker:innen, so wie er sich in den Tweets dieser Personen niederschlägt. Auf dieser Basis wird ein Populismuswert, bestehend aus mehreren Teilwerten, berechnet und auf Parteiebenen (als Mittel der zugehörigen Politiker:innen) berechnet. Natürlich fragt man sich, wie Populismus definiert ist und wie diese Definition in den Berechnungen umgesetzt wurde. Finden Sie es selber heraus: Im Github-Repo sind alle Details dokumentiert.\nZum Einstieg hilft ein Überblick über die Ergebnisse der Analyse, die in diesem Vortrag zusammengefasst sind.\nDieser Post stellt die Ergebnisse mit etwas Kontext dar."
  },
  {
    "objectID": "word-embedding.html",
    "href": "word-embedding.html",
    "title": "5  Word Embedding",
    "section": "",
    "text": "Arbeiten Sie Hvitfeldt und Silge (2022), Kap. 5 durch.\n\n\n\n\nHvitfeldt, Emil, und Julia Silge. 2022. Supervised Machine Learning for Text Analysis in R. 1. Aufl. Boca Raton: Chapman; Hall/CRC. https://doi.org/10.1201/9781003093459."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Hvitfeldt, Emil, and Julia Silge. 2022. Supervised Machine Learning\nfor Text Analysis in r. 1st ed. Boca Raton: Chapman;\nHall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nKönig, Tim, Wolf J. Schünemann, Alexander Brand, Julian Freyberg, and\nMichael Gertz. 2022. “The EPINetz Twitter Politicians\nDataset 2021. A New Resource for the Study of the German Twittersphere\nand Its Application for the 2021 Federal Elections.”\nPolitische Vierteljahresschrift 63 (3): 529–47. https://doi.org/10.1007/s11615-022-00405-7.\n\n\nLex, Alexander, Nils Gehlenborg, Hendrik Strobelt, Romain Vuillemot, and\nHanspeter Pfister. 2014. “UpSet: Visualization of\nIntersecting Sets.” IEEE Transactions on\nVisualization and Computer Graphics 20 (12): 1983–92. https://doi.org/10.1109/TVCG.2014.2346248.\n\n\nWickham, Hadley, and Garrett Grolemund. 2018. R Für Data Science:\nDaten Importieren, Bereinigen, Umformen, Modellieren Und\nVisualisieren. Translated by Frank Langenau. 1. Auflage.\nHeidelberg: O’Reilly. https://r4ds.had.co.nz/index.html."
  }
]