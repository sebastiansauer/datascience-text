[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science 2: Textdaten als Grundlage pr√§diktiver Modelle",
    "section": "",
    "text": "falls Sie die Pakete schon installiert haben, k√∂nnten Sie mal in RStudio auf ‚Äúupdate.packages‚Äù klicken‚Ü©Ô∏é"
  },
  {
    "objectID": "klassifikation.html",
    "href": "klassifikation.html",
    "title": "1¬† Klassifikation von Hatespeech",
    "section": "",
    "text": "Sie k√∂nnen grundlegende Verfahren zur Klassifikation von Hatespeech einsetzen und erkl√§ren\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(rio)\nlibrary(tidymodels)\nlibrary(tidytext)\nlibrary(textrecipes)\nlibrary(lsa)  # stopwords\nlibrary(discrim)  # naive bayes classification\nlibrary(naivebayes)\nlibrary(tictoc)  # Zeitmessung\nlibrary(fastrtext)  # Worteinbettungen\nlibrary(remoji)  # Emojis\nlibrary(tokenizers)  # Vektoren tokenisieren"
  },
  {
    "objectID": "klassifikation.html#daten",
    "href": "klassifikation.html#daten",
    "title": "1¬† Klassifikation von Hatespeech",
    "section": "1.2 Daten",
    "text": "1.2 Daten\nF√ºr Maschinenlernen brauchen wir Trainingsdaten, Daten also, bei denen wir pro Beobachtung der Wert der Zielvariablen kennen. Man spricht auch von ‚Äúgelabelten‚Äù Daten.\nWir nutzen die Daten von Wiegand (2019a) bzw. Wiegand (2019b). Die Daten sind unter CC-By-4.0 Int. lizensiert.\n\nd_raw <- \n  import(\"data/germeval2018.training.txt\",\n         header = FALSE)\n\nWarning in (function (input = \"\", file = NULL, text = NULL, cmd = NULL, : Found\nand resolved improper quoting out-of-sample. First healed line 111: <<\"Edel sei\nder Mensch, hilfreich und gut\" - Nicht eine dieser Charaktereigenschaften kann\nMerkel f√ºr sich beanspruchen. OTHER OTHER>>. If the fields are not quoted (e.g.\nfield separator does not appear within any field), try quote=\"\" to avoid this\nwarning.\n\n\nDa die Daten keine Spaltenk√∂pfe haben, informieren wir die Funktion dazu mit header = FALSE.\nBenennen wir die die Spalten um:\n\nnames(d_raw) <- c(\"text\", \"c1\", \"c2\")\n\nDabei soll c1 und c2 f√ºr die 1. bzw. 2. Klassifikation stehen.\nIn c1 finden sich diese Werte:\n\nd_raw %>% \n  count(c1)\n\n\n\n\n\nc1\nn\n\n\n\n\nOFFENSE\n1688\n\n\nOTHER\n3321\n\n\n\n\n\n\nHier wurde klassifiziert, ob beleidigende Sprache (offensive language) vorlag oder nicht (isch-etal-2021-overview?):\n\nTask 1 was to decide whether a tweet includes some form of offensive language or not. The tweets had to be classiÔ¨Åed into the two classes OFFENSE and OTHER. The OFFENSE category covered abusive language, insults, as well as merely profane statements.\n\nUnd in c2 finden sich folgende Auspr√§gungen:\n\nd_raw %>% \n  count(c2)\n\n\n\n\n\nc2\nn\n\n\n\n\nABUSE\n1022\n\n\nINSULT\n595\n\n\nOTHER\n3321\n\n\nPROFANITY\n71\n\n\n\n\n\n\nIn c2 ging es um eine feinere Klassifikation beleidigender Sprache (isch-etal-2021-overview?):\n\nThe second task involved four categories, a nonoffensive OTHER class and three sub-categories of what is OFFENSE in Task 1. In the case of PROFANITY, profane words are used, however, the tweet does not want to insult anyone. This typically concerns the usage of swearwords (Schei√üe, Fuck etc.) and cursing (Zur H√∂lle! Verdammt! etc.). This can be often found in youth language. Swearwords and cursing may, but need not, co-occur with insults or abusive speech. Profane language may in fact be used in tweets with positive sentiment to express emphasis. Whenever profane words are not directed towards a speciÔ¨Åc person or group of persons and there are no separate cues of INSULT or ABUSE, then tweets are labeled as simple cases of PROFANITY.\n\nSind Texte, die als OFFENSE klassifiziert sind, auch (fast) immer als ABUSE, INSULT oder PROFANITY klassifiziert?\n\nd_raw %>% \n  filter(c1 == \"OTHER\", c2 == \"OTHER\") %>% \n  nrow() / nrow(d_raw)\n\n[1] 0.6630066\n\n\nIn ca. 2/3 der F√§lle wurden in beiden Klassifikation OTHER klassifiziert.\n\nd_raw %>% \n  filter(c1 != \"OTHER\", c2 != \"OTHER\") %>% \n  nrow() / nrow(d_raw)\n\n[1] 0.3369934\n\n\nEntsprechend in ca. 1/3 der F√§lle wurde jeweils nicht mit OTHER klassifiziert.\nWir begn√ºgen uns hier mit der ersten, gr√∂beren Klassifikation."
  },
  {
    "objectID": "klassifikation.html#feature-engineering",
    "href": "klassifikation.html#feature-engineering",
    "title": "1¬† Klassifikation von Hatespeech",
    "section": "1.3 Feature Engineering",
    "text": "1.3 Feature Engineering\nReichern wir die Daten mit weiteren Features an, in der Hoffnung, damit eine bessere Klassifikation erzielen zu k√∂nnen.\n\n1.3.1 Textl√§nge\n\nd2 <-\n  d_raw %>% \n  mutate(text_length = str_length(text)) %>% \n  mutate(id = 1:nrow(.))\n\nhead(d2)\n\n\n\n\n\n\n\n\n\n\n\n\ntext\nc1\nc2\ntext_length\nid\n\n\n\n\n(corinnamilborn?) Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\nOTHER\nOTHER\n109\n1\n\n\n(Martin28a?) Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\nOTHER\nOTHER\n142\n2\n\n\n(ahrens_theo?) fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\nOTHER\nOTHER\n69\n3\n\n\n(dushanwegner?) Amis h√§tten alles und jeden gew√§hlt‚Ä¶nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\nOTHER\nOTHER\n140\n4\n\n\n(spdde?) kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\nOFFENSE\nINSULT\n136\n5\n\n\n(Dirki_M?) Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\nOTHER\nOTHER\n284\n6\n\n\n\n\n\n\n\n\n1.3.2 Sentimentanalyse\nWir nutzen dazu SentiWS (Remus, Quasthoff, und Heyer 2010).\n\nsentiws <- read_csv(\"https://osf.io/x89wq/?action=download\")\n\nRows: 3468 Columns: 4\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (3): neg_pos, word, inflections\ndbl (1): value\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nd2_long <-\n  d2 %>% \n  unnest_tokens(input = text, output = token)\n\nhead(d2_long)\n\n\n\n\n\nc1\nc2\ntext_length\nid\ntoken\n\n\n\n\nOTHER\nOTHER\n109\n1\ncorinnamilborn\n\n\nOTHER\nOTHER\n109\n1\nliebe\n\n\nOTHER\nOTHER\n109\n1\ncorinna\n\n\nOTHER\nOTHER\n109\n1\nwir\n\n\nOTHER\nOTHER\n109\n1\nw√ºrden\n\n\nOTHER\nOTHER\n109\n1\ndich\n\n\n\n\n\n\nJetzt filtern wir unsere Textdaten so, dass nur W√∂rter mit Sentimentwert √ºbrig bleiben:\n\nd2_long_senti <- \n  d2_long %>%  \n  inner_join(sentiws %>% select(-inflections), by = c(\"token\" = \"word\"))\n\nhead(d2_long)\n\n\n\n\n\nc1\nc2\ntext_length\nid\ntoken\n\n\n\n\nOTHER\nOTHER\n109\n1\ncorinnamilborn\n\n\nOTHER\nOTHER\n109\n1\nliebe\n\n\nOTHER\nOTHER\n109\n1\ncorinna\n\n\nOTHER\nOTHER\n109\n1\nwir\n\n\nOTHER\nOTHER\n109\n1\nw√ºrden\n\n\nOTHER\nOTHER\n109\n1\ndich\n\n\n\n\n\n\nSchlie√ülich berechnen wir die Sentimentwert pro Polarit√§t und pro Tweet:\n\nd2_sentis <-\n  d2_long_senti %>% \n  group_by(id, neg_pos) %>% \n  summarise(senti_avg = mean(value))\n\n`summarise()` has grouped output by 'id'. You can override using the `.groups`\nargument.\n\nhead(d2_sentis)\n\n\n\n\n\nid\nneg_pos\nsenti_avg\n\n\n\n\n1\npos\n0.0040\n\n\n2\nneg\n-0.3466\n\n\n6\nneg\n-0.2042\n\n\n6\npos\n0.0040\n\n\n8\nneg\n-0.5023\n\n\n9\npos\n0.5161\n\n\n\n\n\n\nDiese Tabelle bringen wir wieder eine breitere Form, um sie dann wieder mit den Hauptdaten zu vereinigen.\n\nd2_sentis_wide <-\n  d2_sentis %>% \n  pivot_wider(names_from = \"neg_pos\", values_from = \"senti_avg\")\n\nd2_sentis_wide %>% head()\n\n\n\n\n\nid\npos\nneg\n\n\n\n\n1\n0.0040\nNA\n\n\n2\nNA\n-0.3466\n\n\n6\n0.0040\n-0.2042\n\n\n8\nNA\n-0.5023\n\n\n9\n0.5161\nNA\n\n\n11\n0.0040\nNA\n\n\n\n\n\n\n\nd3 <-\n  d2 %>% \n  full_join(d2_sentis_wide)\n\nJoining, by = \"id\"\n\nhead(d3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntext\nc1\nc2\ntext_length\nid\npos\nneg\n\n\n\n\n(corinnamilborn?) Liebe Corinna, wir w√ºrden dich gerne als Moderatorin f√ºr uns gewinnen! W√§rst du begeisterbar?\nOTHER\nOTHER\n109\n1\n0.004\nNA\n\n\n(Martin28a?) Sie haben ja auch Recht. Unser Tweet war etwas missverst√§ndlich. Dass das BVerfG Sachleistungen nicht ausschlie√üt, kritisieren wir.\nOTHER\nOTHER\n142\n2\nNA\n-0.3466\n\n\n(ahrens_theo?) fr√∂hlicher gru√ü aus der sch√∂nsten stadt der welt theo ‚öìÔ∏è\nOTHER\nOTHER\n69\n3\nNA\nNA\n\n\n(dushanwegner?) Amis h√§tten alles und jeden gew√§hlt‚Ä¶nur Hillary wollten sie nicht und eine Fortsetzung von Obama-Politik erst recht nicht..!\nOTHER\nOTHER\n140\n4\nNA\nNA\n\n\n(spdde?) kein verl√§√ülicher Verhandlungspartner. Nachkarteln nach den Sondierzngsgespr√§chen - schickt diese St√ºmper #SPD in die Versenkung.\nOFFENSE\nINSULT\n136\n5\nNA\nNA\n\n\n(Dirki_M?) Ja, aber wo widersprechen die Zahlen denn denen, die im von uns verlinkten Artikel stehen? In unserem Tweet geht es rein um subs. Gesch√ºtzte. 2017 ist der gesamte Familiennachzug im Vergleich zu 2016 - die Zahlen, die Hr. Brandner bem√ºht - √ºbrigens leicht r√ºckl√§ufig gewesen.\nOTHER\nOTHER\n284\n6\n0.004\n-0.2042\n\n\n\n\n\n\n\n\n\n\n\n\nHinweis\n\n\n\nDie Sentimentanalyse hier vernachl√§ssigt Flexionen der W√∂rter. Der Autor f√ºhlt den Drang zu schreiben: ‚ÄúLeft as an exercise for the reader‚Äù :-)\n\n\n\n\n1.3.3 Schimpfw√∂rter\nZ√§hlen wir die Schimpfw√∂rter pro Text. Dazu nutzen wir die Daten von LDNOOBW, lizensiert nach CC-BY-4.0-Int.\n\nschimpf1 <- import(\"https://raw.githubusercontent.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words/master/de\", format = \",\", header = FALSE)\n\nL√§nger aber noch ist die Liste aus dem InsultWiki, lizensiert CC0.\n\nschimpf2 <- \n  import(\"data/insult-de.txt\", header = FALSE) %>% \n  mutate_all(str_to_lower)\n\nBinden wir die Listen zusammen:\n\nschimpf <-\n  schimpf1 %>% \n  bind_rows(schimpf2) %>% \n  distinct() %>% \n  rename(word = \"V1\")\n\nnrow(schimpf)\n\n[1] 6208\n\n\nUm die Lesis vor (unn√∂tiger?) Kopfverschmutzung zu bewahren, sind diese Schimpfw√∂rter hier nicht abgedruckt.\nJetzt z√§hlen wir, ob unsere Tweets/Texte solcherlei W√∂rter enthalten.\n\nd_schimpf <- \nd2_long %>% \n  select(id, token) %>% \n  mutate(schimpf = token %in% schimpf$word)\n  \nd_schimpf %>% \n  filter(schimpf)\n\n\n\n\n\nid\ntoken\nschimpf\n\n\n\n\n5\nst√ºmper\nTRUE\n\n\n7\narsch\nTRUE\n\n\n15\nschamlos\nTRUE\n\n\n31\nschw√§tzer\nTRUE\n\n\n45\nhelfershelfer\nTRUE\n\n\n58\nheuchler\nTRUE\n\n\n60\nwaschlappen\nTRUE\n\n\n65\nb√ºrger\nTRUE\n\n\n65\nmistst√ºck\nTRUE\n\n\n69\nhause\nTRUE\n\n\n73\nhaut\nTRUE\n\n\n77\nnichts\nTRUE\n\n\n78\nnichts\nTRUE\n\n\n81\npack\nTRUE\n\n\n82\nschnecke\nTRUE\n\n\n92\nnichts\nTRUE\n\n\n95\nkleber\nTRUE\n\n\n104\npilz\nTRUE\n\n\n113\nhaut\nTRUE\n\n\n114\nweihnachtsmann\nTRUE\n\n\n117\ntyp\nTRUE\n\n\n118\ngesicht\nTRUE\n\n\n118\nfratze\nTRUE\n\n\n119\nnichts\nTRUE\n\n\n126\ndreck\nTRUE\n\n\n135\nhaut\nTRUE\n\n\n135\nkacke\nTRUE\n\n\n135\nbravo\nTRUE\n\n\n140\nnichts\nTRUE\n\n\n140\nlangsam\nTRUE\n\n\n143\nfreier\nTRUE\n\n\n152\npack\nTRUE\n\n\n155\ntroll\nTRUE\n\n\n156\nhause\nTRUE\n\n\n170\nhause\nTRUE\n\n\n174\nkammerj√§ger\nTRUE\n\n\n178\nnichts\nTRUE\n\n\n192\nnichts\nTRUE\n\n\n196\npest\nTRUE\n\n\n197\nnichts\nTRUE\n\n\n199\nbild\nTRUE\n\n\n203\nlauch\nTRUE\n\n\n203\nscheisser\nTRUE\n\n\n203\ntroll\nTRUE\n\n\n212\ntrolle\nTRUE\n\n\n213\narsch\nTRUE\n\n\n213\nhitler\nTRUE\n\n\n221\nding\nTRUE\n\n\n221\ngeist\nTRUE\n\n\n222\nhund\nTRUE\n\n\n227\nschauspieler\nTRUE\n\n\n229\nb√ºrger\nTRUE\n\n\n231\nopfer\nTRUE\n\n\n246\nhitler\nTRUE\n\n\n246\nantichrist\nTRUE\n\n\n247\nidiot\nTRUE\n\n\n260\nnichts\nTRUE\n\n\n262\nschmock\nTRUE\n\n\n263\npack\nTRUE\n\n\n266\nopfer\nTRUE\n\n\n277\nsozialschmarotzer\nTRUE\n\n\n279\ndreck\nTRUE\n\n\n280\nluder\nTRUE\n\n\n283\nmarionette\nTRUE\n\n\n295\ngesicht\nTRUE\n\n\n298\nbild\nTRUE\n\n\n305\nopfer\nTRUE\n\n\n308\nart\nTRUE\n\n\n312\ntor\nTRUE\n\n\n315\nzwitter\nTRUE\n\n\n316\nseele\nTRUE\n\n\n323\nbild\nTRUE\n\n\n325\npack\nTRUE\n\n\n338\nnichts\nTRUE\n\n\n339\nart\nTRUE\n\n\n348\nhecke\nTRUE\n\n\n348\npissen\nTRUE\n\n\n358\ndreck\nTRUE\n\n\n360\nnichts\nTRUE\n\n\n368\nbild\nTRUE\n\n\n369\ntyp\nTRUE\n\n\n369\ntyp\nTRUE\n\n\n372\nhund\nTRUE\n\n\n373\nschlepper\nTRUE\n\n\n393\nwicht\nTRUE\n\n\n397\nnichts\nTRUE\n\n\n399\nhause\nTRUE\n\n\n400\nabschaum\nTRUE\n\n\n403\nniemand\nTRUE\n\n\n406\nopfer\nTRUE\n\n\n408\nniemand\nTRUE\n\n\n412\nnichts\nTRUE\n\n\n427\nnichts\nTRUE\n\n\n427\nschmarotzer\nTRUE\n\n\n428\nst√ºck\nTRUE\n\n\n435\ndackel\nTRUE\n\n\n442\nwitzfigur\nTRUE\n\n\n444\nspinner\nTRUE\n\n\n452\nhexe\nTRUE\n\n\n453\nhitler\nTRUE\n\n\n456\nnichts\nTRUE\n\n\n457\npack\nTRUE\n\n\n457\nteufel\nTRUE\n\n\n459\nnichts\nTRUE\n\n\n461\nporno\nTRUE\n\n\n467\nfresse\nTRUE\n\n\n467\nkacke\nTRUE\n\n\n468\nmaul\nTRUE\n\n\n469\nlangsam\nTRUE\n\n\n474\nniemand\nTRUE\n\n\n481\nratte\nTRUE\n\n\n484\ndumpfbacke\nTRUE\n\n\n488\nhund\nTRUE\n\n\n488\ngurgel\nTRUE\n\n\n495\nvolksverr√§ter\nTRUE\n\n\n513\nhaufen\nTRUE\n\n\n518\nst√ºck\nTRUE\n\n\n518\nnichts\nTRUE\n\n\n533\nschw√§tzer\nTRUE\n\n\n538\npack\nTRUE\n\n\n538\nschlampe\nTRUE\n\n\n547\nabschaum\nTRUE\n\n\n547\nschei√üe\nTRUE\n\n\n548\nrenner\nTRUE\n\n\n549\nschmierfinke\nTRUE\n\n\n551\ntor\nTRUE\n\n\n555\nkuh\nTRUE\n\n\n558\nhause\nTRUE\n\n\n561\nb√ºrger\nTRUE\n\n\n565\ndieb\nTRUE\n\n\n565\ndieb\nTRUE\n\n\n574\nbild\nTRUE\n\n\n582\nnichts\nTRUE\n\n\n584\nsesselfurzer\nTRUE\n\n\n598\nnichts\nTRUE\n\n\n600\nb√ºrger\nTRUE\n\n\n608\nschn√∂sel\nTRUE\n\n\n611\nbild\nTRUE\n\n\n617\nhurensohn\nTRUE\n\n\n628\nausrei√üer\nTRUE\n\n\n629\nverbrecher\nTRUE\n\n\n630\nb√ºrger\nTRUE\n\n\n637\nmaul\nTRUE\n\n\n638\nniemand\nTRUE\n\n\n652\nbild\nTRUE\n\n\n653\nb√ºrger\nTRUE\n\n\n664\nfl√ºchtling\nTRUE\n\n\n668\nneandertaler\nTRUE\n\n\n668\nprolle\nTRUE\n\n\n670\nzwitter\nTRUE\n\n\n670\nzwitter\nTRUE\n\n\n671\ngesicht\nTRUE\n\n\n678\nbild\nTRUE\n\n\n681\narsch\nTRUE\n\n\n699\nspinner\nTRUE\n\n\n700\narsch\nTRUE\n\n\n703\nbild\nTRUE\n\n\n706\nl√§cherlich\nTRUE\n\n\n707\ntyp\nTRUE\n\n\n707\nnichts\nTRUE\n\n\n711\nbaby\nTRUE\n\n\n718\nniemand\nTRUE\n\n\n718\nfeind\nTRUE\n\n\n728\nkuh\nTRUE\n\n\n728\nhund\nTRUE\n\n\n749\nm√∂rder\nTRUE\n\n\n749\nvergewaltiger\nTRUE\n\n\n751\nspeichellecker\nTRUE\n\n\n757\nfreier\nTRUE\n\n\n761\nversager\nTRUE\n\n\n761\nnichts\nTRUE\n\n\n764\nvaterlandsverr√§ter\nTRUE\n\n\n767\nniemand\nTRUE\n\n\n771\nlangsam\nTRUE\n\n\n771\nsack\nTRUE\n\n\n772\nbild\nTRUE\n\n\n774\nniemand\nTRUE\n\n\n782\nlangsam\nTRUE\n\n\n785\nzweifler\nTRUE\n\n\n791\nfeigling\nTRUE\n\n\n796\nverlierer\nTRUE\n\n\n809\nniemand\nTRUE\n\n\n811\nschimmel\nTRUE\n\n\n815\nverbrecher\nTRUE\n\n\n817\nfettsack\nTRUE\n\n\n817\npack\nTRUE\n\n\n829\narschloch\nTRUE\n\n\n834\nnichts\nTRUE\n\n\n835\nnichts\nTRUE\n\n\n837\nnull\nTRUE\n\n\n860\nniemand\nTRUE\n\n\n862\nnichts\nTRUE\n\n\n871\nhetzer\nTRUE\n\n\n872\nhartzer\nTRUE\n\n\n888\nl√§cherlich\nTRUE\n\n\n891\nratte\nTRUE\n\n\n893\nniemand\nTRUE\n\n\n900\nfeigling\nTRUE\n\n\n905\narsch\nTRUE\n\n\n908\npirat\nTRUE\n\n\n908\nflasche\nTRUE\n\n\n922\nmaul\nTRUE\n\n\n923\nb√ºrger\nTRUE\n\n\n923\nb√ºrger\nTRUE\n\n\n926\nstorch\nTRUE\n\n\n930\nkn√ºppel\nTRUE\n\n\n932\nnichts\nTRUE\n\n\n942\ndreck\nTRUE\n\n\n943\npack\nTRUE\n\n\n950\nhecht\nTRUE\n\n\n951\npudel\nTRUE\n\n\n959\nsch√ºssel\nTRUE\n\n\n961\nschwein\nTRUE\n\n\n965\nteufel\nTRUE\n\n\n965\nbl√∂dmann\nTRUE\n\n\n965\nidiot\nTRUE\n\n\n967\nnichts\nTRUE\n\n\n968\ntrulla\nTRUE\n\n\n976\nwaschlappen\nTRUE\n\n\n996\nopfer\nTRUE\n\n\n996\nl√ºgner\nTRUE\n\n\n997\ndreck\nTRUE\n\n\n998\narsch\nTRUE\n\n\n1004\nb√ºrger\nTRUE\n\n\n1012\nb√ºrger\nTRUE\n\n\n1024\nnichts\nTRUE\n\n\n1027\nbild\nTRUE\n\n\n1030\ncurrywurst\nTRUE\n\n\n1039\nnichts\nTRUE\n\n\n1042\ntroll\nTRUE\n\n\n1046\nduckm√§user\nTRUE\n\n\n1050\nverr√§ter\nTRUE\n\n\n1055\nziege\nTRUE\n\n\n1065\ngesicht\nTRUE\n\n\n1065\ngesicht\nTRUE\n\n\n1073\nbild\nTRUE\n\n\n1075\ngutmensch\nTRUE\n\n\n1078\nhitler\nTRUE\n\n\n1081\nhaut\nTRUE\n\n\n1081\npfeife\nTRUE\n\n\n1085\npack\nTRUE\n\n\n1092\nb√ºrger\nTRUE\n\n\n1104\nbild\nTRUE\n\n\n1104\nschlampe\nTRUE\n\n\n1115\nspinner\nTRUE\n\n\n1116\ndreck\nTRUE\n\n\n1123\nnichts\nTRUE\n\n\n1133\ngesindel\nTRUE\n\n\n1133\nart\nTRUE\n\n\n1140\npack\nTRUE\n\n\n1140\nhitler\nTRUE\n\n\n1140\nschl√§ger\nTRUE\n\n\n1144\nniemand\nTRUE\n\n\n1148\nmaul\nTRUE\n\n\n1150\nbesenbinder\nTRUE\n\n\n1166\nvollpfosten\nTRUE\n\n\n1170\nidiot\nTRUE\n\n\n1173\nanarchist\nTRUE\n\n\n1193\nb√ºrger\nTRUE\n\n\n1195\nart\nTRUE\n\n\n1200\ngutmensch\nTRUE\n\n\n1203\npest\nTRUE\n\n\n1210\nkotzbrocken\nTRUE\n\n\n1216\ngesicht\nTRUE\n\n\n1227\nst√ºck\nTRUE\n\n\n1230\nfl√ºchtling\nTRUE\n\n\n1235\ndreck\nTRUE\n\n\n1242\nding\nTRUE\n\n\n1255\nfrauenbild\nTRUE\n\n\n1256\ngesindel\nTRUE\n\n\n1262\nwitzbold\nTRUE\n\n\n1266\neitel\nTRUE\n\n\n1266\nart\nTRUE\n\n\n1269\nbild\nTRUE\n\n\n1270\narsch\nTRUE\n\n\n1270\nlecker\nTRUE\n\n\n1272\nnichts\nTRUE\n\n\n1274\nnichts\nTRUE\n\n\n1274\nheuchler\nTRUE\n\n\n1283\nnichts\nTRUE\n\n\n1290\nmist\nTRUE\n\n\n1295\nteufel\nTRUE\n\n\n1297\ntor\nTRUE\n\n\n1316\nknecht\nTRUE\n\n\n1323\nverbrecher\nTRUE\n\n\n1328\npfeife\nTRUE\n\n\n1331\nnichts\nTRUE\n\n\n1332\nbild\nTRUE\n\n\n1344\npr√ºgel\nTRUE\n\n\n1352\nb√∂ser\nTRUE\n\n\n1362\nm√∂rder\nTRUE\n\n\n1377\narsch\nTRUE\n\n\n1379\nfresse\nTRUE\n\n\n1391\nnichts\nTRUE\n\n\n1393\nb√ºrger\nTRUE\n\n\n1394\nfisch\nTRUE\n\n\n1396\nschei√üe\nTRUE\n\n\n1401\nkindersch√§nder\nTRUE\n\n\n1402\ndummerchen\nTRUE\n\n\n1408\nziegenbart\nTRUE\n\n\n1408\ntoller\nTRUE\n\n\n1409\nverbrecher\nTRUE\n\n\n1418\nart\nTRUE\n\n\n1434\ntraumt√§nzer\nTRUE\n\n\n1438\nb√ºrger\nTRUE\n\n\n1441\nnull\nTRUE\n\n\n1447\nasozialer\nTRUE\n\n\n1447\npenner\nTRUE\n\n\n1457\nverr√§ter\nTRUE\n\n\n1460\nlangsam\nTRUE\n\n\n1465\nkasten\nTRUE\n\n\n1472\nnichts\nTRUE\n\n\n1476\neimer\nTRUE\n\n\n1483\nlauch\nTRUE\n\n\n1484\nnichts\nTRUE\n\n\n1487\nhitler\nTRUE\n\n\n1489\nstrick\nTRUE\n\n\n1491\nkacke\nTRUE\n\n\n1493\nstreiter\nTRUE\n\n\n1494\ntonne\nTRUE\n\n\n1495\nopfer\nTRUE\n\n\n1495\nopfer\nTRUE\n\n\n1499\nnichts\nTRUE\n\n\n1504\nschlaumeier\nTRUE\n\n\n1504\nbild\nTRUE\n\n\n1511\nbild\nTRUE\n\n\n1518\nnase\nTRUE\n\n\n1524\ncurrywurst\nTRUE\n\n\n1524\ndreck\nTRUE\n\n\n1527\nmatschbirne\nTRUE\n\n\n1527\nlangsam\nTRUE\n\n\n1528\nungeziefer\nTRUE\n\n\n1534\ngeisterfahrer\nTRUE\n\n\n1537\nfeind\nTRUE\n\n\n1539\nniemand\nTRUE\n\n\n1544\nnichts\nTRUE\n\n\n1550\ntrolle\nTRUE\n\n\n1558\nbild\nTRUE\n\n\n1559\nversager\nTRUE\n\n\n1560\npfeife\nTRUE\n\n\n1570\nauswurf\nTRUE\n\n\n1571\nversager\nTRUE\n\n\n1574\npack\nTRUE\n\n\n1579\nniemand\nTRUE\n\n\n1583\nnerd\nTRUE\n\n\n1588\narsch\nTRUE\n\n\n1590\nsau\nTRUE\n\n\n1593\nnichts\nTRUE\n\n\n1593\nb√∂sewicht\nTRUE\n\n\n1594\nnichts\nTRUE\n\n\n1594\nopfer\nTRUE\n\n\n1600\ngeist\nTRUE\n\n\n1604\nversager\nTRUE\n\n\n1610\nschn√ºffler\nTRUE\n\n\n1615\nratte\nTRUE\n\n\n1618\nfell\nTRUE\n\n\n1627\nstock\nTRUE\n\n\n1627\nfettarsch\nTRUE\n\n\n1630\nziege\nTRUE\n\n\n1638\nkratzer\nTRUE\n\n\n1639\nnull\nTRUE\n\n\n1642\nbild\nTRUE\n\n\n1648\nart\nTRUE\n\n\n1656\nnichts\nTRUE\n\n\n1659\nfrosch\nTRUE\n\n\n1660\nnichts\nTRUE\n\n\n1662\nscheisser\nTRUE\n\n\n1669\nraffzahn\nTRUE\n\n\n1672\nfl√ºchtling\nTRUE\n\n\n1673\nauss√§tziger\nTRUE\n\n\n1678\nschmierfinke\nTRUE\n\n\n1680\nnichts\nTRUE\n\n\n1687\ntrulla\nTRUE\n\n\n1699\ntrampel\nTRUE\n\n\n1710\nschwuchtel\nTRUE\n\n\n1712\nopfer\nTRUE\n\n\n1718\narschloch\nTRUE\n\n\n1733\nm√∂rder\nTRUE\n\n\n1752\nm√∂nch\nTRUE\n\n\n1755\nnichts\nTRUE\n\n\n1757\npfeife\nTRUE\n\n\n1762\nnichts\nTRUE\n\n\n1762\nhungrig\nTRUE\n\n\n1762\nhungrig\nTRUE\n\n\n1767\nspinne\nTRUE\n\n\n1772\nhause\nTRUE\n\n\n1774\nl√§cherlich\nTRUE\n\n\n1783\nwespe\nTRUE\n\n\n1788\nhelfershelfer\nTRUE\n\n\n1813\nbild\nTRUE\n\n\n1813\nbild\nTRUE\n\n\n1820\nschwein\nTRUE\n\n\n1827\ngegner\nTRUE\n\n\n1838\nweib\nTRUE\n\n\n1841\nnichts\nTRUE\n\n\n1856\nschlampe\nTRUE\n\n\n1857\narsch\nTRUE\n\n\n1868\nunkraut\nTRUE\n\n\n1873\nzunge\nTRUE\n\n\n1873\nnase\nTRUE\n\n\n1877\nnichts\nTRUE\n\n\n1882\nscheinheiliger\nTRUE\n\n\n1885\nbaby\nTRUE\n\n\n1886\nbild\nTRUE\n\n\n1886\nbild\nTRUE\n\n\n1893\nbande\nTRUE\n\n\n1894\ntrottel\nTRUE\n\n\n1895\nlachnummer\nTRUE\n\n\n1908\nbazille\nTRUE\n\n\n1914\nmade\nTRUE\n\n\n1919\nb√ºrger\nTRUE\n\n\n1928\nnichts\nTRUE\n\n\n1930\nniemand\nTRUE\n\n\n1931\ntrolle\nTRUE\n\n\n1931\nvollpfosten\nTRUE\n\n\n1934\npapagei\nTRUE\n\n\n1934\nnichts\nTRUE\n\n\n1935\nnichts\nTRUE\n\n\n1940\ngeist\nTRUE\n\n\n1945\nhetzer\nTRUE\n\n\n1948\nhurensohn\nTRUE\n\n\n1958\nnichts\nTRUE\n\n\n1959\nteufel\nTRUE\n\n\n1962\nfresse\nTRUE\n\n\n1972\nb√ºrger\nTRUE\n\n\n1984\ngegner\nTRUE\n\n\n1992\narschloch\nTRUE\n\n\n1999\nwichtigtuer\nTRUE\n\n\n2000\nnichts\nTRUE\n\n\n2005\nnull\nTRUE\n\n\n2006\nschweinepriester\nTRUE\n\n\n2015\ndreck\nTRUE\n\n\n2027\npack\nTRUE\n\n\n2033\nkuh\nTRUE\n\n\n2039\nbild\nTRUE\n\n\n2045\nlappen\nTRUE\n\n\n2052\nduckm√§user\nTRUE\n\n\n2052\nfanatiker\nTRUE\n\n\n2054\nbild\nTRUE\n\n\n2054\nbild\nTRUE\n\n\n2060\nnichts\nTRUE\n\n\n2069\nbrut\nTRUE\n\n\n2069\nstinker\nTRUE\n\n\n2081\npisser\nTRUE\n\n\n2082\npack\nTRUE\n\n\n2084\nbrandstifter\nTRUE\n\n\n2085\nstinkstiefel\nTRUE\n\n\n2090\nhasser\nTRUE\n\n\n2097\nhaufen\nTRUE\n\n\n2097\nb√∂ser\nTRUE\n\n\n2102\nkuh\nTRUE\n\n\n2104\nmichel\nTRUE\n\n\n2106\nwicht\nTRUE\n\n\n2119\nhaufen\nTRUE\n\n\n2126\nschmarotzer\nTRUE\n\n\n2134\nblender\nTRUE\n\n\n2137\nbild\nTRUE\n\n\n2155\npack\nTRUE\n\n\n2155\nfresse\nTRUE\n\n\n2160\nsau\nTRUE\n\n\n2163\npack\nTRUE\n\n\n2174\nscheisser\nTRUE\n\n\n2176\nschmierfinke\nTRUE\n\n\n2184\nschwanz\nTRUE\n\n\n2185\nart\nTRUE\n\n\n2190\ntr√ºffelschwein\nTRUE\n\n\n2199\nlangsam\nTRUE\n\n\n2204\nlangsam\nTRUE\n\n\n2204\nnichts\nTRUE\n\n\n2205\nheuchler\nTRUE\n\n\n2226\ngesindel\nTRUE\n\n\n2226\nnigger\nTRUE\n\n\n2227\nversager\nTRUE\n\n\n2229\nhelfershelfer\nTRUE\n\n\n2231\narsch\nTRUE\n\n\n2241\nhagel\nTRUE\n\n\n2245\nschabracke\nTRUE\n\n\n2246\nbild\nTRUE\n\n\n2248\nb√ºrger\nTRUE\n\n\n2253\ntropf\nTRUE\n\n\n2265\narschloch\nTRUE\n\n\n2269\nnichts\nTRUE\n\n\n2271\nnichts\nTRUE\n\n\n2271\nnichts\nTRUE\n\n\n2275\nbild\nTRUE\n\n\n2286\nstumm\nTRUE\n\n\n2288\nding\nTRUE\n\n\n2289\npack\nTRUE\n\n\n2289\narsch\nTRUE\n\n\n2299\nverbrecher\nTRUE\n\n\n2303\nkr√∂te\nTRUE\n\n\n2308\nnichts\nTRUE\n\n\n2311\ndummkopf\nTRUE\n\n\n2312\nsack\nTRUE\n\n\n2318\ntor\nTRUE\n\n\n2324\nnichts\nTRUE\n\n\n2327\nbild\nTRUE\n\n\n2331\nschreiber\nTRUE\n\n\n2331\nschreiber\nTRUE\n\n\n2332\nnichts\nTRUE\n\n\n2333\nb√ºrger\nTRUE\n\n\n2335\ndreck\nTRUE\n\n\n2338\nb√ºrger\nTRUE\n\n\n2339\nonanieren\nTRUE\n\n\n2341\nkreuzritter\nTRUE\n\n\n2349\nnichts\nTRUE\n\n\n2354\nfreier\nTRUE\n\n\n2356\nfresse\nTRUE\n\n\n2360\nding\nTRUE\n\n\n2363\nnichts\nTRUE\n\n\n2371\nnichts\nTRUE\n\n\n2382\nmaul\nTRUE\n\n\n2382\nnichts\nTRUE\n\n\n2384\nb√ºrger\nTRUE\n\n\n2387\nfleisch\nTRUE\n\n\n2389\nversager\nTRUE\n\n\n2396\ntor\nTRUE\n\n\n2406\nm√∂rder\nTRUE\n\n\n2410\nfeind\nTRUE\n\n\n2415\nschlepper\nTRUE\n\n\n2416\nverbrecher\nTRUE\n\n\n2418\npest\nTRUE\n\n\n2430\ndreck\nTRUE\n\n\n2432\nzeug\nTRUE\n\n\n2434\nhitler\nTRUE\n\n\n2440\nneger\nTRUE\n\n\n2440\npack\nTRUE\n\n\n2442\ntroll\nTRUE\n\n\n2443\nterrorist\nTRUE\n\n\n2444\ngesicht\nTRUE\n\n\n2457\nbengel\nTRUE\n\n\n2457\nnichts\nTRUE\n\n\n2457\nsch√§del\nTRUE\n\n\n2460\npack\nTRUE\n\n\n2462\nbild\nTRUE\n\n\n2474\nnichts\nTRUE\n\n\n2475\nficken\nTRUE\n\n\n2475\nschandmaul\nTRUE\n\n\n2477\nteufel\nTRUE\n\n\n2481\nnichts\nTRUE\n\n\n2492\nschei√üdreck\nTRUE\n\n\n2504\nlangsam\nTRUE\n\n\n2505\nbesen\nTRUE\n\n\n2507\nhitler\nTRUE\n\n\n2510\nbande\nTRUE\n\n\n2512\nkasten\nTRUE\n\n\n2513\nnase\nTRUE\n\n\n2523\nb√ºrger\nTRUE\n\n\n2536\nfeind\nTRUE\n\n\n2537\nabschaum\nTRUE\n\n\n2537\nnichts\nTRUE\n\n\n2543\nhasser\nTRUE\n\n\n2545\nverlierer\nTRUE\n\n\n2550\nkoffer\nTRUE\n\n\n2551\nseehund\nTRUE\n\n\n2559\nmuschi\nTRUE\n\n\n2560\nlangsam\nTRUE\n\n\n2565\nkaputter\nTRUE\n\n\n2565\nhetzer\nTRUE\n\n\n2565\nhetzer\nTRUE\n\n\n2573\nblock\nTRUE\n\n\n2575\nnase\nTRUE\n\n\n2577\nbild\nTRUE\n\n\n2578\nwitzfigur\nTRUE\n\n\n2599\ngesicht\nTRUE\n\n\n2600\nfigur\nTRUE\n\n\n2608\nfreier\nTRUE\n\n\n2620\nmaul\nTRUE\n\n\n2625\nstorch\nTRUE\n\n\n2628\nhause\nTRUE\n\n\n2631\nb√ºrger\nTRUE\n\n\n2631\nidiot\nTRUE\n\n\n2633\nnichts\nTRUE\n\n\n2635\nschmarotzer\nTRUE\n\n\n2639\nniemand\nTRUE\n\n\n2641\nvolltrottel\nTRUE\n\n\n2644\nsch√§ferhund\nTRUE\n\n\n2646\nb√ºrger\nTRUE\n\n\n2657\nvergewaltiger\nTRUE\n\n\n2665\nlecker\nTRUE\n\n\n2669\nb√ºrger\nTRUE\n\n\n2672\nnichts\nTRUE\n\n\n2673\nniemand\nTRUE\n\n\n2676\nart\nTRUE\n\n\n2676\nart\nTRUE\n\n\n2678\nfresse\nTRUE\n\n\n2682\nfresse\nTRUE\n\n\n2686\nhause\nTRUE\n\n\n2690\nheuchler\nTRUE\n\n\n2698\nidiot\nTRUE\n\n\n2704\nart\nTRUE\n\n\n2705\nfell\nTRUE\n\n\n2709\nhause\nTRUE\n\n\n2723\nbild\nTRUE\n\n\n2723\narsch\nTRUE\n\n\n2725\nkindersch√§nder\nTRUE\n\n\n2727\nopfer\nTRUE\n\n\n2732\nneidhammel\nTRUE\n\n\n2734\nvollpfosten\nTRUE\n\n\n2737\ntoller\nTRUE\n\n\n2738\nbild\nTRUE\n\n\n2740\nweihnachtsmann\nTRUE\n\n\n2741\nmaul\nTRUE\n\n\n2744\nnackt\nTRUE\n\n\n2761\ngesicht\nTRUE\n\n\n2764\nnichts\nTRUE\n\n\n2780\nger√§t\nTRUE\n\n\n2785\nhitler\nTRUE\n\n\n2785\npest\nTRUE\n\n\n2785\nhitler\nTRUE\n\n\n2790\narschloch\nTRUE\n\n\n2795\nschwein\nTRUE\n\n\n2797\nsch√§del\nTRUE\n\n\n2806\nnichts\nTRUE\n\n\n2807\nbild\nTRUE\n\n\n2807\nschlampe\nTRUE\n\n\n2813\nbild\nTRUE\n\n\n2831\nklugschei√üer\nTRUE\n\n\n2832\ntierqu√§ler\nTRUE\n\n\n2834\nhetzer\nTRUE\n\n\n2841\nb√ºrger\nTRUE\n\n\n2844\nmistst√ºck\nTRUE\n\n\n2845\nbild\nTRUE\n\n\n2848\nkuh\nTRUE\n\n\n2851\nhorde\nTRUE\n\n\n2852\npack\nTRUE\n\n\n2855\nwesen\nTRUE\n\n\n2871\nniemand\nTRUE\n\n\n2871\nniemand\nTRUE\n\n\n2884\nnichts\nTRUE\n\n\n2885\nnichts\nTRUE\n\n\n2885\nopfer\nTRUE\n\n\n2897\nkratzer\nTRUE\n\n\n2897\nhund\nTRUE\n\n\n2900\nschlange\nTRUE\n\n\n2901\nger√§t\nTRUE\n\n\n2904\nhurensohn\nTRUE\n\n\n2912\nnichts\nTRUE\n\n\n2920\nmist\nTRUE\n\n\n2921\nhause\nTRUE\n\n\n2925\narsch\nTRUE\n\n\n2930\ngesindel\nTRUE\n\n\n2935\nart\nTRUE\n\n\n2940\nterrorist\nTRUE\n\n\n2947\neselstreiber\nTRUE\n\n\n2951\nabschaum\nTRUE\n\n\n2957\nnichts\nTRUE\n\n\n2959\nnull\nTRUE\n\n\n2965\ntaugenichts\nTRUE\n\n\n2973\npack\nTRUE\n\n\n2974\nhenker\nTRUE\n\n\n2975\nvolksverr√§ter\nTRUE\n\n\n2981\nheuchler\nTRUE\n\n\n2983\nteufel\nTRUE\n\n\n2988\nnichts\nTRUE\n\n\n2991\nbild\nTRUE\n\n\n2992\nniemand\nTRUE\n\n\n2997\nverbrecher\nTRUE\n\n\n2997\nopfer\nTRUE\n\n\n3001\nnichts\nTRUE\n\n\n3007\nbild\nTRUE\n\n\n3014\nseele\nTRUE\n\n\n3014\ngeist\nTRUE\n\n\n3019\nstumm\nTRUE\n\n\n3022\nhure\nTRUE\n\n\n3048\nbild\nTRUE\n\n\n3050\nlahm\nTRUE\n\n\n3050\ngegner\nTRUE\n\n\n3055\ntrolle\nTRUE\n\n\n3064\nnichts\nTRUE\n\n\n3066\nph√∂nix\nTRUE\n\n\n3076\nlangsam\nTRUE\n\n\n3079\nbild\nTRUE\n\n\n3087\nmade\nTRUE\n\n\n3089\nb√ºrger\nTRUE\n\n\n3100\nnichts\nTRUE\n\n\n3101\nnichts\nTRUE\n\n\n3102\nnase\nTRUE\n\n\n3108\nbild\nTRUE\n\n\n3108\npack\nTRUE\n\n\n3113\nheuchler\nTRUE\n\n\n3115\nnichts\nTRUE\n\n\n3115\nschwachsinniger\nTRUE\n\n\n3119\ngesicht\nTRUE\n\n\n3120\nstiefmutter\nTRUE\n\n\n3124\nniemand\nTRUE\n\n\n3128\nniemand\nTRUE\n\n\n3133\nschwanz\nTRUE\n\n\n3142\nmaul\nTRUE\n\n\n3143\nfeind\nTRUE\n\n\n3145\nnase\nTRUE\n\n\n3145\nhetzer\nTRUE\n\n\n3145\nnichts\nTRUE\n\n\n3152\nbild\nTRUE\n\n\n3154\neingeschr√§nkt\nTRUE\n\n\n3166\nwildschwein\nTRUE\n\n\n3168\nbild\nTRUE\n\n\n3170\nschmarotzer\nTRUE\n\n\n3177\nhitler\nTRUE\n\n\n3183\nl√§cherlich\nTRUE\n\n\n3184\nfresse\nTRUE\n\n\n3187\nnichts\nTRUE\n\n\n3200\npenner\nTRUE\n\n\n3207\nnichts\nTRUE\n\n\n3207\nverlierer\nTRUE\n\n\n3210\nhetzer\nTRUE\n\n\n3211\narschkriecher\nTRUE\n\n\n3212\ndreist\nTRUE\n\n\n3218\nl√§cherlich\nTRUE\n\n\n3222\nmonster\nTRUE\n\n\n3225\nvollpfosten\nTRUE\n\n\n3227\nhetzer\nTRUE\n\n\n3230\nhurensohn\nTRUE\n\n\n3246\npfeife\nTRUE\n\n\n3247\nopfer\nTRUE\n\n\n3258\nopfer\nTRUE\n\n\n3261\ntrulla\nTRUE\n\n\n3268\nger√§t\nTRUE\n\n\n3270\nhetzer\nTRUE\n\n\n3276\nkamel\nTRUE\n\n\n3277\nverbrecher\nTRUE\n\n\n3286\nnichts\nTRUE\n\n\n3304\nnichts\nTRUE\n\n\n3318\nfanatiker\nTRUE\n\n\n3321\ngutmensch\nTRUE\n\n\n3321\nkinderfeind\nTRUE\n\n\n3324\nneger\nTRUE\n\n\n3331\nb√ºrger\nTRUE\n\n\n3334\nb√ºrger\nTRUE\n\n\n3342\nhammer\nTRUE\n\n\n3353\nbild\nTRUE\n\n\n3353\nmade\nTRUE\n\n\n3354\nhetzer\nTRUE\n\n\n3354\ngutmensch\nTRUE\n\n\n3354\nlatte\nTRUE\n\n\n3360\nhause\nTRUE\n\n\n3364\nabfall\nTRUE\n\n\n3369\nnichts\nTRUE\n\n\n3371\nniemand\nTRUE\n\n\n3389\nnull\nTRUE\n\n\n3389\nmelkkuh\nTRUE\n\n\n3398\nfleisch\nTRUE\n\n\n3405\nnichts\nTRUE\n\n\n3410\nlecker\nTRUE\n\n\n3414\nl√§cherlich\nTRUE\n\n\n3416\nspieler\nTRUE\n\n\n3425\nbild\nTRUE\n\n\n3437\nfeind\nTRUE\n\n\n3437\nfeind\nTRUE\n\n\n3443\nfreier\nTRUE\n\n\n3453\nlacher\nTRUE\n\n\n3456\nnichts\nTRUE\n\n\n3470\nnichts\nTRUE\n\n\n3481\ndepp\nTRUE\n\n\n3486\nspinner\nTRUE\n\n\n3491\narsch\nTRUE\n\n\n3495\nnichts\nTRUE\n\n\n3498\nabschaum\nTRUE\n\n\n3502\nhaut\nTRUE\n\n\n3504\nvollpfosten\nTRUE\n\n\n3505\nbild\nTRUE\n\n\n3510\ntor\nTRUE\n\n\n3511\nart\nTRUE\n\n\n3511\nfl√ºchtling\nTRUE\n\n\n3517\nnichts\nTRUE\n\n\n3519\nbild\nTRUE\n\n\n3527\nfl√ºchtling\nTRUE\n\n\n3535\nbild\nTRUE\n\n\n3542\ntrolle\nTRUE\n\n\n3546\nbild\nTRUE\n\n\n3548\nnase\nTRUE\n\n\n3552\ngesocks\nTRUE\n\n\n3559\nhause\nTRUE\n\n\n3564\nb√ºrger\nTRUE\n\n\n3565\nniemand\nTRUE\n\n\n3569\nunkraut\nTRUE\n\n\n3572\nverbrecher\nTRUE\n\n\n3572\nfanatiker\nTRUE\n\n\n3573\nopfer\nTRUE\n\n\n3573\ngesicht\nTRUE\n\n\n3574\nhause\nTRUE\n\n\n3581\ntropf\nTRUE\n\n\n3591\ndreck\nTRUE\n\n\n3601\nfresse\nTRUE\n\n\n3601\nkacke\nTRUE\n\n\n3607\nnichts\nTRUE\n\n\n3614\nfaschist\nTRUE\n\n\n3615\narsch\nTRUE\n\n\n3623\nnudel\nTRUE\n\n\n3625\nnichts\nTRUE\n\n\n3628\nbrut\nTRUE\n\n\n3628\nhause\nTRUE\n\n\n3637\nb√ºrger\nTRUE\n\n\n3640\nseele\nTRUE\n\n\n3640\nsatan\nTRUE\n\n\n3643\nkuh\nTRUE\n\n\n3643\nschmierfinke\nTRUE\n\n\n3653\nl√∂we\nTRUE\n\n\n3653\nesel\nTRUE\n\n\n3653\npest\nTRUE\n\n\n3653\nratte\nTRUE\n\n\n3656\nmassenm√∂rder\nTRUE\n\n\n3665\nmaul\nTRUE\n\n\n3666\nnichts\nTRUE\n\n\n3669\ndummbrot\nTRUE\n\n\n3670\nschmarotzer\nTRUE\n\n\n3670\nhaut\nTRUE\n\n\n3675\nnichts\nTRUE\n\n\n3690\nvergewaltiger\nTRUE\n\n\n3697\ntor\nTRUE\n\n\n3698\nunkraut\nTRUE\n\n\n3702\nnichts\nTRUE\n\n\n3702\nopfer\nTRUE\n\n\n3717\nzwitter\nTRUE\n\n\n3717\ntunte\nTRUE\n\n\n3720\nabschaum\nTRUE\n\n\n3723\nignorant\nTRUE\n\n\n3725\nschmierfinke\nTRUE\n\n\n3727\nbild\nTRUE\n\n\n3731\nabschaum\nTRUE\n\n\n3732\nvergewaltiger\nTRUE\n\n\n3732\nm√∂rder\nTRUE\n\n\n3750\nschlampe\nTRUE\n\n\n3766\nnichts\nTRUE\n\n\n3767\nhammer\nTRUE\n\n\n3775\naffe\nTRUE\n\n\n3777\nflasche\nTRUE\n\n\n3785\nbild\nTRUE\n\n\n3785\nneger\nTRUE\n\n\n3790\nhahn\nTRUE\n\n\n3793\nniemand\nTRUE\n\n\n3803\ntusse\nTRUE\n\n\n3805\nbastard\nTRUE\n\n\n3807\nopfer\nTRUE\n\n\n3807\ngeist\nTRUE\n\n\n3808\nsau\nTRUE\n\n\n3815\nm√∂rder\nTRUE\n\n\n3816\nniemand\nTRUE\n\n\n3818\ntyp\nTRUE\n\n\n3819\nfisch\nTRUE\n\n\n3820\nbrut\nTRUE\n\n\n3824\nmist\nTRUE\n\n\n3833\nniemand\nTRUE\n\n\n3833\nspinner\nTRUE\n\n\n3836\nart\nTRUE\n\n\n3841\ntoller\nTRUE\n\n\n3843\nverlierer\nTRUE\n\n\n3844\nniemand\nTRUE\n\n\n3845\nkacke\nTRUE\n\n\n3847\nbluthund\nTRUE\n\n\n3847\nverr√§ter\nTRUE\n\n\n3849\nbazille\nTRUE\n\n\n3850\ngeier\nTRUE\n\n\n3862\nsack\nTRUE\n\n\n3862\nkn√ºppel\nTRUE\n\n\n3863\nb√ºrger\nTRUE\n\n\n3863\nb√ºrger\nTRUE\n\n\n3863\nhaut\nTRUE\n\n\n3864\nnichts\nTRUE\n\n\n3864\nnichts\nTRUE\n\n\n3865\nbild\nTRUE\n\n\n3880\nbild\nTRUE\n\n\n3882\nst√ºck\nTRUE\n\n\n3888\nlumpenpack\nTRUE\n\n\n3900\nbastard\nTRUE\n\n\n3915\nding\nTRUE\n\n\n3930\nopfer\nTRUE\n\n\n3930\nopfer\nTRUE\n\n\n3939\nmist\nTRUE\n\n\n3956\nhurensohn\nTRUE\n\n\n3975\nkr√∂te\nTRUE\n\n\n3980\ndichter\nTRUE\n\n\n3980\nduckm√§user\nTRUE\n\n\n3982\nheulsuse\nTRUE\n\n\n3992\nspeichellecker\nTRUE\n\n\n3994\nopfer\nTRUE\n\n\n4004\ntor\nTRUE\n\n\n4004\nniemand\nTRUE\n\n\n4005\nbumsen\nTRUE\n\n\n4008\nweib\nTRUE\n\n\n4010\nfresse\nTRUE\n\n\n4016\nnichts\nTRUE\n\n\n4016\nnichts\nTRUE\n\n\n4017\nnichts\nTRUE\n\n\n4024\nbild\nTRUE\n\n\n4024\npinkeln\nTRUE\n\n\n4032\npack\nTRUE\n\n\n4036\nnichts\nTRUE\n\n\n4042\nb√ºrger\nTRUE\n\n\n4047\nlangsam\nTRUE\n\n\n4055\nnase\nTRUE\n\n\n4055\nzeug\nTRUE\n\n\n4061\nbild\nTRUE\n\n\n4063\nzeug\nTRUE\n\n\n4067\nopfer\nTRUE\n\n\n4071\nnichts\nTRUE\n\n\n4072\nverlierer\nTRUE\n\n\n4087\nschn√ºffler\nTRUE\n\n\n4092\nhenker\nTRUE\n\n\n4092\nart\nTRUE\n\n\n4094\nhamster\nTRUE\n\n\n4094\nhamster\nTRUE\n\n\n4103\nabschaum\nTRUE\n\n\n4104\nmist\nTRUE\n\n\n4108\nopfer\nTRUE\n\n\n4120\nvaterlandsverr√§ter\nTRUE\n\n\n4128\ngegner\nTRUE\n\n\n4133\nnudel\nTRUE\n\n\n4138\nfl√ºchtling\nTRUE\n\n\n4140\ndreck\nTRUE\n\n\n4144\nbild\nTRUE\n\n\n4146\nnichts\nTRUE\n\n\n4151\narsch\nTRUE\n\n\n4153\nausbeuter\nTRUE\n\n\n4154\narsch\nTRUE\n\n\n4173\nnichts\nTRUE\n\n\n4175\nnichts\nTRUE\n\n\n4178\nhaufen\nTRUE\n\n\n4181\narsch\nTRUE\n\n\n4187\npuppe\nTRUE\n\n\n4189\ntrittbrettfahrer\nTRUE\n\n\n4191\nding\nTRUE\n\n\n4199\ndichter\nTRUE\n\n\n4209\nlangsam\nTRUE\n\n\n4215\nschei√üe\nTRUE\n\n\n4226\nhitler\nTRUE\n\n\n4233\nart\nTRUE\n\n\n4233\npinkeln\nTRUE\n\n\n4233\nnichts\nTRUE\n\n\n4234\nrattenf√§nger\nTRUE\n\n\n4234\nhitler\nTRUE\n\n\n4237\nnichts\nTRUE\n\n\n4247\nniemand\nTRUE\n\n\n4250\nb√ºrger\nTRUE\n\n\n4250\nnichts\nTRUE\n\n\n4259\nnichts\nTRUE\n\n\n4264\nnichts\nTRUE\n\n\n4280\nb√ºrger\nTRUE\n\n\n4288\nart\nTRUE\n\n\n4291\nzeug\nTRUE\n\n\n4301\nhitler\nTRUE\n\n\n4303\nfettsack\nTRUE\n\n\n4306\nmassenm√∂rder\nTRUE\n\n\n4306\nterrorist\nTRUE\n\n\n4308\np√∂bel\nTRUE\n\n\n4310\nm√∂rder\nTRUE\n\n\n4310\nverbrecher\nTRUE\n\n\n4325\nopfer\nTRUE\n\n\n4325\nkreatur\nTRUE\n\n\n4330\nkatze\nTRUE\n\n\n4331\ntor\nTRUE\n\n\n4335\nb√ºrger\nTRUE\n\n\n4341\nart\nTRUE\n\n\n4342\ngiraffe\nTRUE\n\n\n4343\nnichts\nTRUE\n\n\n4347\nhause\nTRUE\n\n\n4351\nabschaum\nTRUE\n\n\n4353\nbild\nTRUE\n\n\n4354\nbande\nTRUE\n\n\n4359\ntr√ºffelschwein\nTRUE\n\n\n4360\narsch\nTRUE\n\n\n4361\nfanatiker\nTRUE\n\n\n4366\nhonk\nTRUE\n\n\n4371\nnichts\nTRUE\n\n\n4385\nniemand\nTRUE\n\n\n4385\nniemand\nTRUE\n\n\n4389\narsch\nTRUE\n\n\n4390\nnichts\nTRUE\n\n\n4390\ndreck\nTRUE\n\n\n4394\nfl√ºchtling\nTRUE\n\n\n4395\ntoller\nTRUE\n\n\n4410\ndreck\nTRUE\n\n\n4413\nschwuchtel\nTRUE\n\n\n4419\nscherge\nTRUE\n\n\n4421\npfeife\nTRUE\n\n\n4424\nabschaum\nTRUE\n\n\n4432\nb√ºrger\nTRUE\n\n\n4441\nnichts\nTRUE\n\n\n4454\ntrulla\nTRUE\n\n\n4456\nschei√üe\nTRUE\n\n\n4456\nb√ºrger\nTRUE\n\n\n4458\nkratzer\nTRUE\n\n\n4461\nfeigling\nTRUE\n\n\n4473\neselficker\nTRUE\n\n\n4479\nabschaum\nTRUE\n\n\n4481\nlump\nTRUE\n\n\n4481\nflasche\nTRUE\n\n\n4482\ngro√ümaul\nTRUE\n\n\n4482\nmaul\nTRUE\n\n\n4492\nnichts\nTRUE\n\n\n4493\nmuschi\nTRUE\n\n\n4493\nkatze\nTRUE\n\n\n4493\nschwanz\nTRUE\n\n\n4493\nschweif\nTRUE\n\n\n4493\nst√ºck\nTRUE\n\n\n4493\nhund\nTRUE\n\n\n4495\nbild\nTRUE\n\n\n4496\nverbrecher\nTRUE\n\n\n4510\nmaul\nTRUE\n\n\n4520\nniemand\nTRUE\n\n\n4527\nschamlos\nTRUE\n\n\n4536\nhetzer\nTRUE\n\n\n4536\nhetzer\nTRUE\n\n\n4541\nkerl\nTRUE\n\n\n4543\nart\nTRUE\n\n\n4548\nkratzer\nTRUE\n\n\n4548\nopfer\nTRUE\n\n\n4552\nbild\nTRUE\n\n\n4554\ngeist\nTRUE\n\n\n4554\ngeist\nTRUE\n\n\n4555\nniemand\nTRUE\n\n\n4563\ndreck\nTRUE\n\n\n4564\nstock\nTRUE\n\n\n4572\nfresse\nTRUE\n\n\n4578\nesel\nTRUE\n\n\n4580\nfresse\nTRUE\n\n\n4588\nschei√üe\nTRUE\n\n\n4588\npack\nTRUE\n\n\n4590\nnichts\nTRUE\n\n\n4592\nfeind\nTRUE\n\n\n4610\nvogel\nTRUE\n\n\n4610\ngesicht\nTRUE\n\n\n4610\nbulle\nTRUE\n\n\n4613\nverlierer\nTRUE\n\n\n4615\nbock\nTRUE\n\n\n4617\nding\nTRUE\n\n\n4618\npest\nTRUE\n\n\n4624\nhause\nTRUE\n\n\n4626\nzerst√∂rer\nTRUE\n\n\n4626\nhitler\nTRUE\n\n\n4632\nschwein\nTRUE\n\n\n4634\nnichts\nTRUE\n\n\n4638\nnichts\nTRUE\n\n\n4638\nnichts\nTRUE\n\n\n4638\nversager\nTRUE\n\n\n4647\nkoffer\nTRUE\n\n\n4649\nmist\nTRUE\n\n\n4651\nm√∂rder\nTRUE\n\n\n4651\nvergewaltiger\nTRUE\n\n\n4651\nmist\nTRUE\n\n\n4654\nwichtigtuer\nTRUE\n\n\n4654\nversager\nTRUE\n\n\n4664\nhurensohn\nTRUE\n\n\n4672\nbild\nTRUE\n\n\n4672\nesel\nTRUE\n\n\n4675\nphilosoph\nTRUE\n\n\n4682\nfreier\nTRUE\n\n\n4690\nnichts\nTRUE\n\n\n4694\nsack\nTRUE\n\n\n4714\nnichts\nTRUE\n\n\n4717\nlecker\nTRUE\n\n\n4721\nfeind\nTRUE\n\n\n4730\nteufel\nTRUE\n\n\n4738\nbild\nTRUE\n\n\n4738\nbock\nTRUE\n\n\n4738\nmarionette\nTRUE\n\n\n4745\nbande\nTRUE\n\n\n4748\nnichts\nTRUE\n\n\n4754\nschei√üe\nTRUE\n\n\n4759\nzicke\nTRUE\n\n\n4762\nlump\nTRUE\n\n\n4770\nschatten\nTRUE\n\n\n4775\nnichts\nTRUE\n\n\n4781\nschwein\nTRUE\n\n\n4783\nopfer\nTRUE\n\n\n4785\nrassel\nTRUE\n\n\n4788\nfleisch\nTRUE\n\n\n4789\nnichts\nTRUE\n\n\n4796\nl√ºmmel\nTRUE\n\n\n4805\nleidenschaftlich\nTRUE\n\n\n4806\nniemand\nTRUE\n\n\n4808\noberpfeife\nTRUE\n\n\n4809\nhurensohn\nTRUE\n\n\n4815\nmichel\nTRUE\n\n\n4815\nnichts\nTRUE\n\n\n4816\nkreatur\nTRUE\n\n\n4820\nh√§kchen\nTRUE\n\n\n4821\nspeichellecker\nTRUE\n\n\n4821\nnull\nTRUE\n\n\n4825\nlarve\nTRUE\n\n\n4825\nlarve\nTRUE\n\n\n4827\nbild\nTRUE\n\n\n4840\nb√ºrger\nTRUE\n\n\n4840\nnull\nTRUE\n\n\n4847\njunker\nTRUE\n\n\n4847\nniemand\nTRUE\n\n\n4853\nhitler\nTRUE\n\n\n4854\ntyp\nTRUE\n\n\n4856\nbild\nTRUE\n\n\n4858\nbild\nTRUE\n\n\n4859\narsch\nTRUE\n\n\n4867\nbild\nTRUE\n\n\n4870\nkuh\nTRUE\n\n\n4870\nfleischfresser\nTRUE\n\n\n4880\nbild\nTRUE\n\n\n4880\ntrolle\nTRUE\n\n\n4881\narsch\nTRUE\n\n\n4881\nvollidiot\nTRUE\n\n\n4883\nhering\nTRUE\n\n\n4886\nbild\nTRUE\n\n\n4891\nnichts\nTRUE\n\n\n4892\nkerl\nTRUE\n\n\n4897\nbild\nTRUE\n\n\n4897\ntoller\nTRUE\n\n\n4898\nl√∂we\nTRUE\n\n\n4898\nhamster\nTRUE\n\n\n4898\nhamster\nTRUE\n\n\n4901\ndreck\nTRUE\n\n\n4909\nbild\nTRUE\n\n\n4916\nkerl\nTRUE\n\n\n4922\nvolltrottel\nTRUE\n\n\n4922\ntrottel\nTRUE\n\n\n4923\nsimpel\nTRUE\n\n\n4925\ntor\nTRUE\n\n\n4926\nnichts\nTRUE\n\n\n4927\nb√ºrger\nTRUE\n\n\n4930\nm√∂se\nTRUE\n\n\n4931\nkr√∂te\nTRUE\n\n\n4931\nnichts\nTRUE\n\n\n4936\nkatze\nTRUE\n\n\n4938\nhungrig\nTRUE\n\n\n4941\narsch\nTRUE\n\n\n4942\nanus\nTRUE\n\n\n4943\nschauspieler\nTRUE\n\n\n4957\nhetzer\nTRUE\n\n\n4957\npack\nTRUE\n\n\n4959\narsch\nTRUE\n\n\n4960\nb√ºrger\nTRUE\n\n\n4960\narsch\nTRUE\n\n\n4964\nvollpfosten\nTRUE\n\n\n4965\nfeind\nTRUE\n\n\n4966\nnichts\nTRUE\n\n\n4975\nnichts\nTRUE\n\n\n4976\nniemand\nTRUE\n\n\n4989\nverbrecher\nTRUE\n\n\n5004\nst√ºck\nTRUE\n\n\n\n\n\n\nWie viele Schimpfw√∂rter haben wir gefunden?\n\nd_schimpf %>% \n  count(schimpf)\n\n\n\n\n\nschimpf\nn\n\n\n\n\nFALSE\n99081\n\n\nTRUE\n1136\n\n\n\n\n\n\nEtwa ein Prozent der W√∂rter sind Schimpfw√∂rter in unserem Corpus.\n\nd_schimpf2 <-\n  d_schimpf %>% \n  group_by(id) %>% \n  summarise(schimpf_n = sum(schimpf))\n\nhead(d_schimpf2)\n\n\n\n\n\nid\nschimpf_n\n\n\n\n\n1\n0\n\n\n2\n0\n\n\n3\n0\n\n\n4\n0\n\n\n5\n1\n\n\n6\n0\n\n\n\n\n\n\n\nd_main <-\n  d3 %>% \n  full_join(d_schimpf2)\n\nJoining, by = \"id\"\n\n\n\n\n\n\n\n\nWichtig\n\n\n\nNamen wie final, main oder result sind gef√§hrlich, da es unter Garantie ein ‚Äúfinal-final geben wird, oder der‚ÄùHaupt-Datensat‚Äù pl√∂tzlich nicht mehr so wichtig erscheint und so weiter.\n\n\n\n\n1.3.4 Emojis\n\nemj <- emoji(list_emoji(), pad = FALSE)\n\nhead(emj)\n\n[1] \"üòÑ\" \"üòÉ\" \"üòÄ\" \"üòä\" \"‚ò∫Ô∏è\"  \"üòâ\"\n\n\nDiese Liste umfasst knapp 900 Emojis, das sind allerdings noch nicht alle, die es gibt. Diese Liste umfasst mit gut 1800 Emojis gut das Doppelte.\nSelbstkuratierte Liste an ‚Äúwilden‚Äù Emoji; diese Liste ist inspiriert von emojicombos.com.\n\nwild_emojis <- \n  c(\n    emoji(find_emoji(\"gun\")),\n    emoji(find_emoji(\"bomb\")),\n    emoji(find_emoji(\"fist\")),\n    emoji(find_emoji(\"knife\"))[1],\n     emoji(find_emoji(\"ambulance\")),\n    \"üò†\",\n    \"üëπ\",\n    \"üí©\",\n    \"‚ò†\",\n    \"üñï\",\n    emoji(find_emoji(\"middle finger\")),\n    \"üò°\",\n    \"ü§¢\",\n    \"ü§Æ\",\n    \"üòñ\",\n    \"üò£\",\n    \"üò©\",\n    \"üò®\",\n    \"üòù\",\n    \"üò≥\",\n    \"üò¨\",\n    \"üò±\",\n    \"üòµ\",\n    \"üò§\",\n    \"ü§¶‚Äç‚ôÄÔ∏è\",\n    \"ü§¶‚Äç‚ôÇÔ∏è\"\n  )\n\nAuf dieser Basis k√∂nnen wir einen Pr√§diktor erstellen, der z√§hlt, ob ein Tweet einen oder mehrere der ‚Äúwilden‚Äù Emojis enth√§lt."
  },
  {
    "objectID": "klassifikation.html#workflow-1-rezept-1-naive-bayes",
    "href": "klassifikation.html#workflow-1-rezept-1-naive-bayes",
    "title": "1¬† Klassifikation von Hatespeech",
    "section": "1.4 Workflow 1: Rezept 1 + Naive-Bayes",
    "text": "1.4 Workflow 1: Rezept 1 + Naive-Bayes\n\n1.4.1 Dummy-Rezept\nHier ist ein einfaches Beispiel, um die Textvorbereitung mit {textrecipes} zu verdeutlichen.\nWir erstellen uns einen Dummy-Text:\n\ndummy <- \n  tibble(text = c(\"Ich gehe heim und der die das nicht in ein and the\"))\n\nDann tokenisieren wir den Text:\n\nrec_dummy <-\n  recipe(text ~ 1, data = dummy) %>% \n  step_tokenize(text)\n  \nrec_dummy\n\nRecipe\n\nInputs:\n\n    role #variables\n outcome          1\n\nOperations:\n\nTokenization for text\n\n\nDie Tokens kann man sich so zeigen lassen:\n\nshow_tokens(rec_dummy, text)\n\n[[1]]\n [1] \"ich\"   \"gehe\"  \"heim\"  \"und\"   \"der\"   \"die\"   \"das\"   \"nicht\" \"in\"   \n[10] \"ein\"   \"and\"   \"the\"  \n\n\nJetzt entfernen wir die Stopw√∂rter deutscher Sprache; daf√ºr nutzen wir die Stopwort-Quelle snowball:\n\nrec_dummy <-\n  recipe(text ~ 1, data = dummy) %>% \n  step_tokenize(text) %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\")\n\nrec_dummy\n\nRecipe\n\nInputs:\n\n    role #variables\n outcome          1\n\nOperations:\n\nTokenization for text\nStop word removal for text\n\n\nPr√ºfen wir die Tokens; sind die Stopw√∂rter wirklich entfernt?\n\nshow_tokens(rec_dummy, text)\n\n[[1]]\n[1] \"gehe\" \"heim\" \"and\"  \"the\" \n\n\nJa, die deutschen Stopw√∂rter sind entfernt. Die englischen nicht; das macht Sinn!\n\n\n1.4.2 Datenaufteilung\n\nd_split <- initial_split(d_main, strata = c1)\n\nd_train <- training(d_split)\nd_test <- testing(d_split)\n\n\n\n1.4.3 Rezept 1\nRezept definieren:\n\nrec1 <- \n  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% \n  update_role(id, new_role = \"id\") %>% \n  step_tokenize(text) %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>% \n  step_stem(text) %>% \n  step_tokenfilter(text, max_tokens = 1e2) %>% \n  step_tfidf(text) %>% \n  step_normalize(all_numeric_predictors())\n\nrec1\n\nRecipe\n\nInputs:\n\n      role #variables\n        id          1\n   outcome          1\n predictor          1\n\nOperations:\n\nTokenization for text\nStop word removal for text\nStemming for text\nText filtering for text\nTerm frequency-inverse document frequency with text\nCentering and scaling for all_numeric_predictors()\n\n\nPreppen:\n\nrec1_prepped <- prep(rec1)\n\nUnd backen:\n\nd_rec1 <- bake(rec1_prepped, new_data = NULL)\n\nhead(d_rec1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nc1\ntfidf_text__macmik\ntfidf_text_2\ntfidf_text_ab\ntfidf_text_afd\ntfidf_text_amp\ntfidf_text_anna_iina\ntfidf_text_antisemitismu\ntfidf_text_athinamala\ntfidf_text_besser\ntfidf_text_bild\ntfidf_text_cdu\ntfidf_text_charlie_silv\ntfidf_text_csu\ntfidf_text_d\ntfidf_text_daf√ºr\ntfidf_text_dank\ntfidf_text_dass\ntfidf_text_deutsch\ntfidf_text_deutschen\ntfidf_text_deutschland\ntfidf_text_dumm\ntfidf_text_einfach\ntfidf_text_ellibisathid\ntfidf_text_endlich\ntfidf_text_ennof_\ntfidf_text_erst\ntfidf_text_eu\ntfidf_text_europa\ntfidf_text_fdp\ntfidf_text_feldenfrizz\ntfidf_text_focusonlin\ntfidf_text_frage\ntfidf_text_frau\ntfidf_text_ganz\ntfidf_text_geht\ntfidf_text_gerad\ntfidf_text_gibt\ntfidf_text_gr√ºnen\ntfidf_text_gt\ntfidf_text_gut\ntfidf_text_h√§tte\ntfidf_text_heut\ntfidf_text_immer\ntfidf_text_info2099\ntfidf_text_islam\ntfidf_text_israel\ntfidf_text_ja\ntfidf_text_jahr\ntfidf_text_juden\ntfidf_text_kommt\ntfidf_text_krippmari\ntfidf_text_land\ntfidf_text_lassen\ntfidf_text_lbr\ntfidf_text_lifetrend\ntfidf_text_link\ntfidf_text_macht\ntfidf_text_machtjanix23\ntfidf_text_mal\ntfidf_text_md_franz\ntfidf_text_mehr\ntfidf_text_menschen\ntfidf_text_merkel\ntfidf_text_miriamozen\ntfidf_text_moslem\ntfidf_text_m√ºssen\ntfidf_text_nancypeggymandi\ntfidf_text_nasanas\ntfidf_text_noherrman\ntfidf_text_norbinator2403\ntfidf_text_partei\ntfidf_text_petpanther0\ntfidf_text_politik\ntfidf_text_recht\ntfidf_text_richtig\ntfidf_text_sagt\ntfidf_text_schmiddiemaik\ntfidf_text_schon\ntfidf_text_schulz\ntfidf_text_seit\ntfidf_text_sicher\ntfidf_text_spd\ntfidf_text_tagesschau\ntfidf_text_thomasgbau\ntfidf_text_troll_putin\ntfidf_text_trump\ntfidf_text_tun\ntfidf_text_t√ºrken\ntfidf_text_u\ntfidf_text_unser\ntfidf_text_viel\ntfidf_text_volk\ntfidf_text_w√§re\ntfidf_text_warum\ntfidf_text_welt\ntfidf_text_wer\ntfidf_text_willjrosenblatt\ntfidf_text_wohl\ntfidf_text_wurd\ntfidf_text_zeit\n\n\n\n\n9\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n6.1558148\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n9.5543591\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n12\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n3.6921593\n-0.0804698\n-0.1036414\n-0.0836286\n3.385033\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n1.2297516\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n17\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n3.7258962\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n4.1966394\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n4.4285094\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n33\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n3.6445592\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n3.1601002\n-0.1167916\n-0.2184447\n-0.0966546\n5.4434700\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n42\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n6.6612452\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n1.2297516\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n5.9134349\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n44\nOFFENSE\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n17.7948786\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n\n\n\n\n\n\n1.4.4 Modellspezifikation 1\nWir definiere einen Naive-Bayes-Algorithmus:\n\nnb_spec <- naive_Bayes() %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"naivebayes\")\n\nnb_spec\n\nNaive Bayes Model Specification (classification)\n\nComputational engine: naivebayes \n\n\nUnd setzen auf die klassische zehnfache Kreuzvalidierung.\n\nset.seed(42)\nfolds1 <- vfold_cv(d_train)\n\n\n\n1.4.5 Workflow 1\n\nwf1 <-\n  workflow() %>% \n  add_recipe(rec1) %>% \n  add_model(nb_spec)\n\nwf1\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: naive_Bayes()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n6 Recipe Steps\n\n‚Ä¢ step_tokenize()\n‚Ä¢ step_stopwords()\n‚Ä¢ step_stem()\n‚Ä¢ step_tokenfilter()\n‚Ä¢ step_tfidf()\n‚Ä¢ step_normalize()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nNaive Bayes Model Specification (classification)\n\nComputational engine: naivebayes \n\n\n\n\n1.4.6 Fitting 1\n\nfit1 <-\n  fit_resamples(\n    wf1,\n    folds1,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nDie Vorhersagen speichern wir ab, um die Performanz in den Faltungen des Hold-out-Samples zu berechnen.\nM√∂chte man sich die Zeit sparen, die Syntax wieder durchlaufen zu lassen, kann man das Objekt speichern. Aber Vorsicht: Dabei kann es passieren, dass man mit veralteten Objekten arbeitet.\n\nwrite_rds(fit1, \"objects/chap_classific_fit1.rds\")\n\n\n\n\n\n\n1.4.7 Performanz 1\n\nwf1_performance <-\n  collect_metrics(fit1)\n\nwf1_performance\n\n\n\n\n\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\naccuracy\nbinary\n0.6637270\n10\n0.0057716\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.5893296\n10\n0.0081290\nPreprocessor1_Model1\n\n\n\n\n\n\n\nwf_preds <-\n  collect_predictions(fit1)\n\nwf_preds %>% \n  group_by(id) %>% \n  roc_curve(truth = c1, .pred_OFFENSE) %>% \n  autoplot()\n\n\n\n\n\nconf_mat_resampled(fit1, tidy = FALSE) %>% \n  autoplot(type = \"heatmap\")"
  },
  {
    "objectID": "klassifikation.html#nullmodell",
    "href": "klassifikation.html#nullmodell",
    "title": "1¬† Klassifikation von Hatespeech",
    "section": "1.5 Nullmodell",
    "text": "1.5 Nullmodell\n\nnull_classification <- \n  parsnip::null_model() %>%\n  set_engine(\"parsnip\") %>%\n  set_mode(\"classification\")\n\nnull_rs <- workflow() %>%\n  add_recipe(rec1) %>%\n  add_model(null_classification) %>%\n  fit_resamples(\n    folds1\n  )\n\n\n\n\n\n\n\nHier ist die Performanz des Nullmodells.\n\nnull_rs %>%\n  collect_metrics()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model01\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model01\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model02\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model02\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model03\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model03\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model04\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model04\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model05\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model05\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model06\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model06\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model07\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model07\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model08\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model08\n\n\n0.0000001\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model09\n\n\n0.0000001\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model09\n\n\n0.0000001\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model10\n\n\n0.0000001\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model10\n\n\n0.0000003\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model11\n\n\n0.0000003\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model11\n\n\n0.0000006\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model12\n\n\n0.0000006\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model12\n\n\n0.0000014\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model13\n\n\n0.0000014\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model13\n\n\n0.0000030\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model14\n\n\n0.0000030\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model14\n\n\n0.0000067\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model15\n\n\n0.0000067\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model15\n\n\n0.0000149\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model16\n\n\n0.0000149\nroc_auc\nbinary\n0.8095845\n10\n0.0096008\nPreprocessor1_Model16\n\n\n0.0000329\naccuracy\nbinary\n0.7667645\n10\n0.0061340\nPreprocessor1_Model17\n\n\n0.0000329\nroc_auc\nbinary\n0.8095282\n10\n0.0095826\nPreprocessor1_Model17\n\n\n0.0000728\naccuracy\nbinary\n0.7667645\n10\n0.0061340\nPreprocessor1_Model18\n\n\n0.0000728\nroc_auc\nbinary\n0.8095638\n10\n0.0095511\nPreprocessor1_Model18\n\n\n0.0001610\naccuracy\nbinary\n0.7662333\n10\n0.0057794\nPreprocessor1_Model19\n\n\n0.0001610\nroc_auc\nbinary\n0.8099159\n10\n0.0094448\nPreprocessor1_Model19\n\n\n0.0003562\naccuracy\nbinary\n0.7654348\n10\n0.0063700\nPreprocessor1_Model20\n\n\n0.0003562\nroc_auc\nbinary\n0.8103737\n10\n0.0092381\nPreprocessor1_Model20\n\n\n0.0007880\naccuracy\nbinary\n0.7664993\n10\n0.0062776\nPreprocessor1_Model21\n\n\n0.0007880\nroc_auc\nbinary\n0.8111630\n10\n0.0089414\nPreprocessor1_Model21\n\n\n0.0017433\naccuracy\nbinary\n0.7670333\n10\n0.0066734\nPreprocessor1_Model22\n\n\n0.0017433\nroc_auc\nbinary\n0.8116297\n10\n0.0087106\nPreprocessor1_Model22\n\n\n0.0038566\naccuracy\nbinary\n0.7646319\n10\n0.0069158\nPreprocessor1_Model23\n\n\n0.0038566\nroc_auc\nbinary\n0.8093719\n10\n0.0079992\nPreprocessor1_Model23\n\n\n0.0085317\naccuracy\nbinary\n0.7553156\n10\n0.0061916\nPreprocessor1_Model24\n\n\n0.0085317\nroc_auc\nbinary\n0.8032327\n10\n0.0073114\nPreprocessor1_Model24\n\n\n0.0188739\naccuracy\nbinary\n0.7308227\n10\n0.0069456\nPreprocessor1_Model25\n\n\n0.0188739\nroc_auc\nbinary\n0.7830419\n10\n0.0087585\nPreprocessor1_Model25\n\n\n0.0417532\naccuracy\nbinary\n0.6996695\n10\n0.0085704\nPreprocessor1_Model26\n\n\n0.0417532\nroc_auc\nbinary\n0.7537161\n10\n0.0090227\nPreprocessor1_Model26\n\n\n0.0923671\naccuracy\nbinary\n0.6629305\n10\n0.0054329\nPreprocessor1_Model27\n\n\n0.0923671\nroc_auc\nbinary\n0.6848928\n10\n0.0102870\nPreprocessor1_Model27\n\n\n0.2043360\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model28\n\n\n0.2043360\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model28\n\n\n0.4520354\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model29\n\n\n0.4520354\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model29\n\n\n1.0000000\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model30\n\n\n1.0000000\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model30"
  },
  {
    "objectID": "klassifikation.html#workflow-2-rezept-1-lasso",
    "href": "klassifikation.html#workflow-2-rezept-1-lasso",
    "title": "1¬† Klassifikation von Hatespeech",
    "section": "1.6 Workflow 2: Rezept 1 + Lasso",
    "text": "1.6 Workflow 2: Rezept 1 + Lasso\n\nlasso_spec <- logistic_reg(penalty = tune(), mixture = 1) %>%\n  set_mode(\"classification\") %>%\n  set_engine(\"glmnet\")\n\nlasso_spec\n\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\nWir definieren die Auspr√§gungen von penalty, die wir ausprobieren wollen:\n\nlambda_grid <- grid_regular(penalty(), levels = 30)\n\n\nwf2 <-\n  workflow() %>% \n  add_recipe(rec1) %>% \n  add_model(lasso_spec)\n\nwf2\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: logistic_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n6 Recipe Steps\n\n‚Ä¢ step_tokenize()\n‚Ä¢ step_stopwords()\n‚Ä¢ step_stem()\n‚Ä¢ step_tokenfilter()\n‚Ä¢ step_tfidf()\n‚Ä¢ step_normalize()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\nTunen und Fitten:\n\nset.seed(42)\n\nfit2 <-\n  tune_grid(\n    wf2,\n    folds1,\n    grid = lambda_grid,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nfit2\n\nVorsicht beim Abspeichern.\n\nwrite_rds(fit2, \"objects/chap_classific_fit2.rds\")\n\n\n\n\nHier ist die Performanz:\n\ncollect_metrics(fit2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model01\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model01\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model02\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model02\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model03\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model03\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model04\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model04\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model05\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model05\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model06\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model06\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model07\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model07\n\n\n0.0000000\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model08\n\n\n0.0000000\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model08\n\n\n0.0000001\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model09\n\n\n0.0000001\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model09\n\n\n0.0000001\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model10\n\n\n0.0000001\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model10\n\n\n0.0000003\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model11\n\n\n0.0000003\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model11\n\n\n0.0000006\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model12\n\n\n0.0000006\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model12\n\n\n0.0000014\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model13\n\n\n0.0000014\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model13\n\n\n0.0000030\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model14\n\n\n0.0000030\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model14\n\n\n0.0000067\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model15\n\n\n0.0000067\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model15\n\n\n0.0000149\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model16\n\n\n0.0000149\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model16\n\n\n0.0000329\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model17\n\n\n0.0000329\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model17\n\n\n0.0000728\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model18\n\n\n0.0000728\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model18\n\n\n0.0001610\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model19\n\n\n0.0001610\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model19\n\n\n0.0003562\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model20\n\n\n0.0003562\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model20\n\n\n0.0007880\naccuracy\nbinary\n0.6746411\n10\n0.0059103\nPreprocessor1_Model21\n\n\n0.0007880\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model21\n\n\n0.0017433\naccuracy\nbinary\n0.6727759\n10\n0.0063031\nPreprocessor1_Model22\n\n\n0.0017433\nroc_auc\nbinary\n0.5990815\n10\n0.0093387\nPreprocessor1_Model22\n\n\n0.0038566\naccuracy\nbinary\n0.6701156\n10\n0.0063769\nPreprocessor1_Model23\n\n\n0.0038566\nroc_auc\nbinary\n0.5965799\n10\n0.0089758\nPreprocessor1_Model23\n\n\n0.0085317\naccuracy\nbinary\n0.6703823\n10\n0.0062284\nPreprocessor1_Model24\n\n\n0.0085317\nroc_auc\nbinary\n0.5973047\n10\n0.0090449\nPreprocessor1_Model24\n\n\n0.0188739\naccuracy\nbinary\n0.6695844\n10\n0.0055210\nPreprocessor1_Model25\n\n\n0.0188739\nroc_auc\nbinary\n0.5891358\n10\n0.0089649\nPreprocessor1_Model25\n\n\n0.0417532\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model26\n\n\n0.0417532\nroc_auc\nbinary\n0.5802395\n10\n0.0071230\nPreprocessor1_Model26\n\n\n0.0923671\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model27\n\n\n0.0923671\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model27\n\n\n0.2043360\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model28\n\n\n0.2043360\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model28\n\n\n0.4520354\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model29\n\n\n0.4520354\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model29\n\n\n1.0000000\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model30\n\n\n1.0000000\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model30\n\n\n\n\n\n\n\nautoplot(fit2)\n\n\n\n\n\nfit2 %>% \n  show_best(\"roc_auc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model01\n\n\n0\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model02\n\n\n0\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model03\n\n\n0\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model04\n\n\n0\nroc_auc\nbinary\n0.5997476\n10\n0.0090575\nPreprocessor1_Model05\n\n\n\n\n\n\n\nchosen_auc <- \n  fit2 %>%\n  select_by_one_std_err(metric = \"roc_auc\", -penalty)\n\nFinalisieren:\n\nwf2_final <-\n  finalize_workflow(wf2, chosen_auc)\n\nwf2_final\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: logistic_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n6 Recipe Steps\n\n‚Ä¢ step_tokenize()\n‚Ä¢ step_stopwords()\n‚Ä¢ step_stem()\n‚Ä¢ step_tokenfilter()\n‚Ä¢ step_tfidf()\n‚Ä¢ step_normalize()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.00853167852417281\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\nfit2_final_train <-\n  fit(wf2_final, d_train)\n\n\nfit2_final_train %>% \n  extract_fit_parsnip() %>% \n  tidy() %>% \n  arrange(-abs(estimate))\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-6\n\n\n\n\n\n\nterm\nestimate\npenalty\n\n\n\n\n(Intercept)\n0.6992837\n0.0085317\n\n\ntfidf_text_dumm\n-0.2201192\n0.0085317\n\n\ntfidf_text_merkel\n-0.2139564\n0.0085317\n\n\ntfidf_text_moslem\n-0.1772228\n0.0085317\n\n\ntfidf_text_lbr\n-0.1459591\n0.0085317\n\n\ntfidf_text_islam\n-0.1168911\n0.0085317\n\n\ntfidf_text_schulz\n-0.1125708\n0.0085317\n\n\ntfidf_text_anna_iina\n-0.1059814\n0.0085317\n\n\ntfidf_text_t√ºrken\n-0.0957637\n0.0085317\n\n\ntfidf_text_dank\n0.0929712\n0.0085317\n\n\ntfidf_text_gut\n0.0792327\n0.0085317\n\n\ntfidf_text_israel\n0.0705250\n0.0085317\n\n\ntfidf_text_tagesschau\n-0.0699302\n0.0085317\n\n\ntfidf_text_gr√ºnen\n-0.0668897\n0.0085317\n\n\ntfidf_text_link\n-0.0576155\n0.0085317\n\n\ntfidf_text_deutsch\n-0.0548113\n0.0085317\n\n\ntfidf_text_trump\n-0.0499617\n0.0085317\n\n\ntfidf_text_einfach\n-0.0498839\n0.0085317\n\n\ntfidf_text__macmik\n0.0469582\n0.0085317\n\n\ntfidf_text_dass\n0.0464695\n0.0085317\n\n\ntfidf_text_jahr\n0.0464606\n0.0085317\n\n\ntfidf_text_politik\n-0.0429593\n0.0085317\n\n\ntfidf_text_krippmari\n-0.0420569\n0.0085317\n\n\ntfidf_text_deutschen\n-0.0404395\n0.0085317\n\n\ntfidf_text_schon\n-0.0395614\n0.0085317\n\n\ntfidf_text_w√§re\n-0.0390549\n0.0085317\n\n\ntfidf_text_antisemitismu\n0.0387323\n0.0085317\n\n\ntfidf_text_ab\n-0.0343773\n0.0085317\n\n\ntfidf_text_gt\n-0.0294070\n0.0085317\n\n\ntfidf_text_fdp\n0.0282413\n0.0085317\n\n\ntfidf_text_welt\n-0.0271037\n0.0085317\n\n\ntfidf_text_bild\n-0.0238585\n0.0085317\n\n\ntfidf_text_gibt\n-0.0226347\n0.0085317\n\n\ntfidf_text_eu\n0.0176105\n0.0085317\n\n\ntfidf_text_csu\n0.0154015\n0.0085317\n\n\ntfidf_text_lassen\n-0.0147725\n0.0085317\n\n\ntfidf_text_mal\n-0.0145759\n0.0085317\n\n\ntfidf_text_nasanas\n0.0120621\n0.0085317\n\n\ntfidf_text_wohl\n-0.0103838\n0.0085317\n\n\ntfidf_text_europa\n-0.0099091\n0.0085317\n\n\ntfidf_text_volk\n0.0088143\n0.0085317\n\n\ntfidf_text_frage\n0.0086949\n0.0085317\n\n\ntfidf_text_wer\n0.0061202\n0.0085317\n\n\ntfidf_text_heut\n0.0025037\n0.0085317\n\n\ntfidf_text_noherrman\n-0.0012571\n0.0085317\n\n\ntfidf_text_unser\n0.0004523\n0.0085317\n\n\ntfidf_text_deutschland\n-0.0003935\n0.0085317\n\n\ntfidf_text_feldenfrizz\n0.0000029\n0.0085317\n\n\ntfidf_text_2\n0.0000000\n0.0085317\n\n\ntfidf_text_afd\n0.0000000\n0.0085317\n\n\ntfidf_text_amp\n0.0000000\n0.0085317\n\n\ntfidf_text_athinamala\n0.0000000\n0.0085317\n\n\ntfidf_text_besser\n0.0000000\n0.0085317\n\n\ntfidf_text_cdu\n0.0000000\n0.0085317\n\n\ntfidf_text_charlie_silv\n0.0000000\n0.0085317\n\n\ntfidf_text_d\n0.0000000\n0.0085317\n\n\ntfidf_text_daf√ºr\n0.0000000\n0.0085317\n\n\ntfidf_text_ellibisathid\n0.0000000\n0.0085317\n\n\ntfidf_text_endlich\n0.0000000\n0.0085317\n\n\ntfidf_text_ennof_\n0.0000000\n0.0085317\n\n\ntfidf_text_erst\n0.0000000\n0.0085317\n\n\ntfidf_text_focusonlin\n0.0000000\n0.0085317\n\n\ntfidf_text_frau\n0.0000000\n0.0085317\n\n\ntfidf_text_ganz\n0.0000000\n0.0085317\n\n\ntfidf_text_geht\n0.0000000\n0.0085317\n\n\ntfidf_text_gerad\n0.0000000\n0.0085317\n\n\ntfidf_text_h√§tte\n0.0000000\n0.0085317\n\n\ntfidf_text_immer\n0.0000000\n0.0085317\n\n\ntfidf_text_info2099\n0.0000000\n0.0085317\n\n\ntfidf_text_ja\n0.0000000\n0.0085317\n\n\ntfidf_text_juden\n0.0000000\n0.0085317\n\n\ntfidf_text_kommt\n0.0000000\n0.0085317\n\n\ntfidf_text_land\n0.0000000\n0.0085317\n\n\ntfidf_text_lifetrend\n0.0000000\n0.0085317\n\n\ntfidf_text_macht\n0.0000000\n0.0085317\n\n\ntfidf_text_machtjanix23\n0.0000000\n0.0085317\n\n\ntfidf_text_md_franz\n0.0000000\n0.0085317\n\n\ntfidf_text_mehr\n0.0000000\n0.0085317\n\n\ntfidf_text_menschen\n0.0000000\n0.0085317\n\n\ntfidf_text_miriamozen\n0.0000000\n0.0085317\n\n\ntfidf_text_m√ºssen\n0.0000000\n0.0085317\n\n\ntfidf_text_nancypeggymandi\n0.0000000\n0.0085317\n\n\ntfidf_text_norbinator2403\n0.0000000\n0.0085317\n\n\ntfidf_text_partei\n0.0000000\n0.0085317\n\n\ntfidf_text_petpanther0\n0.0000000\n0.0085317\n\n\ntfidf_text_recht\n0.0000000\n0.0085317\n\n\ntfidf_text_richtig\n0.0000000\n0.0085317\n\n\ntfidf_text_sagt\n0.0000000\n0.0085317\n\n\ntfidf_text_schmiddiemaik\n0.0000000\n0.0085317\n\n\ntfidf_text_seit\n0.0000000\n0.0085317\n\n\ntfidf_text_sicher\n0.0000000\n0.0085317\n\n\ntfidf_text_spd\n0.0000000\n0.0085317\n\n\ntfidf_text_thomasgbau\n0.0000000\n0.0085317\n\n\ntfidf_text_troll_putin\n0.0000000\n0.0085317\n\n\ntfidf_text_tun\n0.0000000\n0.0085317\n\n\ntfidf_text_u\n0.0000000\n0.0085317\n\n\ntfidf_text_viel\n0.0000000\n0.0085317\n\n\ntfidf_text_warum\n0.0000000\n0.0085317\n\n\ntfidf_text_willjrosenblatt\n0.0000000\n0.0085317\n\n\ntfidf_text_wurd\n0.0000000\n0.0085317\n\n\ntfidf_text_zeit\n0.0000000\n0.0085317\n\n\n\n\n\n\n\nfit2_final_test <-\n  last_fit(wf2_final, d_split)\n\ncollect_metrics(fit2_final_test)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.6831604\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.6561186\nPreprocessor1_Model1\n\n\n\n\n\n\n\n1.6.1 Vorhersage\n\n\n1.6.2 Vohersagedaten\nPfad zu den Daten:\n\ntweet_data_path <- \"/Users/sebastiansaueruser/github-repos/hate-speech/data/\"\n\n\ntweet_data_files_names <- list.files(path = tweet_data_path,\n                                     pattern  = \"tweets-to-.*\\\\.rds$\")\nhead(tweet_data_files_names)\n\n[1] \"tweets-to-_FriedrichMerz_2021.rds\" \"tweets-to-_FriedrichMerz_2022.rds\"\n[3] \"tweets-to-ABaerbock_2021.rds\"      \"tweets-to-ABaerbock_2022.rds\"     \n[5] \"tweets-to-Alice_Weidel_2021.rds\"   \"tweets-to-Alice_Weidel_2022.rds\"  \n\n\nWie viele Dateien sind es?\n\nlength(tweet_data_files_names)\n\n[1] 26\n\n\nWir geben den Elementen des Vektors g√§ngige Namen, das hilft uns gleich bei map:\n\nnames(tweet_data_files_names) <- str_remove(tweet_data_files_names, \"\\\\.rds\")\n\nOK, weiter: So k√∂nnen wir eine der Datendateien einlesen:\n\nd_raw <-\n  read_rds(file = paste0(tweet_data_path, tweet_data_files_names[1])) \n\nd <- \n  d_raw %>% \n  select(id, author_id, created_at, public_metrics) %>% \n  unnest_wider(public_metrics)\n\nhead(d)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nauthor_id\ncreated_at\nretweet_count\nreply_count\nlike_count\nquote_count\n\n\n\n\n1476992850944475136\n1270540287786565632\n2021-12-31T19:05:11.000Z\n0\n0\n0\n0\n\n\n1476982994556665862\n1471100575337140229\n2021-12-31T18:26:01.000Z\n0\n0\n0\n0\n\n\n1476958785977597958\n1438467230157602821\n2021-12-31T16:49:49.000Z\n0\n0\n0\n0\n\n\n1476637742884925447\n589112870\n2021-12-30T19:34:07.000Z\n0\n0\n0\n0\n\n\n1476587037046226949\n1041038433064562688\n2021-12-30T16:12:37.000Z\n0\n0\n0\n0\n\n\n1476534413802549249\n1425085042800406536\n2021-12-30T12:43:31.000Z\n10\n2\n44\n2\n\n\n\n\n\n\nUnd so lesen wir alle ein:\nZun√§chst erstellen wir uns eine Helper-Funktion:\n\nread_and_select <- function(file_name, path_to_tweet_data = tweet_data_path) {\n  \n  out <- \n    read_rds(file = paste0(path_to_tweet_data, file_name)) %>% \n    select(id, author_id, created_at, text, public_metrics) %>% \n    unnest_wider(public_metrics)\n  \n  cat(\"Data file was read.\\n\")\n  \n  return(out)\n}\n\nTesten:\n\nd1 <- read_and_select(tweet_data_files_names[1])\n\nhead(d1)\n\nDie Funktion read_and_select mappen wir auf alle Datendateien:\n\ntic()\nds <-\n  tweet_data_files_names %>% \n  map_dfr(read_and_select, .id = \"dataset\")\ntoc()\n\n214.531 sec elapsed\nDa wir den Elementen von tweet_data_files_names Namen gegeben haben, finden wir diese Namen praktischerweise wieder in ds:\n\n\n\n\n\n\n\nhead(ds)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndataset\nid\nauthor_id\ncreated_at\ntext\nretweet_count\nreply_count\nlike_count\nquote_count\n\n\n\n\ntweets-to-_FriedrichMerz_2021\n1476992850944475136\n1270540287786565632\n2021-12-31T19:05:11.000Z\n(_FriedrichMerz?) https://t.co/YR8HQh6TKT\n0\n0\n0\n0\n\n\ntweets-to-_FriedrichMerz_2021\n1476982994556665862\n1471100575337140229\n2021-12-31T18:26:01.000Z\n(_FriedrichMerz?) Ich freue mich auf eine neue, moderne und wiedererstarkte CDU unter F√ºhrung von Friedrich Merz. Bernd\n0\n0\n0\n0\n\n\ntweets-to-_FriedrichMerz_2021\n1476958785977597958\n1438467230157602821\n2021-12-31T16:49:49.000Z\n(_FriedrichMerz?)\n\n\n\n\n\n\n\n(Volker_Beck?) China is exploiting poor and neighboring countries either through aggression or debt trap. The expansion in the Chinese Navy is causing a psychological threat to these poor countries. #ChineseNavalExpansion #CCPGlobalThreat https://t.co/kHp5gu649x | 0| 0| 0| 0| |tweets-to-_FriedrichMerz_2021 |1476637742884925447 |589112870 |2021-12-30T19:34:07.000Z |(_FriedrichMerz?) Viele Mediziner werden den Sprung zum neuen Paradigma der menschlichen Gesundheit nie schaffen. Sie sind zu schwach und √§ngstlich und werden zur√ºckbleiben, sich gegenseitig bek√§mpfen und sich selbst zerst√∂ren. So wie sie es jetzt tun. https://t.co/Jsecipn1m4 | 0| 0| 0| 0| |tweets-to-_FriedrichMerz_2021 |1476587037046226949 |1041038433064562688 |2021-12-30T16:12:37.000Z |(_FriedrichMerz?) hat vielleicht eine Antwort. (Alice_Weidel?) hat sicher eine. https://t.co/mTcPCKYDek | 0| 0| 0| 0| |tweets-to-_FriedrichMerz_2021 |1476534413802549249 |1425085042800406536 |2021-12-30T12:43:31.000Z |(_FriedrichMerz?) + (c_lindner?) - warum trauen sich die Parteien der #Mitte in #D nicht, die Position des d√§nischen Innenministers (KaareDypvad?) ebenso deutlich auszusprechen!? Warum √ºberlassen wir #Migration #Ideologen statt dem vern√ºnftigen d√§nischen Vorbild zu folgen? #Asyl (welt?) https://t.co/tA2ERbM1qf | 10| 2| 44| 2|\n\n\n\nVielleicht ist es zum Entwickeln besser, mit einem kleineren Datensatz einstweilen zu arbeiten:\n\nds_short <- slice_sample(ds, prop = .05)\n\n\n\n\n\n\n1.6.3 Vokabular erstellen\n\nds_long <-\n  ds %>% \n  select(text) %>% \n  unnest_tweets(input = text, output = word)\n\nPuh, das hat gedauert!\nSpeichern wir uns diese Daten daher auf die Festplatte:\n\nwrite_rds(ds_long, file = paste0(tweet_data_path, \"ds_long.rds\"))\n\nEntfernen wir daraus die Duplikate, um uns ein Vokabular zu erstellen:\n\nds_voc <-\n  ds_long %>% \n  #slice_head(n = 10) %>% \n  distinct(word)\n\nUnd das resultierende Objekt speichern wir wieder ab:\n\nwrite_rds(ds_voc, file = paste0(tweet_data_path, \"ds_voc.rds\"))"
  },
  {
    "objectID": "klassifikation.html#worteinbettungen-erstellen",
    "href": "klassifikation.html#worteinbettungen-erstellen",
    "title": "1¬† Klassifikation von Hatespeech",
    "section": "1.7 Worteinbettungen erstellen",
    "text": "1.7 Worteinbettungen erstellen\n\n1.7.1 FastText-Modell\nDefiniere die Konstanten f√ºr das fastText-Modell:\n\ntexts <- ds %>% pull(text)\ntexts <- tolower(texts)\n\n\nout_file_txt <- \"/Users/sebastiansaueruser/datasets/Twitter/twitter-polit-model.vec\"\nout_file_model <- \"/Users/sebastiansaueruser/datasets/Twitter/twitter-polit-model.bin\"\n\n\nwriteLines(text = texts, con = out_file_txt)\nexecute(commands = c(\"skipgram\", \"-input\", tmp_file_txt, \"-output\", out_file_model, \"-verbose\", 1))\n\nRead 22M words\nNumber of words:  130328\nNumber of labels: 0\nProgress: 100.0% words/sec/thread:   49218 lr:  0.000000 avg.loss:  1.720812 ETA:   0h 0m 0s\nJetzt laden wir das Modell von der Festplatte:\n\ntwitter_fasttext_model <- load_model(out_file_model)\ndict <- get_dictionary(twitter_fasttext_model)\n\nSchauen wir uns einige Begriffe aus dem Vokabular an:\n\nprint(head(dict, 10))\n\n [1] \"</s>\"            \"die\"             \"und\"             \"der\"            \n [5] \"sie\"             \"das\"             \"nicht\"           \"in\"             \n [9] \"ist\"             \"@_friedrichmerz\"\n\n\nHier sind die ersten paar Elemente des Vektors f√ºr menschen:\n\nget_word_vectors(twitter_fasttext_model, c(\"menschen\")) %>% `[`(1:10)\n\n [1]  0.14156282  0.44875699  0.23911817 -0.02580349  0.29811972  0.03870077\n [7]  0.06518744  0.22527063  0.28198120  0.39931887\nErstellen wir uns einen Tibble, der als erste Spalte das Vokabular und in den √ºbrigen 100 Spalten die Dimensionen enth√§lt:\n\nword_embedding_twitter <-\n  tibble(\n    word = dict\n  )\n\n\nwords_vecs_twitter <-\n  get_word_vectors(twitter_fasttext_model)\n\n\nword_embedding_twitter <-\n  word_embedding_twitter %>% \n  bind_cols(words_vecs_twitter)\n\nnames(word_embedding_twitter) <- c(\"word\", paste0(\"v\", sprintf(\"%03d\", 1:100)))  # Namen versch√∂nern\n\nUnd als Worteinbettungs-Datei abspeichern:\n\nwrite_rds(word_embedding_twitter, file = paste0(tweet_data_path, \"word_embedding_twitter.rds\"))\n\n\n\n\n\n\n1.7.2 Aufbereiten\nAm besten nur die Spalten behalten, die wir zum Modellieren nutzen:\n\nds_short2 <-\n  ds_short %>% \n  select(text, id)\n\nDann backen wir die Daten mit dem vorhandenen Rezept:\n\nds_baked <- bake(rec1_prepped, new_data = ds_short2)\n\nhead(ds_baked)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntfidf_text__macmik\ntfidf_text_2\ntfidf_text_ab\ntfidf_text_afd\ntfidf_text_amp\ntfidf_text_anna_iina\ntfidf_text_antisemitismu\ntfidf_text_athinamala\ntfidf_text_besser\ntfidf_text_bild\ntfidf_text_cdu\ntfidf_text_charlie_silv\ntfidf_text_csu\ntfidf_text_d\ntfidf_text_daf√ºr\ntfidf_text_dank\ntfidf_text_dass\ntfidf_text_deutsch\ntfidf_text_deutschen\ntfidf_text_deutschland\ntfidf_text_dumm\ntfidf_text_einfach\ntfidf_text_ellibisathid\ntfidf_text_endlich\ntfidf_text_ennof_\ntfidf_text_erst\ntfidf_text_eu\ntfidf_text_europa\ntfidf_text_fdp\ntfidf_text_feldenfrizz\ntfidf_text_focusonlin\ntfidf_text_frage\ntfidf_text_frau\ntfidf_text_ganz\ntfidf_text_geht\ntfidf_text_gerad\ntfidf_text_gibt\ntfidf_text_gr√ºnen\ntfidf_text_gt\ntfidf_text_gut\ntfidf_text_h√§tte\ntfidf_text_heut\ntfidf_text_immer\ntfidf_text_info2099\ntfidf_text_islam\ntfidf_text_israel\ntfidf_text_ja\ntfidf_text_jahr\ntfidf_text_juden\ntfidf_text_kommt\ntfidf_text_krippmari\ntfidf_text_land\ntfidf_text_lassen\ntfidf_text_lbr\ntfidf_text_lifetrend\ntfidf_text_link\ntfidf_text_macht\ntfidf_text_machtjanix23\ntfidf_text_mal\ntfidf_text_md_franz\ntfidf_text_mehr\ntfidf_text_menschen\ntfidf_text_merkel\ntfidf_text_miriamozen\ntfidf_text_moslem\ntfidf_text_m√ºssen\ntfidf_text_nancypeggymandi\ntfidf_text_nasanas\ntfidf_text_noherrman\ntfidf_text_norbinator2403\ntfidf_text_partei\ntfidf_text_petpanther0\ntfidf_text_politik\ntfidf_text_recht\ntfidf_text_richtig\ntfidf_text_sagt\ntfidf_text_schmiddiemaik\ntfidf_text_schon\ntfidf_text_schulz\ntfidf_text_seit\ntfidf_text_sicher\ntfidf_text_spd\ntfidf_text_tagesschau\ntfidf_text_thomasgbau\ntfidf_text_troll_putin\ntfidf_text_trump\ntfidf_text_tun\ntfidf_text_t√ºrken\ntfidf_text_u\ntfidf_text_unser\ntfidf_text_viel\ntfidf_text_volk\ntfidf_text_w√§re\ntfidf_text_warum\ntfidf_text_welt\ntfidf_text_wer\ntfidf_text_willjrosenblatt\ntfidf_text_wohl\ntfidf_text_wurd\ntfidf_text_zeit\n\n\n\n\n1586768624320135168\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n6.8580253\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n3.5879501\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n4.4080594\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n1583554257470357504\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n17.0144371\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n1583140717236391936\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n6.4682819\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n4.8888601\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n1418452119460454404\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n1585276821565759489\n-0.1472962\n-0.1025123\n-0.1045303\n-0.1545404\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n-0.1116953\n-0.4023143\n-0.1445296\n-0.1052941\n7.0164922\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n4.7406218\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n1441493674437664775\n-0.1472962\n-0.1025123\n-0.1045303\n6.1558148\n-0.1196412\n-0.1016498\n-0.0827688\n-0.1412023\n-0.0994077\n-0.1000636\n-0.1061901\n-0.1450561\n-0.0881935\n-0.1365693\n-0.0938978\n-0.1176754\n-0.1911377\n-0.1543987\n-0.1519219\n-0.1996601\n-0.1040022\n-0.1195335\n-0.1473094\n-0.0995996\n-0.1182767\n-0.1107598\n-0.111993\n-0.1066217\n-0.0974439\n-0.1472962\n-0.0985444\n-0.0967565\n-0.0949119\n-0.1145095\n-0.1429535\n-0.108501\n-0.1648097\n-0.1039788\n-0.0926214\n-0.126624\n-0.0955942\n-0.1650169\n-0.1623571\n-0.0804698\n-0.1036414\n-0.0836286\n-0.175643\n-0.0937953\n-0.0974094\n-0.0961735\n-0.1455853\n-0.1441996\n6.8580253\n-0.4023143\n-0.1445296\n-0.1052941\n-0.1245217\n-0.1088789\n-0.1709422\n-0.1082684\n-0.1829629\n-0.1167916\n-0.2184447\n-0.0966546\n-0.0942649\n-0.1315249\n-0.1182767\n-0.1096851\n-0.090148\n-0.0631584\n-0.0922659\n-0.0922453\n-0.1476062\n-0.1162279\n-0.0976874\n-0.0964543\n-0.1435878\n-0.2044771\n-0.1013316\n-0.1270926\n-0.0937495\n-0.1342917\n-0.1043247\n-0.1473094\n-0.1211889\n-0.1009074\n-0.1080669\n-0.1045075\n-0.150687\n-0.1585372\n-0.0998685\n-0.1090701\n-0.1112479\n-0.103608\n-0.1466292\n-0.1567758\n-0.1435878\n-0.1091472\n-0.1136727\n-0.1001727\n\n\n\n\n\n\nIst das nicht komfortabel? Das Textrezept √ºbernimmt die Arbeit f√ºr uns, mit den richtigen Features zu arbeiten, die tf-idfs f√ºr die richtigen Tokens zu berechnen.\nWer dem Frieden nicht traut, dem sei geraten, nachzupr√ºfen :-)"
  },
  {
    "objectID": "klassifikation.html#workflow-3-rezept-2-lasso",
    "href": "klassifikation.html#workflow-3-rezept-2-lasso",
    "title": "1¬† Klassifikation von Hatespeech",
    "section": "1.8 Workflow 3: Rezept 2 + Lasso",
    "text": "1.8 Workflow 3: Rezept 2 + Lasso\n\n1.8.1 Daten aufteilen\n\nd_split <- initial_split(d2, strata = c1)\n\nd_train <- training(d_split)\nd_test <- testing(d_split)\n\n\n\n1.8.2 Hilfsfunktionen\n\ndummy <- c(\"hallo\", \"baby\", \"fatal\")\n\n\ncount_profane <- function(text) {\n  sum((tokenize_tweets(text, simplify = TRUE) %>% simplify()) %in% schimpf$word)\n}\n\ncount_profane(dummy) \n\n[1] 1\n\n\n\ncount_emo_words <- function(text) {\n  sum((tokenize_tweets(text, simplify = TRUE) %>% simplify()) %in% sentiws$word)\n}\n\ncount_emo_words(dummy)\n\n[1] 1\n\n\n\ncount_emojis <- function(text){\n  sum((tokenize_tweets(text, simplify = TRUE) %>% simplify()) %in% trimws(emj))\n}\n\ndummy <- c(\"baby\", \"und\", \"üÜó\", \"üñï\")\n\ncount_emojis(dummy)\n\n[1] 1\n\n\n\ncount_wild_emojis <- function(text){\n  sum((tokenize_tweets(text, simplify = TRUE) %>% simplify()) %in% wild_emojis)\n}\n\ncount_wild_emojis(dummy) \n\n[1] 1\n\n\n\n\n1.8.3 Rezept mit Worteinbettungen\n\nrec2 <- \n  recipe(c1 ~ ., data = select(d_train, text, c1, id)) %>% \n  update_role(id, new_role = \"id\") %>% \n  step_text_normalization(text) %>% \n  step_mutate(text_copy = text,\n              profane_n = map_int(text, count_profane),\n              emo_words_n = map_int(text, count_emo_words),\n              emojis_n = map_int(text, count_emojis),\n              wild_emojis_n = map_int(text, count_wild_emojis)\n  ) %>% \n  step_textfeature(text_copy) %>% \n  step_tokenize(text, token = \"tweets\") %>% \n  step_stopwords(text, language = \"de\", stopword_source = \"snowball\") %>% \n  step_word_embeddings(text, embeddings = word_embedding_twitter)\n \nrec2\n\nRecipe\n\nInputs:\n\n      role #variables\n        id          1\n   outcome          1\n predictor          1\n\nOperations:\n\nText Normalization for text\nVariable mutation for text, map_int(text, count_profane), map_in...\nText feature extraction for text_copy\nTokenization for text\nStop word removal for text\nWord embeddings aggregated from text\n\n\n\nrec2_prepped <- prep(rec2)\nrec2_baked <- bake(rec2_prepped, new_data = NULL)\n\n\nrec2_baked %>% \n  select(1:15) %>% \n  glimpse()\n\nRows: 3,756\nColumns: 15\n$ id                                  <int> 5, 7, 9, 10, 17, 42, 44, 48, 53, 5‚Ä¶\n$ c1                                  <fct> OFFENSE, OFFENSE, OFFENSE, OFFENSE‚Ä¶\n$ profane_n                           <int> 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1‚Ä¶\n$ emo_words_n                         <int> 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0‚Ä¶\n$ emojis_n                            <int> 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 2‚Ä¶\n$ wild_emojis_n                       <int> 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n$ textfeature_text_copy_n_words       <int> 16, 32, 12, 15, 19, 30, 31, 6, 24,‚Ä¶\n$ textfeature_text_copy_n_uq_words    <int> 16, 28, 12, 15, 17, 29, 29, 6, 23,‚Ä¶\n$ textfeature_text_copy_n_charS       <int> 121, 145, 66, 119, 112, 171, 170, ‚Ä¶\n$ textfeature_text_copy_n_uq_charS    <int> 31, 29, 29, 30, 36, 42, 35, 23, 30‚Ä¶\n$ textfeature_text_copy_n_digits      <int> 0, 4, 0, 0, 4, 0, 1, 0, 2, 0, 2, 0‚Ä¶\n$ textfeature_text_copy_n_hashtags    <int> 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0‚Ä¶\n$ textfeature_text_copy_n_uq_hashtags <int> 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3, 0‚Ä¶\n$ textfeature_text_copy_n_mentions    <int> 1, 1, 1, 0, 0, 5, 1, 0, 1, 1, 0, 2‚Ä¶\n$ textfeature_text_copy_n_uq_mentions <int> 1, 1, 1, 0, 0, 5, 1, 0, 1, 1, 0, 2‚Ä¶\n\n\n\n\n1.8.4 Fitting 3\n\nwf3 <-\n  workflow() %>% \n  add_recipe(rec2) %>% \n  add_model(lasso_spec)\n\nwf3\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: logistic_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n6 Recipe Steps\n\n‚Ä¢ step_text_normalization()\n‚Ä¢ step_mutate()\n‚Ä¢ step_textfeature()\n‚Ä¢ step_tokenize()\n‚Ä¢ step_stopwords()\n‚Ä¢ step_word_embeddings()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n\nTunen und Fitten:\n\nset.seed(42)\n\ntic()\nfit3 <-\n  tune_grid(\n    wf3,\n    folds1,\n    grid = lambda_grid,\n    control = control_resamples(save_pred = TRUE)\n  )\n(toc)\nfit3\n\n\nwrite_rds(fit3, \"objects/chap_classific_fit3.rds\")\n\n\n\n\nHier ist die Performanz:\n\ncollect_metrics(fit3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model01\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model01\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model02\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model02\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model03\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model03\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model04\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model04\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model05\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model05\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model06\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model06\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model07\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model07\n\n\n0.0000000\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model08\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model08\n\n\n0.0000001\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model09\n\n\n0.0000001\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model09\n\n\n0.0000001\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model10\n\n\n0.0000001\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model10\n\n\n0.0000003\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model11\n\n\n0.0000003\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model11\n\n\n0.0000006\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model12\n\n\n0.0000006\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model12\n\n\n0.0000014\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model13\n\n\n0.0000014\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model13\n\n\n0.0000030\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model14\n\n\n0.0000030\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model14\n\n\n0.0000067\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model15\n\n\n0.0000067\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model15\n\n\n0.0000149\naccuracy\nbinary\n0.7670305\n10\n0.0063002\nPreprocessor1_Model16\n\n\n0.0000149\nroc_auc\nbinary\n0.8095845\n10\n0.0096008\nPreprocessor1_Model16\n\n\n0.0000329\naccuracy\nbinary\n0.7667645\n10\n0.0061340\nPreprocessor1_Model17\n\n\n0.0000329\nroc_auc\nbinary\n0.8095282\n10\n0.0095826\nPreprocessor1_Model17\n\n\n0.0000728\naccuracy\nbinary\n0.7667645\n10\n0.0061340\nPreprocessor1_Model18\n\n\n0.0000728\nroc_auc\nbinary\n0.8095638\n10\n0.0095511\nPreprocessor1_Model18\n\n\n0.0001610\naccuracy\nbinary\n0.7662333\n10\n0.0057794\nPreprocessor1_Model19\n\n\n0.0001610\nroc_auc\nbinary\n0.8099159\n10\n0.0094448\nPreprocessor1_Model19\n\n\n0.0003562\naccuracy\nbinary\n0.7654348\n10\n0.0063700\nPreprocessor1_Model20\n\n\n0.0003562\nroc_auc\nbinary\n0.8103737\n10\n0.0092381\nPreprocessor1_Model20\n\n\n0.0007880\naccuracy\nbinary\n0.7664993\n10\n0.0062776\nPreprocessor1_Model21\n\n\n0.0007880\nroc_auc\nbinary\n0.8111630\n10\n0.0089414\nPreprocessor1_Model21\n\n\n0.0017433\naccuracy\nbinary\n0.7670333\n10\n0.0066734\nPreprocessor1_Model22\n\n\n0.0017433\nroc_auc\nbinary\n0.8116297\n10\n0.0087106\nPreprocessor1_Model22\n\n\n0.0038566\naccuracy\nbinary\n0.7646319\n10\n0.0069158\nPreprocessor1_Model23\n\n\n0.0038566\nroc_auc\nbinary\n0.8093719\n10\n0.0079992\nPreprocessor1_Model23\n\n\n0.0085317\naccuracy\nbinary\n0.7553156\n10\n0.0061916\nPreprocessor1_Model24\n\n\n0.0085317\nroc_auc\nbinary\n0.8032327\n10\n0.0073114\nPreprocessor1_Model24\n\n\n0.0188739\naccuracy\nbinary\n0.7308227\n10\n0.0069456\nPreprocessor1_Model25\n\n\n0.0188739\nroc_auc\nbinary\n0.7830419\n10\n0.0087585\nPreprocessor1_Model25\n\n\n0.0417532\naccuracy\nbinary\n0.6996695\n10\n0.0085704\nPreprocessor1_Model26\n\n\n0.0417532\nroc_auc\nbinary\n0.7537161\n10\n0.0090227\nPreprocessor1_Model26\n\n\n0.0923671\naccuracy\nbinary\n0.6629305\n10\n0.0054329\nPreprocessor1_Model27\n\n\n0.0923671\nroc_auc\nbinary\n0.6848928\n10\n0.0102870\nPreprocessor1_Model27\n\n\n0.2043360\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model28\n\n\n0.2043360\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model28\n\n\n0.4520354\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model29\n\n\n0.4520354\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model29\n\n\n1.0000000\naccuracy\nbinary\n0.6629305\n10\n0.0053307\nPreprocessor1_Model30\n\n\n1.0000000\nroc_auc\nbinary\n0.5000000\n10\n0.0000000\nPreprocessor1_Model30\n\n\n\n\n\n\n\nautoplot(fit3)\n\n\n\n\n\nfit3 %>% \n  show_best(\"roc_auc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npenalty\n.metric\n.estimator\nmean\nn\nstd_err\n.config\n\n\n\n\n0.0017433\nroc_auc\nbinary\n0.8116297\n10\n0.0087106\nPreprocessor1_Model22\n\n\n0.0007880\nroc_auc\nbinary\n0.8111630\n10\n0.0089414\nPreprocessor1_Model21\n\n\n0.0003562\nroc_auc\nbinary\n0.8103737\n10\n0.0092381\nPreprocessor1_Model20\n\n\n0.0001610\nroc_auc\nbinary\n0.8099159\n10\n0.0094448\nPreprocessor1_Model19\n\n\n0.0000000\nroc_auc\nbinary\n0.8095907\n10\n0.0096029\nPreprocessor1_Model01\n\n\n\n\n\n\n\nchosen_auc_fit3 <- \n  fit3 %>%\n  select_by_one_std_err(metric = \"roc_auc\", -penalty)\n\nFinalisieren:\n\nwf3_final <-\n  finalize_workflow(wf3, chosen_auc_fit3)\n\nwf3_final\n\n‚ïê‚ïê Workflow ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\nPreprocessor: Recipe\nModel: logistic_reg()\n\n‚îÄ‚îÄ Preprocessor ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n6 Recipe Steps\n\n‚Ä¢ step_text_normalization()\n‚Ä¢ step_mutate()\n‚Ä¢ step_textfeature()\n‚Ä¢ step_tokenize()\n‚Ä¢ step_stopwords()\n‚Ä¢ step_word_embeddings()\n\n‚îÄ‚îÄ Model ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nLogistic Regression Model Specification (classification)\n\nMain Arguments:\n  penalty = 0.00853167852417281\n  mixture = 1\n\nComputational engine: glmnet \n\n\n\nfit3_final_train <-\n  fit(wf3_final, d_train)\n\n\nfit3_final_train %>% \n  extract_fit_parsnip() %>% \n  tidy() %>% \n  arrange(-abs(estimate)) %>% \n  head()\n\n\n\n\n\nterm\nestimate\npenalty\n\n\n\n\n(Intercept)\n1.2325023\n0.0085317\n\n\nprofane_n\n-0.5899329\n0.0085317\n\n\ntextfeature_text_copy_n_exclaims\n-0.1987554\n0.0085317\n\n\nwordembed_text_v055\n0.1799862\n0.0085317\n\n\nwordembed_text_v059\n-0.1465378\n0.0085317\n\n\nwordembed_text_v054\n0.1455451\n0.0085317\n\n\n\n\n\n\n\nfit3_final_test <-\n  last_fit(wf3_final, d_split)\n\ncollect_metrics(fit3_final_test)\n\n\n\n\n\n.metric\n.estimator\n.estimate\n.config\n\n\n\n\naccuracy\nbinary\n0.7533919\nPreprocessor1_Model1\n\n\nroc_auc\nbinary\n0.7871291\nPreprocessor1_Model1\n\n\n\n\n\n\nAm Ende so eines Arbeitsganges, bei dem man wieder (und wieder) die gleichen Funktionen kopiert, und nur aufpassen muss, aus fit2 an der richtigen Stelle fit3 zu machen: Da blickt man jedem Umbau dieses Codes zu einer Funktion freudig ins Gesicht.\nEin anderes Problem, f√ºr das hier keine elegante L√∂sung vorliegt, sind die langen Berechnungszeiten, die, wenn man Pecht hat, auch noch mehrfach wiederholt werden m√ºssen.\nZu diesen Punkten sp√§ter mehr.\n\n\n\n\nRemus, Robert, Uwe Quasthoff, und Gerhard Heyer. 2010. ‚ÄûSentiWS - a Publicly Available German-language Resource for Sentiment Analysis‚Äú. Proceedings of the 7th International Language Ressources and Evaluation (LREC‚Äô10), 1168‚Äì71.\n\n\nWiegand, Michael. 2019a. ‚ÄûGermEval-2018 Corpus (DE)‚Äú. heiDATA. https://doi.org/10.11588/DATA/0B5VML.\n\n\n‚Äî‚Äî‚Äî. 2019b. ‚ÄûGermEval-2018-Data-master‚Äú. In GermEval-2018 corpus (DE). heiDATA. https://doi.org/10.11588/data/0B5VML/XIUWJ7."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Hvitfeldt, Emil, and Julia Silge. 2022. Supervised Machine Learning\nfor Text Analysis in r. 1st ed. Boca Raton: Chapman;\nHall/CRC. https://doi.org/10.1201/9781003093459.\n\n\nRemus, Robert, Uwe Quasthoff, and Gerhard Heyer. 2010.\n‚ÄúSentiWS - a Publicly Available German-Language\nResource for Sentiment Analysis.‚Äù Proceedings of the 7th\nInternational Language Ressources and Evaluation\n(LREC‚Äô10), 1168‚Äì71.\n\n\nWiegand, Michael. 2019a. ‚ÄúGermEval-2018 Corpus\n(DE).‚Äù heiDATA. https://doi.org/10.11588/DATA/0B5VML.\n\n\n‚Äî‚Äî‚Äî. 2019b. ‚ÄúGermEval-2018-Data-Master.‚Äù In\nGermEval-2018 Corpus (DE).\nheiDATA. https://doi.org/10.11588/data/0B5VML/XIUWJ7."
  }
]